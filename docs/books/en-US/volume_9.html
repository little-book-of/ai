<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.23">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Volume 9. Unsupervised, self-supervised and representation – The Little Book of Artificial Intelligence</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../books/en-US/volume_8.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-1fe81d0376b2c50856e68e651e390326.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-27c261d06b905028a18691de25d09dde.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../books/en-US/volume_9.html"><span class="chapter-title">Volume 9. Unsupervised, self-supervised and representation</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../../index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">The Little Book of Artificial Intelligence</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Contents</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../books/en-US/volume_1.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Volume 1. First principles of Artificial Intelligence</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../books/en-US/volume_2.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Volume 2. Mathematicial Foundations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../books/en-US/volume_3.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Volume 3. Data and Representation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../books/en-US/volume_4.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Volume 4. Search and Planning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../books/en-US/volume_5.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Volume 5. Logic and Knowledge</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../books/en-US/volume_6.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Volume 6. Probabilistic Modeling and Inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../books/en-US/volume_7.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Volume 7. Machine Learning Theory and Practice</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../books/en-US/volume_8.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Volume 8. Supervised Learning Systems</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../books/en-US/volume_9.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Volume 9. Unsupervised, self-supervised and representation</span></a>
  </div>
</li>
    </ul>
    </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#chapter-81.-clustering-k-means-hierarchical-dbscan" id="toc-chapter-81.-clustering-k-means-hierarchical-dbscan" class="nav-link active" data-scroll-target="#chapter-81.-clustering-k-means-hierarchical-dbscan">Chapter 81. Clustering (k-means, hierarchical, DBSCAN)</a>
  <ul class="collapse">
  <li><a href="#introduction-to-clustering" id="toc-introduction-to-clustering" class="nav-link" data-scroll-target="#introduction-to-clustering">801. Introduction to Clustering</a></li>
  <li><a href="#similarity-and-distance-metrics" id="toc-similarity-and-distance-metrics" class="nav-link" data-scroll-target="#similarity-and-distance-metrics">802. Similarity and Distance Metrics</a></li>
  <li><a href="#k-means-objective-and-iterative-refinement" id="toc-k-means-objective-and-iterative-refinement" class="nav-link" data-scroll-target="#k-means-objective-and-iterative-refinement">803. k-Means: Objective and Iterative Refinement</a></li>
  <li><a href="#variants-of-k-means-mini-batch-k-medoids" id="toc-variants-of-k-means-mini-batch-k-medoids" class="nav-link" data-scroll-target="#variants-of-k-means-mini-batch-k-medoids">804. Variants of k-Means (Mini-Batch, k-Medoids)</a></li>
  <li><a href="#hierarchical-clustering-agglomerative-vs.-divisive" id="toc-hierarchical-clustering-agglomerative-vs.-divisive" class="nav-link" data-scroll-target="#hierarchical-clustering-agglomerative-vs.-divisive">805. Hierarchical Clustering: Agglomerative vs.&nbsp;Divisive</a></li>
  <li><a href="#linkage-criteria-single-complete-average-ward" id="toc-linkage-criteria-single-complete-average-ward" class="nav-link" data-scroll-target="#linkage-criteria-single-complete-average-ward">806. Linkage Criteria (Single, Complete, Average, Ward)</a></li>
  <li><a href="#density-based-methods-dbscan-and-hdbscan" id="toc-density-based-methods-dbscan-and-hdbscan" class="nav-link" data-scroll-target="#density-based-methods-dbscan-and-hdbscan">807. Density-Based Methods: DBSCAN and HDBSCAN</a></li>
  <li><a href="#cluster-evaluation-metrics-silhouette-daviesbouldin" id="toc-cluster-evaluation-metrics-silhouette-daviesbouldin" class="nav-link" data-scroll-target="#cluster-evaluation-metrics-silhouette-daviesbouldin">808. Cluster Evaluation Metrics (Silhouette, Davies–Bouldin)</a></li>
  <li><a href="#scalability-and-approximate-clustering-methods" id="toc-scalability-and-approximate-clustering-methods" class="nav-link" data-scroll-target="#scalability-and-approximate-clustering-methods">809. Scalability and Approximate Clustering Methods</a></li>
  <li><a href="#applications-and-case-studies-in-clustering" id="toc-applications-and-case-studies-in-clustering" class="nav-link" data-scroll-target="#applications-and-case-studies-in-clustering">810. Applications and Case Studies in Clustering</a></li>
  </ul></li>
  <li><a href="#chapter-82.-density-estimation-and-mixture-models" id="toc-chapter-82.-density-estimation-and-mixture-models" class="nav-link" data-scroll-target="#chapter-82.-density-estimation-and-mixture-models">Chapter 82. Density estimation and mixture models</a>
  <ul class="collapse">
  <li><a href="#basics-of-density-estimation" id="toc-basics-of-density-estimation" class="nav-link" data-scroll-target="#basics-of-density-estimation">811. Basics of Density Estimation</a></li>
  <li><a href="#histograms-and-kernel-density-estimation" id="toc-histograms-and-kernel-density-estimation" class="nav-link" data-scroll-target="#histograms-and-kernel-density-estimation">812. Histograms and Kernel Density Estimation</a></li>
  <li><a href="#parametric-vs.-non-parametric-density-estimation" id="toc-parametric-vs.-non-parametric-density-estimation" class="nav-link" data-scroll-target="#parametric-vs.-non-parametric-density-estimation">813. Parametric vs.&nbsp;Non-Parametric Density Estimation</a></li>
  <li><a href="#gaussian-mixture-models-gmms" id="toc-gaussian-mixture-models-gmms" class="nav-link" data-scroll-target="#gaussian-mixture-models-gmms">814. Gaussian Mixture Models (GMMs)</a></li>
  <li><a href="#expectation-maximization-for-mixtures" id="toc-expectation-maximization-for-mixtures" class="nav-link" data-scroll-target="#expectation-maximization-for-mixtures">815. Expectation-Maximization for Mixtures</a></li>
  <li><a href="#identifiability-and-model-selection-bic-aic" id="toc-identifiability-and-model-selection-bic-aic" class="nav-link" data-scroll-target="#identifiability-and-model-selection-bic-aic">816. Identifiability and Model Selection (BIC, AIC)</a></li>
  <li><a href="#bayesian-mixture-models-and-dirichlet-processes" id="toc-bayesian-mixture-models-and-dirichlet-processes" class="nav-link" data-scroll-target="#bayesian-mixture-models-and-dirichlet-processes">817. Bayesian Mixture Models and Dirichlet Processes</a></li>
  <li><a href="#copulas-and-multivariate-densities" id="toc-copulas-and-multivariate-densities" class="nav-link" data-scroll-target="#copulas-and-multivariate-densities">818. Copulas and Multivariate Densities</a></li>
  <li><a href="#density-estimation-in-high-dimensions" id="toc-density-estimation-in-high-dimensions" class="nav-link" data-scroll-target="#density-estimation-in-high-dimensions">819. Density Estimation in High Dimensions</a></li>
  <li><a href="#applications-of-density-estimation" id="toc-applications-of-density-estimation" class="nav-link" data-scroll-target="#applications-of-density-estimation">820. Applications of Density Estimation</a></li>
  </ul></li>
  <li><a href="#chapter-83.-matrix-factorization-and-nmf" id="toc-chapter-83.-matrix-factorization-and-nmf" class="nav-link" data-scroll-target="#chapter-83.-matrix-factorization-and-nmf">Chapter 83. Matrix factorization and NMF</a>
  <ul class="collapse">
  <li><a href="#motivation-for-matrix-factorization" id="toc-motivation-for-matrix-factorization" class="nav-link" data-scroll-target="#motivation-for-matrix-factorization">821. Motivation for Matrix Factorization</a></li>
  <li><a href="#singular-value-decomposition-svd" id="toc-singular-value-decomposition-svd" class="nav-link" data-scroll-target="#singular-value-decomposition-svd">822. Singular Value Decomposition (SVD)</a></li>
  <li><a href="#low-rank-approximations" id="toc-low-rank-approximations" class="nav-link" data-scroll-target="#low-rank-approximations">823. Low-Rank Approximations</a></li>
  <li><a href="#non-negative-matrix-factorization-nmf" id="toc-non-negative-matrix-factorization-nmf" class="nav-link" data-scroll-target="#non-negative-matrix-factorization-nmf">824. Non-Negative Matrix Factorization (NMF)</a></li>
  <li><a href="#probabilistic-matrix-factorization-pmf" id="toc-probabilistic-matrix-factorization-pmf" class="nav-link" data-scroll-target="#probabilistic-matrix-factorization-pmf">825. Probabilistic Matrix Factorization (PMF)</a></li>
  <li><a href="#alternating-least-squares-and-gradient-methods" id="toc-alternating-least-squares-and-gradient-methods" class="nav-link" data-scroll-target="#alternating-least-squares-and-gradient-methods">826. Alternating Least Squares and Gradient Methods</a></li>
  <li><a href="#regularization-in-factorization" id="toc-regularization-in-factorization" class="nav-link" data-scroll-target="#regularization-in-factorization">827. Regularization in Factorization</a></li>
  <li><a href="#interpretability-of-factorized-components" id="toc-interpretability-of-factorized-components" class="nav-link" data-scroll-target="#interpretability-of-factorized-components">828. Interpretability of Factorized Components</a></li>
  <li><a href="#matrix-factorization-for-recommender-systems" id="toc-matrix-factorization-for-recommender-systems" class="nav-link" data-scroll-target="#matrix-factorization-for-recommender-systems">829. Matrix Factorization for Recommender Systems</a></li>
  <li><a href="#beyond-matrices-tensor-factorization" id="toc-beyond-matrices-tensor-factorization" class="nav-link" data-scroll-target="#beyond-matrices-tensor-factorization">830. Beyond Matrices: Tensor Factorization</a></li>
  </ul></li>
  <li><a href="#chapter-84.-dimensionality-reduction-pcal-sne-umap" id="toc-chapter-84.-dimensionality-reduction-pcal-sne-umap" class="nav-link" data-scroll-target="#chapter-84.-dimensionality-reduction-pcal-sne-umap">Chapter 84. Dimensionality reduction (PCA,l-SNE, UMAP)</a>
  <ul class="collapse">
  <li><a href="#motivation-for-dimensionality-reduction" id="toc-motivation-for-dimensionality-reduction" class="nav-link" data-scroll-target="#motivation-for-dimensionality-reduction">831. Motivation for Dimensionality Reduction</a></li>
  <li><a href="#principal-component-analysis-pca-basics" id="toc-principal-component-analysis-pca-basics" class="nav-link" data-scroll-target="#principal-component-analysis-pca-basics">832. Principal Component Analysis (PCA) Basics</a></li>
  <li><a href="#eigen-decomposition-and-svd-connections" id="toc-eigen-decomposition-and-svd-connections" class="nav-link" data-scroll-target="#eigen-decomposition-and-svd-connections">833. Eigen-Decomposition and SVD Connections</a></li>
  <li><a href="#linear-vs.-nonlinear-reduction" id="toc-linear-vs.-nonlinear-reduction" class="nav-link" data-scroll-target="#linear-vs.-nonlinear-reduction">834. Linear vs.&nbsp;Nonlinear Reduction</a></li>
  <li><a href="#t-sne-intuition-and-mechanics" id="toc-t-sne-intuition-and-mechanics" class="nav-link" data-scroll-target="#t-sne-intuition-and-mechanics">835. t-SNE: Intuition and Mechanics</a></li>
  <li><a href="#umap-topological-and-graph-based-approach" id="toc-umap-topological-and-graph-based-approach" class="nav-link" data-scroll-target="#umap-topological-and-graph-based-approach">836. UMAP: Topological and Graph-Based Approach</a></li>
  <li><a href="#tradeoffs-interpretability-vs.-expressiveness" id="toc-tradeoffs-interpretability-vs.-expressiveness" class="nav-link" data-scroll-target="#tradeoffs-interpretability-vs.-expressiveness">837. Tradeoffs: Interpretability vs.&nbsp;Expressiveness</a></li>
  <li><a href="#evaluation-and-visualization-of-low-dim-spaces" id="toc-evaluation-and-visualization-of-low-dim-spaces" class="nav-link" data-scroll-target="#evaluation-and-visualization-of-low-dim-spaces">838. Evaluation and Visualization of Low-Dim Spaces</a></li>
  <li><a href="#dimensionality-reduction-in-large-scale-systems" id="toc-dimensionality-reduction-in-large-scale-systems" class="nav-link" data-scroll-target="#dimensionality-reduction-in-large-scale-systems">839. Dimensionality Reduction in Large-Scale Systems</a></li>
  <li><a href="#case-studies-in-representation-learning" id="toc-case-studies-in-representation-learning" class="nav-link" data-scroll-target="#case-studies-in-representation-learning">840. Case Studies in Representation Learning</a></li>
  </ul></li>
  <li><a href="#chapter-85.-manifold-learning-and-topological-methods" id="toc-chapter-85.-manifold-learning-and-topological-methods" class="nav-link" data-scroll-target="#chapter-85.-manifold-learning-and-topological-methods">Chapter 85. Manifold learning and topological methods</a>
  <ul class="collapse">
  <li><a href="#manifold-hypothesis-in-machine-learning" id="toc-manifold-hypothesis-in-machine-learning" class="nav-link" data-scroll-target="#manifold-hypothesis-in-machine-learning">841. Manifold Hypothesis in Machine Learning</a></li>
  <li><a href="#isomap-and-geodesic-distances" id="toc-isomap-and-geodesic-distances" class="nav-link" data-scroll-target="#isomap-and-geodesic-distances">842. Isomap and Geodesic Distances</a></li>
  <li><a href="#locally-linear-embedding-lle" id="toc-locally-linear-embedding-lle" class="nav-link" data-scroll-target="#locally-linear-embedding-lle">843. Locally Linear Embedding (LLE)</a></li>
  <li><a href="#laplacian-eigenmaps-and-spectral-embedding" id="toc-laplacian-eigenmaps-and-spectral-embedding" class="nav-link" data-scroll-target="#laplacian-eigenmaps-and-spectral-embedding">844. Laplacian Eigenmaps and Spectral Embedding</a></li>
  <li><a href="#diffusion-maps-and-dynamics" id="toc-diffusion-maps-and-dynamics" class="nav-link" data-scroll-target="#diffusion-maps-and-dynamics">845. Diffusion Maps and Dynamics</a></li>
  <li><a href="#persistent-homology-and-topological-data-analysis" id="toc-persistent-homology-and-topological-data-analysis" class="nav-link" data-scroll-target="#persistent-homology-and-topological-data-analysis">846. Persistent Homology and Topological Data Analysis</a></li>
  <li><a href="#graph-based-manifold-learning-approaches" id="toc-graph-based-manifold-learning-approaches" class="nav-link" data-scroll-target="#graph-based-manifold-learning-approaches">847. Graph-Based Manifold Learning Approaches</a></li>
  <li><a href="#evaluating-manifold-assumptions" id="toc-evaluating-manifold-assumptions" class="nav-link" data-scroll-target="#evaluating-manifold-assumptions">848. Evaluating Manifold Assumptions</a></li>
  <li><a href="#scalability-challenges-in-manifold-learning" id="toc-scalability-challenges-in-manifold-learning" class="nav-link" data-scroll-target="#scalability-challenges-in-manifold-learning">849. Scalability Challenges in Manifold Learning</a></li>
  <li><a href="#applications-in-science-and-engineering" id="toc-applications-in-science-and-engineering" class="nav-link" data-scroll-target="#applications-in-science-and-engineering">850. Applications in Science and Engineering</a></li>
  </ul></li>
  <li><a href="#chapter-86.-topic-models-and-laten-dirichlet-allocation" id="toc-chapter-86.-topic-models-and-laten-dirichlet-allocation" class="nav-link" data-scroll-target="#chapter-86.-topic-models-and-laten-dirichlet-allocation">Chapter 86. Topic models and laten dirichlet allocation</a>
  <ul class="collapse">
  <li><a href="#introduction-to-topic-modeling" id="toc-introduction-to-topic-modeling" class="nav-link" data-scroll-target="#introduction-to-topic-modeling">851. Introduction to Topic Modeling</a></li>
  <li><a href="#latent-semantic-analysis-lsa" id="toc-latent-semantic-analysis-lsa" class="nav-link" data-scroll-target="#latent-semantic-analysis-lsa">852. Latent Semantic Analysis (LSA)</a></li>
  <li><a href="#probabilistic-latent-semantic-analysis-plsa" id="toc-probabilistic-latent-semantic-analysis-plsa" class="nav-link" data-scroll-target="#probabilistic-latent-semantic-analysis-plsa">853. Probabilistic Latent Semantic Analysis (pLSA)</a></li>
  <li><a href="#latent-dirichlet-allocation-lda-basics" id="toc-latent-dirichlet-allocation-lda-basics" class="nav-link" data-scroll-target="#latent-dirichlet-allocation-lda-basics">854. Latent Dirichlet Allocation (LDA) Basics</a></li>
  <li><a href="#inference-in-lda-gibbs-sampling-variational-bayes" id="toc-inference-in-lda-gibbs-sampling-variational-bayes" class="nav-link" data-scroll-target="#inference-in-lda-gibbs-sampling-variational-bayes">855. Inference in LDA: Gibbs Sampling, Variational Bayes</a></li>
  <li><a href="#extensions-dynamic-hierarchical-and-correlated-topic-models" id="toc-extensions-dynamic-hierarchical-and-correlated-topic-models" class="nav-link" data-scroll-target="#extensions-dynamic-hierarchical-and-correlated-topic-models">856. Extensions: Dynamic, Hierarchical, and Correlated Topic Models</a></li>
  <li><a href="#neural-topic-models" id="toc-neural-topic-models" class="nav-link" data-scroll-target="#neural-topic-models">857. Neural Topic Models</a></li>
  <li><a href="#evaluation-metrics-for-topic-models-perplexity-coherence" id="toc-evaluation-metrics-for-topic-models-perplexity-coherence" class="nav-link" data-scroll-target="#evaluation-metrics-for-topic-models-perplexity-coherence">858. Evaluation Metrics for Topic Models (Perplexity, Coherence)</a></li>
  <li><a href="#applications-in-text-mining-and-beyond" id="toc-applications-in-text-mining-and-beyond" class="nav-link" data-scroll-target="#applications-in-text-mining-and-beyond">859. Applications in Text Mining and Beyond</a></li>
  <li><a href="#challenges-interpretability-scalability-bias" id="toc-challenges-interpretability-scalability-bias" class="nav-link" data-scroll-target="#challenges-interpretability-scalability-bias">860. Challenges: Interpretability, Scalability, Bias</a></li>
  </ul></li>
  <li><a href="#chapter-87.-autoencoders-and-representation-learning" id="toc-chapter-87.-autoencoders-and-representation-learning" class="nav-link" data-scroll-target="#chapter-87.-autoencoders-and-representation-learning">Chapter 87. Autoencoders and representation learning</a>
  <ul class="collapse">
  <li><a href="#basics-of-autoencoders" id="toc-basics-of-autoencoders" class="nav-link" data-scroll-target="#basics-of-autoencoders">861. Basics of Autoencoders</a></li>
  <li><a href="#undercomplete-vs.-overcomplete-representations" id="toc-undercomplete-vs.-overcomplete-representations" class="nav-link" data-scroll-target="#undercomplete-vs.-overcomplete-representations">862. Undercomplete vs.&nbsp;Overcomplete Representations</a></li>
  <li><a href="#variational-autoencoders-vaes" id="toc-variational-autoencoders-vaes" class="nav-link" data-scroll-target="#variational-autoencoders-vaes">863. Variational Autoencoders (VAEs)</a></li>
  <li><a href="#denoising-and-robust-autoencoders" id="toc-denoising-and-robust-autoencoders" class="nav-link" data-scroll-target="#denoising-and-robust-autoencoders">864. Denoising and Robust Autoencoders</a></li>
  <li><a href="#sparse-and-contractive-autoencoders" id="toc-sparse-and-contractive-autoencoders" class="nav-link" data-scroll-target="#sparse-and-contractive-autoencoders">865. Sparse and Contractive Autoencoders</a></li>
  <li><a href="#adversarial-autoencoders" id="toc-adversarial-autoencoders" class="nav-link" data-scroll-target="#adversarial-autoencoders">866. Adversarial Autoencoders</a></li>
  <li><a href="#representation-quality-and-latent-spaces" id="toc-representation-quality-and-latent-spaces" class="nav-link" data-scroll-target="#representation-quality-and-latent-spaces">867. Representation Quality and Latent Spaces</a></li>
  <li><a href="#disentangled-representation-learning" id="toc-disentangled-representation-learning" class="nav-link" data-scroll-target="#disentangled-representation-learning">868. Disentangled Representation Learning</a></li>
  <li><a href="#applications-compression-denoising-generation" id="toc-applications-compression-denoising-generation" class="nav-link" data-scroll-target="#applications-compression-denoising-generation">869. Applications: Compression, Denoising, Generation</a></li>
  <li><a href="#beyond-autoencoders-general-representation-learning" id="toc-beyond-autoencoders-general-representation-learning" class="nav-link" data-scroll-target="#beyond-autoencoders-general-representation-learning">870. Beyond Autoencoders: General Representation Learning</a></li>
  </ul></li>
  <li><a href="#chapter-88.-contrastive-and-self-supervised-learning" id="toc-chapter-88.-contrastive-and-self-supervised-learning" class="nav-link" data-scroll-target="#chapter-88.-contrastive-and-self-supervised-learning">Chapter 88. Contrastive and self-supervised learning</a>
  <ul class="collapse">
  <li><a href="#why-self-supervised-learning" id="toc-why-self-supervised-learning" class="nav-link" data-scroll-target="#why-self-supervised-learning">871. Why Self-Supervised Learning?</a></li>
  <li><a href="#contrastive-learning-objectives-infonce-triplet-loss" id="toc-contrastive-learning-objectives-infonce-triplet-loss" class="nav-link" data-scroll-target="#contrastive-learning-objectives-infonce-triplet-loss">872. Contrastive Learning Objectives (InfoNCE, Triplet Loss)</a></li>
  <li><a href="#simclr-moco-byol-key-frameworks" id="toc-simclr-moco-byol-key-frameworks" class="nav-link" data-scroll-target="#simclr-moco-byol-key-frameworks">873. SimCLR, MoCo, BYOL: Key Frameworks</a></li>
  <li><a href="#negative-sampling-and-memory-banks" id="toc-negative-sampling-and-memory-banks" class="nav-link" data-scroll-target="#negative-sampling-and-memory-banks">874. Negative Sampling and Memory Banks</a></li>
  <li><a href="#bootstrap-and-predictive-methods" id="toc-bootstrap-and-predictive-methods" class="nav-link" data-scroll-target="#bootstrap-and-predictive-methods">875. Bootstrap and Predictive Methods</a></li>
  <li><a href="#masked-prediction-approaches-bert-mae" id="toc-masked-prediction-approaches-bert-mae" class="nav-link" data-scroll-target="#masked-prediction-approaches-bert-mae">876. Masked Prediction Approaches (BERT, MAE)</a></li>
  <li><a href="#alignment-vs.-uniformity-in-representations" id="toc-alignment-vs.-uniformity-in-representations" class="nav-link" data-scroll-target="#alignment-vs.-uniformity-in-representations">877. Alignment vs.&nbsp;Uniformity in Representations</a></li>
  <li><a href="#evaluation-protocols-for-self-supervised-learning" id="toc-evaluation-protocols-for-self-supervised-learning" class="nav-link" data-scroll-target="#evaluation-protocols-for-self-supervised-learning">878. Evaluation Protocols for Self-Supervised Learning</a></li>
  <li><a href="#scaling-self-supervised-models" id="toc-scaling-self-supervised-models" class="nav-link" data-scroll-target="#scaling-self-supervised-models">879. Scaling Self-Supervised Models</a></li>
  <li><a href="#applications-across-modalities" id="toc-applications-across-modalities" class="nav-link" data-scroll-target="#applications-across-modalities">880. Applications Across Modalities</a></li>
  </ul></li>
  <li><a href="#chapter-89.-anomaly-and-novelty-detection" id="toc-chapter-89.-anomaly-and-novelty-detection" class="nav-link" data-scroll-target="#chapter-89.-anomaly-and-novelty-detection">Chapter 89. Anomaly and novelty detection</a>
  <ul class="collapse">
  <li><a href="#fundamentals-of-anomaly-detection" id="toc-fundamentals-of-anomaly-detection" class="nav-link" data-scroll-target="#fundamentals-of-anomaly-detection">881. Fundamentals of Anomaly Detection</a></li>
  <li><a href="#statistical-approaches-and-control-charts" id="toc-statistical-approaches-and-control-charts" class="nav-link" data-scroll-target="#statistical-approaches-and-control-charts">882. Statistical Approaches and Control Charts</a></li>
  <li><a href="#clustering-based-anomaly-detection" id="toc-clustering-based-anomaly-detection" class="nav-link" data-scroll-target="#clustering-based-anomaly-detection">883. Clustering-Based Anomaly Detection</a></li>
  <li><a href="#one-class-classification-e.g.-one-class-svm" id="toc-one-class-classification-e.g.-one-class-svm" class="nav-link" data-scroll-target="#one-class-classification-e.g.-one-class-svm">884. One-Class Classification (e.g., One-Class SVM)</a></li>
  <li><a href="#density-based-and-isolation-forest-methods" id="toc-density-based-and-isolation-forest-methods" class="nav-link" data-scroll-target="#density-based-and-isolation-forest-methods">885. Density-Based and Isolation Forest Methods</a></li>
  <li><a href="#deep-learning-for-anomaly-detection" id="toc-deep-learning-for-anomaly-detection" class="nav-link" data-scroll-target="#deep-learning-for-anomaly-detection">886. Deep Learning for Anomaly Detection</a></li>
  <li><a href="#novelty-detection-vs.-outlier-detection" id="toc-novelty-detection-vs.-outlier-detection" class="nav-link" data-scroll-target="#novelty-detection-vs.-outlier-detection">887. Novelty Detection vs.&nbsp;Outlier Detection</a></li>
  <li><a href="#evaluation-metrics-precision-roc-pr-auc" id="toc-evaluation-metrics-precision-roc-pr-auc" class="nav-link" data-scroll-target="#evaluation-metrics-precision-roc-pr-auc">888. Evaluation Metrics (Precision, ROC, PR, AUC)</a></li>
  <li><a href="#industrial-medical-and-security-applications" id="toc-industrial-medical-and-security-applications" class="nav-link" data-scroll-target="#industrial-medical-and-security-applications">889. Industrial, Medical, and Security Applications</a></li>
  <li><a href="#challenges-imbalance-concept-drift-explainability" id="toc-challenges-imbalance-concept-drift-explainability" class="nav-link" data-scroll-target="#challenges-imbalance-concept-drift-explainability">890. Challenges: Imbalance, Concept Drift, Explainability</a></li>
  </ul></li>
  <li><a href="#chapter-90.-graph-representation-learning" id="toc-chapter-90.-graph-representation-learning" class="nav-link" data-scroll-target="#chapter-90.-graph-representation-learning">Chapter 90. Graph representation learning</a>
  <ul class="collapse">
  <li><a href="#basics-of-graphs-and-graph-data" id="toc-basics-of-graphs-and-graph-data" class="nav-link" data-scroll-target="#basics-of-graphs-and-graph-data">891. Basics of Graphs and Graph Data</a></li>
  <li><a href="#node-embeddings-deepwalk-node2vec" id="toc-node-embeddings-deepwalk-node2vec" class="nav-link" data-scroll-target="#node-embeddings-deepwalk-node2vec">892. Node Embeddings: DeepWalk, node2vec</a></li>
  <li><a href="#graph-neural-networks-gcn-gat-graphsage" id="toc-graph-neural-networks-gcn-gat-graphsage" class="nav-link" data-scroll-target="#graph-neural-networks-gcn-gat-graphsage">893. Graph Neural Networks (GCN, GAT, GraphSAGE)</a></li>
  <li><a href="#message-passing-and-aggregation" id="toc-message-passing-and-aggregation" class="nav-link" data-scroll-target="#message-passing-and-aggregation">894. Message Passing and Aggregation</a></li>
  <li><a href="#graph-autoencoders-and-variants" id="toc-graph-autoencoders-and-variants" class="nav-link" data-scroll-target="#graph-autoencoders-and-variants">895. Graph Autoencoders and Variants</a></li>
  <li><a href="#heterogeneous-graphs-and-knowledge-graph-embeddings" id="toc-heterogeneous-graphs-and-knowledge-graph-embeddings" class="nav-link" data-scroll-target="#heterogeneous-graphs-and-knowledge-graph-embeddings">896. Heterogeneous Graphs and Knowledge Graph Embeddings</a></li>
  <li><a href="#temporal-and-dynamic-graph-models" id="toc-temporal-and-dynamic-graph-models" class="nav-link" data-scroll-target="#temporal-and-dynamic-graph-models">897. Temporal and Dynamic Graph Models</a></li>
  <li><a href="#evaluation-of-graph-representations" id="toc-evaluation-of-graph-representations" class="nav-link" data-scroll-target="#evaluation-of-graph-representations">898. Evaluation of Graph Representations</a></li>
  <li><a href="#applications-in-social-biological-and-knowledge-graphs" id="toc-applications-in-social-biological-and-knowledge-graphs" class="nav-link" data-scroll-target="#applications-in-social-biological-and-knowledge-graphs">899. Applications in Social, Biological, and Knowledge Graphs</a></li>
  <li><a href="#open-challenges-and-future-directions-in-graph-learning" id="toc-open-challenges-and-future-directions-in-graph-learning" class="nav-link" data-scroll-target="#open-challenges-and-future-directions-in-graph-learning">900. Open Challenges and Future Directions in Graph Learning</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">Volume 9. Unsupervised, self-supervised and representation</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">No</span> teacher in sight,</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ex">patterns</span> whisper in the dark,</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="ex">structure</span> finds itself.</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<section id="chapter-81.-clustering-k-means-hierarchical-dbscan" class="level2">
<h2 class="anchored" data-anchor-id="chapter-81.-clustering-k-means-hierarchical-dbscan">Chapter 81. Clustering (k-means, hierarchical, DBSCAN)</h2>
<section id="introduction-to-clustering" class="level3">
<h3 class="anchored" data-anchor-id="introduction-to-clustering">801. Introduction to Clustering</h3>
<p>Clustering is the task of grouping data points so that items within the same group are more similar to each other than to items in other groups. Unlike supervised learning, clustering has no labels to guide the process. Instead, algorithms discover structure directly from the data. At its core, clustering is about uncovering patterns, structure, and latent organization when nothing explicit has been provided.</p>
<section id="picture-in-your-head" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head">Picture in Your Head</h4>
<p>Imagine a scatterplot of thousands of dots. At first, it looks chaotic. But if you squint, you can see the dots form clouds. perhaps one cloud is tight and circular, another stretched and elongated, another more diffuse. Clustering is like drawing invisible boundaries around these clouds. The result is a partition of the dataset into “natural” groups that may correspond to meaningful categories in the real world.</p>
</section>
<section id="deep-dive" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive">Deep Dive</h4>
<p>Clustering sits at the foundation of unsupervised learning. It answers questions like: <em>How many kinds of customers shop here?</em> or <em>What biological cell types are present in this dataset?</em></p>
<ul>
<li>Objective: Clustering tries to maximize intra-cluster similarity and minimize inter-cluster similarity. Different algorithms operationalize this differently (e.g., distance minimization, density thresholds, probabilistic mixtures).</li>
<li>Assumptions: Every clustering method encodes assumptions. For example, k-Means assumes roughly spherical clusters of similar size, while DBSCAN assumes clusters are dense regions separated by sparse ones.</li>
<li>Challenges: Choosing the “right” number of clusters, handling outliers, dealing with high-dimensional data, and interpreting the results. Unlike classification, there is no universal ground truth, which makes evaluation tricky.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 19%">
<col style="width: 39%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Aspect</th>
<th>Typical Question</th>
<th>Example Method</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Shape of clusters</td>
<td>Are they spherical, elongated, or arbitrary?</td>
<td>k-Means (spherical), DBSCAN (arbitrary)</td>
</tr>
<tr class="even">
<td>Number of clusters</td>
<td>Is it known in advance or inferred?</td>
<td>k-Means (fixed k), Hierarchical (dendrogram cut)</td>
</tr>
<tr class="odd">
<td>Noise sensitivity</td>
<td>Can the algorithm handle outliers gracefully?</td>
<td>DBSCAN is robust; k-Means is not</td>
</tr>
<tr class="even">
<td>Scalability</td>
<td>Can it scale to millions of points?</td>
<td>Mini-Batch k-Means, Approximate methods</td>
</tr>
</tbody>
</table>
<p>Clustering is often the first exploratory step in a new dataset. It reveals hidden groups, detects anomalies, and serves as preprocessing for later models.</p>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_blobs</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate toy data</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>X, _ <span class="op">=</span> make_blobs(n_samples<span class="op">=</span><span class="dv">300</span>, centers<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Cluster with k-Means</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>).fit(X)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> kmeans.labels_</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot clusters</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:,<span class="dv">0</span>], X[:,<span class="dv">1</span>], c<span class="op">=</span>labels, cmap<span class="op">=</span><span class="st">"viridis"</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>plt.scatter(kmeans.cluster_centers_[:,<span class="dv">0</span>],</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>            kmeans.cluster_centers_[:,<span class="dv">1</span>],</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>            c<span class="op">=</span><span class="st">"red"</span>, marker<span class="op">=</span><span class="st">"x"</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This short script generates synthetic data, applies k-Means, and visualizes the clusters with their centroids.</p>
</section>
<section id="try-it-yourself" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself">Try It Yourself</h4>
<ol type="1">
<li>Change the number of clusters from 3 to 4. What happens to the results?</li>
<li>Replace <code>make_blobs</code> with <code>make_moons</code> from <code>sklearn.datasets</code>. Does k-Means still work well? Why or why not?</li>
<li>Experiment with <code>random_state</code>. does initialization affect results?</li>
<li>Compute and compare the silhouette score for different values of <code>k</code>.</li>
</ol>
</section>
</section>
<section id="similarity-and-distance-metrics" class="level3">
<h3 class="anchored" data-anchor-id="similarity-and-distance-metrics">802. Similarity and Distance Metrics</h3>
<p>Clustering relies on the idea of similarity. To decide whether two data points belong in the same group, we need a way to measure how alike they are. This measurement is usually expressed as a <em>distance</em> (small distance = high similarity) or a <em>similarity score</em> (high score = high similarity). The choice of metric has a direct impact on the clusters produced.</p>
<section id="picture-in-your-head-1" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-1">Picture in Your Head</h4>
<p>Think of arranging books in a library. If similarity is based on color, you might cluster by spine color. If it’s based on subject, you’d cluster by topic. The way you define “closeness” changes the groups you see. In data, a Euclidean distance might make sense for points in space, while cosine similarity might be better for documents represented as word vectors.</p>
</section>
<section id="deep-dive-1" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-1">Deep Dive</h4>
<ul>
<li>Euclidean Distance: Measures straight-line distance in continuous space. Sensitive to scale; works best when features are comparable.</li>
<li>Manhattan Distance: Sum of absolute differences. Useful in high-dimensional spaces with grid-like structures.</li>
<li>Cosine Similarity: Focuses on angle between vectors, not magnitude. Common in text, embeddings, and sparse high-dimensional data.</li>
<li>Jaccard Similarity: Ratio of shared features to total features. Useful for sets, binary attributes, and categorical data.</li>
<li>Mahalanobis Distance: Accounts for correlations between features. Effective when variables have different variances.</li>
</ul>
<p>The metric must align with the structure in the data. A poor choice can obscure clusters, while a good one can reveal them.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 48%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Metric</th>
<th>Best For</th>
<th>Weakness</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Euclidean</td>
<td>Geometric data, low dimensions</td>
<td>Sensitive to scale</td>
</tr>
<tr class="even">
<td>Manhattan</td>
<td>High dimensions, grid-based data</td>
<td>Less intuitive in some domains</td>
</tr>
<tr class="odd">
<td>Cosine</td>
<td>Text embeddings, sparse vectors</td>
<td>Ignores magnitude</td>
</tr>
<tr class="even">
<td>Jaccard</td>
<td>Sets, categorical features</td>
<td>Cannot handle continuous data</td>
</tr>
<tr class="odd">
<td>Mahalanobis</td>
<td>Correlated, multivariate distributions</td>
<td>Requires covariance estimation</td>
</tr>
</tbody>
</table>
</section>
<section id="why-it-matters" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters">Why It Matters</h4>
<p>Clustering results are only as meaningful as the metric used. For text embeddings, Euclidean distance may group documents incorrectly, while cosine similarity captures thematic closeness. In biology, Mahalanobis distance can uncover subtle relationships hidden by variance. Choosing the right metric is often the difference between insight and noise.</p>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> euclidean_distances, cosine_similarity</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Two example vectors</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>]])</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> np.array([[<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>]])</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute distances/similarities</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>eu_dist <span class="op">=</span> euclidean_distances(a, b)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>cos_sim <span class="op">=</span> cosine_similarity(a, b)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Euclidean distance:"</span>, eu_dist)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Cosine similarity:"</span>, cos_sim)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This shows how the same two vectors can look close or far depending on the metric.</p>
</section>
<section id="try-it-yourself-1" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-1">Try It Yourself</h4>
<ol type="1">
<li>Compute Manhattan distance between vectors <code>a</code> and <code>b</code>. Compare it to Euclidean.</li>
<li>Take three short text sentences, embed them with TF–IDF, and compute cosine similarities. Which pair is most similar?</li>
<li>Generate correlated 2D data and test Mahalanobis vs.&nbsp;Euclidean distance. Which captures the structure better?</li>
<li>Use Jaccard similarity on binary vectors representing movie genres. Which movies seem most alike?</li>
</ol>
</section>
</section>
<section id="k-means-objective-and-iterative-refinement" class="level3">
<h3 class="anchored" data-anchor-id="k-means-objective-and-iterative-refinement">803. k-Means: Objective and Iterative Refinement</h3>
<p>k-Means is one of the simplest and most widely used clustering algorithms. It partitions data into k groups by minimizing the variance within each cluster. Each cluster is defined by a centroid (the mean of its points), and points are assigned to the nearest centroid. The process iteratively updates assignments and centroids until stability.</p>
<section id="picture-in-your-head-2" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-2">Picture in Your Head</h4>
<p>Imagine placing k pins on a table scattered with beads. Each bead sticks to the nearest pin. Then you slide each pin to the center of the beads attached to it. Reassign beads to the nearest pin again, and repeat. After a few rounds, the pins stop moving, and you’ve got stable groups of beads around them.</p>
</section>
<section id="deep-dive-2" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-2">Deep Dive</h4>
<ul>
<li><p>Objective Function: k-Means minimizes the within-cluster sum of squared distances (WCSS):</p>
<p><span class="math display">\[
J = \sum_{i=1}^{k} \sum_{x \in C_i} \| x - \mu_i \|^2
\]</span></p>
<p>where <span class="math inline">\(C_i\)</span> is cluster i and <span class="math inline">\(\mu_i\)</span> its centroid.</p></li>
<li><p>Algorithm Steps:</p>
<ol type="1">
<li>Initialize k centroids (randomly or using k-means++).</li>
<li>Assign each point to the nearest centroid.</li>
<li>Update centroids as the mean of assigned points.</li>
<li>Repeat until assignments no longer change or improvement is negligible.</li>
</ol></li>
<li><p>Complexity: Each iteration is <span class="math inline">\(O(n \cdot k \cdot d)\)</span>, where n = number of points, k = clusters, d = dimensions.</p></li>
<li><p>Limitations: Sensitive to initialization, assumes spherical clusters, struggles with outliers, requires k in advance.</p></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 36%">
<col style="width: 45%">
</colgroup>
<thead>
<tr class="header">
<th>Step</th>
<th>Description</th>
<th>Impact</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Initialization</td>
<td>Place starting centroids</td>
<td>Poor choice can trap in local minima</td>
</tr>
<tr class="even">
<td>Assignment</td>
<td>Each point → nearest centroid</td>
<td>Defines temporary clusters</td>
</tr>
<tr class="odd">
<td>Update</td>
<td>Move centroid to cluster mean</td>
<td>Reduces error function</td>
</tr>
<tr class="even">
<td>Convergence</td>
<td>Stop when centroids stabilize</td>
<td>Typically fast, but local optima</td>
</tr>
</tbody>
</table>
</section>
<section id="why-it-matters-1" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-1">Why It Matters</h4>
<p>Despite its simplicity, k-Means is a workhorse algorithm for clustering. It is fast, scalable, and often a first baseline. From image compression to market segmentation, k-Means provides quick insight into structure. Understanding its mechanics also lays the foundation for more advanced clustering methods.</p>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate 2D synthetic data</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.vstack([</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    np.random.normal([<span class="dv">0</span>,<span class="dv">0</span>], <span class="fl">0.5</span>, (<span class="dv">100</span>,<span class="dv">2</span>)),</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    np.random.normal([<span class="dv">3</span>,<span class="dv">3</span>], <span class="fl">0.5</span>, (<span class="dv">100</span>,<span class="dv">2</span>)),</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    np.random.normal([<span class="dv">0</span>,<span class="dv">4</span>], <span class="fl">0.5</span>, (<span class="dv">100</span>,<span class="dv">2</span>))</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Run k-Means with k=3</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, n_init<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> kmeans.fit_predict(X)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot results</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:,<span class="dv">0</span>], X[:,<span class="dv">1</span>], c<span class="op">=</span>labels, cmap<span class="op">=</span><span class="st">"viridis"</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>plt.scatter(kmeans.cluster_centers_[:,<span class="dv">0</span>],</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>            kmeans.cluster_centers_[:,<span class="dv">1</span>],</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>            c<span class="op">=</span><span class="st">"red"</span>, marker<span class="op">=</span><span class="st">"x"</span>, s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="try-it-yourself-2" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-2">Try It Yourself</h4>
<ol type="1">
<li>Run the code with different <code>n_clusters</code> (e.g., 2, 4, 5). How does it change the clusters?</li>
<li>Try initializing with <code>n_init=1</code>. Do results vary across runs?</li>
<li>Generate non-spherical data (e.g., concentric circles with <code>make_circles</code>). How does k-Means perform?</li>
<li>Measure the inertia (<code>kmeans.inertia_</code>) for different k. Plot it to create an elbow plot. Where is the “best” k?</li>
</ol>
</section>
</section>
<section id="variants-of-k-means-mini-batch-k-medoids" class="level3">
<h3 class="anchored" data-anchor-id="variants-of-k-means-mini-batch-k-medoids">804. Variants of k-Means (Mini-Batch, k-Medoids)</h3>
<p>While standard k-Means is effective, it has limitations in scalability, sensitivity to outliers, and its reliance on means. Variants like Mini-Batch k-Means and k-Medoids address these weaknesses by improving speed or robustness, making clustering more practical for large or noisy datasets.</p>
<section id="picture-in-your-head-3" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-3">Picture in Your Head</h4>
<p>Think of standard k-Means as trying to organize a huge warehouse by moving every single item at once. Mini-Batch k-Means instead looks at just a handful of items at a time, adjusting shelves more quickly. k-Medoids is like choosing representative “prototypes” (actual items) to stand for each shelf, rather than averages that may not exist in reality.</p>
</section>
<section id="deep-dive-3" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-3">Deep Dive</h4>
<ul>
<li>Mini-Batch k-Means: Processes random subsets (mini-batches) of data at each iteration, updating centroids incrementally. This reduces memory usage and accelerates convergence on massive datasets.</li>
<li>k-Medoids (PAM, CLARA): Uses actual data points (medoids) as cluster centers. More robust to outliers since medoids are not influenced by extreme values. Often applied in domains where mean values are not meaningful (e.g., categorical or mixed data).</li>
<li>Comparison to k-Means:</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 34%">
<col style="width: 46%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Strengths</th>
<th>Weaknesses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Standard k-Means</td>
<td>Simple, fast, widely used</td>
<td>Sensitive to outliers, assumes mean is valid</td>
</tr>
<tr class="even">
<td>Mini-Batch k-Means</td>
<td>Scales to millions of points</td>
<td>Slightly lower accuracy</td>
</tr>
<tr class="odd">
<td>k-Medoids</td>
<td>Robust to noise, categorical data</td>
<td>Slower, higher computational cost</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_blobs</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> MiniBatchKMeans</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn_extra.cluster <span class="im">import</span> KMedoids</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate synthetic data</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>X, _ <span class="op">=</span> make_blobs(n_samples<span class="op">=</span><span class="dv">1000</span>, centers<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Mini-Batch k-Means</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>mbk <span class="op">=</span> MiniBatchKMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, batch_size<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>labels_mbk <span class="op">=</span> mbk.fit_predict(X)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co"># k-Medoids</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>kmed <span class="op">=</span> KMedoids(n_clusters<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>labels_kmed <span class="op">=</span> kmed.fit_predict(X)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mini-Batch inertia:"</span>, mbk.inertia_)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"k-Medoids centers:"</span>, kmed.cluster_centers_)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-2" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-2">Why It Matters</h4>
<p>Variants extend the reach of k-Means. Mini-Batch makes it feasible to cluster billions of records in real time, as in online advertising or recommender systems. k-Medoids provides robustness in fields like healthcare or finance, where extreme values should not distort groupings. Understanding these variations ensures the right tool is chosen for both scale and data characteristics.</p>
</section>
<section id="try-it-yourself-3" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-3">Try It Yourself</h4>
<ol type="1">
<li>Compare runtime between k-Means and Mini-Batch k-Means for 1M points. Which is faster?</li>
<li>Introduce outliers into a dataset. How do k-Means and k-Medoids differ in results?</li>
<li>Apply k-Medoids to categorical data encoded with one-hot vectors. How do the medoids differ from centroids?</li>
<li>Experiment with different batch sizes in Mini-Batch k-Means. How does it affect accuracy and runtime?</li>
</ol>
</section>
</section>
<section id="hierarchical-clustering-agglomerative-vs.-divisive" class="level3">
<h3 class="anchored" data-anchor-id="hierarchical-clustering-agglomerative-vs.-divisive">805. Hierarchical Clustering: Agglomerative vs.&nbsp;Divisive</h3>
<p>Hierarchical clustering builds a hierarchy of nested clusters. Unlike k-Means, it does not require the number of clusters in advance. It produces a dendrogram, a tree-like structure that shows how clusters merge or split at different levels. There are two main approaches: agglomerative (bottom-up) and divisive (top-down).</p>
<section id="picture-in-your-head-4" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-4">Picture in Your Head</h4>
<p>Imagine grouping family photos. In agglomerative clustering, you start with each photo in its own folder, then gradually merge folders that look most similar until everything is in one album. In divisive clustering, you start with one giant folder and keep splitting it into smaller albums until each contains closely related photos.</p>
</section>
<section id="deep-dive-4" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-4">Deep Dive</h4>
<ul>
<li><p>Agglomerative Clustering (Bottom-Up): Begins with each data point as its own cluster. At each step, the two most similar clusters are merged. Process continues until only one cluster remains or a stopping condition is reached.</p></li>
<li><p>Divisive Clustering (Top-Down): Starts with all data points in one cluster. At each step, the cluster with the highest dissimilarity is split. This continues until each point stands alone or a desired level of granularity is achieved.</p></li>
<li><p>Linkage Criteria: Define how distances between clusters are computed.</p>
<ul>
<li><em>Single linkage:</em> Closest points between clusters.</li>
<li><em>Complete linkage:</em> Farthest points.</li>
<li><em>Average linkage:</em> Average distance across all pairs.</li>
<li><em>Ward’s method:</em> Minimizes increase in variance.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 17%">
<col style="width: 35%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th>Approach</th>
<th>Process Direction</th>
<th>Strengths</th>
<th>Weaknesses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Agglomerative</td>
<td>Bottom-up</td>
<td>Intuitive, widely used</td>
<td>Expensive for large datasets</td>
</tr>
<tr class="even">
<td>Divisive</td>
<td>Top-down</td>
<td>Captures broad structure first</td>
<td>Less common, computationally heavier</td>
</tr>
<tr class="odd">
<td>Linkage choice</td>
<td>Cluster similarity</td>
<td>Shapes cluster boundaries differently</td>
<td>Sensitive to noise</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_blobs</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.cluster.hierarchy <span class="im">import</span> dendrogram, linkage</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate data</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>X, _ <span class="op">=</span> make_blobs(n_samples<span class="op">=</span><span class="dv">30</span>, centers<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform agglomerative clustering</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> linkage(X, method<span class="op">=</span><span class="st">'ward'</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot dendrogram</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">4</span>))</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>dendrogram(Z)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Hierarchical Clustering Dendrogram"</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Data Points"</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Distance"</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-3" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-3">Why It Matters</h4>
<p>Hierarchical clustering is especially useful for exploratory analysis because it shows structure at multiple levels. Analysts can cut the dendrogram at different heights to reveal varying numbers of clusters. This flexibility makes it valuable in biology (phylogenetic trees), text mining (document hierarchies), and customer segmentation.</p>
</section>
<section id="try-it-yourself-4" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-4">Try It Yourself</h4>
<ol type="1">
<li>Generate data with four clusters and compare results using single, complete, and average linkage. How do dendrograms differ?</li>
<li>Apply Ward’s method to compare variance minimization with other linkage strategies.</li>
<li>Cut the dendrogram at different heights. How does the number of clusters change?</li>
<li>Use hierarchical clustering on small text embeddings. Does it reveal meaningful document groupings?</li>
</ol>
</section>
</section>
<section id="linkage-criteria-single-complete-average-ward" class="level3">
<h3 class="anchored" data-anchor-id="linkage-criteria-single-complete-average-ward">806. Linkage Criteria (Single, Complete, Average, Ward)</h3>
<p>In hierarchical clustering, the way we measure the distance between clusters determines how they grow or split. This is called a linkage criterion. Different linkage methods emphasize different aspects of inter-cluster relationships, leading to distinct cluster shapes and dendrogram structures.</p>
<section id="picture-in-your-head-5" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-5">Picture in Your Head</h4>
<p>Think of connecting islands with bridges.</p>
<ul>
<li>Single linkage connects the two closest shores.</li>
<li>Complete linkage builds the longest possible bridge, ensuring all islands within a group are close.</li>
<li>Average linkage balances by averaging all possible bridge lengths.</li>
<li>Ward’s method is like redistributing sand to minimize unevenness whenever islands are grouped.</li>
</ul>
</section>
<section id="deep-dive-5" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-5">Deep Dive</h4>
<ul>
<li>Single Linkage: Distance between two clusters = minimum pairwise distance. Good for detecting elongated clusters but prone to chaining effect.</li>
<li>Complete Linkage: Distance = maximum pairwise distance. Produces compact clusters but sensitive to outliers.</li>
<li>Average Linkage: Distance = mean of all pairwise distances. A compromise between chaining and compactness.</li>
<li>Ward’s Method: Minimizes the increase in total within-cluster variance when merging. Prefers clusters of similar size and spherical shape.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 9%">
<col style="width: 24%">
<col style="width: 34%">
<col style="width: 31%">
</colgroup>
<thead>
<tr class="header">
<th>Linkage</th>
<th>Formula</th>
<th>Strengths</th>
<th>Weaknesses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Single</td>
<td>min distance</td>
<td>Captures irregular shapes</td>
<td>Chaining effect</td>
</tr>
<tr class="even">
<td>Complete</td>
<td>max distance</td>
<td>Compact, evenly shaped groups</td>
<td>Sensitive to outliers</td>
</tr>
<tr class="odd">
<td>Average</td>
<td>mean of distances</td>
<td>Balanced clusters</td>
<td>Computationally heavier</td>
</tr>
<tr class="even">
<td>Ward</td>
<td>variance minimization</td>
<td>Robust, spherical clusters</td>
<td>Assumes equal-size clusters</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_blobs</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.cluster.hierarchy <span class="im">import</span> linkage, dendrogram</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate synthetic data</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>X, _ <span class="op">=</span> make_blobs(n_samples<span class="op">=</span><span class="dv">40</span>, centers<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Try different linkage criteria</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>methods <span class="op">=</span> [<span class="st">"single"</span>, <span class="st">"complete"</span>, <span class="st">"average"</span>, <span class="st">"ward"</span>]</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">8</span>))</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, m <span class="kw">in</span> <span class="bu">enumerate</span>(methods, <span class="dv">1</span>):</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> linkage(X, method<span class="op">=</span>m)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, i)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    dendrogram(Z, no_labels<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"</span><span class="sc">{</span>m<span class="sc">.</span>capitalize()<span class="sc">}</span><span class="ss"> Linkage"</span>)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-4" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-4">Why It Matters</h4>
<p>Linkage choice has a profound impact on clustering results. In practice, analysts often compare multiple linkages to see which best matches domain expectations. For instance, single linkage is effective in detecting chained geographic routes, while Ward’s method is common in gene expression studies. The “best” criterion depends on both data distribution and interpretability needs.</p>
</section>
<section id="try-it-yourself-5" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-5">Try It Yourself</h4>
<ol type="1">
<li>Apply hierarchical clustering with single, complete, and Ward linkage on concentric circles. Which method best captures structure?</li>
<li>Add outliers to your dataset. How does complete linkage respond compared to average linkage?</li>
<li>Compute dendrograms with 2,000 points using Ward vs.&nbsp;average linkage. Which is more scalable?</li>
<li>Experiment with cutting the dendrogram at different levels for each linkage. Do the resulting clusters align with intuition?</li>
</ol>
</section>
</section>
<section id="density-based-methods-dbscan-and-hdbscan" class="level3">
<h3 class="anchored" data-anchor-id="density-based-methods-dbscan-and-hdbscan">807. Density-Based Methods: DBSCAN and HDBSCAN</h3>
<p>Density-based clustering groups points by regions of high density, separating them from areas of low density. Unlike k-Means or hierarchical methods, these algorithms can find clusters of arbitrary shape and automatically identify outliers as noise. The most widely used are DBSCAN and its extension HDBSCAN.</p>
<section id="picture-in-your-head-6" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-6">Picture in Your Head</h4>
<p>Imagine pouring ink drops onto paper. Where the ink pools, you see dark dense regions. these are clusters. Sparse scattered dots remain isolated, ignored as noise. DBSCAN is like drawing boundaries around these dense pools, while HDBSCAN adapts when densities vary, outlining both big pools and smaller ones without having to guess how many exist.</p>
</section>
<section id="deep-dive-6" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-6">Deep Dive</h4>
<ul>
<li><p>DBSCAN (Density-Based Spatial Clustering of Applications with Noise):</p>
<ul>
<li>Defines clusters as areas where each point has at least <code>minPts</code> neighbors within a radius <code>eps</code>.</li>
<li>Classifies points into core (dense interior), border (near edges), or noise (isolated).</li>
<li>Handles arbitrary shapes well but struggles when cluster densities vary.</li>
</ul></li>
<li><p>HDBSCAN (Hierarchical DBSCAN):</p>
<ul>
<li>Extends DBSCAN by building a hierarchy of density-based clusters.</li>
<li>Can find clusters at multiple density levels and is less sensitive to parameter choice.</li>
<li>Produces a stability score for clusters, aiding interpretability.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 7%">
<col style="width: 18%">
<col style="width: 41%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Key Parameters</th>
<th>Strengths</th>
<th>Weaknesses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>DBSCAN</td>
<td><code>eps</code>, <code>minPts</code></td>
<td>Finds arbitrary shapes, detects noise</td>
<td>Hard to tune for mixed densities</td>
</tr>
<tr class="even">
<td>HDBSCAN</td>
<td><code>min_cluster_size</code></td>
<td>Adapts to varying densities, less tuning</td>
<td>More computationally intensive</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_moons</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate nonlinear data</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>X, _ <span class="op">=</span> make_moons(n_samples<span class="op">=</span><span class="dv">300</span>, noise<span class="op">=</span><span class="fl">0.05</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Run DBSCAN</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="fl">0.2</span>, min_samples<span class="op">=</span><span class="dv">5</span>).fit(X)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> db.labels_</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot clusters (noise = -1 in black)</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:,<span class="dv">0</span>], X[:,<span class="dv">1</span>], c<span class="op">=</span>labels, cmap<span class="op">=</span><span class="st">"plasma"</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"DBSCAN Clustering (moons)"</span>)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-5" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-5">Why It Matters</h4>
<p>Density-based methods are powerful for messy, real-world data. They excel at detecting unusual shapes in geospatial data, molecular conformations, or customer behavior. They also inherently identify outliers, making them useful for anomaly detection. HDBSCAN in particular has become popular in domains where data densities vary widely, such as biology and NLP embeddings.</p>
</section>
<section id="try-it-yourself-6" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-6">Try It Yourself</h4>
<ol type="1">
<li>Run DBSCAN on concentric circle data. Does it capture the rings?</li>
<li>Vary <code>eps</code> and <code>minPts</code>. When do clusters fragment or merge?</li>
<li>Add random noise points to the dataset. How are they classified?</li>
<li>Compare DBSCAN vs.&nbsp;k-Means on non-spherical data. Which captures structure better?</li>
</ol>
</section>
</section>
<section id="cluster-evaluation-metrics-silhouette-daviesbouldin" class="level3">
<h3 class="anchored" data-anchor-id="cluster-evaluation-metrics-silhouette-daviesbouldin">808. Cluster Evaluation Metrics (Silhouette, Davies–Bouldin)</h3>
<p>Clustering lacks ground-truth labels, so evaluating results is nontrivial. Cluster evaluation metrics quantify how well data points are grouped, based on cohesion (how close points are within a cluster) and separation (how distinct clusters are from each other). Two popular metrics are the Silhouette score and the Davies–Bouldin index.</p>
<section id="picture-in-your-head-7" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-7">Picture in Your Head</h4>
<p>Think of a group of friends at a party. If each person feels closer to their own group than to other groups, the clusters are strong (high silhouette). If groups overlap and people stand awkwardly between them, the clusters are weak (low silhouette, high Davies–Bouldin). These metrics are like surveys asking: <em>Do you belong here, or are you closer to another group?</em></p>
</section>
<section id="deep-dive-7" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-7">Deep Dive</h4>
<ul>
<li><p>Silhouette Score: For each point <span class="math inline">\(i\)</span>, compute:</p>
<ul>
<li><p><span class="math inline">\(a(i)\)</span>: average distance to other points in the same cluster.</p></li>
<li><p><span class="math inline">\(b(i)\)</span>: smallest average distance to points in a different cluster.</p></li>
<li><p>Silhouette:</p>
<p><span class="math display">\[
s(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}
\]</span></p></li>
</ul>
<p>Values near +1 indicate good clustering, near 0 suggest overlap, negative values imply misclassification.</p></li>
<li><p>Davies–Bouldin Index (DBI): Measures the average “similarity” between each cluster and its most similar other cluster. Lower is better:</p>
<p><span class="math display">\[
DBI = \frac{1}{k} \sum_{i=1}^k \max_{j \neq i} \frac{\sigma_i + \sigma_j}{d(\mu_i, \mu_j)}
\]</span></p>
<p>where <span class="math inline">\(\sigma_i\)</span> is average distance within cluster <span class="math inline">\(i\)</span>, <span class="math inline">\(\mu_i\)</span> is its centroid, and <span class="math inline">\(d\)</span> is inter-centroid distance.</p></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 22%">
<col style="width: 28%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th>Metric</th>
<th>Range / Goal</th>
<th>Strengths</th>
<th>Weaknesses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Silhouette Score</td>
<td>-1 to 1 (higher = better)</td>
<td>Intuitive, point-level insight</td>
<td>Computationally heavy for large datasets</td>
</tr>
<tr class="even">
<td>Davies–Bouldin</td>
<td>≥ 0 (lower = better)</td>
<td>Fast, compares clusters globally</td>
<td>Less interpretable</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_blobs</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score, davies_bouldin_score</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate synthetic data</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>X, _ <span class="op">=</span> make_blobs(n_samples<span class="op">=</span><span class="dv">500</span>, centers<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit k-Means</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>).fit(X)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> kmeans.labels_</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>sil <span class="op">=</span> silhouette_score(X, labels)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>dbi <span class="op">=</span> davies_bouldin_score(X, labels)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Silhouette Score:"</span>, sil)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Davies–Bouldin Index:"</span>, dbi)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-6" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-6">Why It Matters</h4>
<p>Without labels, clustering evaluation depends on internal metrics. Silhouette gives granular insight into how well each point fits, while Davies–Bouldin provides a quick global assessment. These metrics guide practitioners in selecting the number of clusters (k) and comparing algorithm performance, ensuring that the discovered structure is both meaningful and robust.</p>
</section>
<section id="try-it-yourself-7" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-7">Try It Yourself</h4>
<ol type="1">
<li>Run k-Means with different <code>k</code> values (2–6) and plot Silhouette scores. Where is the optimal k?</li>
<li>Compare Silhouette and Davies–Bouldin scores for DBSCAN vs.&nbsp;k-Means. Do they agree?</li>
<li>Add noise points to the dataset. How do the metrics respond?</li>
<li>Apply metrics to non-spherical data. Which metric better captures quality?</li>
</ol>
</section>
</section>
<section id="scalability-and-approximate-clustering-methods" class="level3">
<h3 class="anchored" data-anchor-id="scalability-and-approximate-clustering-methods">809. Scalability and Approximate Clustering Methods</h3>
<p>As datasets grow into millions or billions of points, traditional clustering algorithms become impractical. Scalability challenges arise from memory limits, high computation, and streaming data. Approximate clustering methods trade some accuracy for speed, enabling clustering at scale.</p>
<section id="picture-in-your-head-8" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-8">Picture in Your Head</h4>
<p>Imagine trying to sort all the grains of sand on a beach into piles. Doing it one by one (classic clustering) is impossible. Instead, you grab handfuls, make rough piles, and refine only where needed. The result is not perfect, but it’s fast enough to reveal the overall structure.</p>
</section>
<section id="deep-dive-8" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-8">Deep Dive</h4>
<ul>
<li>Mini-Batch k-Means: Processes small random batches instead of the full dataset, updating centroids incrementally.</li>
<li>Coreset Methods: Construct a small weighted sample (coreset) that approximates the full dataset for clustering.</li>
<li>Streaming Clustering: Algorithms like BIRCH or online k-Means maintain summaries as new data arrives, useful in real-time systems.</li>
<li>Approximate Nearest Neighbor (ANN) Indexes: Used to speed up distance calculations in high dimensions (e.g., KD-Trees, HNSW).</li>
<li>Distributed Frameworks: Systems like Spark MLlib and scalable libraries (e.g., FAISS for similarity search) parallelize clustering across many machines.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 30%">
<col style="width: 22%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Strategy</th>
<th>Strengths</th>
<th>Weaknesses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Mini-Batch k-Means</td>
<td>Random subsamples</td>
<td>Very fast, scalable</td>
<td>Less accurate</td>
</tr>
<tr class="even">
<td>Coresets</td>
<td>Weighted representative subset</td>
<td>Strong approximation</td>
<td>Complexity in coreset design</td>
</tr>
<tr class="odd">
<td>Streaming (BIRCH)</td>
<td>Incremental summarization</td>
<td>Handles real-time data</td>
<td>Loses fine detail</td>
</tr>
<tr class="even">
<td>ANN-based clustering</td>
<td>Fast approximate distances</td>
<td>Efficient in high-d</td>
<td>May miss exact neighbors</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_blobs</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> MiniBatchKMeans</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate large dataset</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>X, _ <span class="op">=</span> make_blobs(n_samples<span class="op">=</span><span class="dv">100000</span>, centers<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Mini-Batch k-Means</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>mbk <span class="op">=</span> MiniBatchKMeans(n_clusters<span class="op">=</span><span class="dv">5</span>, batch_size<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> mbk.fit_predict(X)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Inertia:"</span>, mbk.inertia_)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Cluster centers:"</span>, mbk.cluster_centers_)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-7" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-7">Why It Matters</h4>
<p>Big data requires algorithms that scale. Approximate clustering allows practical analysis of datasets that would otherwise be impossible to process. From recommendation engines handling billions of users to anomaly detection in real-time network traffic, scalable clustering ensures insights can be drawn within time and resource limits.</p>
</section>
<section id="try-it-yourself-8" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-8">Try It Yourself</h4>
<ol type="1">
<li>Compare runtime of k-Means vs.&nbsp;Mini-Batch k-Means on 1M points. How large is the speedup?</li>
<li>Try different batch sizes for Mini-Batch k-Means. How does accuracy vs.&nbsp;runtime trade off?</li>
<li>Use BIRCH on streaming data. Does it adapt to new clusters appearing over time?</li>
<li>Apply ANN indexing (e.g., FAISS or scikit-learn’s KDTree) before clustering. How much faster are distance computations?</li>
</ol>
</section>
</section>
<section id="applications-and-case-studies-in-clustering" class="level3">
<h3 class="anchored" data-anchor-id="applications-and-case-studies-in-clustering">810. Applications and Case Studies in Clustering</h3>
<p>Clustering is not just a theoretical tool; it has wide-ranging real-world applications. It enables discovery of hidden structure, customer segmentation, anomaly detection, and scientific insights. By grouping data without supervision, clustering often serves as the first step in exploration and hypothesis generation.</p>
<section id="picture-in-your-head-9" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-9">Picture in Your Head</h4>
<p>Imagine standing in a busy airport terminal. People naturally form groups: families waiting together, business travelers rushing, tourists with cameras. Clustering algorithms would “see” these groups without needing labels like <em>family</em> or <em>tourist</em>. In the same way, clustering helps us uncover natural groupings in complex datasets.</p>
</section>
<section id="deep-dive-9" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-9">Deep Dive</h4>
<ul>
<li>Business &amp; Marketing: Customer segmentation for targeted advertising, product recommendations, or pricing strategies.</li>
<li>Healthcare &amp; Biology: Identifying disease subtypes from genetic data, clustering cells in single-cell RNA sequencing, or detecting anomalies in medical scans.</li>
<li>Cybersecurity: Grouping network traffic patterns to detect abnormal or malicious activity.</li>
<li>Image &amp; Signal Processing: Image compression, organizing large photo collections, speaker diarization in audio.</li>
<li>Natural Language Processing: Topic discovery in document corpora, clustering word embeddings for lexicon building.</li>
<li>Social Networks: Community detection, influencer identification, behavior analysis.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 50%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Domain</th>
<th>Example Use Case</th>
<th>Method Often Used</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Marketing</td>
<td>Customer segmentation</td>
<td>k-Means, DBSCAN</td>
</tr>
<tr class="even">
<td>Healthcare</td>
<td>Disease subtype discovery</td>
<td>Hierarchical, HDBSCAN</td>
</tr>
<tr class="odd">
<td>Cybersecurity</td>
<td>Intrusion detection</td>
<td>Density-based</td>
</tr>
<tr class="even">
<td>Image Processing</td>
<td>Image compression, face grouping</td>
<td>k-Means, Spectral</td>
</tr>
<tr class="odd">
<td>NLP</td>
<td>Topic discovery, embedding clustering</td>
<td>LDA, k-Means</td>
</tr>
<tr class="even">
<td>Social Networks</td>
<td>Community detection</td>
<td>Graph clustering</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_digits</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load digits dataset (images of 0–9)</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>digits <span class="op">=</span> load_digits()</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> PCA(<span class="dv">50</span>).fit_transform(digits.data)  <span class="co"># reduce dimensionality</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Cluster images</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> kmeans.fit_predict(X)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize first 100 images with cluster labels</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">10</span>, <span class="dv">10</span>, figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">8</span>))</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, ax <span class="kw">in</span> <span class="bu">enumerate</span>(axes.flat):</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    ax.imshow(digits.images[i], cmap<span class="op">=</span><span class="st">"gray"</span>)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>    ax.set_title(labels[i])</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    ax.axis(<span class="st">"off"</span>)</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-8" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-8">Why It Matters</h4>
<p>Clustering transforms raw, unlabeled data into actionable insight. It empowers companies to personalize experiences, scientists to discover new phenomena, and engineers to organize information at scale. From medicine to marketing, clustering remains one of the most versatile tools in AI and data science.</p>
</section>
<section id="try-it-yourself-9" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-9">Try It Yourself</h4>
<ol type="1">
<li>Cluster images of handwritten digits (MNIST). Do clusters align with digit identity?</li>
<li>Apply clustering to customer transaction data. What natural groups emerge?</li>
<li>Use DBSCAN on network logs. Can you spot unusual traffic patterns?</li>
<li>Cluster documents with TF–IDF embeddings. What topics naturally form?</li>
</ol>
</section>
</section>
</section>
<section id="chapter-82.-density-estimation-and-mixture-models" class="level2">
<h2 class="anchored" data-anchor-id="chapter-82.-density-estimation-and-mixture-models">Chapter 82. Density estimation and mixture models</h2>
<section id="basics-of-density-estimation" class="level3">
<h3 class="anchored" data-anchor-id="basics-of-density-estimation">811. Basics of Density Estimation</h3>
<p>Density estimation is the task of modeling the underlying probability distribution of a dataset. Instead of assigning points to discrete clusters, density estimation seeks to answer: <em>how likely is it to observe a point at this location in space?</em> This provides a smooth view of data structure and is central to unsupervised learning.</p>
<section id="picture-in-your-head-10" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-10">Picture in Your Head</h4>
<p>Imagine pouring sand onto a table where each grain represents a data point. Over time, little hills form where grains accumulate densely, and flat areas remain where data is sparse. A density estimator builds a “landscape map” of these hills and valleys, showing where data tends to live and where it is rare.</p>
</section>
<section id="deep-dive-10" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-10">Deep Dive</h4>
<ul>
<li>Parametric vs.&nbsp;Non-Parametric: Parametric methods assume a specific distribution (e.g., Gaussian), while non-parametric methods (e.g., histograms, kernel density estimation) let the data shape the distribution.</li>
<li>Use Cases: Density estimation underpins anomaly detection (points in low-density regions are anomalies), generative modeling, and clustering (clusters often correspond to high-density regions).</li>
<li>Challenges: The curse of dimensionality makes density estimation difficult in high dimensions. Trade-offs exist between bias (oversimplification) and variance (overfitting).</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 23%">
<col style="width: 31%">
<col style="width: 31%">
</colgroup>
<thead>
<tr class="header">
<th>Method Type</th>
<th>Examples</th>
<th>Strengths</th>
<th>Weaknesses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Parametric</td>
<td>Gaussian, Exponential</td>
<td>Simple, interpretable</td>
<td>Misses complex structures</td>
</tr>
<tr class="even">
<td>Non-Parametric</td>
<td>Histograms, KDE</td>
<td>Flexible, data-driven</td>
<td>Sensitive to bandwidth/bin size</td>
</tr>
<tr class="odd">
<td>Semi-Parametric</td>
<td>Gaussian Mixture Models</td>
<td>Balance flexibility &amp; structure</td>
<td>Harder to tune</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KernelDensity</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate 1D data</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.concatenate([</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    np.random.normal(<span class="op">-</span><span class="dv">2</span>, <span class="fl">0.5</span>, <span class="dv">200</span>),</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    np.random.normal(<span class="dv">3</span>, <span class="fl">1.0</span>, <span class="dv">300</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>])[:, np.newaxis]</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Kernel Density Estimation</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>kde <span class="op">=</span> KernelDensity(kernel<span class="op">=</span><span class="st">"gaussian"</span>, bandwidth<span class="op">=</span><span class="fl">0.5</span>).fit(X)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>x_vals <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">200</span>)[:, np.newaxis]</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>log_density <span class="op">=</span> kde.score_samples(x_vals)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>plt.hist(X, bins<span class="op">=</span><span class="dv">30</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>plt.plot(x_vals, np.exp(log_density), color<span class="op">=</span><span class="st">"red"</span>)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Kernel Density Estimation"</span>)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-9" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-9">Why It Matters</h4>
<p>Density estimation provides a foundation for many AI systems. It enables probabilistic reasoning, guides anomaly detection, and powers generative models like VAEs and normalizing flows. By estimating how data is distributed, we gain a deeper understanding of structure beyond hard cluster boundaries.</p>
</section>
<section id="try-it-yourself-10" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-10">Try It Yourself</h4>
<ol type="1">
<li>Fit both a Gaussian and a KDE to the same dataset. Which captures multimodality better?</li>
<li>Experiment with different <code>bandwidth</code> values in KDE. How does it affect smoothness?</li>
<li>Use histograms with varying bin sizes. Compare to KDE.</li>
<li>Apply KDE on 2D synthetic data and plot contour lines. Do density “hills” correspond to clusters?</li>
</ol>
</section>
</section>
<section id="histograms-and-kernel-density-estimation" class="level3">
<h3 class="anchored" data-anchor-id="histograms-and-kernel-density-estimation">812. Histograms and Kernel Density Estimation</h3>
<p>Histograms and kernel density estimation (KDE) are two fundamental non-parametric approaches to estimating probability density. A histogram divides data into discrete bins and counts frequency, while KDE places smooth kernels on each data point to create a continuous estimate of density.</p>
<section id="picture-in-your-head-11" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-11">Picture in Your Head</h4>
<p>Think of a histogram as stacking blocks in columns, one for each bin. a stepwise skyline showing where data lives. KDE, by contrast, is like dropping little bells (kernels) on each data point; their curves overlap and sum into a smooth rolling landscape.</p>
</section>
<section id="deep-dive-11" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-11">Deep Dive</h4>
<ul>
<li><p>Histograms:</p>
<ul>
<li>Divide range into bins of equal (or adaptive) width.</li>
<li>Frequency in each bin approximates probability mass.</li>
<li>Easy to compute, but sensitive to bin width and placement.</li>
</ul></li>
<li><p>Kernel Density Estimation (KDE):</p>
<ul>
<li>Places a kernel (e.g., Gaussian) at each data point.</li>
<li>Smoothness controlled by bandwidth: small = jagged, large = oversmoothed.</li>
<li>Produces continuous probability density function (PDF).</li>
</ul></li>
<li><p>Comparison: Histograms are intuitive but coarse; KDEs are smoother and more flexible but computationally heavier.</p></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 37%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Strengths</th>
<th>Weaknesses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Histogram</td>
<td>Simple, interpretable</td>
<td>Sensitive to bin choice, discontinuous</td>
</tr>
<tr class="even">
<td>KDE</td>
<td>Smooth, captures fine detail</td>
<td>Sensitive to bandwidth, slower</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KernelDensity</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.concatenate([</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    np.random.normal(<span class="op">-</span><span class="dv">2</span>, <span class="fl">0.5</span>, <span class="dv">200</span>),</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    np.random.normal(<span class="dv">3</span>, <span class="fl">1.0</span>, <span class="dv">300</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>])[:, <span class="va">None</span>]</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Histogram</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>plt.hist(X, bins<span class="op">=</span><span class="dv">30</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">"Histogram"</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="co"># KDE</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>kde <span class="op">=</span> KernelDensity(kernel<span class="op">=</span><span class="st">"gaussian"</span>, bandwidth<span class="op">=</span><span class="fl">0.5</span>).fit(X)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>x_vals <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">200</span>)[:, <span class="va">None</span>]</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>log_dens <span class="op">=</span> kde.score_samples(x_vals)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>plt.plot(x_vals, np.exp(log_dens), label<span class="op">=</span><span class="st">"KDE"</span>, color<span class="op">=</span><span class="st">"red"</span>)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Histogram vs. KDE"</span>)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-10" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-10">Why It Matters</h4>
<p>These simple tools are often the first step in data analysis. Histograms provide a quick, rough view of data shape, while KDEs offer a refined lens. They underpin more advanced methods like anomaly detection, clustering, and generative models, making them essential in both exploratory data analysis and model building.</p>
</section>
<section id="try-it-yourself-11" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-11">Try It Yourself</h4>
<ol type="1">
<li>Vary histogram bin sizes. When does the distribution look misleading?</li>
<li>Change KDE bandwidth from 0.1 to 2.0. How does smoothness change?</li>
<li>Use different kernels in KDE (Gaussian, Epanechnikov). Do results differ?</li>
<li>Compare histogram vs.&nbsp;KDE on multimodal data. Which reveals multiple peaks more clearly?</li>
</ol>
</section>
</section>
<section id="parametric-vs.-non-parametric-density-estimation" class="level3">
<h3 class="anchored" data-anchor-id="parametric-vs.-non-parametric-density-estimation">813. Parametric vs.&nbsp;Non-Parametric Density Estimation</h3>
<p>Density estimation can follow two philosophies. Parametric methods assume data follows a known family of distributions (e.g., Gaussian, exponential), estimating only a few parameters. Non-parametric methods make minimal assumptions, letting the data shape the distribution (e.g., histograms, KDE). Choosing between them depends on data complexity and prior knowledge.</p>
<section id="picture-in-your-head-12" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-12">Picture in Your Head</h4>
<p>Imagine fitting clothing. A parametric approach is like assuming everyone wears T-shirts: just pick size (S, M, L). Non-parametric is tailoring each piece individually: more flexible, but more effort. Parametric methods are fast and efficient when the assumption fits, while non-parametric can adapt to any shape but require more data.</p>
</section>
<section id="deep-dive-12" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-12">Deep Dive</h4>
<ul>
<li><p>Parametric Methods:</p>
<ul>
<li>Assume fixed form, e.g., Gaussian with mean μ and variance σ².</li>
<li>Estimate parameters using maximum likelihood or Bayesian methods.</li>
<li>Simple and efficient but risk <em>model misspecification</em>.</li>
</ul></li>
<li><p>Non-Parametric Methods:</p>
<ul>
<li>No fixed distributional form. Examples: histograms, KDE, nearest neighbors.</li>
<li>Flexibility grows with more data, avoiding rigid assumptions.</li>
<li>Prone to overfitting in high dimensions.</li>
</ul></li>
<li><p>Trade-Off: Parametric = low variance, high bias. Non-parametric = low bias, high variance. Semi-parametric methods aim to balance both.</p></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 25%">
<col style="width: 29%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="header">
<th>Approach</th>
<th>Example</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Parametric</td>
<td>Gaussian, Poisson</td>
<td>Simple, interpretable</td>
<td>Wrong assumption = poor fit</td>
</tr>
<tr class="even">
<td>Non-Parametric</td>
<td>KDE, Histograms</td>
<td>Very flexible</td>
<td>Needs lots of data</td>
</tr>
<tr class="odd">
<td>Semi-Parametric</td>
<td>Gaussian Mixture Models</td>
<td>Balance between both worlds</td>
<td>Complexity in tuning</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KernelDensity</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample multimodal data</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.concatenate([</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    np.random.normal(<span class="op">-</span><span class="dv">2</span>, <span class="fl">0.5</span>, <span class="dv">200</span>),</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    np.random.normal(<span class="dv">3</span>, <span class="fl">1.0</span>, <span class="dv">300</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>])[:, <span class="va">None</span>]</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Parametric fit (single Gaussian)</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>mu, sigma <span class="op">=</span> X.mean(), X.std()</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>x_vals <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">200</span>)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>plt.plot(x_vals, norm.pdf(x_vals, mu, sigma), label<span class="op">=</span><span class="st">"Parametric Gaussian"</span>)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Non-parametric fit (KDE)</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>kde <span class="op">=</span> KernelDensity(kernel<span class="op">=</span><span class="st">"gaussian"</span>, bandwidth<span class="op">=</span><span class="fl">0.5</span>).fit(X)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>plt.plot(x_vals, np.exp(kde.score_samples(x_vals[:, <span class="va">None</span>])), label<span class="op">=</span><span class="st">"KDE"</span>, color<span class="op">=</span><span class="st">"red"</span>)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>plt.hist(X, bins<span class="op">=</span><span class="dv">30</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Parametric vs. Non-Parametric Estimation"</span>)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-11" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-11">Why It Matters</h4>
<p>Parametric methods are powerful when domain knowledge suggests a distribution (e.g., lifetimes ~ exponential, errors ~ Gaussian). Non-parametric shines in exploratory analysis and multimodal data. Knowing when to use each prevents false assumptions, ensures better generalization, and avoids misleading conclusions.</p>
</section>
<section id="try-it-yourself-12" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-12">Try It Yourself</h4>
<ol type="1">
<li>Fit a Gaussian to multimodal data. Does it capture both peaks?</li>
<li>Compare KDE results with different bandwidths to the Gaussian fit.</li>
<li>Apply parametric exponential vs.&nbsp;KDE to model waiting times. Which fits better?</li>
<li>Try Gaussian Mixture Models as a semi-parametric compromise. How do they perform compared to single Gaussian and KDE?</li>
</ol>
</section>
</section>
<section id="gaussian-mixture-models-gmms" class="level3">
<h3 class="anchored" data-anchor-id="gaussian-mixture-models-gmms">814. Gaussian Mixture Models (GMMs)</h3>
<p>A Gaussian Mixture Model assumes that data is generated from a mixture of several Gaussian distributions, each with its own mean and variance. Instead of assigning points to a single cluster, GMMs assign probabilities, making them a soft clustering method. This flexibility allows GMMs to capture overlapping clusters and complex shapes.</p>
<section id="picture-in-your-head-13" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-13">Picture in Your Head</h4>
<p>Imagine a jar filled with marbles from different bags: red, blue, green. If you draw one marble, it might belong mostly to the “red bag” but with some chance it came from “blue.” GMMs estimate both the parameters of each bag (distribution) and the probability that each marble came from which bag.</p>
</section>
<section id="deep-dive-13" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-13">Deep Dive</h4>
<ul>
<li><p>Model Definition: A mixture model with <span class="math inline">\(k\)</span> components:</p>
<p><span class="math display">\[
p(x) = \sum_{i=1}^k \pi_i \, \mathcal{N}(x \mid \mu_i, \Sigma_i)
\]</span></p>
<p>where <span class="math inline">\(\pi_i\)</span> are mixture weights (sum to 1), and <span class="math inline">\(\mu_i, \Sigma_i\)</span> are Gaussian mean and covariance.</p></li>
<li><p>Soft Assignment: Each point has a responsibility vector (probability of belonging to each cluster). Unlike k-Means, which forces hard labels, GMMs capture uncertainty.</p></li>
<li><p>Flexibility: Can model elliptical clusters (via covariance matrices), unlike spherical-only k-Means.</p></li>
<li><p>Fitting: Estimated via Expectation-Maximization (EM):</p>
<ul>
<li><em>E-step:</em> Estimate responsibilities given current parameters.</li>
<li><em>M-step:</em> Update parameters to maximize likelihood.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Feature</th>
<th>k-Means</th>
<th>GMMs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Assignment</td>
<td>Hard</td>
<td>Soft (probabilistic)</td>
</tr>
<tr class="even">
<td>Cluster Shape</td>
<td>Spherical</td>
<td>Elliptical</td>
</tr>
<tr class="odd">
<td>Parameters</td>
<td>Centroids</td>
<td>Mean + covariance</td>
</tr>
<tr class="even">
<td>Algorithm</td>
<td>Minimizes distances</td>
<td>Maximizes likelihood</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_blobs</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.mixture <span class="im">import</span> GaussianMixture</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate synthetic data</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>X, _ <span class="op">=</span> make_blobs(n_samples<span class="op">=</span><span class="dv">500</span>, centers<span class="op">=</span><span class="dv">3</span>, cluster_std<span class="op">=</span>[<span class="fl">0.5</span>, <span class="fl">1.0</span>, <span class="fl">1.5</span>], random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Gaussian Mixture</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>gmm <span class="op">=</span> GaussianMixture(n_components<span class="op">=</span><span class="dv">3</span>, covariance_type<span class="op">=</span><span class="st">'full'</span>, random_state<span class="op">=</span><span class="dv">42</span>).fit(X)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> gmm.predict(X)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot results</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:,<span class="dv">0</span>], X[:,<span class="dv">1</span>], c<span class="op">=</span>labels, cmap<span class="op">=</span><span class="st">"viridis"</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>plt.scatter(gmm.means_[:,<span class="dv">0</span>], gmm.means_[:,<span class="dv">1</span>], c<span class="op">=</span><span class="st">"red"</span>, marker<span class="op">=</span><span class="st">"x"</span>, s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Gaussian Mixture Model Clustering"</span>)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-12" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-12">Why It Matters</h4>
<p>GMMs extend clustering beyond rigid partitions, capturing overlapping groups and uncertainty. They underpin anomaly detection (points with low likelihood), speech recognition (acoustic modeling), and computer vision. Their probabilistic nature makes them a bridge between clustering and full generative modeling.</p>
</section>
<section id="try-it-yourself-13" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-13">Try It Yourself</h4>
<ol type="1">
<li>Compare GMM vs.&nbsp;k-Means on elongated clusters. Which fits better?</li>
<li>Change <code>covariance_type</code> (<code>spherical</code>, <code>diag</code>, <code>tied</code>, <code>full</code>). How do results differ?</li>
<li>Inspect cluster probabilities (<code>gmm.predict_proba</code>). Are some points ambiguous?</li>
<li>Generate multimodal data with different variances. Does GMM capture them accurately?</li>
</ol>
</section>
</section>
<section id="expectation-maximization-for-mixtures" class="level3">
<h3 class="anchored" data-anchor-id="expectation-maximization-for-mixtures">815. Expectation-Maximization for Mixtures</h3>
<p>The Expectation-Maximization (EM) algorithm is the workhorse behind fitting Gaussian Mixture Models (and many other latent variable models). EM alternates between assigning probabilities of cluster membership (Expectation step) and updating parameters to maximize likelihood (Maximization step), repeating until convergence.</p>
<section id="picture-in-your-head-14" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-14">Picture in Your Head</h4>
<p>Think of sorting blurry photos into albums. First, you <em>guess</em> which album each photo belongs to (E-step). Then, you <em>update</em> the description of each album (M-step) based on your guesses. With each round, your assignments and album descriptions improve until they stabilize.</p>
</section>
<section id="deep-dive-14" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-14">Deep Dive</h4>
<ul>
<li><p>E-Step (Expectation): Compute the probability (responsibility) that each data point belongs to each cluster given current parameters.</p>
<p><span class="math display">\[
r_{ik} = \frac{\pi_k \, \mathcal{N}(x_i \mid \mu_k, \Sigma_k)}{\sum_{j=1}^K \pi_j \, \mathcal{N}(x_i \mid \mu_j, \Sigma_j)}
\]</span></p></li>
<li><p>M-Step (Maximization): Update parameters using weighted averages based on responsibilities:</p>
<p><span class="math display">\[
\mu_k = \frac{\sum_i r_{ik} x_i}{\sum_i r_{ik}}, \quad
\Sigma_k = \frac{\sum_i r_{ik} (x_i - \mu_k)(x_i - \mu_k)^T}{\sum_i r_{ik}}, \quad
\pi_k = \frac{1}{N} \sum_i r_{ik}
\]</span></p></li>
<li><p>Convergence: Repeat until log-likelihood stabilizes or changes fall below a threshold.</p></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Step</th>
<th>What Happens</th>
<th>Effect</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>E-step</td>
<td>Assign fractional membership</td>
<td>Captures uncertainty</td>
</tr>
<tr class="even">
<td>M-step</td>
<td>Update means, covariances, weights</td>
<td>Improves likelihood</td>
</tr>
<tr class="odd">
<td>Iterate</td>
<td>Repeat until stable</td>
<td>Finds local optimum</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.mixture <span class="im">import</span> GaussianMixture</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate toy data</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.vstack([</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    np.random.normal([<span class="dv">0</span>,<span class="dv">0</span>], <span class="fl">0.5</span>, (<span class="dv">100</span>,<span class="dv">2</span>)),</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    np.random.normal([<span class="dv">3</span>,<span class="dv">3</span>], <span class="fl">0.5</span>, (<span class="dv">100</span>,<span class="dv">2</span>)),</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    np.random.normal([<span class="dv">0</span>,<span class="dv">4</span>], <span class="fl">0.5</span>, (<span class="dv">100</span>,<span class="dv">2</span>))</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit GMM using EM</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>gmm <span class="op">=</span> GaussianMixture(n_components<span class="op">=</span><span class="dv">3</span>, covariance_type<span class="op">=</span><span class="st">"full"</span>, max_iter<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>gmm.fit(X)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Means:</span><span class="ch">\n</span><span class="st">"</span>, gmm.means_)</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Weights:"</span>, gmm.weights_)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Log-likelihood:"</span>, gmm.score(X))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-13" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-13">Why It Matters</h4>
<p>EM provides a general framework for estimating parameters when data has hidden structure. It is not limited to GMMs: EM powers algorithms in natural language processing (HMMs), computer vision, and genetics. Its iterative “guess and refine” strategy makes it a cornerstone technique in probabilistic modeling.</p>
</section>
<section id="try-it-yourself-14" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-14">Try It Yourself</h4>
<ol type="1">
<li>Fit GMMs with different random initializations. Do they converge to the same solution?</li>
<li>Track log-likelihood at each iteration. Does it always increase?</li>
<li>Try reducing <code>max_iter</code> to 5. How does this affect parameter estimates?</li>
<li>Apply EM to fit a mixture with too many components. What happens to responsibilities and weights?</li>
</ol>
</section>
</section>
<section id="identifiability-and-model-selection-bic-aic" class="level3">
<h3 class="anchored" data-anchor-id="identifiability-and-model-selection-bic-aic">816. Identifiability and Model Selection (BIC, AIC)</h3>
<p>In mixture models like GMMs, one challenge is identifiability—different parameter configurations can explain the data equally well. Another is choosing the right number of components. Information criteria such as AIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion) help balance model fit and complexity.</p>
<section id="picture-in-your-head-15" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-15">Picture in Your Head</h4>
<p>Imagine multiple chefs baking the same cake. One uses more sugar, another adds more flour, yet both cakes taste nearly identical. That’s non-identifiability: different recipes leading to the same outcome. Now, deciding how many cake layers to include is like selecting the number of mixture components. Too few, and it’s plain; too many, and it’s overcomplicated.</p>
</section>
<section id="deep-dive-15" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-15">Deep Dive</h4>
<ul>
<li><p>Identifiability:</p>
<ul>
<li>Label switching: swapping component labels gives identical likelihood.</li>
<li>Redundant components: two Gaussians may overlap and mimic one.</li>
<li>Local optima: EM may settle on different solutions from different initializations.</li>
</ul></li>
<li><p>Model Selection Criteria: Both criteria penalize likelihood with a complexity term:</p>
<ul>
<li><p>AIC:</p>
<p><span class="math display">\[
AIC = 2k - 2 \ln(L)
\]</span></p>
<p>where <span class="math inline">\(k\)</span> = number of parameters, <span class="math inline">\(L\)</span> = max likelihood.</p></li>
<li><p>BIC:</p>
<p><span class="math display">\[
BIC = k \ln(n) - 2 \ln(L)
\]</span></p>
<p>where <span class="math inline">\(n\)</span> = number of data points.</p></li>
<li><p>Lower values indicate better trade-off between fit and simplicity.</p></li>
</ul></li>
<li><p>Comparison:</p>
<ul>
<li>AIC favors more complex models.</li>
<li>BIC is more conservative, especially with large datasets.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Criterion</th>
<th>Penalty Term</th>
<th>Effect on Models</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>AIC</td>
<td><span class="math inline">\(2k\)</span></td>
<td>More clusters tolerated</td>
</tr>
<tr class="even">
<td>BIC</td>
<td><span class="math inline">\(k \ln(n)\)</span></td>
<td>Penalizes extra clusters more heavily</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.mixture <span class="im">import</span> GaussianMixture</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate synthetic data</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.concatenate([</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    np.random.normal(<span class="op">-</span><span class="dv">2</span>, <span class="fl">0.5</span>, <span class="dv">200</span>),</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    np.random.normal(<span class="dv">3</span>, <span class="fl">1.0</span>, <span class="dv">300</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>])[:, <span class="va">None</span>]</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit GMMs with different components</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">6</span>):</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    gmm <span class="op">=</span> GaussianMixture(n_components<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>).fit(X)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"k=</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">: AIC=</span><span class="sc">{</span>gmm<span class="sc">.</span>aic(X)<span class="sc">:.2f}</span><span class="ss">, BIC=</span><span class="sc">{</span>gmm<span class="sc">.</span>bic(X)<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-14" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-14">Why It Matters</h4>
<p>Without careful selection, mixture models risk overfitting (too many clusters) or underfitting (too few). AIC and BIC provide principled ways to balance fit against complexity, guiding practitioners in choosing the right model. This is critical in domains like genomics, NLP, and market segmentation where structure discovery must be both accurate and interpretable.</p>
</section>
<section id="try-it-yourself-15" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-15">Try It Yourself</h4>
<ol type="1">
<li>Fit GMMs with 1–10 components on a dataset. Which k minimizes BIC? Which minimizes AIC?</li>
<li>Add redundant clusters to synthetic data. How do AIC and BIC respond?</li>
<li>Run EM with different random seeds. Do log-likelihoods differ while BIC stays consistent?</li>
<li>Apply AIC/BIC on high-dimensional embeddings. Does dimensionality impact selection?</li>
</ol>
</section>
</section>
<section id="bayesian-mixture-models-and-dirichlet-processes" class="level3">
<h3 class="anchored" data-anchor-id="bayesian-mixture-models-and-dirichlet-processes">817. Bayesian Mixture Models and Dirichlet Processes</h3>
<p>Bayesian mixture models extend classical mixture models by placing priors over parameters, allowing uncertainty to be quantified. A special case, the Dirichlet Process Mixture Model (DPMM), removes the need to predefine the number of clusters, instead letting the data determine how many are needed.</p>
<section id="picture-in-your-head-16" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-16">Picture in Your Head</h4>
<p>Imagine a buffet line with infinitely many dishes. Each new guest (data point) chooses an existing dish with probability proportional to how many people already have it, or tries a brand-new dish with some small probability. This is the Chinese Restaurant Process—a metaphor for how clusters grow dynamically in Bayesian nonparametric models.</p>
</section>
<section id="deep-dive-16" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-16">Deep Dive</h4>
<ul>
<li><p>Bayesian Mixture Models:</p>
<ul>
<li>Parameters (means, variances, weights) have prior distributions.</li>
<li>Posterior distributions capture uncertainty in cluster assignments and parameters.</li>
<li>Inference methods: Gibbs sampling, Variational Inference.</li>
</ul></li>
<li><p>Dirichlet Process (DP):</p>
<ul>
<li>A DP is a distribution over distributions, parameterized by a base distribution <span class="math inline">\(G_0\)</span> and concentration parameter <span class="math inline">\(\alpha\)</span>.</li>
<li>Encourages a flexible number of clusters: small <span class="math inline">\(\alpha\)</span> → few large clusters; large <span class="math inline">\(\alpha\)</span> → many small clusters.</li>
</ul></li>
<li><p>Dirichlet Process Mixture Model (DPMM):</p>
<ul>
<li>Each data point belongs to a cluster drawn from a DP.</li>
<li>Effectively an “infinite mixture model.”</li>
<li>Often used when the true number of groups is unknown.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 28%">
<col style="width: 28%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="header">
<th>Model Type</th>
<th>Assumptions</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Finite GMM</td>
<td>Fixed k clusters</td>
<td>Simple, fast</td>
<td>Must pick k</td>
</tr>
<tr class="even">
<td>Bayesian GMM</td>
<td>Priors on parameters</td>
<td>Uncertainty quantification</td>
<td>More complex inference</td>
</tr>
<tr class="odd">
<td>DPMM (Dirichlet)</td>
<td>Infinite possible clusters</td>
<td>Learns k automatically</td>
<td>Computationally heavy</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, scikit-learn style)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.mixture <span class="im">import</span> BayesianGaussianMixture</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate synthetic data</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.concatenate([</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    np.random.normal(<span class="op">-</span><span class="dv">2</span>, <span class="fl">0.5</span>, <span class="dv">200</span>),</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    np.random.normal(<span class="dv">3</span>, <span class="fl">1.0</span>, <span class="dv">300</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>])[:, <span class="va">None</span>]</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Bayesian Gaussian Mixture (variational inference approximation)</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>bgmm <span class="op">=</span> BayesianGaussianMixture(n_components<span class="op">=</span><span class="dv">10</span>, weight_concentration_prior_type<span class="op">=</span><span class="st">"dirichlet_process"</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>bgmm.fit(X)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated active components:"</span>, np.<span class="bu">sum</span>(bgmm.weights_ <span class="op">&gt;</span> <span class="fl">0.05</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-15" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-15">Why It Matters</h4>
<p>Bayesian mixture models provide a principled framework for uncertainty in clustering. Dirichlet processes are especially valuable when the number of groups is unknown or evolving, such as in topic modeling, customer segmentation, and biological data. This flexibility allows models to grow with data, rather than being constrained by arbitrary choices of k.</p>
</section>
<section id="try-it-yourself-16" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-16">Try It Yourself</h4>
<ol type="1">
<li>Fit a Bayesian Gaussian Mixture with different <code>n_components</code>. Does the model prune unused components?</li>
<li>Change the concentration parameter <span class="math inline">\(\alpha\)</span>. How does it affect the number of clusters?</li>
<li>Compare standard GMM vs.&nbsp;Bayesian GMM on the same dataset. Which gives more stable results?</li>
<li>Apply Bayesian mixtures to text embeddings. Do new semantic clusters emerge naturally?</li>
</ol>
</section>
</section>
<section id="copulas-and-multivariate-densities" class="level3">
<h3 class="anchored" data-anchor-id="copulas-and-multivariate-densities">818. Copulas and Multivariate Densities</h3>
<p>Copulas are mathematical functions that allow us to model dependencies between random variables separately from their marginal distributions. They provide a flexible way to build multivariate distributions by combining arbitrary one-dimensional marginals with a dependence structure.</p>
<section id="picture-in-your-head-17" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-17">Picture in Your Head</h4>
<p>Think of baking a layered cake. Each layer (marginal distribution) can be flavored differently. chocolate, vanilla, strawberry. The copula is the frosting that binds the layers together, controlling how they interact. You can change the frosting without altering the layers, giving freedom to model dependence independently from individual distributions.</p>
</section>
<section id="deep-dive-17" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-17">Deep Dive</h4>
<ul>
<li><p>Sklar’s Theorem: Any multivariate joint distribution <span class="math inline">\(F(x_1, \dots, x_d)\)</span> can be decomposed into:</p>
<p><span class="math display">\[
F(x_1, \dots, x_d) = C(F_1(x_1), \dots, F_d(x_d))
\]</span></p>
<p>where <span class="math inline">\(F_i\)</span> are marginal distributions and <span class="math inline">\(C\)</span> is a copula capturing dependencies.</p></li>
<li><p>Types of Copulas:</p>
<ul>
<li>Gaussian Copula: Based on multivariate normal correlation structure.</li>
<li>t-Copula: Captures tail dependence, useful in finance.</li>
<li>Archimedean Copulas (Clayton, Gumbel, Frank): Flexible families modeling asymmetry and nonlinear dependencies.</li>
</ul></li>
<li><p>Applications:</p>
<ul>
<li>Finance: Modeling asset dependencies, portfolio risk.</li>
<li>Insurance: Joint modeling of claims.</li>
<li>Environmental science: Capturing correlation between rainfall, temperature, wind.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 46%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Copula Type</th>
<th>Strengths</th>
<th>Weaknesses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Gaussian</td>
<td>Simple, well-known correlation</td>
<td>No tail dependence</td>
</tr>
<tr class="even">
<td>t-Copula</td>
<td>Captures heavy tails</td>
<td>More parameters</td>
</tr>
<tr class="odd">
<td>Archimedean</td>
<td>Flexible, asymmetric dependence</td>
<td>Limited to specific forms</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, using copulas library)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> copulas.multivariate <span class="im">import</span> GaussianMultivariate</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate synthetic data</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.random.multivariate_normal([<span class="dv">0</span>,<span class="dv">0</span>], [[<span class="dv">1</span>,<span class="fl">0.8</span>],[<span class="fl">0.8</span>,<span class="dv">1</span>]], size<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Gaussian Copula</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> GaussianMultivariate()</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>model.fit(X)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample new data</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> model.sample(<span class="dv">500</span>)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>plt.scatter(samples.iloc[:,<span class="dv">0</span>], samples.iloc[:,<span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Samples from Gaussian Copula"</span>)</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-16" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-16">Why It Matters</h4>
<p>Copulas are powerful because they decouple marginals from dependence. This means we can model complex, realistic systems where variables have very different individual behaviors but still interact strongly. They are widely used in finance, risk management, and any domain where understanding joint behavior matters more than individual distributions.</p>
</section>
<section id="try-it-yourself-17" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-17">Try It Yourself</h4>
<ol type="1">
<li>Fit a Gaussian copula to two correlated financial returns. Does it reproduce correlation?</li>
<li>Compare Gaussian vs.&nbsp;t-Copula on heavy-tailed data. Which captures extremes better?</li>
<li>Generate synthetic rainfall and temperature data with different marginals but shared dependence.</li>
<li>Use an Archimedean copula (e.g., Clayton) to capture asymmetric relationships.</li>
</ol>
</section>
</section>
<section id="density-estimation-in-high-dimensions" class="level3">
<h3 class="anchored" data-anchor-id="density-estimation-in-high-dimensions">819. Density Estimation in High Dimensions</h3>
<p>Estimating probability densities becomes extremely challenging as the number of dimensions grows. This difficulty, known as the curse of dimensionality, causes data to become sparse and traditional density estimators (like histograms or KDE) to break down. Specialized methods are needed to handle high-dimensional spaces.</p>
<section id="picture-in-your-head-18" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-18">Picture in Your Head</h4>
<p>Imagine sprinkling sand in a box. In 2D, the sand quickly forms visible hills and valleys. In 10D, the sand spreads so thin that every point seems isolated. the “hills” flatten, and it’s hard to tell where the density really lies. High-dimensional density estimation is like trying to map invisible landscapes.</p>
</section>
<section id="deep-dive-18" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-18">Deep Dive</h4>
<ul>
<li><p>Curse of Dimensionality:</p>
<ul>
<li>Volume grows exponentially with dimensions.</li>
<li>Data becomes sparse, requiring exponentially more samples for accurate estimation.</li>
<li>Distances between points become less informative (concentration of measure).</li>
</ul></li>
<li><p>Problems for Classic Estimators:</p>
<ul>
<li>Histograms: Require too many bins.</li>
<li>KDE: Bandwidth selection becomes nearly impossible.</li>
<li>Parametric Models: Risk severe misspecification.</li>
</ul></li>
<li><p>Strategies to Cope:</p>
<ul>
<li>Dimensionality Reduction: Apply PCA, autoencoders, or manifold learning before density estimation.</li>
<li>Structured Models: Use probabilistic graphical models to exploit conditional independencies.</li>
<li>Factorization: Model joint distribution as products of simpler low-dimensional distributions.</li>
<li>Neural Density Estimators: Normalizing flows, autoregressive models (MAF, PixelCNN), energy-based models.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 25%">
<col style="width: 21%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th>Approach</th>
<th>Example Methods</th>
<th>Strengths</th>
<th>Weaknesses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Dim. Reduction + KDE</td>
<td>PCA + KDE</td>
<td>Simple, practical</td>
<td>May lose structure</td>
</tr>
<tr class="even">
<td>Graphical Models</td>
<td>Bayesian networks, MRFs</td>
<td>Capture dependencies</td>
<td>Requires structure knowledge</td>
</tr>
<tr class="odd">
<td>Neural Estimators</td>
<td>Normalizing flows, VAEs</td>
<td>Very flexible</td>
<td>Training complexity</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KernelDensity</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># High-dimensional synthetic data</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, (<span class="dv">1000</span>, <span class="dv">20</span>))  <span class="co"># 20D Gaussian</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Reduce to 2D with PCA before KDE</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>X_reduced <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>).fit_transform(X)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>kde <span class="op">=</span> KernelDensity(kernel<span class="op">=</span><span class="st">"gaussian"</span>, bandwidth<span class="op">=</span><span class="fl">0.5</span>).fit(X_reduced)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>log_density <span class="op">=</span> kde.score_samples(X_reduced[:<span class="dv">10</span>])</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated log density (first 10 pts):"</span>, log_density)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-17" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-17">Why It Matters</h4>
<p>Most modern AI applications involve high-dimensional data: images (thousands of pixels), text embeddings, biological signals. Traditional density estimation fails here, but advanced methods like normalizing flows and VAEs provide scalable solutions. Understanding these challenges helps avoid naïve mistakes and motivates why deep generative models are necessary.</p>
</section>
<section id="try-it-yourself-18" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-18">Try It Yourself</h4>
<ol type="1">
<li>Apply KDE to raw 20D data vs.&nbsp;PCA-reduced 2D data. How do results differ?</li>
<li>Train a VAE on MNIST and use it as a density estimator. Which digits have low likelihood?</li>
<li>Compare distances between random points in 2D vs.&nbsp;100D. What happens?</li>
<li>Build a simple normalizing flow (e.g., RealNVP) and compare its flexibility to Gaussian mixtures.</li>
</ol>
</section>
</section>
<section id="applications-of-density-estimation" class="level3">
<h3 class="anchored" data-anchor-id="applications-of-density-estimation">820. Applications of Density Estimation</h3>
<p>Density estimation provides more than just a mathematical description of data distribution. it enables applications across science, engineering, and business. By knowing where data is likely to occur, we can detect anomalies, simulate new samples, compress information, and support decision-making.</p>
<section id="picture-in-your-head-19" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-19">Picture in Your Head</h4>
<p>Think of a city map showing where people usually gather. Bright areas represent dense neighborhoods (common behaviors), while dark areas mark quiet corners (rare events). Such a density map helps city planners, just as density estimation helps data scientists uncover structure and irregularities.</p>
</section>
<section id="deep-dive-19" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-19">Deep Dive</h4>
<ul>
<li><p>Anomaly Detection: Points in low-density regions are likely anomalies. useful in fraud detection, network security, or medical diagnostics.</p></li>
<li><p>Generative Modeling: Sampling from estimated densities allows creation of synthetic data resembling the real one (e.g., generating plausible handwritten digits).</p></li>
<li><p>Data Compression: Probabilistic models based on density estimation underpin efficient coding schemes like arithmetic coding.</p></li>
<li><p>Simulation &amp; Forecasting: Scientists use density models to simulate weather, financial returns, or biological systems.</p></li>
<li><p>Clustering: Many clustering algorithms rely on density estimation, where clusters correspond to modes (peaks) of the density.</p></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Application</th>
<th>Example Domain</th>
<th>Method Often Used</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Anomaly Detection</td>
<td>Credit card fraud</td>
<td>KDE, GMM</td>
</tr>
<tr class="even">
<td>Generative Models</td>
<td>Image synthesis</td>
<td>Normalizing flows, VAEs</td>
</tr>
<tr class="odd">
<td>Compression</td>
<td>Data transmission</td>
<td>Probabilistic coding</td>
</tr>
<tr class="even">
<td>Simulation</td>
<td>Climate, finance</td>
<td>Parametric + Bayesian</td>
</tr>
<tr class="odd">
<td>Clustering</td>
<td>Customer segmentation</td>
<td>Mean-shift, DBSCAN</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KernelDensity</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: anomaly detection</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.concatenate([</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">500</span>),    <span class="co"># normal data</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    np.random.normal(<span class="dv">8</span>, <span class="fl">0.5</span>, <span class="dv">20</span>)    <span class="co"># anomalies</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>])[:, <span class="va">None</span>]</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit KDE on normal-looking data</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>kde <span class="op">=</span> KernelDensity(kernel<span class="op">=</span><span class="st">"gaussian"</span>, bandwidth<span class="op">=</span><span class="fl">0.5</span>).fit(X)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Score points</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> kde.score_samples(X)</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>anomalies <span class="op">=</span> X[scores <span class="op">&lt;</span> <span class="op">-</span><span class="dv">5</span>]  <span class="co"># thresholding</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Detected anomalies:"</span>, anomalies[:<span class="dv">10</span>].ravel())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-18" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-18">Why It Matters</h4>
<p>Density estimation is a backbone of unsupervised learning and probabilistic AI. It equips practitioners to detect the unexpected, generate realistic simulations, and reason under uncertainty. Its impact spans fraud prevention, climate science, medicine, and next-generation generative AI.</p>
</section>
<section id="try-it-yourself-19" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-19">Try It Yourself</h4>
<ol type="1">
<li>Train a KDE on normal data, then add outliers. Can you detect them by density thresholding?</li>
<li>Sample from a fitted GMM. Does the synthetic data resemble the original?</li>
<li>Use density estimation to compress data: compare entropy before and after.</li>
<li>Apply mean-shift clustering to a dataset. Do the modes align with intuitive groupings?</li>
</ol>
</section>
</section>
</section>
<section id="chapter-83.-matrix-factorization-and-nmf" class="level2">
<h2 class="anchored" data-anchor-id="chapter-83.-matrix-factorization-and-nmf">Chapter 83. Matrix factorization and NMF</h2>
<section id="motivation-for-matrix-factorization" class="level3">
<h3 class="anchored" data-anchor-id="motivation-for-matrix-factorization">821. Motivation for Matrix Factorization</h3>
<p>Matrix factorization is a technique for decomposing a large matrix into the product of smaller matrices, revealing hidden structure in the data. It reduces complexity while preserving essential information, making it a cornerstone in recommender systems, signal processing, and dimensionality reduction.</p>
<section id="picture-in-your-head-20" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-20">Picture in Your Head</h4>
<p>Imagine a huge bookshelf with thousands of books and readers. The full record of which reader likes which book is a massive grid, mostly empty. Matrix factorization is like compressing this bookshelf into two smaller lists: one describing reader preferences, the other describing book themes. Multiplying them back together reconstructs the grid.</p>
</section>
<section id="deep-dive-20" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-20">Deep Dive</h4>
<ul>
<li><p>Why Factorize? Many datasets are too large or sparse to analyze directly. Factorization simplifies them into lower-dimensional representations that capture latent patterns.</p></li>
<li><p>Applications:</p>
<ul>
<li>Recommender Systems: Factorize the user–item rating matrix into latent user and item factors.</li>
<li>Topic Modeling: Factorize a term–document matrix into topics and weights.</li>
<li>Image Compression: Factorize image pixel matrices into basis images and coefficients.</li>
</ul></li>
<li><p>Mathematical Intuition: For a matrix <span class="math inline">\(X \in \mathbb{R}^{m \times n}\)</span>, factorization finds:</p>
<p><span class="math display">\[
X \approx U V^T
\]</span></p>
<p>where <span class="math inline">\(U \in \mathbb{R}^{m \times k}\)</span>, <span class="math inline">\(V \in \mathbb{R}^{n \times k}\)</span>, and <span class="math inline">\(k \ll \min(m,n)\)</span>. Each row of <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> captures low-dimensional features of rows and columns of <span class="math inline">\(X\)</span>.</p></li>
<li><p>Benefits:</p>
<ul>
<li>Dimensionality reduction.</li>
<li>Discovery of latent structure.</li>
<li>Efficient storage and computation.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 34%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th>Domain</th>
<th>Matrix Factorized</th>
<th>Insight Gained</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Recommender System</td>
<td>User–item ratings</td>
<td>Latent preferences &amp; genres</td>
</tr>
<tr class="even">
<td>Text Mining</td>
<td>Document–term matrix</td>
<td>Hidden topics</td>
</tr>
<tr class="odd">
<td>Vision</td>
<td>Image pixel intensities</td>
<td>Basis patterns (e.g., edges)</td>
</tr>
<tr class="even">
<td>Biology</td>
<td>Gene expression matrices</td>
<td>Shared genetic pathways</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> NMF</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Example user-item rating matrix (sparse)</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array([</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">1</span>],</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>],</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">5</span>],</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">4</span>],</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">4</span>]</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply Non-negative Matrix Factorization</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>nmf <span class="op">=</span> NMF(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> nmf.fit_transform(X)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>V <span class="op">=</span> nmf.components_</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"User features:</span><span class="ch">\n</span><span class="st">"</span>, U)</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Item features:</span><span class="ch">\n</span><span class="st">"</span>, V)</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Reconstructed matrix:</span><span class="ch">\n</span><span class="st">"</span>, np.<span class="bu">round</span>(U <span class="op">@</span> V))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-19" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-19">Why It Matters</h4>
<p>Matrix factorization is the backbone of many modern systems. From Netflix recommending movies to scientists uncovering gene networks, it extracts interpretable, compact structure from overwhelming data. By reducing dimensions while keeping patterns, it makes complex systems understandable and actionable.</p>
</section>
<section id="try-it-yourself-20" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-20">Try It Yourself</h4>
<ol type="1">
<li>Factorize a document–term matrix. Do topics emerge?</li>
<li>Change <code>n_components</code> in NMF. How does the reconstruction quality change?</li>
<li>Compare NMF with SVD on the same dataset. Which produces more interpretable factors?</li>
<li>Use matrix factorization on image patches. Do the factors resemble meaningful shapes (edges, textures)?</li>
</ol>
</section>
</section>
<section id="singular-value-decomposition-svd" class="level3">
<h3 class="anchored" data-anchor-id="singular-value-decomposition-svd">822. Singular Value Decomposition (SVD)</h3>
<p>Singular Value Decomposition (SVD) is a powerful linear algebra tool that decomposes any matrix into three components: left singular vectors, singular values, and right singular vectors. It captures the directions of maximum variance and provides a foundation for dimensionality reduction, compression, and latent structure discovery.</p>
<section id="picture-in-your-head-21" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-21">Picture in Your Head</h4>
<p>Imagine shining a light on a 3D object from different angles. SVD finds the best set of axes to describe the object’s shape. Instead of relying on the original messy coordinate system, it rotates and stretches space so the main structure is clear and compact.</p>
</section>
<section id="deep-dive-21" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-21">Deep Dive</h4>
<ul>
<li><p>Mathematical Definition: For a matrix <span class="math inline">\(X \in \mathbb{R}^{m \times n}\)</span>:</p>
<p><span class="math display">\[
X = U \Sigma V^T
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(U \in \mathbb{R}^{m \times m}\)</span>: left singular vectors (orthogonal).</li>
<li><span class="math inline">\(\Sigma \in \mathbb{R}^{m \times n}\)</span>: diagonal matrix of singular values.</li>
<li><span class="math inline">\(V \in \mathbb{R}^{n \times n}\)</span>: right singular vectors (orthogonal).</li>
</ul></li>
<li><p>Interpretation:</p>
<ul>
<li>Singular values measure the “importance” of each component.</li>
<li>Truncating to top-k singular values approximates the original matrix with minimal error (Eckart–Young theorem).</li>
</ul></li>
<li><p>Applications:</p>
<ul>
<li>Latent Semantic Analysis (LSA): Reveals hidden structure in term–document matrices.</li>
<li>Image Compression: Store only top singular values/vectors.</li>
<li>Recommender Systems: Approximate user–item interactions.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Component</th>
<th>Represents</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>U (left vectors)</td>
<td>Basis for rows (e.g., users)</td>
</tr>
<tr class="even">
<td>Σ (singular vals)</td>
<td>Strength of each latent factor</td>
</tr>
<tr class="odd">
<td>V (right vectors)</td>
<td>Basis for columns (e.g., items)</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> TruncatedSVD</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create synthetic matrix</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.random.rand(<span class="dv">10</span>, <span class="dv">8</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Full SVD using NumPy</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>U, S, VT <span class="op">=</span> np.linalg.svd(X, full_matrices<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Singular values:"</span>, S)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Truncated SVD (dimensionality reduction)</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>svd <span class="op">=</span> TruncatedSVD(n_components<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>X_reduced <span class="op">=</span> svd.fit_transform(X)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Reduced shape:"</span>, X_reduced.shape)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-20" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-20">Why It Matters</h4>
<p>SVD is the mathematical backbone of many data science techniques. It reveals latent features in text, compresses high-dimensional images, and underpins algorithms like PCA. Its ability to reduce noise and highlight essential structure makes it indispensable in machine learning and AI.</p>
</section>
<section id="try-it-yourself-21" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-21">Try It Yourself</h4>
<ol type="1">
<li>Perform SVD on an image matrix. Reconstruct using only top 10 singular values. How does it look?</li>
<li>Compare reconstruction error as you increase the number of singular values kept.</li>
<li>Apply SVD to a term–document matrix. Do top components reveal coherent topics?</li>
<li>Use SVD on a user–item rating matrix. Does it group users with similar preferences?</li>
</ol>
</section>
</section>
<section id="low-rank-approximations" class="level3">
<h3 class="anchored" data-anchor-id="low-rank-approximations">823. Low-Rank Approximations</h3>
<p>Low-rank approximation reduces a large, complex matrix into a simpler version that captures its most important structure using fewer dimensions. By keeping only the top singular values and vectors (from SVD), we approximate the original data while discarding noise and redundancy.</p>
<section id="picture-in-your-head-22" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-22">Picture in Your Head</h4>
<p>Think of compressing a detailed photograph into a sketch. The sketch doesn’t preserve every pixel, but it captures the main shapes and contrasts. Low-rank approximations do the same for data matrices: keep the essentials, drop the fine-grain details.</p>
</section>
<section id="deep-dive-22" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-22">Deep Dive</h4>
<ul>
<li><p>Mathematical Basis: From SVD:</p>
<p><span class="math display">\[
X = U \Sigma V^T
\]</span></p>
<p>Keep only the top <span class="math inline">\(k\)</span> singular values and vectors:</p>
<p><span class="math display">\[
X_k = U_k \Sigma_k V_k^T
\]</span></p>
<p>where <span class="math inline">\(X_k\)</span> is the best rank-<span class="math inline">\(k\)</span> approximation of <span class="math inline">\(X\)</span> under Frobenius norm.</p></li>
<li><p>Error Bound (Eckart–Young theorem): The approximation error is minimized by truncating the smallest singular values:</p>
<p><span class="math display">\[
\|X - X_k\|_F^2 = \sum_{i=k+1}^{r} \sigma_i^2
\]</span></p>
<p>where <span class="math inline">\(\sigma_i\)</span> are singular values.</p></li>
<li><p>Applications:</p>
<ul>
<li>Image Compression: Store fewer singular values → smaller files.</li>
<li>Noise Reduction: Ignore small singular values that correspond to noise.</li>
<li>Recommender Systems: Low-rank approximations reveal latent user–item factors.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>k (rank) kept</th>
<th>Effect on Approximation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Small k</td>
<td>Very compressed, more distortion</td>
</tr>
<tr class="even">
<td>Medium k</td>
<td>Balance between compression and detail</td>
</tr>
<tr class="odd">
<td>Large k</td>
<td>High fidelity, less compression</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skimage <span class="im">import</span> data, color</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skimage.transform <span class="im">import</span> resize</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load image (grayscale, small size)</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> color.rgb2gray(data.astronaut())</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> resize(img, (<span class="dv">100</span>, <span class="dv">100</span>))</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="co"># SVD</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>U, S, VT <span class="op">=</span> np.linalg.svd(img, full_matrices<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Low-rank approximation (rank k=20)</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>approx <span class="op">=</span> (U[:, :k] <span class="op">*</span> S[:k]) <span class="op">@</span> VT[:k, :]</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare original vs. approximation</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">3</span>))</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].imshow(img, cmap<span class="op">=</span><span class="st">"gray"</span>)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">"Original"</span>)</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].imshow(approx, cmap<span class="op">=</span><span class="st">"gray"</span>)</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="ss">f"Rank </span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> Approx"</span>)</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-21" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-21">Why It Matters</h4>
<p>Low-rank approximations make massive datasets manageable. They enable compression in computer vision, topic extraction in NLP, and collaborative filtering in recommender systems. By capturing only the dominant structures, they strike a balance between efficiency and interpretability.</p>
</section>
<section id="try-it-yourself-22" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-22">Try It Yourself</h4>
<ol type="1">
<li>Reconstruct an image with ranks 5, 20, and 50. How does quality improve with rank?</li>
<li>Plot reconstruction error vs.&nbsp;rank. Where is the “elbow”?</li>
<li>Apply low-rank approximation to a user–item matrix. Does it reveal hidden preferences?</li>
<li>Use low-rank approximation on noisy data. Does it denoise effectively?</li>
</ol>
</section>
</section>
<section id="non-negative-matrix-factorization-nmf" class="level3">
<h3 class="anchored" data-anchor-id="non-negative-matrix-factorization-nmf">824. Non-Negative Matrix Factorization (NMF)</h3>
<p>Non-Negative Matrix Factorization (NMF) is a variant of matrix factorization where all entries in the factors are constrained to be non-negative. This makes the factors additive and parts-based, which often improves interpretability. especially in domains like text, audio, and images.</p>
<section id="picture-in-your-head-23" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-23">Picture in Your Head</h4>
<p>Imagine building a painting using only additive layers of colored transparencies. You can’t subtract paint, only stack more. NMF works the same way: it represents complex data as combinations of non-negative components, like combining topics in text or instruments in music.</p>
</section>
<section id="deep-dive-23" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-23">Deep Dive</h4>
<ul>
<li><p>Mathematical Formulation: For a non-negative matrix <span class="math inline">\(X \in \mathbb{R}^{m \times n}\)</span>:</p>
<p><span class="math display">\[
X \approx WH
\]</span></p>
<p>where <span class="math inline">\(W \in \mathbb{R}^{m \times k}, H \in \mathbb{R}^{k \times n}\)</span>, and <span class="math inline">\(W, H \geq 0\)</span>.</p>
<ul>
<li><span class="math inline">\(W\)</span>: basis matrix (parts or topics).</li>
<li><span class="math inline">\(H\)</span>: coefficient matrix (weights for reconstruction).</li>
</ul></li>
<li><p>Optimization: Minimize reconstruction error with non-negativity constraints:</p>
<p><span class="math display">\[
\min_{W, H \geq 0} \|X - WH\|_F^2
\]</span></p>
<p>Commonly solved with multiplicative updates or alternating minimization.</p></li>
<li><p>Interpretability:</p>
<ul>
<li>In text: documents = sum of topics, topics = sum of words.</li>
<li>In images: faces = sum of parts (eyes, nose, mouth).</li>
<li>In audio: signals = sum of instrument components.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 24%">
<col style="width: 33%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>PCA/SVD</th>
<th>NMF</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Values</td>
<td>Can be negative</td>
<td>Non-negative only</td>
</tr>
<tr class="even">
<td>Representation</td>
<td>Subtractive + additive</td>
<td>Purely additive</td>
</tr>
<tr class="odd">
<td>Interpretability</td>
<td>Harder to interpret</td>
<td>More intuitive, parts-based</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> NMF</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Toy document-term matrix</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array([</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>],</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">0</span>],</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">4</span>, <span class="dv">5</span>],</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">4</span>]</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Factorize into 2 topics</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>nmf <span class="op">=</span> NMF(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> nmf.fit_transform(X)</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>H <span class="op">=</span> nmf.components_</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Basis (topics):</span><span class="ch">\n</span><span class="st">"</span>, H)</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Document mixtures:</span><span class="ch">\n</span><span class="st">"</span>, W)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-22" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-22">Why It Matters</h4>
<p>NMF is widely used for topic modeling, bioinformatics, and signal separation because it provides interpretable, sparse representations. Its non-negativity mirrors real-world constraints (you can’t have negative word counts or negative pixels), making results more meaningful than PCA or SVD in many domains.</p>
</section>
<section id="try-it-yourself-23" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-23">Try It Yourself</h4>
<ol type="1">
<li>Apply NMF to a document–term matrix. Do the components resemble coherent topics?</li>
<li>Use NMF on face images. Do the basis vectors look like parts of faces?</li>
<li>Compare NMF to PCA on the same dataset. Which produces more interpretable factors?</li>
<li>Try different numbers of components <span class="math inline">\(k\)</span>. How does interpretability change?</li>
</ol>
</section>
</section>
<section id="probabilistic-matrix-factorization-pmf" class="level3">
<h3 class="anchored" data-anchor-id="probabilistic-matrix-factorization-pmf">825. Probabilistic Matrix Factorization (PMF)</h3>
<p>Probabilistic Matrix Factorization (PMF) extends classical matrix factorization into a probabilistic framework. Instead of treating factorization as a purely algebraic decomposition, PMF models observed entries as generated from latent factors with uncertainty, allowing principled handling of missing data and noise.</p>
<section id="picture-in-your-head-24" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-24">Picture in Your Head</h4>
<p>Imagine rating movies on a streaming service. You haven’t rated most films, but your preferences still exist in the background. PMF treats each rating as a noisy glimpse into hidden user and movie traits, filling in the blanks with probabilities instead of fixed guesses.</p>
</section>
<section id="deep-dive-24" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-24">Deep Dive</h4>
<ul>
<li><p>Generative Model: For a user–item rating matrix <span class="math inline">\(R \in \mathbb{R}^{m \times n}\)</span>:</p>
<ul>
<li><p>Each user <span class="math inline">\(u_i \in \mathbb{R}^k\)</span> and item <span class="math inline">\(v_j \in \mathbb{R}^k\)</span> are latent vectors.</p></li>
<li><p>Rating:</p>
<p><span class="math display">\[
r_{ij} \sim \mathcal{N}(u_i^T v_j, \sigma^2)
\]</span></p></li>
</ul></li>
<li><p>Assumptions:</p>
<ul>
<li>Ratings are conditionally independent given latent factors.</li>
<li>Gaussian noise accounts for variability.</li>
</ul></li>
<li><p>Learning:</p>
<ul>
<li>Optimize likelihood (or MAP with priors).</li>
<li>Gradient descent or Bayesian inference (MCMC, variational).</li>
</ul></li>
<li><p>Advantages:</p>
<ul>
<li>Handles missing entries naturally.</li>
<li>Provides uncertainty estimates.</li>
<li>Can be extended with hierarchical priors (Bayesian PMF).</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 27%">
<col style="width: 32%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="header">
<th>Factorization Type</th>
<th>Nature</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Classical MF</td>
<td>Deterministic</td>
<td>Simple, fast</td>
<td>No uncertainty</td>
</tr>
<tr class="even">
<td>PMF</td>
<td>Probabilistic (Gaussian)</td>
<td>Handles noise, missing data</td>
<td>More complex</td>
</tr>
<tr class="odd">
<td>Bayesian PMF</td>
<td>Priors on factors</td>
<td>Avoids overfitting, flexible</td>
<td>Heavier inference</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, PyMC Example)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Toy user-item matrix with missing values</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>R <span class="op">=</span> np.array([</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">5</span>, <span class="dv">3</span>, np.nan, <span class="dv">1</span>],</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">4</span>, np.nan, np.nan, <span class="dv">1</span>],</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">1</span>, <span class="dv">1</span>, np.nan, <span class="dv">5</span>],</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>    [np.nan, np.nan, <span class="dv">5</span>, <span class="dv">4</span>],</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>num_users, num_items <span class="op">=</span> R.shape</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">2</span>  <span class="co"># latent dimension</span></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    U <span class="op">=</span> pm.Normal(<span class="st">"U"</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">1</span>, shape<span class="op">=</span>(num_users, k))</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>    V <span class="op">=</span> pm.Normal(<span class="st">"V"</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">1</span>, shape<span class="op">=</span>(num_items, k))</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>    R_hat <span class="op">=</span> pm.Deterministic(<span class="st">"R_hat"</span>, U <span class="op">@</span> V.T)</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>    observed_idx <span class="op">=</span> <span class="op">~</span>np.isnan(R)</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>    pm.Normal(<span class="st">"obs"</span>, mu<span class="op">=</span>R_hat[observed_idx], sigma<span class="op">=</span><span class="fl">0.5</span>, observed<span class="op">=</span>R[observed_idx])</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>    trace <span class="op">=</span> pm.sample(<span class="dv">500</span>, tune<span class="op">=</span><span class="dv">500</span>, chains<span class="op">=</span><span class="dv">2</span>, target_accept<span class="op">=</span><span class="fl">0.9</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-23" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-23">Why It Matters</h4>
<p>PMF powers modern recommender systems by providing uncertainty-aware predictions. It avoids overfitting sparse data, improves personalization, and integrates naturally with Bayesian extensions. This probabilistic framing also connects matrix factorization with the broader field of graphical models.</p>
</section>
<section id="try-it-yourself-24" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-24">Try It Yourself</h4>
<ol type="1">
<li>Train PMF with different latent dimensions <span class="math inline">\(k\)</span>. How does prediction accuracy change?</li>
<li>Compare PMF vs.&nbsp;classical MF on a dataset with many missing values. Which performs better?</li>
<li>Add priors on latent factors (Bayesian PMF). Does this improve stability?</li>
<li>Apply PMF to implicit feedback data (clicks instead of ratings). Does it still uncover meaningful patterns?</li>
</ol>
</section>
</section>
<section id="alternating-least-squares-and-gradient-methods" class="level3">
<h3 class="anchored" data-anchor-id="alternating-least-squares-and-gradient-methods">826. Alternating Least Squares and Gradient Methods</h3>
<p>Matrix factorization problems are typically solved by optimization. Two major strategies are Alternating Least Squares (ALS) and Gradient-Based Methods. ALS solves one factor at a time with closed-form least-squares solutions, while gradient methods update both factors iteratively with stochastic or batch gradients.</p>
<section id="picture-in-your-head-25" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-25">Picture in Your Head</h4>
<p>Think of tuning a guitar. With ALS, you fix one string, tune the others to it, then switch. With gradient descent, you tune all strings gradually together, nudging them toward harmony. Both reach a playable tune, but through different processes.</p>
</section>
<section id="deep-dive-25" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-25">Deep Dive</h4>
<ul>
<li><p>Alternating Least Squares (ALS):</p>
<ul>
<li>Fix <span class="math inline">\(V\)</span>, solve for <span class="math inline">\(U\)</span> using least squares.</li>
<li>Fix <span class="math inline">\(U\)</span>, solve for <span class="math inline">\(V\)</span>.</li>
<li>Repeat until convergence.</li>
<li>Works well with sparse matrices (can ignore missing values directly).</li>
<li>Popular in large-scale recommender systems (e.g., Spark MLlib).</li>
</ul></li>
<li><p>Gradient Descent Methods:</p>
<ul>
<li><p>Define loss function (e.g., squared error with regularization):</p>
<p><span class="math display">\[
L = \sum_{(i,j) \in \Omega} (r_{ij} - u_i^T v_j)^2 + \lambda (||u_i||^2 + ||v_j||^2)
\]</span></p></li>
<li><p>Update via gradient descent (SGD, Adam, etc.).</p></li>
<li><p>Scales well, flexible, but requires careful learning-rate tuning.</p></li>
</ul></li>
<li><p>Comparison:</p></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 46%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Strengths</th>
<th>Weaknesses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ALS</td>
<td>Closed-form updates, handles sparsity well, parallelizable</td>
<td>Requires solving linear systems, slower for dense data</td>
</tr>
<tr class="even">
<td>SGD</td>
<td>Flexible, efficient on huge data, online learning</td>
<td>Sensitive to hyperparameters, may converge slowly</td>
</tr>
<tr class="odd">
<td>Adam/Variants</td>
<td>Adaptive learning rates, fast convergence</td>
<td>Heavier memory use</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Toy rating matrix (sparse)</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>R <span class="op">=</span> np.array([</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">1</span>],</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>],</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">5</span>],</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">4</span>],</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">4</span>]</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>num_users, num_items <span class="op">=</span> R.shape</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> np.random.rand(num_users, k)</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>V <span class="op">=</span> np.random.rand(num_items, k)</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>lambda_reg <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple SGD updates</span></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_users):</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(num_items):</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> R[i, j] <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>                err <span class="op">=</span> R[i, j] <span class="op">-</span> U[i, :] <span class="op">@</span> V[j, :].T</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>                U[i, :] <span class="op">+=</span> lr <span class="op">*</span> (err <span class="op">*</span> V[j, :] <span class="op">-</span> lambda_reg <span class="op">*</span> U[i, :])</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>                V[j, :] <span class="op">+=</span> lr <span class="op">*</span> (err <span class="op">*</span> U[i, :] <span class="op">-</span> lambda_reg <span class="op">*</span> V[j, :])</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted matrix:</span><span class="ch">\n</span><span class="st">"</span>, np.<span class="bu">round</span>(U <span class="op">@</span> V.T, <span class="dv">2</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-24" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-24">Why It Matters</h4>
<p>ALS and gradient-based methods are the workhorses of practical matrix factorization. ALS dominates large recommender systems (Netflix, Spotify) due to its robustness on sparse data, while gradient descent powers deep learning integrations and online personalization. Knowing both approaches ensures the right choice for scalability, accuracy, and system constraints.</p>
</section>
<section id="try-it-yourself-25" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-25">Try It Yourself</h4>
<ol type="1">
<li>Implement ALS by alternating updates for <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span>. Compare speed vs.&nbsp;SGD.</li>
<li>Experiment with different learning rates in SGD. How does convergence change?</li>
<li>Add L2 regularization. Does it improve generalization?</li>
<li>Use mini-batch SGD instead of full loops. How does runtime scale?</li>
</ol>
</section>
</section>
<section id="regularization-in-factorization" class="level3">
<h3 class="anchored" data-anchor-id="regularization-in-factorization">827. Regularization in Factorization</h3>
<p>Regularization prevents matrix factorization models from overfitting sparse and noisy data. By penalizing overly large latent factors, regularization ensures the learned representations generalize beyond the observed entries, which is especially critical in recommender systems with limited ratings per user or item.</p>
<section id="picture-in-your-head-26" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-26">Picture in Your Head</h4>
<p>Imagine trying to balance weights on a scale. Without regulation, some weights get too heavy and dominate. Regularization is like placing gentle springs that pull weights back toward the center, keeping the system stable and balanced.</p>
</section>
<section id="deep-dive-26" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-26">Deep Dive</h4>
<ul>
<li><p>Problem Without Regularization:</p>
<ul>
<li>Latent factors can grow arbitrarily large to minimize error on training data.</li>
<li>Leads to poor generalization on unseen entries.</li>
</ul></li>
<li><p>Common Regularization Forms:</p>
<ul>
<li><p>L2 (Ridge): Penalizes squared magnitude of factors.</p>
<p><span class="math display">\[
L = \sum_{(i,j)\in \Omega} (r_{ij} - u_i^T v_j)^2 + \lambda \left(\|U\|_F^2 + \|V\|_F^2\right)
\]</span></p>
<p>Encourages small, smooth factors.</p></li>
<li><p>L1 (Lasso): Penalizes absolute values. Promotes sparsity in latent factors, useful when only a few features matter.</p></li>
<li><p>Elastic Net: Combines L1 and L2 for balanced smoothness and sparsity.</p></li>
</ul></li>
<li><p>Bias Terms: Adding user and item bias terms prevents factors from compensating for global shifts:</p>
<p><span class="math display">\[
r_{ij} \approx \mu + b_i + c_j + u_i^T v_j
\]</span></p></li>
<li><p>Hyperparameter Tuning: <span class="math inline">\(\lambda\)</span> controls strength. Small → risk of overfitting, large → underfitting.</p></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 29%">
<col style="width: 35%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th>Regularization Type</th>
<th>Effect on Factors</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>L2</td>
<td>Shrinks values smoothly</td>
<td>Standard recommender MF</td>
</tr>
<tr class="even">
<td>L1</td>
<td>Produces sparse factors</td>
<td>Feature selection</td>
</tr>
<tr class="odd">
<td>Elastic Net</td>
<td>Balance of both</td>
<td>Complex data patterns</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Toy rating matrix</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>R <span class="op">=</span> np.array([</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">1</span>],</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>],</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">5</span>],</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">4</span>],</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">4</span>]</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>num_users, num_items <span class="op">=</span> R.shape</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> np.random.rand(num_users, k)</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>V <span class="op">=</span> np.random.rand(num_items, k)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>lambda_reg <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a><span class="co"># SGD with L2 regularization</span></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">500</span>):</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_users):</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(num_items):</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> R[i, j] <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>                err <span class="op">=</span> R[i, j] <span class="op">-</span> U[i, :] <span class="op">@</span> V[j, :].T</span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>                U[i, :] <span class="op">+=</span> lr <span class="op">*</span> (err <span class="op">*</span> V[j, :] <span class="op">-</span> lambda_reg <span class="op">*</span> U[i, :])</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>                V[j, :] <span class="op">+=</span> lr <span class="op">*</span> (err <span class="op">*</span> U[i, :] <span class="op">-</span> lambda_reg <span class="op">*</span> V[j, :])</span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted matrix:</span><span class="ch">\n</span><span class="st">"</span>, np.<span class="bu">round</span>(U <span class="op">@</span> V.T, <span class="dv">2</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-25" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-25">Why It Matters</h4>
<p>Regularization is the guardrail of factorization. Without it, models memorize noise in sparse data. With it, models generalize, making robust predictions. This balance is critical in real-world systems like Netflix, Amazon, or Spotify, where data is incomplete and highly imbalanced.</p>
</section>
<section id="try-it-yourself-26" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-26">Try It Yourself</h4>
<ol type="1">
<li>Train MF with no regularization, then with <span class="math inline">\(\lambda=0.1\)</span>. Compare predictions.</li>
<li>Add L1 regularization manually. Do many latent features shrink to zero?</li>
<li>Include user/item bias terms. Does RMSE improve?</li>
<li>Tune <span class="math inline">\(\lambda\)</span> across a grid. Where is the sweet spot between under- and overfitting?</li>
</ol>
</section>
</section>
<section id="interpretability-of-factorized-components" class="level3">
<h3 class="anchored" data-anchor-id="interpretability-of-factorized-components">828. Interpretability of Factorized Components</h3>
<p>Matrix factorization not only reduces dimensionality but also reveals latent components that can be interpreted as meaningful patterns. Interpretability makes factorization more than a compression tool. it becomes a window into hidden structure, such as topics in text, genres in movies, or biological processes in gene data.</p>
<section id="picture-in-your-head-27" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-27">Picture in Your Head</h4>
<p>Imagine mixing paint colors. Each final color (observed data) is made from a few base pigments (latent factors). Matrix factorization uncovers those hidden pigments, letting us understand what fundamental pieces create the observed patterns.</p>
</section>
<section id="deep-dive-27" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-27">Deep Dive</h4>
<ul>
<li><p>Interpretable Latent Factors:</p>
<ul>
<li>Recommender Systems: Latent factors align with tastes like “prefers romance vs.&nbsp;action” in movies.</li>
<li>Topic Models: NMF applied to documents uncovers topics (clusters of words).</li>
<li>Vision: Factorization of face images often yields basis vectors resembling eyes, noses, and mouths.</li>
</ul></li>
<li><p>Constraints for Interpretability:</p>
<ul>
<li>Non-negativity (NMF): Ensures additive, parts-based decomposition.</li>
<li>Sparsity: Forces each data point to use fewer factors → easier to interpret.</li>
<li>Orthogonality: Reduces overlap between components.</li>
</ul></li>
<li><p>Evaluation of Interpretability:</p>
<ul>
<li>Qualitative: Human inspection of topics, image bases, etc.</li>
<li>Quantitative: Topic coherence in NLP, sparsity measures, entropy of factor distributions.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Method</th>
<th>Interpretability Boost</th>
<th>Example Domain</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>NMF</td>
<td>Additive, non-negative</td>
<td>Topic modeling, vision</td>
</tr>
<tr class="even">
<td>Sparse MF</td>
<td>Compact representations</td>
<td>Bioinformatics</td>
</tr>
<tr class="odd">
<td>Orthogonal MF</td>
<td>Distinct features</td>
<td>Signal processing</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> NMF</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Toy term-document matrix</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array([</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>],  <span class="co"># about sports</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>],</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">4</span>, <span class="dv">5</span>],  <span class="co"># about science</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">4</span>]</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>nmf <span class="op">=</span> NMF(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> nmf.fit_transform(X)</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>H <span class="op">=</span> nmf.components_</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Document-topic matrix:</span><span class="ch">\n</span><span class="st">"</span>, np.<span class="bu">round</span>(W, <span class="dv">2</span>))</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Topic-word matrix:</span><span class="ch">\n</span><span class="st">"</span>, np.<span class="bu">round</span>(H, <span class="dv">2</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-26" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-26">Why It Matters</h4>
<p>Interpretability bridges the gap between raw computation and actionable insights. Businesses want to know <em>why</em> an algorithm recommends a movie, not just <em>what</em> it recommends. Scientists want to see meaningful biological pathways, not arbitrary factors. Making latent components interpretable builds trust and accelerates discovery.</p>
</section>
<section id="try-it-yourself-27" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-27">Try It Yourself</h4>
<ol type="1">
<li>Apply NMF to a set of news articles. Do topics align with human-understandable themes?</li>
<li>Compare PCA vs.&nbsp;NMF on text data. Which produces more interpretable factors?</li>
<li>Add sparsity regularization in NMF. Does it improve clarity of topics?</li>
<li>Factorize facial images. Do components resemble meaningful parts?</li>
</ol>
</section>
</section>
<section id="matrix-factorization-for-recommender-systems" class="level3">
<h3 class="anchored" data-anchor-id="matrix-factorization-for-recommender-systems">829. Matrix Factorization for Recommender Systems</h3>
<p>Matrix factorization is the backbone of many recommender systems. It decomposes the user–item interaction matrix into latent user preferences and item attributes, allowing personalized predictions even when most entries are missing.</p>
<section id="picture-in-your-head-28" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-28">Picture in Your Head</h4>
<p>Think of a giant movie–viewer table where most cells are blank. Matrix factorization fills in those blanks by uncovering hidden “taste axes” (e.g., romance vs.&nbsp;action, mainstream vs.&nbsp;niche) for users and movies. Matching users and movies along these hidden axes predicts ratings.</p>
</section>
<section id="deep-dive-28" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-28">Deep Dive</h4>
<ul>
<li><p>User–Item Matrix: Rows = users, columns = items (e.g., movies, songs, products). Entries = explicit ratings (1–5 stars) or implicit signals (clicks, watch time).</p></li>
<li><p>Factorization Model:</p>
<p><span class="math display">\[
r_{ij} \approx u_i^T v_j
\]</span></p>
<p>where <span class="math inline">\(u_i\)</span> = latent user vector, <span class="math inline">\(v_j\)</span> = latent item vector.</p></li>
<li><p>Bias Terms: Improves accuracy by accounting for global effects:</p>
<p><span class="math display">\[
r_{ij} \approx \mu + b_i + c_j + u_i^T v_j
\]</span></p>
<ul>
<li><span class="math inline">\(\mu\)</span>: global average rating.</li>
<li><span class="math inline">\(b_i\)</span>: user bias (e.g., some users rate higher).</li>
<li><span class="math inline">\(c_j\)</span>: item bias (e.g., some movies are universally loved).</li>
</ul></li>
<li><p>Learning:</p>
<ul>
<li>ALS and SGD are common optimization methods.</li>
<li>Regularization prevents overfitting on sparse data.</li>
</ul></li>
<li><p>Extensions:</p>
<ul>
<li>Implicit Feedback Models (Hu, Koren, Volinsky).</li>
<li>Temporal Dynamics (factorization with time-aware biases).</li>
<li>Hybrid Models (factorization + content-based features).</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Feature</th>
<th>Classical MF</th>
<th>Recommender Adaptation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Input</td>
<td>Complete matrix</td>
<td>Sparse user–item matrix</td>
</tr>
<tr class="even">
<td>Bias handling</td>
<td>Not included</td>
<td>Essential (global, user, item)</td>
</tr>
<tr class="odd">
<td>Training</td>
<td>Dense least squares</td>
<td>Sparse ALS or SGD</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example user-item rating matrix (0 = missing)</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>R <span class="op">=</span> np.array([</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">1</span>],</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>],</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">5</span>],</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">4</span>],</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">4</span>]</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>num_users, num_items <span class="op">=</span> R.shape</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> np.random.rand(num_users, k)</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>V <span class="op">=</span> np.random.rand(num_items, k)</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>lr, reg <span class="op">=</span> <span class="fl">0.01</span>, <span class="fl">0.1</span></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple SGD loop</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_users):</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(num_items):</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> R[i, j] <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>                err <span class="op">=</span> R[i, j] <span class="op">-</span> U[i] <span class="op">@</span> V[j].T</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>                U[i] <span class="op">+=</span> lr <span class="op">*</span> (err <span class="op">*</span> V[j] <span class="op">-</span> reg <span class="op">*</span> U[i])</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>                V[j] <span class="op">+=</span> lr <span class="op">*</span> (err <span class="op">*</span> U[i] <span class="op">-</span> reg <span class="op">*</span> V[j])</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted Ratings:</span><span class="ch">\n</span><span class="st">"</span>, np.<span class="bu">round</span>(U <span class="op">@</span> V.T, <span class="dv">2</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-27" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-27">Why It Matters</h4>
<p>Matrix factorization made personalized recommendation at scale feasible. powering systems like Netflix, Amazon, and Spotify. It uncovers hidden relationships in sparse, high-dimensional data, enabling accurate predictions and personalization even with millions of users and items.</p>
</section>
<section id="try-it-yourself-28" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-28">Try It Yourself</h4>
<ol type="1">
<li>Train MF on MovieLens dataset. Compare RMSE with and without bias terms.</li>
<li>Use implicit feedback (clicks, views) instead of ratings. Does performance drop?</li>
<li>Add temporal biases (time-aware factorization). Does it capture evolving tastes?</li>
<li>Compare MF with nearest-neighbor recommenders. Which scales better?</li>
</ol>
</section>
</section>
<section id="beyond-matrices-tensor-factorization" class="level3">
<h3 class="anchored" data-anchor-id="beyond-matrices-tensor-factorization">830. Beyond Matrices: Tensor Factorization</h3>
<p>While matrix factorization deals with two-dimensional data (rows × columns), many real-world datasets are naturally multi-dimensional. Tensor factorization generalizes matrix factorization to higher-order arrays, enabling the discovery of latent structure across multiple modes (e.g., users × items × time).</p>
<section id="picture-in-your-head-29" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-29">Picture in Your Head</h4>
<p>Think of a cube of data instead of a flat sheet. Each slice along one axis gives a different view. for example, how different users rate different movies at different times. Tensor factorization breaks this cube into smaller building blocks, revealing hidden patterns that span across all dimensions.</p>
</section>
<section id="deep-dive-29" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-29">Deep Dive</h4>
<ul>
<li><p>Tensor Basics: A tensor is a multi-way array (2D = matrix, 3D = cube, higher-D = hypercube). Factorization expresses it as combinations of low-rank components.</p></li>
<li><p>Common Methods:</p>
<ul>
<li><p>CANDECOMP/PARAFAC (CP) Decomposition:</p>
<p><span class="math display">\[
X \approx \sum_{r=1}^k a_r \otimes b_r \otimes c_r
\]</span></p>
<p>Decomposes tensor into sum of rank-1 components.</p></li>
<li><p>Tucker Decomposition: Generalizes SVD with a core tensor and factor matrices, capturing interactions between components.</p></li>
</ul></li>
<li><p>Applications:</p>
<ul>
<li>Recommender Systems: Model user × item × time (dynamic preferences).</li>
<li>Signal Processing: Separate overlapping signals in multi-sensor data.</li>
<li>Computer Vision: Analyze video as a tensor (height × width × time).</li>
<li>Healthcare: Patient × symptoms × time for disease progression.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Factorization</th>
<th>Structure</th>
<th>Analogy to Matrices</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>CP</td>
<td>Rank-1 sums</td>
<td>Like low-rank SVD</td>
</tr>
<tr class="even">
<td>Tucker</td>
<td>Core + factors</td>
<td>Like PCA with rotations</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorly <span class="im">as</span> tl</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorly.decomposition <span class="im">import</span> parafac</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create synthetic 3D tensor: users × items × time</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> np.random.rand(<span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">3</span>)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="co"># CP decomposition (rank=2)</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>factors <span class="op">=</span> parafac(tensor, rank<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"User factors:</span><span class="ch">\n</span><span class="st">"</span>, factors[<span class="dv">0</span>])</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Item factors:</span><span class="ch">\n</span><span class="st">"</span>, factors[<span class="dv">1</span>])</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Time factors:</span><span class="ch">\n</span><span class="st">"</span>, factors[<span class="dv">2</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-28" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-28">Why It Matters</h4>
<p>Tensor factorization captures richer, multi-dimensional relationships that matrices cannot. This makes it invaluable for modeling temporal dynamics, context, and multimodal data. It extends the reach of factorization from simple collaborative filtering to dynamic, context-aware, and complex systems.</p>
</section>
<section id="try-it-yourself-29" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-29">Try It Yourself</h4>
<ol type="1">
<li>Apply CP decomposition to a user × item × time tensor. Do patterns change over time?</li>
<li>Compare CP vs.&nbsp;Tucker decomposition. Which is easier to interpret?</li>
<li>Use tensor factorization on video data (frames as slices). Can it compress motion patterns?</li>
<li>Model healthcare data with tensors. Do latent factors capture disease progression stages?</li>
</ol>
</section>
</section>
</section>
<section id="chapter-84.-dimensionality-reduction-pcal-sne-umap" class="level2">
<h2 class="anchored" data-anchor-id="chapter-84.-dimensionality-reduction-pcal-sne-umap">Chapter 84. Dimensionality reduction (PCA,l-SNE, UMAP)</h2>
<section id="motivation-for-dimensionality-reduction" class="level3">
<h3 class="anchored" data-anchor-id="motivation-for-dimensionality-reduction">831. Motivation for Dimensionality Reduction</h3>
<p>Dimensionality reduction transforms high-dimensional data into a lower-dimensional representation while preserving as much structure as possible. It combats the curse of dimensionality, reduces noise, and enables visualization and efficient learning on complex datasets.</p>
<section id="picture-in-your-head-30" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-30">Picture in Your Head</h4>
<p>Imagine trying to understand a sprawling 1,000-page book. Instead of reading every word, you create a concise summary that captures the key storylines. Dimensionality reduction is that summary: a compressed version of data that keeps the essence without the overload.</p>
</section>
<section id="deep-dive-30" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-30">Deep Dive</h4>
<ul>
<li><p>Challenges in High Dimensions:</p>
<ul>
<li>Distances become less meaningful (concentration of measure).</li>
<li>Models overfit easily due to sparsity.</li>
<li>Visualization is impossible beyond 3D.</li>
</ul></li>
<li><p>Benefits of Dimensionality Reduction:</p>
<ul>
<li>Noise Reduction: Removes irrelevant features.</li>
<li>Compression: Saves storage and computation.</li>
<li>Visualization: Projects data into 2D or 3D for exploration.</li>
<li>Improved Learning: Makes models faster and sometimes more accurate.</li>
</ul></li>
<li><p>Approaches:</p>
<ul>
<li>Linear Methods: PCA, LDA.</li>
<li>Nonlinear Methods: t-SNE, UMAP, Isomap.</li>
<li>Neural Methods: Autoencoders, variational embeddings.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 28%">
<col style="width: 22%">
<col style="width: 49%">
</colgroup>
<thead>
<tr class="header">
<th>Goal</th>
<th>Example Method</th>
<th>Advantage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Reduce noise</td>
<td>PCA</td>
<td>Keeps major variance directions</td>
</tr>
<tr class="even">
<td>Preserve structure</td>
<td>t-SNE, UMAP</td>
<td>Captures nonlinear manifolds</td>
</tr>
<tr class="odd">
<td>Interpret features</td>
<td>LDA, NMF</td>
<td>Human-readable components</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_digits</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load digits dataset (64D)</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>digits <span class="op">=</span> load_digits()</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> digits.data</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Reduce to 2D</span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>X_reduced <span class="op">=</span> pca.fit_transform(X)</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_reduced[:,<span class="dv">0</span>], X_reduced[:,<span class="dv">1</span>], c<span class="op">=</span>digits.target, cmap<span class="op">=</span><span class="st">"tab10"</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Digits Data Reduced with PCA"</span>)</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-29" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-29">Why It Matters</h4>
<p>Dimensionality reduction is essential in modern AI. It enables working with embeddings, visualizing high-dimensional structures, and improving generalization. Without it, most real-world tasks. from image recognition to genomic analysis. would be computationally infeasible and conceptually opaque.</p>
</section>
<section id="try-it-yourself-30" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-30">Try It Yourself</h4>
<ol type="1">
<li>Apply PCA to a high-dimensional dataset and plot the explained variance ratio. How many components are enough?</li>
<li>Compare PCA vs.&nbsp;t-SNE on the same dataset. Which preserves clusters better?</li>
<li>Use dimensionality reduction as preprocessing before classification. Does accuracy improve?</li>
<li>Try autoencoders for dimensionality reduction. How do they differ from PCA?</li>
</ol>
</section>
</section>
<section id="principal-component-analysis-pca-basics" class="level3">
<h3 class="anchored" data-anchor-id="principal-component-analysis-pca-basics">832. Principal Component Analysis (PCA) Basics</h3>
<p>Principal Component Analysis (PCA) is the most widely used dimensionality reduction technique. It finds new axes (principal components) that capture the maximum variance in the data, projecting high-dimensional data onto a smaller subspace while retaining its most important patterns.</p>
<section id="picture-in-your-head-31" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-31">Picture in Your Head</h4>
<p>Imagine spinning a cloud of points in 3D space. PCA finds the best orientation so that, when projected onto fewer dimensions, the shadow retains the maximum spread of points. It’s like turning a flashlight until the shadow shows the clearest outline.</p>
</section>
<section id="deep-dive-31" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-31">Deep Dive</h4>
<ul>
<li><p>Mathematical Formulation:</p>
<ul>
<li><p>Center data: subtract mean.</p></li>
<li><p>Compute covariance matrix:</p>
<p><span class="math display">\[
\Sigma = \frac{1}{n} X^T X
\]</span></p></li>
<li><p>Find eigenvalues/eigenvectors of <span class="math inline">\(\Sigma\)</span>.</p></li>
<li><p>Principal components = top eigenvectors.</p></li>
<li><p>Explained variance = eigenvalues.</p></li>
</ul></li>
<li><p>Projection: Data <span class="math inline">\(X\)</span> is projected as:</p>
<p><span class="math display">\[
Z = X W_k
\]</span></p>
<p>where <span class="math inline">\(W_k\)</span> contains top-k eigenvectors.</p></li>
<li><p>Key Properties:</p>
<ul>
<li>Linear method.</li>
<li>Components are orthogonal.</li>
<li>Optimal for variance preservation.</li>
</ul></li>
<li><p>Limitations:</p>
<ul>
<li>Sensitive to scaling of features.</li>
<li>Captures only linear structure.</li>
<li>Principal components may not be interpretable.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Step</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Center data</td>
<td>Align mean at zero</td>
</tr>
<tr class="even">
<td>Compute covariance</td>
<td>Capture relationships</td>
</tr>
<tr class="odd">
<td>Eigen-decomposition</td>
<td>Extract main axes of variance</td>
</tr>
<tr class="even">
<td>Select top components</td>
<td>Reduce dimensionality</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load Iris dataset (4D features)</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> load_iris(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply PCA to 2D</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(X)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Explained variance ratio:"</span>, pca.explained_variance_ratio_)</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_pca[:,<span class="dv">0</span>], X_pca[:,<span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span><span class="st">"viridis"</span>)</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"PC1"</span>)</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"PC2"</span>)</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Iris Dataset with PCA"</span>)</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-30" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-30">Why It Matters</h4>
<p>PCA is a cornerstone for exploratory data analysis, visualization, and preprocessing. It simplifies models, reduces noise, and reveals latent structures. Whether analyzing images, text embeddings, or financial data, PCA is often the first step in making sense of high-dimensional datasets.</p>
</section>
<section id="try-it-yourself-31" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-31">Try It Yourself</h4>
<ol type="1">
<li>Apply PCA to a dataset and examine the explained variance ratio. How many components cover 95% variance?</li>
<li>Compare PCA on standardized vs.&nbsp;raw features. How do results differ?</li>
<li>Plot the first two principal components of different datasets (digits, Iris). Do clusters appear?</li>
<li>Use PCA as preprocessing for classification. Does accuracy change with fewer dimensions?</li>
</ol>
</section>
</section>
<section id="eigen-decomposition-and-svd-connections" class="level3">
<h3 class="anchored" data-anchor-id="eigen-decomposition-and-svd-connections">833. Eigen-Decomposition and SVD Connections</h3>
<p>Principal Component Analysis (PCA) can be derived either from the eigen-decomposition of the covariance matrix or from the Singular Value Decomposition (SVD) of the data matrix. These two perspectives are mathematically equivalent but differ in intuition and computation.</p>
<section id="picture-in-your-head-32" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-32">Picture in Your Head</h4>
<p>Think of analyzing a choir’s harmony. Eigen-decomposition is like focusing on how voices combine in the overall resonance (covariance structure), while SVD is like separating the voices directly from the recordings (data matrix). Both approaches uncover the same harmonics.</p>
</section>
<section id="deep-dive-32" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-32">Deep Dive</h4>
<ul>
<li><p>Eigen-Decomposition of Covariance Matrix:</p>
<ul>
<li>Compute covariance <span class="math inline">\(\Sigma = \frac{1}{n} X^T X\)</span>.</li>
<li>Eigenvectors of <span class="math inline">\(\Sigma\)</span> = principal component directions.</li>
<li>Eigenvalues = variance explained by each component.</li>
</ul></li>
<li><p>SVD of Data Matrix:</p>
<ul>
<li><p>For data matrix <span class="math inline">\(X\)</span>:</p>
<p><span class="math display">\[
X = U \Sigma V^T
\]</span></p></li>
<li><p>Columns of <span class="math inline">\(V\)</span> = eigenvectors of covariance (principal axes).</p></li>
<li><p>Singular values relate to variance:</p>
<p><span class="math display">\[
\lambda_i = \frac{\sigma_i^2}{n}
\]</span></p></li>
</ul></li>
<li><p>Why Use SVD Instead of Eigen-Decomposition?</p>
<ul>
<li>More numerically stable.</li>
<li>Efficient for large, sparse matrices.</li>
<li>Directly provides principal components without computing covariance.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 37%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Steps Taken</th>
<th>Output Used for PCA</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Eigen-Decomposition</td>
<td>Compute covariance, then eigenpairs</td>
<td>Eigenvectors, eigenvalues</td>
</tr>
<tr class="even">
<td>SVD</td>
<td>Factorize data matrix directly</td>
<td>Right singular vectors, singular values</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>X, _ <span class="op">=</span> load_iris(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>X_centered <span class="op">=</span> X <span class="op">-</span> X.mean(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Eigen-decomposition of covariance</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>cov <span class="op">=</span> np.cov(X_centered, rowvar<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>eigvals, eigvecs <span class="op">=</span> np.linalg.eigh(cov)</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a><span class="co"># SVD of data matrix</span></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>U, S, VT <span class="op">=</span> np.linalg.svd(X_centered, full_matrices<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Top eigenvalues (covariance):"</span>, eigvals[::<span class="op">-</span><span class="dv">1</span>][:<span class="dv">2</span>])</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Top singular values squared / n:"</span>, (S[:<span class="dv">2</span>]<span class="dv">2</span>) <span class="op">/</span> (X.shape[<span class="dv">0</span>]))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-31" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-31">Why It Matters</h4>
<p>Understanding the link between eigen-decomposition and SVD reveals the mathematical backbone of PCA. This dual perspective explains why PCA is both statistically meaningful (variance maximization) and computationally efficient (via SVD). It also bridges concepts across linear algebra, statistics, and machine learning.</p>
</section>
<section id="try-it-yourself-32" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-32">Try It Yourself</h4>
<ol type="1">
<li>Compute PCA via covariance eigen-decomposition and via SVD. Do results match?</li>
<li>On large sparse datasets, compare runtime of covariance eigen vs.&nbsp;SVD. Which is faster?</li>
<li>Compare eigenvalues with squared singular values. Do they align as theory predicts?</li>
<li>Plot the first two principal components obtained from both methods. Are they identical up to sign?</li>
</ol>
</section>
</section>
<section id="linear-vs.-nonlinear-reduction" class="level3">
<h3 class="anchored" data-anchor-id="linear-vs.-nonlinear-reduction">834. Linear vs.&nbsp;Nonlinear Reduction</h3>
<p>Dimensionality reduction methods fall into two main categories: linear (e.g., PCA, LDA) and nonlinear (e.g., t-SNE, UMAP, Isomap). Linear methods assume data lies near a flat subspace, while nonlinear methods assume data lives on a curved manifold. Choosing between them depends on the structure of the data and the task.</p>
<section id="picture-in-your-head-33" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-33">Picture in Your Head</h4>
<p>Imagine flattening a crumpled piece of paper. Linear reduction is like cutting out a straight rectangle. it only works if the paper was mostly flat to begin with. Nonlinear reduction gently unrolls the crumples, preserving curved relationships that linear methods miss.</p>
</section>
<section id="deep-dive-33" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-33">Deep Dive</h4>
<ul>
<li><p>Linear Methods:</p>
<ul>
<li>Assume global linearity.</li>
<li>Examples: PCA, LDA, Linear Autoencoders.</li>
<li>Pros: Simple, efficient, interpretable.</li>
<li>Cons: Cannot capture nonlinear manifolds.</li>
</ul></li>
<li><p>Nonlinear Methods:</p>
<ul>
<li>Preserve local neighborhoods or manifold structure.</li>
<li>Examples: t-SNE (probabilistic neighbors), UMAP (topological structure), Isomap (geodesic distances).</li>
<li>Pros: Capture complex patterns.</li>
<li>Cons: Less interpretable, more computationally expensive.</li>
</ul></li>
<li><p>When to Use What:</p>
<ul>
<li>Linear: when relationships are mostly global and linear.</li>
<li>Nonlinear: when clusters, curves, or manifolds dominate.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 15%">
<col style="width: 36%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="header">
<th>Approach</th>
<th>Examples</th>
<th>Strengths</th>
<th>Weaknesses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Linear</td>
<td>PCA, LDA</td>
<td>Fast, interpretable</td>
<td>Misses nonlinear structure</td>
</tr>
<tr class="even">
<td>Nonlinear</td>
<td>t-SNE, UMAP</td>
<td>Captures complex manifolds</td>
<td>Harder to interpret, tune</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_digits</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>digits <span class="op">=</span> load_digits()</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> digits.data, digits.target</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear reduction (PCA)</span></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>).fit_transform(X)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Nonlinear reduction (t-SNE)</span></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>X_tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, perplexity<span class="op">=</span><span class="dv">30</span>).fit_transform(X)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">4</span>))</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(X_pca[:,<span class="dv">0</span>], X_pca[:,<span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span><span class="st">"tab10"</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">"PCA (Linear)"</span>)</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].scatter(X_tsne[:,<span class="dv">0</span>], X_tsne[:,<span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span><span class="st">"tab10"</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">"t-SNE (Nonlinear)"</span>)</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-32" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-32">Why It Matters</h4>
<p>Linear vs.&nbsp;nonlinear reduction is a fundamental design choice in data analysis. Linear methods excel in efficiency and interpretability, making them reliable baselines. Nonlinear methods, while harder to tune, reveal hidden patterns in embeddings, images, or gene data. Understanding both ensures the right tool is chosen for the problem.</p>
</section>
<section id="try-it-yourself-33" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-33">Try It Yourself</h4>
<ol type="1">
<li>Apply PCA and t-SNE to a dataset with nonlinear clusters (e.g., Swiss roll). Which works better?</li>
<li>Compare runtime of PCA vs.&nbsp;UMAP on large data. Which scales better?</li>
<li>Try linear vs.&nbsp;nonlinear reduction on word embeddings. Which captures semantic neighborhoods?</li>
<li>Apply LDA vs.&nbsp;t-SNE on labeled data. Which preserves class separability more clearly?</li>
</ol>
</section>
</section>
<section id="t-sne-intuition-and-mechanics" class="level3">
<h3 class="anchored" data-anchor-id="t-sne-intuition-and-mechanics">835. t-SNE: Intuition and Mechanics</h3>
<p>t-SNE (t-distributed Stochastic Neighbor Embedding) is a nonlinear dimensionality reduction method designed for visualization. It preserves local neighborhoods by mapping high-dimensional distances into probabilities, ensuring nearby points in high dimensions remain close in the 2D or 3D embedding.</p>
<section id="picture-in-your-head-34" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-34">Picture in Your Head</h4>
<p>Imagine shrinking a globe into a small map. You can’t preserve all distances perfectly, but you try to keep nearby cities close while allowing continents to separate. t-SNE acts like this cartographer, keeping local relationships intact at the expense of global structure.</p>
</section>
<section id="deep-dive-34" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-34">Deep Dive</h4>
<ul>
<li><p>Step 1: Similarities in High-D Space</p>
<ul>
<li><p>For each point <span class="math inline">\(x_i\)</span>, define conditional probability of picking neighbor <span class="math inline">\(x_j\)</span>:</p>
<p><span class="math display">\[
p_{j|i} = \frac{\exp(-||x_i - x_j||^2 / 2\sigma_i^2)}{\sum_{k \neq i} \exp(-||x_i - x_k||^2 / 2\sigma_i^2)}
\]</span></p></li>
<li><p>Bandwidth <span class="math inline">\(\sigma_i\)</span> chosen so that perplexity ≈ number of effective neighbors.</p></li>
</ul></li>
<li><p>Step 2: Similarities in Low-D Space</p>
<ul>
<li><p>Map points to low-dimensional <span class="math inline">\(y_i\)</span>.</p></li>
<li><p>Define similarity using Student’s t-distribution with 1 d.o.f.:</p>
<p><span class="math display">\[
q_{ij} = \frac{(1 + ||y_i - y_j||^2)^{-1}}{\sum_{k \neq l} (1 + ||y_k - y_l||^2)^{-1}}
\]</span></p></li>
</ul></li>
<li><p>Step 3: KL Divergence Minimization</p>
<ul>
<li><p>Optimize embedding by minimizing:</p>
<p><span class="math display">\[
KL(P||Q) = \sum_{i \neq j} p_{ij} \log \frac{p_{ij}}{q_{ij}}
\]</span></p></li>
<li><p>Ensures low-D similarities mirror high-D ones.</p></li>
</ul></li>
<li><p>Properties:</p>
<ul>
<li>Preserves local neighborhoods.</li>
<li>Can distort global distances (clusters may look more separated than they are).</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Feature</th>
<th>Effect</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Perplexity parameter</td>
<td>Controls balance between local vs.&nbsp;global</td>
</tr>
<tr class="even">
<td>t-distribution kernel</td>
<td>Prevents crowding problem</td>
</tr>
<tr class="odd">
<td>KL divergence</td>
<td>Prioritizes local similarity preservation</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_digits</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>digits <span class="op">=</span> load_digits()</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> digits.data, digits.target</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a><span class="co"># t-SNE projection</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, perplexity<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>X_embedded <span class="op">=</span> tsne.fit_transform(X)</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_embedded[:,<span class="dv">0</span>], X_embedded[:,<span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span><span class="st">"tab10"</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"t-SNE Visualization of Digits"</span>)</span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-33" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-33">Why It Matters</h4>
<p>t-SNE has become the go-to method for visualizing embeddings from NLP, vision, and genomics. By preserving local neighborhoods, it reveals hidden clusters and relationships, making high-dimensional patterns interpretable. However, its distortions mean results should be used for exploration, not quantitative analysis.</p>
</section>
<section id="try-it-yourself-34" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-34">Try It Yourself</h4>
<ol type="1">
<li>Run t-SNE with perplexity 5, 30, and 100. How do cluster separations change?</li>
<li>Compare PCA vs.&nbsp;t-SNE on the same dataset. Which shows clearer clusters?</li>
<li>Apply t-SNE to word embeddings. Do semantically similar words cluster together?</li>
<li>Try t-SNE on a Swiss roll dataset. Does it recover the manifold structure?</li>
</ol>
</section>
</section>
<section id="umap-topological-and-graph-based-approach" class="level3">
<h3 class="anchored" data-anchor-id="umap-topological-and-graph-based-approach">836. UMAP: Topological and Graph-Based Approach</h3>
<p>UMAP (Uniform Manifold Approximation and Projection) is a nonlinear dimensionality reduction technique that builds a graph-based representation of the data’s manifold and optimizes a low-dimensional embedding that preserves both local and some global structure. Compared to t-SNE, UMAP is often faster, scales better, and maintains more global continuity.</p>
<section id="picture-in-your-head-35" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-35">Picture in Your Head</h4>
<p>Imagine connecting cities with roads based on their proximity. This road network represents the “true geography” of the region. UMAP takes this network, compresses it onto a smaller map, and tries to preserve the road connectivity so that close cities remain close while still showing broader regions.</p>
</section>
<section id="deep-dive-35" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-35">Deep Dive</h4>
<ul>
<li><p>Step 1: Fuzzy Topological Graph in High-D Space</p>
<ul>
<li>Compute nearest neighbors for each point.</li>
<li>Build weighted graph of local connections, with probabilities representing edge strength.</li>
</ul></li>
<li><p>Step 2: Low-D Embedding Graph</p>
<ul>
<li>Initialize points in low dimensions (2D/3D).</li>
<li>Construct a similar graph in low-D.</li>
</ul></li>
<li><p>Step 3: Cross-Entropy Optimization</p>
<ul>
<li><p>Minimize difference between high-D and low-D graphs:</p>
<p><span class="math display">\[
C = \sum_{(i,j)} [ w_{ij} \log \frac{w_{ij}}{w'_{ij}} + (1-w_{ij}) \log \frac{1-w_{ij}}{1-w'_{ij}} ]
\]</span></p></li>
<li><p>Encourages embeddings that preserve both local neighborhoods and larger clusters.</p></li>
</ul></li>
<li><p>Key Features:</p>
<ul>
<li><p>Speed &amp; Scalability: Faster than t-SNE for large datasets.</p></li>
<li><p>Global Preservation: Better continuity across clusters.</p></li>
<li><p>Parameter Control:</p>
<ul>
<li><em>n_neighbors</em>: tradeoff between local vs.&nbsp;global structure.</li>
<li><em>min_dist</em>: controls tightness of clusters in embedding.</li>
</ul></li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 36%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>t-SNE</th>
<th>UMAP</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Objective</td>
<td>KL divergence (local focus)</td>
<td>Cross-entropy (local + global)</td>
</tr>
<tr class="even">
<td>Global structure</td>
<td>Poor</td>
<td>Better</td>
</tr>
<tr class="odd">
<td>Scalability</td>
<td>Moderate</td>
<td>High</td>
</tr>
<tr class="even">
<td>Parameters</td>
<td>Perplexity</td>
<td>n_neighbors, min_dist</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> umap</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_digits</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>digits <span class="op">=</span> load_digits()</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> digits.data, digits.target</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply UMAP</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>reducer <span class="op">=</span> umap.UMAP(n_neighbors<span class="op">=</span><span class="dv">15</span>, min_dist<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>X_umap <span class="op">=</span> reducer.fit_transform(X)</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_umap[:,<span class="dv">0</span>], X_umap[:,<span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span><span class="st">"tab10"</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"UMAP Visualization of Digits"</span>)</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-34" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-34">Why It Matters</h4>
<p>UMAP has become a powerful alternative to t-SNE in modern AI workflows. It is especially useful for visualizing embeddings (e.g., word embeddings, image features, single-cell RNA data) because it balances local clustering with global structure, enabling both fine-grained and broad insights.</p>
</section>
<section id="try-it-yourself-35" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-35">Try It Yourself</h4>
<ol type="1">
<li>Run UMAP with different <code>n_neighbors</code> values (5, 15, 50). How does local vs.&nbsp;global preservation change?</li>
<li>Adjust <code>min_dist</code> from 0.0 to 0.9. Do clusters become tighter or looser?</li>
<li>Compare UMAP and t-SNE on the same dataset. Which preserves global structure better?</li>
<li>Apply UMAP to embeddings from a deep model (e.g., BERT). Do semantic groupings emerge?</li>
</ol>
</section>
</section>
<section id="tradeoffs-interpretability-vs.-expressiveness" class="level3">
<h3 class="anchored" data-anchor-id="tradeoffs-interpretability-vs.-expressiveness">837. Tradeoffs: Interpretability vs.&nbsp;Expressiveness</h3>
<p>Dimensionality reduction techniques vary in how interpretable their components are versus how expressive they are at capturing complex patterns. Linear methods like PCA are highly interpretable but may miss nonlinear relationships. Nonlinear methods like t-SNE and UMAP capture richer structures but are harder to explain quantitatively.</p>
<section id="picture-in-your-head-36" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-36">Picture in Your Head</h4>
<p>Think of maps. A simple subway map (linear method) is easy to read and navigate but distorts geography. A satellite image (nonlinear method) shows every detail but is harder to interpret quickly. Dimensionality reduction methods make the same tradeoff between clarity and completeness.</p>
</section>
<section id="deep-dive-36" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-36">Deep Dive</h4>
<ul>
<li><p>Interpretability:</p>
<ul>
<li>Linear methods produce components as weighted sums of original features.</li>
<li>Example: In PCA, loadings tell how much each feature contributes to a principal component.</li>
<li>Easy to explain but limited in capturing curved manifolds.</li>
</ul></li>
<li><p>Expressiveness:</p>
<ul>
<li>Nonlinear methods preserve complex structures like clusters or curved manifolds.</li>
<li>Example: t-SNE preserves local neighborhoods, UMAP balances local and global structure.</li>
<li>Difficult to map components back to original features.</li>
</ul></li>
<li><p>The Tradeoff:</p>
<ul>
<li>High interpretability → better for explanation, model transparency, feature engineering.</li>
<li>High expressiveness → better for visualization, discovery of hidden patterns, embeddings for downstream tasks.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 8%">
<col style="width: 22%">
<col style="width: 19%">
<col style="width: 49%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Interpretability</th>
<th>Expressiveness</th>
<th>Example Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>PCA</td>
<td>High</td>
<td>Moderate</td>
<td>Feature reduction, noise filtering</td>
</tr>
<tr class="even">
<td>LDA</td>
<td>High</td>
<td>Moderate</td>
<td>Supervised dimensionality reduction</td>
</tr>
<tr class="odd">
<td>t-SNE</td>
<td>Low</td>
<td>High</td>
<td>Visualizing embeddings and clusters</td>
</tr>
<tr class="even">
<td>UMAP</td>
<td>Medium</td>
<td>High</td>
<td>Large-scale embedding visualization</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_digits</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>digits <span class="op">=</span> load_digits()</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> digits.data, digits.target</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="co"># PCA (linear, interpretable)</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(X)</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a><span class="co"># t-SNE (nonlinear, expressive)</span></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>X_tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, perplexity<span class="op">=</span><span class="dv">30</span>).fit_transform(X)</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot side-by-side</span></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">4</span>))</span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(X_pca[:,<span class="dv">0</span>], X_pca[:,<span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span><span class="st">"tab10"</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">"PCA (Interpretable)"</span>)</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].scatter(X_tsne[:,<span class="dv">0</span>], X_tsne[:,<span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span><span class="st">"tab10"</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">"t-SNE (Expressive)"</span>)</span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-35" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-35">Why It Matters</h4>
<p>AI systems often balance understanding vs.&nbsp;performance. Regulators, scientists, and domain experts may demand interpretability, while exploratory research benefits from expressiveness. Recognizing this tradeoff ensures the right tool is chosen for the context, whether the goal is explanation or discovery.</p>
</section>
<section id="try-it-yourself-36" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-36">Try It Yourself</h4>
<ol type="1">
<li>Apply PCA to a dataset and examine component loadings. Can you interpret feature contributions?</li>
<li>Run t-SNE on the same dataset. Do you see more clusters than PCA shows?</li>
<li>Compare classification accuracy using PCA-reduced features vs.&nbsp;t-SNE embeddings. Which is better?</li>
<li>Use UMAP and analyze whether it provides a middle ground between PCA and t-SNE.</li>
</ol>
</section>
</section>
<section id="evaluation-and-visualization-of-low-dim-spaces" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-and-visualization-of-low-dim-spaces">838. Evaluation and Visualization of Low-Dim Spaces</h3>
<p>After dimensionality reduction, it is essential to evaluate how well the low-dimensional embedding preserves structure and to visualize the results. Evaluation ensures embeddings are faithful representations, while visualization helps interpret patterns, clusters, and anomalies.</p>
<section id="picture-in-your-head-37" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-37">Picture in Your Head</h4>
<p>Imagine compressing a 3D sculpture into a 2D photograph. A good photo preserves the shape and proportions; a bad one distorts features. Similarly, evaluation and visualization check whether dimensionality reduction kept the “shape” of the data intact.</p>
</section>
<section id="deep-dive-37" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-37">Deep Dive</h4>
<ul>
<li><p>Quantitative Evaluation Metrics:</p>
<ul>
<li>Reconstruction Error (linear methods): Difference between original and reconstructed data (used in PCA).</li>
<li>Trustworthiness: Measures how well local neighborhoods are preserved.</li>
<li>Continuity: Measures how much the embedding distorts neighborhood relationships.</li>
<li>KL Divergence / Cross-Entropy: Used in t-SNE/UMAP optimization.</li>
</ul></li>
<li><p>Visualization Techniques:</p>
<ul>
<li>Scatterplots (2D/3D): Standard way to show clusters and structures.</li>
<li>Color Coding: Use labels, density, or feature values for richer interpretation.</li>
<li>Interactive Visualizations: Tools like Plotly or TensorBoard Embedding Projector allow exploration.</li>
</ul></li>
<li><p>Tradeoffs:</p>
<ul>
<li>2D embeddings are easy to visualize but may hide complexity.</li>
<li>3D embeddings show more structure but are harder to interpret on static plots.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Method</th>
<th>Metric / Tool</th>
<th>Strengths</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>PCA</td>
<td>Reconstruction error</td>
<td>Simple, interpretable</td>
</tr>
<tr class="even">
<td>t-SNE / UMAP</td>
<td>Trustworthiness, KL</td>
<td>Captures local neighborhoods</td>
</tr>
<tr class="odd">
<td>Visualization</td>
<td>Scatter, interactive</td>
<td>Human-understandable patterns</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_digits</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> trustworthiness</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>digits <span class="op">=</span> load_digits()</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> digits.data, digits.target</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="co"># t-SNE embedding</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>X_embedded <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>).fit_transform(X)</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate trustworthiness</span></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> trustworthiness(X, X_embedded, n_neighbors<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Trustworthiness score:"</span>, <span class="bu">round</span>(score, <span class="dv">3</span>))</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization</span></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_embedded[:,<span class="dv">0</span>], X_embedded[:,<span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span><span class="st">"tab10"</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"t-SNE Embedding of Digits"</span>)</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-36" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-36">Why It Matters</h4>
<p>Evaluation ensures embeddings are not misleading. crucial when using them for clustering, anomaly detection, or scientific discovery. Visualization makes embeddings accessible, allowing humans to see hidden patterns in otherwise opaque high-dimensional data.</p>
</section>
<section id="try-it-yourself-37" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-37">Try It Yourself</h4>
<ol type="1">
<li>Compute reconstruction error for PCA with different numbers of components. Where is the elbow?</li>
<li>Compare trustworthiness of PCA, t-SNE, and UMAP on the same dataset. Which preserves neighborhoods best?</li>
<li>Visualize embeddings with and without labels. Do clusters appear naturally?</li>
<li>Use interactive visualization (e.g., TensorBoard projector). Does exploration reveal subclusters?</li>
</ol>
</section>
</section>
<section id="dimensionality-reduction-in-large-scale-systems" class="level3">
<h3 class="anchored" data-anchor-id="dimensionality-reduction-in-large-scale-systems">839. Dimensionality Reduction in Large-Scale Systems</h3>
<p>In real-world AI systems, datasets often contain millions of samples with thousands of features. Scaling dimensionality reduction to this size requires approximate methods, distributed computation, and efficient algorithms that balance accuracy and speed.</p>
<section id="picture-in-your-head-38" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-38">Picture in Your Head</h4>
<p>Think of compressing a massive library. If you try to summarize every book word-for-word, you’ll never finish. Instead, you create quick summaries, delegate work to multiple scribes, and keep only the most important details. Large-scale dimensionality reduction works the same way. approximate, parallel, and efficient.</p>
</section>
<section id="deep-dive-38" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-38">Deep Dive</h4>
<ul>
<li><p>Challenges at Scale:</p>
<ul>
<li>High memory usage when computing covariance or distance matrices.</li>
<li>Long runtimes for nonlinear methods like t-SNE.</li>
<li>Data streams that change over time.</li>
</ul></li>
<li><p>Scalable Approaches:</p>
<ul>
<li>Incremental PCA: Processes data in chunks, avoids full covariance matrix.</li>
<li>Randomized SVD: Uses random projections for approximate factorization.</li>
<li>Approximate Nearest Neighbors (ANN): Speeds up graph-based methods like UMAP and t-SNE.</li>
<li>Distributed Systems: Spark MLlib implements large-scale PCA and ALS.</li>
</ul></li>
<li><p>Streaming and Online Methods:</p>
<ul>
<li>Online PCA updates components as new data arrives.</li>
<li>Sketching methods approximate matrices with sublinear memory.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 26%">
<col style="width: 41%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Scale Adaptation</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Incremental PCA</td>
<td>Mini-batch updates</td>
<td>Streaming, huge datasets</td>
</tr>
<tr class="even">
<td>Randomized SVD</td>
<td>Fast approximate decomposition</td>
<td>NLP embeddings</td>
</tr>
<tr class="odd">
<td>ANN + t-SNE/UMAP</td>
<td>Reduce neighbor search cost</td>
<td>Image/embedding analysis</td>
</tr>
<tr class="even">
<td>Distributed ALS/PCA</td>
<td>Parallel on clusters</td>
<td>Recommender systems</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> IncrementalPCA</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_openml</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Load large dataset (e.g., MNIST)</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> fetch_openml(<span class="st">"mnist_784"</span>, version<span class="op">=</span><span class="dv">1</span>, return_X_y<span class="op">=</span><span class="va">True</span>, as_frame<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply Incremental PCA</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>ipca <span class="op">=</span> IncrementalPCA(n_components<span class="op">=</span><span class="dv">100</span>, batch_size<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>X_reduced <span class="op">=</span> ipca.fit_transform(X)</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original shape:"</span>, X.shape)</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Reduced shape:"</span>, X_reduced.shape)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-37" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-37">Why It Matters</h4>
<p>Large-scale dimensionality reduction underpins industrial AI systems: search engines compress embeddings, recommender systems reduce user–item matrices, and genomics pipelines handle millions of features. Scalable methods make these workflows feasible in practice, turning theory into production reality.</p>
</section>
<section id="try-it-yourself-38" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-38">Try It Yourself</h4>
<ol type="1">
<li>Compare PCA vs.&nbsp;Incremental PCA on a dataset with &gt;1M samples. Do results differ significantly?</li>
<li>Run Randomized SVD on a text embedding matrix. How much faster is it than standard SVD?</li>
<li>Test UMAP with ANN libraries (e.g., FAISS). Does runtime improve on large embeddings?</li>
<li>Stream data into Incremental PCA. Does it adapt well to evolving data distributions?</li>
</ol>
</section>
</section>
<section id="case-studies-in-representation-learning" class="level3">
<h3 class="anchored" data-anchor-id="case-studies-in-representation-learning">840. Case Studies in Representation Learning</h3>
<p>Dimensionality reduction is not just a preprocessing trick. it plays a central role in real-world applications where interpretable, compact, and efficient representations are critical. Case studies across domains highlight how methods like PCA, t-SNE, UMAP, and autoencoders turn raw data into actionable insights.</p>
<section id="picture-in-your-head-39" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-39">Picture in Your Head</h4>
<p>Think of a translator who condenses long speeches into concise notes. Each note is a representation: smaller, easier to handle, but still rich in meaning. Representation learning does the same for data, enabling discovery, classification, and decision-making.</p>
</section>
<section id="deep-dive-39" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-39">Deep Dive</h4>
<ul>
<li><p>Natural Language Processing (NLP):</p>
<ul>
<li>Word embeddings reduced to 2D via t-SNE or UMAP reveal semantic clusters (e.g., “king” near “queen”).</li>
<li>Dimensionality reduction helps visualize high-dimensional BERT embeddings.</li>
</ul></li>
<li><p>Computer Vision:</p>
<ul>
<li>PCA compresses images, reducing storage while retaining most visual structure.</li>
<li>Autoencoders discover latent representations useful for denoising and anomaly detection.</li>
</ul></li>
<li><p>Genomics &amp; Bioinformatics:</p>
<ul>
<li>Single-cell RNA sequencing produces tens of thousands of features per cell.</li>
<li>UMAP is widely used to cluster cells into meaningful biological subpopulations.</li>
</ul></li>
<li><p>Recommender Systems:</p>
<ul>
<li>Matrix factorization reduces sparse user–item matrices to low-rank latent features.</li>
<li>Reveals interpretable axes of preference (e.g., “action vs.&nbsp;romance”).</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Domain</th>
<th>Method Used</th>
<th>Insights Gained</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>NLP</td>
<td>t-SNE, UMAP</td>
<td>Semantic word clusters</td>
</tr>
<tr class="even">
<td>Vision</td>
<td>PCA, Autoencoders</td>
<td>Compression, anomaly detection</td>
</tr>
<tr class="odd">
<td>Genomics</td>
<td>UMAP</td>
<td>Cell type discovery</td>
</tr>
<tr class="even">
<td>Recommenders</td>
<td>Matrix Factorization</td>
<td>Latent preference factors</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> umap</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_20newsgroups_vectorized</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="co"># High-dimensional text data</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> fetch_20newsgroups_vectorized(subset<span class="op">=</span><span class="st">"train"</span>).data</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply UMAP</span></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>reducer <span class="op">=</span> umap.UMAP(n_neighbors<span class="op">=</span><span class="dv">15</span>, min_dist<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>X_umap <span class="op">=</span> reducer.fit_transform(X)</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_umap[:,<span class="dv">0</span>], X_umap[:,<span class="dv">1</span>], s<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"UMAP of 20 Newsgroups Text Data"</span>)</span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-38" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-38">Why It Matters</h4>
<p>Case studies prove that dimensionality reduction is not abstract math. it is operational AI infrastructure. From powering biomedical discoveries to shaping the embeddings behind recommender systems and search engines, representation learning through dimensionality reduction drives practical breakthroughs across industries.</p>
</section>
<section id="try-it-yourself-39" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-39">Try It Yourself</h4>
<ol type="1">
<li>Apply UMAP to single-cell RNA data (if available). Do cell populations cluster meaningfully?</li>
<li>Reduce BERT embeddings of sentences with PCA. Do similar sentences cluster?</li>
<li>Compress images with autoencoders. Does the latent space capture semantic features?</li>
<li>Factorize a user–item matrix and visualize users/items in 2D. Are preferences interpretable?</li>
</ol>
</section>
</section>
</section>
<section id="chapter-85.-manifold-learning-and-topological-methods" class="level2">
<h2 class="anchored" data-anchor-id="chapter-85.-manifold-learning-and-topological-methods">Chapter 85. Manifold learning and topological methods</h2>
<section id="manifold-hypothesis-in-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="manifold-hypothesis-in-machine-learning">841. Manifold Hypothesis in Machine Learning</h3>
<p>The manifold hypothesis suggests that high-dimensional data (like images, speech, or text embeddings) lies near a much lower-dimensional manifold within the ambient space. Instead of filling the whole high-dimensional cube, data concentrates on structured surfaces, making learning feasible.</p>
<section id="picture-in-your-head-40" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-40">Picture in Your Head</h4>
<p>Imagine a tangled garden hose lying on the ground. Though it exists in 3D space, the hose itself is essentially 1D. a curve. Similarly, handwritten digits (seemingly 784-dimensional in pixel space) trace out low-dimensional surfaces of variation (like slant, thickness, or style).</p>
</section>
<section id="deep-dive-40" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-40">Deep Dive</h4>
<ul>
<li><p>Why It Matters:</p>
<ul>
<li>Explains why machine learning works at all despite data being high-dimensional.</li>
<li>Suggests we can uncover meaningful low-dimensional structures.</li>
</ul></li>
<li><p>Examples of Manifolds in Data:</p>
<ul>
<li>Images: Despite thousands of pixels, variations are governed by lighting, pose, shape, etc.</li>
<li>Speech: Though signals are long time series, variation follows articulatory and phonetic manifolds.</li>
<li>Text: Sentence embeddings cluster along semantic directions.</li>
</ul></li>
<li><p>Mathematical Framing:</p>
<ul>
<li>Data <span class="math inline">\(x \in \mathbb{R}^D\)</span> lies near a manifold <span class="math inline">\(M\)</span> with dimension <span class="math inline">\(d \ll D\)</span>.</li>
<li>Learning involves mapping from <span class="math inline">\(M\)</span> into useful representations for classification, clustering, or regression.</li>
</ul></li>
<li><p>Implications:</p>
<ul>
<li>Dimensionality reduction works because data isn’t “spread” evenly across space.</li>
<li>Encourages manifold learning methods (Isomap, LLE, diffusion maps).</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 8%">
<col style="width: 31%">
<col style="width: 59%">
</colgroup>
<thead>
<tr class="header">
<th>Domain</th>
<th>High-D Representation</th>
<th>Underlying Manifold</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Images</td>
<td>Pixels (784D)</td>
<td>Object shape, pose, lighting (~10D)</td>
</tr>
<tr class="even">
<td>Speech</td>
<td>Audio waveforms</td>
<td>Vocal tract dynamics (~20D)</td>
</tr>
<tr class="odd">
<td>Text</td>
<td>Word embeddings</td>
<td>Semantic and syntactic structure (~50D)</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Swiss Roll Manifold)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_swiss_roll</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate Swiss roll (3D data lying on 2D manifold)</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>X, color <span class="op">=</span> make_swiss_roll(n_samples<span class="op">=</span><span class="dv">1000</span>, noise<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">5</span>))</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>, projection<span class="op">=</span><span class="st">"3d"</span>)</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>ax.scatter(X[:,<span class="dv">0</span>], X[:,<span class="dv">1</span>], X[:,<span class="dv">2</span>], c<span class="op">=</span>color, cmap<span class="op">=</span>plt.cm.Spectral, s<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"Swiss Roll: High-D Data on a 2D Manifold"</span>)</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-39" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-39">Why It Matters</h4>
<p>The manifold hypothesis underpins modern representation learning, from PCA to deep neural networks. It motivates why dimensionality reduction, embedding learning, and manifold regularization yield compact yet powerful representations, making tasks like classification or clustering possible in high dimensions.</p>
</section>
<section id="try-it-yourself-40" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-40">Try It Yourself</h4>
<ol type="1">
<li>Generate Swiss roll data and apply PCA. Does PCA capture the nonlinear structure?</li>
<li>Apply Isomap to the same data. Does it “unroll” the manifold?</li>
<li>Compare Euclidean distance vs.&nbsp;geodesic distance on Swiss roll. Which reflects true neighborhood?</li>
<li>Test manifold learning on image data (e.g., MNIST). Do digits cluster along low-dimensional factors?</li>
</ol>
</section>
</section>
<section id="isomap-and-geodesic-distances" class="level3">
<h3 class="anchored" data-anchor-id="isomap-and-geodesic-distances">842. Isomap and Geodesic Distances</h3>
<p>Isomap (Isometric Mapping) is a nonlinear dimensionality reduction method that preserves geodesic distances along a manifold rather than straight-line Euclidean distances. It is designed to “unroll” curved manifolds, revealing their intrinsic low-dimensional structure.</p>
<section id="picture-in-your-head-41" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-41">Picture in Your Head</h4>
<p>Think of cities on a globe. The shortest path is not through the Earth (Euclidean) but along the curved surface (geodesic). Isomap respects these surface distances, making the world map look flat without tearing continents apart.</p>
</section>
<section id="deep-dive-41" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-41">Deep Dive</h4>
<ul>
<li><p>Key Idea:</p>
<ul>
<li>Euclidean distances fail on curved manifolds (e.g., Swiss roll).</li>
<li>Geodesic distances approximate true distances along the manifold surface.</li>
</ul></li>
<li><p>Algorithm Steps:</p>
<ol type="1">
<li>Build a neighborhood graph using <span class="math inline">\(k\)</span>-nearest neighbors or <span class="math inline">\(\epsilon\)</span>-radius.</li>
<li>Assign edge weights as Euclidean distances between neighbors.</li>
<li>Compute shortest paths between all points (Floyd–Warshall or Dijkstra).</li>
<li>Apply classical MDS (Multidimensional Scaling) to preserve geodesic distances in lower dimensions.</li>
</ol></li>
<li><p>Strengths:</p>
<ul>
<li>Captures global nonlinear structure.</li>
<li>Effective on manifolds like Swiss roll.</li>
</ul></li>
<li><p>Weaknesses:</p>
<ul>
<li>Sensitive to neighborhood size (<span class="math inline">\(k\)</span>).</li>
<li>Computationally expensive on large datasets.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Step</th>
<th>Technique Used</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Build neighborhood</td>
<td>k-NN or radius graph</td>
</tr>
<tr class="even">
<td>Approx geodesics</td>
<td>Shortest-path algorithms</td>
</tr>
<tr class="odd">
<td>Embed</td>
<td>Classical MDS</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_swiss_roll</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> Isomap</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Swiss roll dataset</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>X, color <span class="op">=</span> make_swiss_roll(n_samples<span class="op">=</span><span class="dv">1000</span>, noise<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply Isomap</span></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>iso <span class="op">=</span> Isomap(n_neighbors<span class="op">=</span><span class="dv">10</span>, n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>X_iso <span class="op">=</span> iso.fit_transform(X)</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_iso[:,<span class="dv">0</span>], X_iso[:,<span class="dv">1</span>], c<span class="op">=</span>color, cmap<span class="op">=</span>plt.cm.Spectral, s<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Isomap Unrolling the Swiss Roll"</span>)</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-40" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-40">Why It Matters</h4>
<p>Isomap was one of the first nonlinear methods to demonstrate that manifolds can be flattened computationally. It influenced later algorithms like LLE and diffusion maps. By preserving geodesic structure, Isomap is invaluable in fields like robotics (trajectory learning), bioinformatics (gene expression), and computer vision (pose estimation).</p>
</section>
<section id="try-it-yourself-41" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-41">Try It Yourself</h4>
<ol type="1">
<li>Apply Isomap with different neighbor sizes (<span class="math inline">\(k=5, 10, 30\)</span>). How does the embedding change?</li>
<li>Compare PCA vs.&nbsp;Isomap on Swiss roll. Which recovers the true 2D structure?</li>
<li>Use Isomap on facial pose datasets. Do embeddings align with head rotation angles?</li>
<li>Measure runtime as dataset size grows. How scalable is Isomap compared to PCA or UMAP?</li>
</ol>
</section>
</section>
<section id="locally-linear-embedding-lle" class="level3">
<h3 class="anchored" data-anchor-id="locally-linear-embedding-lle">843. Locally Linear Embedding (LLE)</h3>
<p>Locally Linear Embedding (LLE) is a nonlinear dimensionality reduction method that preserves local linear relationships. It assumes that each data point can be expressed as a weighted linear combination of its nearest neighbors, and these weights should remain consistent in the lower-dimensional embedding.</p>
<section id="picture-in-your-head-42" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-42">Picture in Your Head</h4>
<p>Imagine laying out tiles on a bumpy floor. Each tile only needs to fit snugly with its immediate neighbors, not the entire surface. LLE preserves these local fits, and when flattened, the global shape of the manifold emerges naturally.</p>
</section>
<section id="deep-dive-42" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-42">Deep Dive</h4>
<ul>
<li><p>Algorithm Steps:</p>
<ol type="1">
<li><p>Neighborhood Construction: For each point, find its <span class="math inline">\(k\)</span>-nearest neighbors.</p></li>
<li><p>Weight Computation: Solve for weights <span class="math inline">\(w_{ij}\)</span> that best reconstruct the point from its neighbors:</p>
<p><span class="math display">\[
x_i \approx \sum_{j} w_{ij} x_j
\]</span></p>
<p>subject to <span class="math inline">\(\sum_j w_{ij} = 1\)</span>.</p></li>
<li><p>Embedding Optimization: Find low-dimensional coordinates <span class="math inline">\(y_i\)</span> that preserve the same weights:</p>
<p><span class="math display">\[
y_i \approx \sum_{j} w_{ij} y_j
\]</span></p></li>
</ol></li>
<li><p>Key Properties:</p>
<ul>
<li>Captures nonlinear manifolds using only local information.</li>
<li>Embedding is obtained by solving a sparse eigenvalue problem.</li>
</ul></li>
<li><p>Strengths:</p>
<ul>
<li>Good at preserving local geometry.</li>
<li>Parameter-free once neighbors are chosen.</li>
</ul></li>
<li><p>Weaknesses:</p>
<ul>
<li>Sensitive to choice of neighbors <span class="math inline">\(k\)</span>.</li>
<li>Struggles with noise and non-uniform sampling.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Step</th>
<th>Operation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Neighborhood graph</td>
<td>k-nearest neighbors</td>
</tr>
<tr class="even">
<td>Weight solving</td>
<td>Local linear reconstruction</td>
</tr>
<tr class="odd">
<td>Embedding</td>
<td>Eigen-decomposition</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_swiss_roll</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> LocallyLinearEmbedding</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Swiss roll dataset</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>X, color <span class="op">=</span> make_swiss_roll(n_samples<span class="op">=</span><span class="dv">1000</span>, noise<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply LLE</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>lle <span class="op">=</span> LocallyLinearEmbedding(n_neighbors<span class="op">=</span><span class="dv">12</span>, n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>X_lle <span class="op">=</span> lle.fit_transform(X)</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_lle[:,<span class="dv">0</span>], X_lle[:,<span class="dv">1</span>], c<span class="op">=</span>color, cmap<span class="op">=</span>plt.cm.Spectral, s<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"LLE Unrolling the Swiss Roll"</span>)</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-41" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-41">Why It Matters</h4>
<p>LLE introduced a local-first perspective on manifold learning, influencing many later algorithms (Hessian LLE, Laplacian Eigenmaps). It highlights that complex global geometry can be captured by stitching together local patches. a principle that resonates with modern graph neural networks.</p>
</section>
<section id="try-it-yourself-42" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-42">Try It Yourself</h4>
<ol type="1">
<li>Apply LLE with different <span class="math inline">\(k\)</span>. How does too small or too large <span class="math inline">\(k\)</span> affect the result?</li>
<li>Compare LLE with Isomap on Swiss roll. Which preserves local neighborhoods better?</li>
<li>Add noise to data and rerun LLE. How robust is it?</li>
<li>Apply LLE on face images with varying poses. Does it order them smoothly by angle?</li>
</ol>
</section>
</section>
<section id="laplacian-eigenmaps-and-spectral-embedding" class="level3">
<h3 class="anchored" data-anchor-id="laplacian-eigenmaps-and-spectral-embedding">844. Laplacian Eigenmaps and Spectral Embedding</h3>
<p>Laplacian Eigenmaps is a manifold learning technique that uses graph Laplacians to preserve local neighborhood structure in a lower-dimensional space. It builds a weighted graph of data points and embeds them by minimizing distances along edges, effectively flattening the manifold while respecting its geometry.</p>
<section id="picture-in-your-head-43" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-43">Picture in Your Head</h4>
<p>Imagine a network of cities connected by roads. The Laplacian Eigenmaps method tries to place the cities on a flat map such that connected cities remain close together, even if the original geography was curved or twisted.</p>
</section>
<section id="deep-dive-43" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-43">Deep Dive</h4>
<ul>
<li><p>Graph Construction:</p>
<ul>
<li><p>Build a neighborhood graph (e.g., k-NN).</p></li>
<li><p>Assign weights using a heat kernel:</p>
<p><span class="math display">\[
w_{ij} = \exp\left(-\frac{\|x_i - x_j\|^2}{t}\right)
\]</span></p>
<p>if <span class="math inline">\(x_j\)</span> is a neighbor of <span class="math inline">\(x_i\)</span>.</p></li>
</ul></li>
<li><p>Graph Laplacian:</p>
<ul>
<li>Degree matrix: <span class="math inline">\(D_{ii} = \sum_j w_{ij}\)</span>.</li>
<li>Laplacian: <span class="math inline">\(L = D - W\)</span>.</li>
</ul></li>
<li><p>Optimization Problem: Find embedding <span class="math inline">\(Y\)</span> that minimizes:</p>
<p><span class="math display">\[
\sum_{i,j} w_{ij} \|y_i - y_j\|^2
\]</span></p>
<p>subject to constraints to avoid trivial solutions.</p></li>
<li><p>Solution:</p>
<ul>
<li><p>Solve generalized eigenvalue problem:</p>
<p><span class="math display">\[
Lf = \lambda D f
\]</span></p></li>
<li><p>Use the eigenvectors corresponding to the smallest nonzero eigenvalues as embedding coordinates.</p></li>
</ul></li>
<li><p>Properties:</p>
<ul>
<li>Preserves local neighborhoods.</li>
<li>Connects graph theory with dimensionality reduction.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Step</th>
<th>Method Used</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Graph construction</td>
<td>k-NN + Gaussian weights</td>
</tr>
<tr class="even">
<td>Laplacian computation</td>
<td><span class="math inline">\(L = D - W\)</span></td>
</tr>
<tr class="odd">
<td>Embedding</td>
<td>Eigenvectors of generalized system</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_swiss_roll</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> SpectralEmbedding</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Swiss roll dataset</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>X, color <span class="op">=</span> make_swiss_roll(n_samples<span class="op">=</span><span class="dv">1000</span>, noise<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply Laplacian Eigenmaps (Spectral Embedding in sklearn)</span></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>se <span class="op">=</span> SpectralEmbedding(n_components<span class="op">=</span><span class="dv">2</span>, n_neighbors<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>X_se <span class="op">=</span> se.fit_transform(X)</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_se[:,<span class="dv">0</span>], X_se[:,<span class="dv">1</span>], c<span class="op">=</span>color, cmap<span class="op">=</span>plt.cm.Spectral, s<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Laplacian Eigenmaps on Swiss Roll"</span>)</span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-42" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-42">Why It Matters</h4>
<p>Laplacian Eigenmaps laid the foundation for spectral methods in machine learning, including spectral clustering and semi-supervised learning. By framing embedding as an eigenvalue problem on graphs, it connects geometry, probability, and algebra, influencing both classical manifold learning and modern deep graph learning.</p>
</section>
<section id="try-it-yourself-43" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-43">Try It Yourself</h4>
<ol type="1">
<li>Apply Laplacian Eigenmaps with different neighbor counts. Does local structure change?</li>
<li>Compare Isomap, LLE, and Laplacian Eigenmaps on Swiss roll. Which preserves clusters best?</li>
<li>Use Laplacian Eigenmaps for spectral clustering. Do clusters align with labels?</li>
<li>Apply to graph data (e.g., social networks). Do embeddings preserve community structure?</li>
</ol>
</section>
</section>
<section id="diffusion-maps-and-dynamics" class="level3">
<h3 class="anchored" data-anchor-id="diffusion-maps-and-dynamics">845. Diffusion Maps and Dynamics</h3>
<p>Diffusion Maps is a nonlinear dimensionality reduction method that interprets data as a Markov diffusion process on a graph. It captures both local and global geometry by modeling how information “flows” over multiple steps, revealing intrinsic structures and scales in the data.</p>
<section id="picture-in-your-head-44" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-44">Picture in Your Head</h4>
<p>Imagine dropping a drop of ink on blotting paper. The way the ink diffuses depends on the paper’s hidden structure. Diffusion maps simulate this process on data, where the flow of probability uncovers the manifold’s geometry.</p>
</section>
<section id="deep-dive-44" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-44">Deep Dive</h4>
<ul>
<li><p>Step 1: Graph Construction</p>
<ul>
<li><p>Build affinity matrix with heat kernel:</p>
<p><span class="math display">\[
w_{ij} = \exp\left(-\frac{\|x_i - x_j\|^2}{\epsilon}\right)
\]</span></p></li>
<li><p>Normalize to form transition probabilities of a Markov chain:</p>
<p><span class="math display">\[
p_{ij} = \frac{w_{ij}}{\sum_k w_{ik}}
\]</span></p></li>
</ul></li>
<li><p>Step 2: Diffusion Operator</p>
<ul>
<li>The Markov chain defines a diffusion operator <span class="math inline">\(P\)</span>.</li>
<li>Powers of <span class="math inline">\(P\)</span> (e.g., <span class="math inline">\(P^t\)</span>) simulate diffusion at scale <span class="math inline">\(t\)</span>.</li>
</ul></li>
<li><p>Step 3: Spectral Decomposition</p>
<ul>
<li><p>Compute eigenvalues <span class="math inline">\(\lambda_i\)</span> and eigenvectors <span class="math inline">\(\phi_i\)</span> of <span class="math inline">\(P\)</span>.</p></li>
<li><p>Define embedding as:</p>
<p><span class="math display">\[
x \mapsto (\lambda_1^t \phi_1(x), \lambda_2^t \phi_2(x), \dots, \lambda_m^t \phi_m(x))
\]</span></p></li>
<li><p>Captures connectivity and intrinsic geometry across scales.</p></li>
</ul></li>
<li><p>Advantages:</p>
<ul>
<li>Preserves both local and global structure.</li>
<li>Naturally multiscale (controlled by diffusion time <span class="math inline">\(t\)</span>).</li>
<li>Robust to noise.</li>
</ul></li>
<li><p>Limitations:</p>
<ul>
<li>Requires kernel bandwidth <span class="math inline">\(\epsilon\)</span> tuning.</li>
<li>Eigen-decomposition can be expensive for very large datasets.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Step</th>
<th>Operation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Build affinity</td>
<td>Heat kernel + normalization</td>
</tr>
<tr class="even">
<td>Define operator</td>
<td>Transition matrix of Markov chain</td>
</tr>
<tr class="odd">
<td>Embed</td>
<td>Eigenvectors weighted by eigenvalues</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, via sklearn Kernel PCA as proxy)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_swiss_roll</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> rbf_kernel</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.sparse.linalg <span class="im">import</span> eigs</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Swiss roll dataset</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>X, color <span class="op">=</span> make_swiss_roll(n_samples<span class="op">=</span><span class="dv">1000</span>, noise<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Build affinity (heat kernel)</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> rbf_kernel(X, gamma<span class="op">=</span><span class="fl">1e-3</span>)</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>P <span class="op">=</span> W <span class="op">/</span> W.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Diffusion operator eigen-decomposition</span></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>vals, vecs <span class="op">=</span> eigs(P, k<span class="op">=</span><span class="dv">3</span>)  <span class="co"># top eigenvectors</span></span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a>X_diff <span class="op">=</span> np.real(vecs[:,<span class="dv">1</span>:<span class="dv">3</span>])  <span class="co"># skip trivial eigenvector</span></span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_diff[:,<span class="dv">0</span>], X_diff[:,<span class="dv">1</span>], c<span class="op">=</span>color, cmap<span class="op">=</span>plt.cm.Spectral, s<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Diffusion Maps on Swiss Roll"</span>)</span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-43" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-43">Why It Matters</h4>
<p>Diffusion maps provide a dynamical view of geometry. They are widely used in physics (molecular dynamics), biology (single-cell trajectories), and computer vision. By modeling connectivity as a diffusion process, they uncover both fine and coarse structures, bridging local neighborhoods and global organization.</p>
</section>
<section id="try-it-yourself-44" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-44">Try It Yourself</h4>
<ol type="1">
<li>Vary diffusion time <span class="math inline">\(t\)</span>. Do embeddings show different levels of structure?</li>
<li>Compare diffusion maps vs.&nbsp;Laplacian Eigenmaps. Which captures global continuity better?</li>
<li>Apply diffusion maps to single-cell RNA data. Do embeddings reveal developmental trajectories?</li>
<li>Test robustness by adding noise. Does diffusion embedding remain stable?</li>
</ol>
</section>
</section>
<section id="persistent-homology-and-topological-data-analysis" class="level3">
<h3 class="anchored" data-anchor-id="persistent-homology-and-topological-data-analysis">846. Persistent Homology and Topological Data Analysis</h3>
<p>Persistent Homology is a method from Topological Data Analysis (TDA) that studies the shape of data across multiple scales. Instead of focusing only on distances, it captures higher-order structures like loops, voids, and connected components, providing insights beyond clustering or dimensionality reduction.</p>
<section id="picture-in-your-head-45" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-45">Picture in Your Head</h4>
<p>Imagine submerging a landscape in water. As water rises, islands appear, merge, and eventually disappear. Persistent homology tracks these events. recording when topological features are “born” and when they “die.” Long-lived features represent meaningful structures; short-lived ones are noise.</p>
</section>
<section id="deep-dive-45" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-45">Deep Dive</h4>
<ul>
<li><p>Simplicial Complex Construction:</p>
<ul>
<li>Build complexes (generalized graphs) from data points.</li>
<li>Common choice: Vietoris–Rips complex, connecting points within a distance <span class="math inline">\(\epsilon\)</span>.</li>
</ul></li>
<li><p>Filtration:</p>
<ul>
<li>Vary <span class="math inline">\(\epsilon\)</span> (scale parameter).</li>
<li>Track how topological features evolve across scales.</li>
</ul></li>
<li><p>Persistence Diagrams / Barcodes:</p>
<ul>
<li>Each feature (component, loop, void) has a “birth” and “death” scale.</li>
<li>Represented as intervals (barcodes) or points (diagrams).</li>
<li>Long persistence = meaningful structure, short persistence = likely noise.</li>
</ul></li>
<li><p>Applications:</p>
<ul>
<li>Shape analysis in computer vision.</li>
<li>Single-cell biology (gene expression topologies).</li>
<li>Sensor networks (coverage gaps).</li>
<li>Material science (pore structures).</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Homology Class</th>
<th>Captures</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(H_0\)</span></td>
<td>Connected components</td>
</tr>
<tr class="even">
<td><span class="math inline">\(H_1\)</span></td>
<td>Loops or cycles</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(H_2\)</span></td>
<td>Voids or cavities</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, using <code>gudhi</code>)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gudhi <span class="im">as</span> gd</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Toy dataset: circle with noise</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span><span class="op">*</span>np.pi, <span class="dv">50</span>)</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.c_[np.cos(theta), np.sin(theta)] <span class="op">+</span> <span class="fl">0.1</span><span class="op">*</span>np.random.randn(<span class="dv">50</span>,<span class="dv">2</span>)</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Rips complex and persistence</span></span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>rips <span class="op">=</span> gd.RipsComplex(points<span class="op">=</span>X, max_edge_length<span class="op">=</span><span class="fl">2.0</span>)</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>st <span class="op">=</span> rips.create_simplex_tree(max_dimension<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>diag <span class="op">=</span> st.persistence()</span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot barcode</span></span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>gd.plot_persistence_barcode(diag)</span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-44" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-44">Why It Matters</h4>
<p>Persistent Homology reveals global shape and structure in data that traditional methods miss. By going beyond distances and densities, TDA provides tools for analyzing robustness, cycles, and voids. critical in biology, materials science, and any domain where geometry matters.</p>
</section>
<section id="try-it-yourself-45" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-45">Try It Yourself</h4>
<ol type="1">
<li>Generate points on a circle vs.&nbsp;a line. Do persistence diagrams distinguish them?</li>
<li>Apply persistent homology to noisy data. Which features persist?</li>
<li>Compare barcodes of different shapes (sphere, torus). Can TDA capture their differences?</li>
<li>Use persistence features as input to a classifier. Does performance improve?</li>
</ol>
</section>
</section>
<section id="graph-based-manifold-learning-approaches" class="level3">
<h3 class="anchored" data-anchor-id="graph-based-manifold-learning-approaches">847. Graph-Based Manifold Learning Approaches</h3>
<p>Graph-based manifold learning represents data as a graph, where nodes are data points and edges connect neighbors. The geometry of this graph encodes the manifold structure, and embeddings are obtained by analyzing connectivity, shortest paths, or spectral properties.</p>
<section id="picture-in-your-head-46" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-46">Picture in Your Head</h4>
<p>Think of a friendship network. Each person (node) is connected to close friends (edges). Even if you can’t see the entire social structure, analyzing connections reveals communities, influence, and hierarchy. Graph-based manifold learning treats data the same way: local links reveal global shape.</p>
</section>
<section id="deep-dive-46" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-46">Deep Dive</h4>
<ul>
<li><p>Neighborhood Graph Construction:</p>
<ul>
<li>Build k-nearest-neighbor (k-NN) or <span class="math inline">\(\epsilon\)</span>-neighborhood graphs.</li>
<li>Edge weights encode similarity (e.g., Gaussian kernel).</li>
</ul></li>
<li><p>Graph Laplacian and Spectrum:</p>
<ul>
<li>Laplacian eigenmaps use eigenvectors of the graph Laplacian to embed points.</li>
<li>Spectral clustering relies on similar principles.</li>
</ul></li>
<li><p>Shortest-Path Methods:</p>
<ul>
<li>Isomap computes geodesic distances via shortest paths in the graph.</li>
<li>Embedding preserves these distances globally.</li>
</ul></li>
<li><p>Diffusion-Based Methods:</p>
<ul>
<li>Diffusion maps simulate random walks on the graph.</li>
<li>Capture connectivity at multiple scales.</li>
</ul></li>
<li><p>Advantages:</p>
<ul>
<li>Flexible, works with any distance metric.</li>
<li>Unifies multiple methods (Isomap, LLE, Laplacian Eigenmaps, Diffusion Maps).</li>
</ul></li>
<li><p>Challenges:</p>
<ul>
<li>Choice of neighborhood size critical.</li>
<li>Graph sparsity vs.&nbsp;connectivity tradeoff.</li>
<li>Computational cost for large graphs.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Method</th>
<th>Graph Use Case</th>
<th>Preserves</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Isomap</td>
<td>Shortest paths</td>
<td>Global structure</td>
</tr>
<tr class="even">
<td>LLE</td>
<td>Reconstruction weights</td>
<td>Local linearity</td>
</tr>
<tr class="odd">
<td>Laplacian Eigenmaps</td>
<td>Laplacian spectrum</td>
<td>Local neighborhoods</td>
</tr>
<tr class="even">
<td>Diffusion Maps</td>
<td>Random walks</td>
<td>Multiscale structure</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_swiss_roll</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> kneighbors_graph</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate Swiss roll</span></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>X, color <span class="op">=</span> make_swiss_roll(n_samples<span class="op">=</span><span class="dv">500</span>, noise<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Build k-NN graph</span></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> kneighbors_graph(X, n_neighbors<span class="op">=</span><span class="dv">10</span>, mode<span class="op">=</span><span class="st">'connectivity'</span>)</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Adjacency matrix shape:"</span>, A.shape)</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot a small part of the graph (2D projection for visualization)</span></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:,<span class="dv">0</span>], X[:,<span class="dv">2</span>], c<span class="op">=</span>color, cmap<span class="op">=</span>plt.cm.Spectral, s<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Swiss Roll with k-NN Graph (Projection)"</span>)</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-45" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-45">Why It Matters</h4>
<p>Graph-based approaches unify manifold learning under a common framework. By reducing data geometry to graph connectivity, they enable spectral analysis, clustering, and embeddings. This foundation also connects directly to modern graph neural networks (GNNs), which generalize these ideas with deep learning.</p>
</section>
<section id="try-it-yourself-46" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-46">Try It Yourself</h4>
<ol type="1">
<li>Build graphs with different <span class="math inline">\(k\)</span> values. How does graph connectivity change?</li>
<li>Compare Isomap, LLE, and Laplacian Eigenmaps on the same dataset. Do they preserve different structures?</li>
<li>Apply graph-based embeddings to non-Euclidean data (e.g., strings with edit distance). Does it still work?</li>
<li>Use diffusion maps vs.&nbsp;shortest-path Isomap. Which captures global structure better?</li>
</ol>
</section>
</section>
<section id="evaluating-manifold-assumptions" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-manifold-assumptions">848. Evaluating Manifold Assumptions</h3>
<p>Manifold learning methods assume that high-dimensional data lies on or near a lower-dimensional manifold. But this assumption may not always hold. Evaluating when and how well the manifold hypothesis applies is critical before applying nonlinear dimensionality reduction.</p>
<section id="picture-in-your-head-47" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-47">Picture in Your Head</h4>
<p>Imagine unfolding an origami crane. If the folds were neat, it flattens nicely into a square (good manifold assumption). But if it’s crumpled paper, flattening distorts the shape badly (weak manifold structure). Data works the same way: some datasets “unroll” smoothly, others resist.</p>
</section>
<section id="deep-dive-47" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-47">Deep Dive</h4>
<ul>
<li><p>When the Assumption Holds:</p>
<ul>
<li>Data varies smoothly with a few intrinsic factors (pose, rotation, expression).</li>
<li>Local neighborhoods are well-sampled and connected.</li>
<li>Distances reflect meaningful relationships.</li>
</ul></li>
<li><p>When It Breaks Down:</p>
<ul>
<li>Data has high noise or irrelevant dimensions.</li>
<li>Manifold is poorly sampled (sparse data).</li>
<li>Intrinsic dimension is still very high.</li>
</ul></li>
<li><p>Evaluation Methods:</p>
<ul>
<li><p>Intrinsic Dimensionality Estimation: Estimate <span class="math inline">\(d\)</span> from data using nearest-neighbor distances, fractal dimensions, or maximum likelihood.</p></li>
<li><p>Trustworthiness &amp; Continuity Metrics: Measure preservation of neighborhoods after embedding.</p></li>
<li><p>Residual Variance: For Isomap:</p>
<p><span class="math display">\[
1 - R^2(y, d_G)
\]</span></p>
<p>where <span class="math inline">\(d_G\)</span> are graph distances, <span class="math inline">\(y\)</span> are embedded coordinates.</p></li>
<li><p>Visual Diagnostics: Scatterplots, stress plots, scree plots.</p></li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 28%">
<col style="width: 34%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Check</th>
<th>Technique</th>
<th>Insight Gained</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Dimensionality</td>
<td>k-NN–based estimators</td>
<td>Is low-d manifold plausible?</td>
</tr>
<tr class="even">
<td>Neighborhood fidelity</td>
<td>Trustworthiness/continuity</td>
<td>Local/global preservation</td>
</tr>
<tr class="odd">
<td>Residual variance</td>
<td>Isomap stress test</td>
<td>Fit of manifold assumption</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_digits</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> Isomap</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> pairwise_distances</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> spearmanr</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Digits dataset</span></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> load_digits(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Isomap embedding</span></span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>iso <span class="op">=</span> Isomap(n_neighbors<span class="op">=</span><span class="dv">10</span>, n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>X_iso <span class="op">=</span> iso.fit_transform(X)</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Residual variance (correlation between graph distances &amp; embedding distances)</span></span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a>D_high <span class="op">=</span> iso.dist_matrix_   <span class="co"># graph distances in high-d</span></span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>D_low <span class="op">=</span> pairwise_distances(X_iso)</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a>corr, _ <span class="op">=</span> spearmanr(D_high.ravel(), D_low.ravel())</span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a>residual_variance <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> corr2</span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Residual variance:"</span>, <span class="bu">round</span>(residual_variance, <span class="dv">3</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-46" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-46">Why It Matters</h4>
<p>Not all data lies on a clean manifold. Evaluating manifold assumptions prevents misuse of nonlinear methods that may introduce artifacts. This step ensures embeddings are meaningful, especially in critical fields like biology, finance, and medicine, where misrepresentations can mislead conclusions.</p>
</section>
<section id="try-it-yourself-47" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-47">Try It Yourself</h4>
<ol type="1">
<li>Estimate intrinsic dimensionality of your dataset with a k-NN–based method. Is it low compared to raw dimension?</li>
<li>Compute trustworthiness for PCA vs.&nbsp;Isomap. Which preserves neighborhoods better?</li>
<li>Apply Isomap and measure residual variance at different neighbor sizes. Where is the sweet spot?</li>
<li>Visualize embeddings from PCA, LLE, and UMAP. Do they all reveal consistent structure?</li>
</ol>
</section>
</section>
<section id="scalability-challenges-in-manifold-learning" class="level3">
<h3 class="anchored" data-anchor-id="scalability-challenges-in-manifold-learning">849. Scalability Challenges in Manifold Learning</h3>
<p>Manifold learning methods like Isomap, LLE, and diffusion maps often struggle to scale to modern datasets with millions of samples and thousands of features. Their reliance on distance computations, graph construction, and eigen-decomposition creates significant computational and memory bottlenecks.</p>
<section id="picture-in-your-head-48" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-48">Picture in Your Head</h4>
<p>Imagine trying to draw a map of a city by measuring the distance between every pair of houses. For a small village it’s feasible; for a megacity it’s impossible. Similarly, manifold learning works well for small datasets but becomes impractical at industrial scale without approximations.</p>
</section>
<section id="deep-dive-48" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-48">Deep Dive</h4>
<ul>
<li><p>Bottlenecks in Classical Methods:</p>
<ul>
<li>Distance matrix computation: Requires <span class="math inline">\(O(n^2)\)</span> storage and time.</li>
<li>Graph construction: k-NN search across all points scales poorly.</li>
<li>Eigen-decomposition: Requires <span class="math inline">\(O(n^3)\)</span> operations in worst case.</li>
</ul></li>
<li><p>Approximation Techniques:</p>
<ul>
<li>Approximate Nearest Neighbors (ANN): Libraries like FAISS or Annoy reduce k-NN search complexity.</li>
<li>Randomized Eigen/SVD: Speeds up eigenvalue problems.</li>
<li>Landmark Isomap/LLE: Use a subset of landmark points and interpolate.</li>
</ul></li>
<li><p>Scalable Variants:</p>
<ul>
<li>Incremental / Online methods: Update embeddings as new data arrives.</li>
<li>Graph sparsification: Reduce edges while preserving structure.</li>
<li>Distributed computation: Spark, GPU-based solvers for large graphs.</li>
</ul></li>
<li><p>Tradeoffs:</p>
<ul>
<li>Approximations reduce runtime but may distort local geometry.</li>
<li>Choice depends on whether visualization or quantitative analysis is the goal.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Challenge</th>
<th>Naive Cost</th>
<th>Scalable Alternative</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Pairwise distances</td>
<td><span class="math inline">\(O(n^2)\)</span></td>
<td>ANN search, landmarks</td>
</tr>
<tr class="even">
<td>Eigen-decomposition</td>
<td><span class="math inline">\(O(n^3)\)</span></td>
<td>Randomized SVD/eigen</td>
</tr>
<tr class="odd">
<td>Graph construction</td>
<td><span class="math inline">\(O(n^2)\)</span></td>
<td>k-d trees, locality hashing</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, using landmark Isomap)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_swiss_roll</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> Isomap</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate large Swiss roll</span></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>X, color <span class="op">=</span> make_swiss_roll(n_samples<span class="op">=</span><span class="dv">5000</span>, noise<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Landmark Isomap: reduce cost by subsampling</span></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>landmark_idx <span class="op">=</span> np.random.choice(<span class="bu">len</span>(X), <span class="dv">500</span>, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>X_landmarks <span class="op">=</span> X[landmark_idx]</span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>iso <span class="op">=</span> Isomap(n_neighbors<span class="op">=</span><span class="dv">10</span>, n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>X_iso <span class="op">=</span> iso.fit_transform(X_landmarks)</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original size:"</span>, X.shape, <span class="st">"Reduced embedding size:"</span>, X_iso.shape)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-47" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-47">Why It Matters</h4>
<p>Without scalable adaptations, manifold learning remains limited to toy datasets. In practice, approximations like UMAP and large-scale t-SNE with ANN made manifold learning viable for real-world applications such as genomics, NLP embeddings, and computer vision. Tackling scalability ensures these methods remain relevant in the era of big data.</p>
</section>
<section id="try-it-yourself-48" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-48">Try It Yourself</h4>
<ol type="1">
<li>Compare runtime of Isomap on 1,000 vs.&nbsp;10,000 samples. How does it scale?</li>
<li>Implement landmark Isomap with 10%, 20%, 50% of data. How does embedding quality change?</li>
<li>Use FAISS for nearest neighbor graph construction. Is it significantly faster?</li>
<li>Apply randomized SVD to PCA vs.&nbsp;full SVD. Is variance retention similar?</li>
</ol>
</section>
</section>
<section id="applications-in-science-and-engineering" class="level3">
<h3 class="anchored" data-anchor-id="applications-in-science-and-engineering">850. Applications in Science and Engineering</h3>
<p>Manifold learning techniques are not just abstract tools. they power real applications across science and engineering, where high-dimensional data often hides low-dimensional structure. By uncovering these manifolds, researchers can visualize, analyze, and model complex systems more effectively.</p>
<section id="picture-in-your-head-49" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-49">Picture in Your Head</h4>
<p>Think of an engineer simplifying a complex machine into a blueprint. The blueprint is lower-dimensional but still captures the essential relationships. Manifold learning provides this kind of “blueprint” for datasets in physics, biology, and engineering.</p>
</section>
<section id="deep-dive-49" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-49">Deep Dive</h4>
<ul>
<li><p>Physics and Chemistry:</p>
<ul>
<li>Molecular Dynamics: Diffusion maps reveal slow collective variables in protein folding.</li>
<li>Quantum Systems: PCA and spectral embeddings reduce wavefunction datasets for analysis.</li>
</ul></li>
<li><p>Biology and Medicine:</p>
<ul>
<li>Single-Cell Genomics: UMAP is standard for visualizing cell populations and differentiation trajectories.</li>
<li>Neuroscience: Manifold learning uncovers neural activity patterns in the brain.</li>
</ul></li>
<li><p>Engineering:</p>
<ul>
<li>Robotics: Isomap and LLE capture robot configuration spaces (e.g., arm poses).</li>
<li>Control Systems: Low-dimensional embeddings simplify state-space models.</li>
</ul></li>
<li><p>Earth and Climate Science:</p>
<ul>
<li>Dimensionality reduction of climate models highlights dominant modes of variability (e.g., ENSO patterns).</li>
<li>Sensor networks analyzed with Laplacian eigenmaps detect anomalies in geophysical data.</li>
</ul></li>
<li><p>Computer Vision:</p>
<ul>
<li>Pose and face manifolds show smooth trajectories of variation.</li>
<li>Nonlinear embeddings reveal intrinsic shape descriptors.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Field</th>
<th>Method Commonly Used</th>
<th>Insights Gained</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Molecular Bio</td>
<td>Diffusion Maps, UMAP</td>
<td>Folding pathways, cell types</td>
</tr>
<tr class="even">
<td>Robotics</td>
<td>Isomap, LLE</td>
<td>Motion/pose spaces</td>
</tr>
<tr class="odd">
<td>Neuroscience</td>
<td>Spectral Embedding</td>
<td>Neural population dynamics</td>
</tr>
<tr class="even">
<td>Climate</td>
<td>PCA, Laplacian Maps</td>
<td>Dominant variability modes</td>
</tr>
<tr class="odd">
<td>Vision</td>
<td>LLE, Autoencoders</td>
<td>Shape/pose manifolds</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Single-Cell Example)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> umap</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_digits</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulating single-cell embedding with digit dataset</span></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> load_digits(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a><span class="co"># UMAP reduction</span></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>reducer <span class="op">=</span> umap.UMAP(n_neighbors<span class="op">=</span><span class="dv">15</span>, min_dist<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>X_umap <span class="op">=</span> reducer.fit_transform(X)</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_umap[:,<span class="dv">0</span>], X_umap[:,<span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span><span class="st">"tab10"</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"UMAP as Analogy for Single-Cell Clustering"</span>)</span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-48" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-48">Why It Matters</h4>
<p>Applications prove that manifold learning is more than visualization. it extracts scientific insight from complex data. From drug discovery to robotics control, these methods bridge theory and practice, revealing structures that were previously invisible in high dimensions.</p>
</section>
<section id="try-it-yourself-49" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-49">Try It Yourself</h4>
<ol type="1">
<li>Apply UMAP to a genomics dataset. Do biological cell types cluster naturally?</li>
<li>Use Isomap to analyze robot joint angle configurations. Does it reveal smooth motion manifolds?</li>
<li>Reduce climate simulation data with PCA vs.&nbsp;Laplacian Eigenmaps. Which captures variability better?</li>
<li>Apply diffusion maps to protein trajectories. Do slow modes align with known folding steps?</li>
</ol>
</section>
</section>
</section>
<section id="chapter-86.-topic-models-and-laten-dirichlet-allocation" class="level2">
<h2 class="anchored" data-anchor-id="chapter-86.-topic-models-and-laten-dirichlet-allocation">Chapter 86. Topic models and laten dirichlet allocation</h2>
<section id="introduction-to-topic-modeling" class="level3">
<h3 class="anchored" data-anchor-id="introduction-to-topic-modeling">851. Introduction to Topic Modeling</h3>
<p>Topic modeling is a family of unsupervised methods that uncover latent themes in collections of documents. Instead of treating text as flat word counts, topic models assume each document is a mixture of topics, and each topic is a distribution over words.</p>
<section id="picture-in-your-head-50" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-50">Picture in Your Head</h4>
<p>Imagine sorting a library without labels. You notice recurring themes: some books talk about space, others about history, others about cooking. Topic modeling is like an automatic librarian that clusters words into topics and mixes those topics to explain each book.</p>
</section>
<section id="deep-dive-50" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-50">Deep Dive</h4>
<ul>
<li><p>Motivation:</p>
<ul>
<li>Text data is high-dimensional and sparse.</li>
<li>Latent structures (topics) provide interpretable summaries.</li>
</ul></li>
<li><p>Basic Idea:</p>
<ul>
<li>Documents are generated by choosing topics.</li>
<li>Each topic defines word probabilities.</li>
<li>Observed word counts arise from these mixtures.</li>
</ul></li>
<li><p>Classic Methods:</p>
<ul>
<li>Latent Semantic Analysis (LSA): Matrix factorization on term–document matrix.</li>
<li>Probabilistic Latent Semantic Analysis (pLSA): Probabilistic mixture model of topics.</li>
<li>Latent Dirichlet Allocation (LDA): Bayesian generative model with priors on topic distributions.</li>
</ul></li>
<li><p>Strengths:</p>
<ul>
<li>Provides interpretable word clusters.</li>
<li>Scales to large text corpora.</li>
<li>Useful for organizing, searching, and summarizing.</li>
</ul></li>
<li><p>Limitations:</p>
<ul>
<li>Bag-of-words assumption ignores word order.</li>
<li>Sensitive to number of topics chosen.</li>
<li>Topics may mix multiple concepts if not well-tuned.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 6%">
<col style="width: 41%">
<col style="width: 26%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>Core Idea</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>LSA</td>
<td>SVD on word–doc matrix</td>
<td>Fast, simple</td>
<td>Linear, less precise</td>
</tr>
<tr class="even">
<td>pLSA</td>
<td>Mixture of topics per document</td>
<td>Probabilistic</td>
<td>No priors, overfits</td>
</tr>
<tr class="odd">
<td>LDA</td>
<td>Bayesian topic model with priors</td>
<td>Robust, interpretable</td>
<td>Requires inference</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, LDA with sklearn)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> LatentDirichletAllocation</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> [</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"The universe is vast and full of stars"</span>,</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Astronomy and space science are fascinating"</span>,</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Recipes for cooking pasta and bread"</span>,</span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"History books tell stories of ancient empires"</span>,</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Cooking with spices makes food delicious"</span></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Vectorize documents</span></span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a>vectorizer <span class="op">=</span> CountVectorizer(stop_words<span class="op">=</span><span class="st">"english"</span>)</span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> vectorizer.fit_transform(docs)</span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a><span class="co"># LDA model</span></span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a>lda <span class="op">=</span> LatentDirichletAllocation(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a>lda.fit(X)</span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Print topics</span></span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, topic <span class="kw">in</span> <span class="bu">enumerate</span>(lda.components_):</span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> [vectorizer.get_feature_names_out()[j] <span class="cf">for</span> j <span class="kw">in</span> topic.argsort()[<span class="op">-</span><span class="dv">5</span>:]]</span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Topic </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">:"</span>, words)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-49" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-49">Why It Matters</h4>
<p>Topic modeling transforms raw text into structured, interpretable representations. It powers document clustering, recommendation, and trend analysis in domains like journalism, legal discovery, and scientific literature. It bridges language and machine learning by uncovering hidden semantic patterns.</p>
</section>
<section id="try-it-yourself-50" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-50">Try It Yourself</h4>
<ol type="1">
<li>Train LDA on a set of news articles. Do topics align with domains (politics, sports, finance)?</li>
<li>Compare LSA vs.&nbsp;LDA. Which produces more interpretable topics?</li>
<li>Experiment with different numbers of topics. How does interpretability change?</li>
<li>Visualize topics using t-SNE or UMAP on document embeddings. Do clusters emerge?</li>
</ol>
</section>
</section>
<section id="latent-semantic-analysis-lsa" class="level3">
<h3 class="anchored" data-anchor-id="latent-semantic-analysis-lsa">852. Latent Semantic Analysis (LSA)</h3>
<p>Latent Semantic Analysis (LSA) is one of the earliest topic modeling techniques. It applies Singular Value Decomposition (SVD) to the term–document matrix, uncovering latent semantic dimensions that capture relationships between words and documents beyond raw co-occurrence.</p>
<section id="picture-in-your-head-51" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-51">Picture in Your Head</h4>
<p>Think of compressing a dictionary. Instead of listing every word separately, you group them into clusters of meaning (like “astronomy,” “politics,” or “cooking”). LSA creates such compressed semantic dimensions, where similar words and documents are closer together.</p>
</section>
<section id="deep-dive-51" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-51">Deep Dive</h4>
<ul>
<li><p>Step 1: Build Term–Document Matrix</p>
<ul>
<li>Each row = word, each column = document.</li>
<li>Entries = word frequency or TF–IDF weight.</li>
</ul></li>
<li><p>Step 2: Apply SVD</p>
<ul>
<li><p>Decompose:</p>
<p><span class="math display">\[
X = U \Sigma V^T
\]</span></p></li>
<li><p>Keep top-<span class="math inline">\(k\)</span> singular values.</p></li>
<li><p>Documents and words are embedded in <span class="math inline">\(k\)</span>-dimensional latent semantic space.</p></li>
</ul></li>
<li><p>Step 3: Interpretation</p>
<ul>
<li>Latent dimensions capture correlations among words and documents.</li>
<li>Words with similar contexts end up close in the reduced space.</li>
</ul></li>
<li><p>Strengths:</p>
<ul>
<li>Simple linear algebra approach.</li>
<li>Handles synonymy (different words with similar meaning).</li>
<li>Useful for information retrieval and search.</li>
</ul></li>
<li><p>Limitations:</p>
<ul>
<li>Components are not probabilistic (harder to interpret as “topics”).</li>
<li>Sensitive to noise and scaling.</li>
<li>Cannot model polysemy (same word with multiple meanings).</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 31%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Step</th>
<th>Technique</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Build matrix</td>
<td>Term–document counts</td>
<td>Represent raw text</td>
</tr>
<tr class="even">
<td>Apply SVD</td>
<td>Matrix factorization</td>
<td>Find latent semantic dimensions</td>
</tr>
<tr class="odd">
<td>Reduce rank</td>
<td>Keep top-<span class="math inline">\(k\)</span> values</td>
<td>Capture dominant semantic themes</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> TruncatedSVD</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> [</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"The universe is vast and full of stars"</span>,</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Astronomy and space science are fascinating"</span>,</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Cooking pasta and baking bread"</span>,</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Spices and recipes make delicious food"</span></span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a><span class="co"># TF–IDF matrix</span></span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>vectorizer <span class="op">=</span> TfidfVectorizer(stop_words<span class="op">=</span><span class="st">"english"</span>)</span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> vectorizer.fit_transform(docs)</span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply LSA (SVD with reduced rank)</span></span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a>lsa <span class="op">=</span> TruncatedSVD(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a>X_lsa <span class="op">=</span> lsa.fit_transform(X)</span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-19"><a href="#cb53-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Top concepts per component:"</span>)</span>
<span id="cb53-20"><a href="#cb53-20" aria-hidden="true" tabindex="-1"></a>terms <span class="op">=</span> vectorizer.get_feature_names_out()</span>
<span id="cb53-21"><a href="#cb53-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, comp <span class="kw">in</span> <span class="bu">enumerate</span>(lsa.components_):</span>
<span id="cb53-22"><a href="#cb53-22" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> [terms[j] <span class="cf">for</span> j <span class="kw">in</span> comp.argsort()[<span class="op">-</span><span class="dv">5</span>:]]</span>
<span id="cb53-23"><a href="#cb53-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Component </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">:"</span>, words)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-50" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-50">Why It Matters</h4>
<p>LSA showed that linear algebra could uncover hidden semantics in language. It laid the groundwork for probabilistic topic models like LDA and modern embedding methods. Even today, LSA-style embeddings are used in search engines, recommender systems, and document clustering.</p>
</section>
<section id="try-it-yourself-51" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-51">Try It Yourself</h4>
<ol type="1">
<li>Apply LSA to a set of scientific abstracts. Do components align with research fields?</li>
<li>Compare word similarity in raw counts vs.&nbsp;LSA-reduced space. Which better captures synonyms?</li>
<li>Visualize documents in 2D after LSA. Do related texts cluster together?</li>
<li>Increase number of components. When does interpretability decrease?</li>
</ol>
</section>
</section>
<section id="probabilistic-latent-semantic-analysis-plsa" class="level3">
<h3 class="anchored" data-anchor-id="probabilistic-latent-semantic-analysis-plsa">853. Probabilistic Latent Semantic Analysis (pLSA)</h3>
<p>Probabilistic Latent Semantic Analysis (pLSA) extends LSA by introducing a probabilistic generative model. Instead of relying on purely linear algebra, it models documents as mixtures of latent topics, and topics as probability distributions over words.</p>
<section id="picture-in-your-head-52" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-52">Picture in Your Head</h4>
<p>Think of a buffet: each diner (document) fills their plate with different amounts of dishes (topics), and each dish is made of specific ingredients (words). pLSA learns both the dishes and how each diner mixes them.</p>
</section>
<section id="deep-dive-52" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-52">Deep Dive</h4>
<ul>
<li><p>Model Assumptions:</p>
<ul>
<li><p>Each document <span class="math inline">\(d\)</span> has a probability distribution over topics <span class="math inline">\(P(z|d)\)</span>.</p></li>
<li><p>Each topic <span class="math inline">\(z\)</span> has a probability distribution over words <span class="math inline">\(P(w|z)\)</span>.</p></li>
<li><p>The probability of a word in a document:</p>
<p><span class="math display">\[
P(w|d) = \sum_{z} P(w|z) P(z|d)
\]</span></p></li>
</ul></li>
<li><p>Training:</p>
<ul>
<li>Uses Expectation-Maximization (EM) to estimate <span class="math inline">\(P(z|d)\)</span> and <span class="math inline">\(P(w|z)\)</span>.</li>
<li>E-step: compute topic responsibilities for each word occurrence.</li>
<li>M-step: update topic–word and document–topic distributions.</li>
</ul></li>
<li><p>Strengths:</p>
<ul>
<li>Probabilistic foundation, unlike LSA.</li>
<li>Captures soft clustering (documents can belong to multiple topics).</li>
<li>Better at modeling synonymy and word co-occurrence.</li>
</ul></li>
<li><p>Limitations:</p>
<ul>
<li>Overfits since it lacks priors (number of parameters grows with dataset).</li>
<li>Not a fully generative model of documents (only models observed words, not unseen ones).</li>
<li>Superseded by Latent Dirichlet Allocation (LDA).</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Step</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>E-step</td>
<td>Assign topic probabilities per word occurrence</td>
</tr>
<tr class="even">
<td>M-step</td>
<td>Update word–topic and doc–topic distributions</td>
</tr>
<tr class="odd">
<td>Iteration</td>
<td>Repeat until convergence</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, using scikit-learn’s LDA as proxy for pLSA)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> LatentDirichletAllocation</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> [</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Stars and galaxies are studied in astronomy"</span>,</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Planets and space missions are fascinating"</span>,</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Cooking recipes use spices and fresh food"</span>,</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Bread and pasta are popular dishes"</span></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Count matrix</span></span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a>vectorizer <span class="op">=</span> CountVectorizer(stop_words<span class="op">=</span><span class="st">"english"</span>)</span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> vectorizer.fit_transform(docs)</span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a><span class="co"># pLSA equivalent: LDA without priors (α, β → fixed)</span></span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a>lda <span class="op">=</span> LatentDirichletAllocation(n_components<span class="op">=</span><span class="dv">2</span>, learning_method<span class="op">=</span><span class="st">"em"</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a>lda.fit(X)</span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-19"><a href="#cb54-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Print topics</span></span>
<span id="cb54-20"><a href="#cb54-20" aria-hidden="true" tabindex="-1"></a>terms <span class="op">=</span> vectorizer.get_feature_names_out()</span>
<span id="cb54-21"><a href="#cb54-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, comp <span class="kw">in</span> <span class="bu">enumerate</span>(lda.components_):</span>
<span id="cb54-22"><a href="#cb54-22" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> [terms[i] <span class="cf">for</span> i <span class="kw">in</span> comp.argsort()[<span class="op">-</span><span class="dv">5</span>:]]</span>
<span id="cb54-23"><a href="#cb54-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Topic </span><span class="sc">{</span>idx<span class="sc">}</span><span class="ss">:"</span>, words)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-51" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-51">Why It Matters</h4>
<p>pLSA was the first major step from linear algebraic methods to probabilistic topic modeling. Although replaced by LDA, it introduced the idea of mixtures of topics per document, which remains foundational in NLP and information retrieval.</p>
</section>
<section id="try-it-yourself-52" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-52">Try It Yourself</h4>
<ol type="1">
<li>Train pLSA on a set of news articles. Do topics correspond to real-world categories?</li>
<li>Compare LSA vs.&nbsp;pLSA embeddings of the same dataset. Which separates topics better?</li>
<li>Increase number of topics. When do they start to fragment?</li>
<li>Evaluate held-out likelihood. Does pLSA overfit compared to LDA?</li>
</ol>
</section>
</section>
<section id="latent-dirichlet-allocation-lda-basics" class="level3">
<h3 class="anchored" data-anchor-id="latent-dirichlet-allocation-lda-basics">854. Latent Dirichlet Allocation (LDA) Basics</h3>
<p>Latent Dirichlet Allocation (LDA) is the most influential topic modeling method. It extends pLSA by placing Dirichlet priors on document–topic and topic–word distributions, making it a fully generative probabilistic model. This prevents overfitting and enables inference on unseen documents.</p>
<section id="picture-in-your-head-53" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-53">Picture in Your Head</h4>
<p>Think of a publishing house. Each book (document) is written by mixing genres (topics), like history or science fiction. Genres themselves have characteristic vocabularies (word distributions). LDA formalizes this process by treating documents as mixtures of topics drawn from prior distributions.</p>
</section>
<section id="deep-dive-53" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-53">Deep Dive</h4>
<ul>
<li><p>Generative Process:</p>
<ol type="1">
<li><p>For each document <span class="math inline">\(d\)</span>, draw topic distribution:</p>
<p><span class="math display">\[
\theta_d \sim \text{Dirichlet}(\alpha)
\]</span></p></li>
<li><p>For each topic <span class="math inline">\(z\)</span>, draw word distribution:</p>
<p><span class="math display">\[
\phi_z \sim \text{Dirichlet}(\beta)
\]</span></p></li>
<li><p>For each word in document <span class="math inline">\(d\)</span>:</p>
<ul>
<li>Choose topic <span class="math inline">\(z \sim \theta_d\)</span>.</li>
<li>Choose word <span class="math inline">\(w \sim \phi_z\)</span>.</li>
</ul></li>
</ol></li>
<li><p>Key Properties:</p>
<ul>
<li><span class="math inline">\(\alpha\)</span>: Controls sparsity of topics per document.</li>
<li><span class="math inline">\(\beta\)</span>: Controls sparsity of words per topic.</li>
<li>Dirichlet priors regularize, avoiding overfitting of pLSA.</li>
</ul></li>
<li><p>Inference:</p>
<ul>
<li>Collapsed Gibbs Sampling or Variational Bayes approximate the hidden structure.</li>
<li>Estimate posterior <span class="math inline">\(P(\theta, \phi, z | w, \alpha, \beta)\)</span>.</li>
</ul></li>
<li><p>Strengths:</p>
<ul>
<li>Fully generative, supports new documents.</li>
<li>Produces interpretable topics.</li>
<li>Robust to overfitting compared to pLSA.</li>
</ul></li>
<li><p>Limitations:</p>
<ul>
<li>Bag-of-words assumption ignores order and syntax.</li>
<li>Computationally expensive for very large corpora.</li>
<li>Choosing number of topics remains tricky.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Model</th>
<th>Regularization</th>
<th>Handles New Docs?</th>
<th>Interpretability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>LSA</td>
<td>None</td>
<td>No</td>
<td>Low</td>
</tr>
<tr class="even">
<td>pLSA</td>
<td>None</td>
<td>No</td>
<td>Medium</td>
</tr>
<tr class="odd">
<td>LDA</td>
<td>Dirichlet priors</td>
<td>Yes</td>
<td>High</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, LDA with Gibbs Sampling via gensim)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim <span class="im">import</span> corpora, models</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> [</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Astronomy explores stars and galaxies"</span>,</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Space missions study planets and black holes"</span>,</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Recipes use pasta, bread, and spices"</span>,</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Cooking food with fresh ingredients is delicious"</span></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Tokenize and build dictionary</span></span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>texts <span class="op">=</span> [doc.lower().split() <span class="cf">for</span> doc <span class="kw">in</span> docs]</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>dictionary <span class="op">=</span> corpora.Dictionary(texts)</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> [dictionary.doc2bow(text) <span class="cf">for</span> text <span class="kw">in</span> texts]</span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a><span class="co"># LDA model</span></span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a>lda <span class="op">=</span> models.LdaModel(corpus, num_topics<span class="op">=</span><span class="dv">2</span>, id2word<span class="op">=</span>dictionary, passes<span class="op">=</span><span class="dv">15</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-18"><a href="#cb55-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, topic <span class="kw">in</span> lda.show_topics(num_topics<span class="op">=</span><span class="dv">2</span>, num_words<span class="op">=</span><span class="dv">5</span>, formatted<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb55-19"><a href="#cb55-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Topic </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">:"</span>, [word <span class="cf">for</span> word, _ <span class="kw">in</span> topic])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-52" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-52">Why It Matters</h4>
<p>LDA marked the transition from linear-algebraic text analysis to Bayesian machine learning for documents. Its framework influenced later advances in hierarchical topic models, neural topic models, and embeddings. Even today, LDA is a baseline for interpretable unsupervised text analysis.</p>
</section>
<section id="try-it-yourself-53" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-53">Try It Yourself</h4>
<ol type="1">
<li>Train LDA with different values of <span class="math inline">\(\alpha\)</span>. Do documents use more or fewer topics?</li>
<li>Compare LDA topics on news vs.&nbsp;scientific articles. Are topics domain-specific?</li>
<li>Evaluate perplexity for different numbers of topics. What’s the optimal range?</li>
<li>Visualize documents in topic space using t-SNE or UMAP. Do clusters align with categories?</li>
</ol>
</section>
</section>
<section id="inference-in-lda-gibbs-sampling-variational-bayes" class="level3">
<h3 class="anchored" data-anchor-id="inference-in-lda-gibbs-sampling-variational-bayes">855. Inference in LDA: Gibbs Sampling, Variational Bayes</h3>
<p>Latent Dirichlet Allocation (LDA) cannot compute exact posteriors, so it relies on approximate inference. Two dominant approaches are Collapsed Gibbs Sampling (a Monte Carlo method) and Variational Bayes (VB) (an optimization method). Both aim to approximate hidden topic assignments and distributions.</p>
<section id="picture-in-your-head-54" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-54">Picture in Your Head</h4>
<p>Think of trying to guess a book’s genre from its words. Gibbs Sampling is like repeatedly reassigning each word to a topic until the overall assignment stabilizes. Variational Bayes is like fitting a simpler “summary distribution” that closely mimics the true, but intractable, posterior.</p>
</section>
<section id="deep-dive-54" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-54">Deep Dive</h4>
<ul>
<li><p>Collapsed Gibbs Sampling</p>
<ul>
<li><p>Iteratively samples topic assignment for each word given all others.</p></li>
<li><p>Conditional probability:</p>
<p><span class="math display">\[
P(z_{i}=k | z_{-i}, w) \propto (n_{dk}^{-i} + \alpha) \cdot \frac{n_{kw}^{-i} + \beta}{n_{k}^{-i} + V\beta}
\]</span></p>
<p>where <span class="math inline">\(n_{dk}\)</span> = count of topic <span class="math inline">\(k\)</span> in doc <span class="math inline">\(d\)</span>, <span class="math inline">\(n_{kw}\)</span> = count of word <span class="math inline">\(w\)</span> in topic <span class="math inline">\(k\)</span>, <span class="math inline">\(n_k\)</span> = total words in topic <span class="math inline">\(k\)</span>.</p></li>
<li><p>After many iterations, samples approximate the posterior.</p></li>
</ul></li>
<li><p>Variational Bayes (VB)</p>
<ul>
<li><p>Uses a simpler distribution <span class="math inline">\(q(\theta, z)\)</span> to approximate true posterior <span class="math inline">\(p(\theta, z|w)\)</span>.</p></li>
<li><p>Minimizes KL divergence:</p>
<p><span class="math display">\[
\text{min } KL(q || p)
\]</span></p></li>
<li><p>Leads to coordinate ascent updates for variational parameters.</p></li>
</ul></li>
<li><p>Comparison:</p>
<ul>
<li>Gibbs Sampling: simpler, often more accurate but slower.</li>
<li>VB: faster, scalable, but sometimes less accurate.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Method</th>
<th>Strengths</th>
<th>Weaknesses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Gibbs Sampling</td>
<td>Simple, accurate</td>
<td>Slow, not scalable</td>
</tr>
<tr class="even">
<td>Variational Bayes</td>
<td>Fast, scalable</td>
<td>Approximation bias</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Gibbs Sampling with gensim)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim <span class="im">import</span> corpora, models</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> [</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Stars and galaxies are studied in astronomy"</span>,</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Planets and missions explore outer space"</span>,</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Cooking recipes use bread, pasta, and spices"</span>,</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Food and ingredients make delicious meals"</span></span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Tokenize and build corpus</span></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>texts <span class="op">=</span> [doc.lower().split() <span class="cf">for</span> doc <span class="kw">in</span> docs]</span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>dictionary <span class="op">=</span> corpora.Dictionary(texts)</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> [dictionary.doc2bow(text) <span class="cf">for</span> text <span class="kw">in</span> texts]</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Gibbs Sampling approximation</span></span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a>lda_gibbs <span class="op">=</span> models.LdaModel(</span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a>    corpus, num_topics<span class="op">=</span><span class="dv">2</span>, id2word<span class="op">=</span>dictionary,</span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a>    passes<span class="op">=</span><span class="dv">20</span>, iterations<span class="op">=</span><span class="dv">50</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb56-19"><a href="#cb56-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb56-20"><a href="#cb56-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-21"><a href="#cb56-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, topic <span class="kw">in</span> lda_gibbs.show_topics(num_topics<span class="op">=</span><span class="dv">2</span>, num_words<span class="op">=</span><span class="dv">5</span>, formatted<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb56-22"><a href="#cb56-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Topic </span><span class="sc">{</span>idx<span class="sc">}</span><span class="ss">:"</span>, [w <span class="cf">for</span> w, _ <span class="kw">in</span> topic])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-53" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-53">Why It Matters</h4>
<p>Inference is the engine of LDA. Without efficient approximation, topic modeling on large corpora (millions of documents) would be impossible. The choice between Gibbs Sampling and Variational Bayes reflects a classic tradeoff in AI: accuracy vs.&nbsp;scalability.</p>
</section>
<section id="try-it-yourself-54" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-54">Try It Yourself</h4>
<ol type="1">
<li>Run LDA with Gibbs Sampling and VB on the same dataset. Do topics differ?</li>
<li>Increase number of iterations in Gibbs Sampling. How does stability improve?</li>
<li>Compare runtime of Gibbs vs.&nbsp;VB on large corpora. Which scales better?</li>
<li>Measure perplexity and coherence for both methods. Which gives higher-quality topics?</li>
</ol>
</section>
</section>
<section id="extensions-dynamic-hierarchical-and-correlated-topic-models" class="level3">
<h3 class="anchored" data-anchor-id="extensions-dynamic-hierarchical-and-correlated-topic-models">856. Extensions: Dynamic, Hierarchical, and Correlated Topic Models</h3>
<p>Latent Dirichlet Allocation (LDA) inspired many extensions to address its limitations. Variants like Dynamic Topic Models (DTM), Hierarchical LDA (hLDA), and Correlated Topic Models (CTM) expand its capabilities to capture temporal changes, hierarchical structures, and correlations between topics.</p>
<section id="picture-in-your-head-55" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-55">Picture in Your Head</h4>
<p>Imagine a library over time: new genres emerge, old ones fade (DTM). Within genres, sub-genres exist (hLDA). Some genres often appear together. like history and politics. reflecting correlations (CTM). These LDA variants model such richer realities.</p>
</section>
<section id="deep-dive-55" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-55">Deep Dive</h4>
<ul>
<li><p>Dynamic Topic Models (DTM):</p>
<ul>
<li>Topics evolve over time slices.</li>
<li>Example: “technology” shifts from “desktop computers” in the 1990s to “cloud computing” today.</li>
<li>Implemented using state-space models on topic distributions.</li>
</ul></li>
<li><p>Hierarchical LDA (hLDA):</p>
<ul>
<li>Topics are organized in a tree, discovered automatically.</li>
<li>Documents traverse paths from root to leaves, mixing hierarchical themes.</li>
<li>Example: “Science → Biology → Genetics.”</li>
</ul></li>
<li><p>Correlated Topic Models (CTM):</p>
<ul>
<li>Standard LDA assumes topics are independent.</li>
<li>CTM replaces Dirichlet with logistic normal distribution to allow correlations.</li>
<li>Example: “Economics” and “Politics” often co-occur in the same articles.</li>
</ul></li>
<li><p>Other Extensions:</p>
<ul>
<li>Author-Topic Models: link topics to document authors.</li>
<li>Relational Topic Models: capture links between documents.</li>
<li>Supervised LDA (sLDA): incorporates labels or outcomes into topic modeling.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 46%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Extension</th>
<th>Key Idea</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>DTM</td>
<td>Topics evolve over time</td>
<td>News, scientific trends</td>
</tr>
<tr class="even">
<td>hLDA</td>
<td>Hierarchical topic structure</td>
<td>Taxonomies, ontology discovery</td>
</tr>
<tr class="odd">
<td>CTM</td>
<td>Topics correlated, not independent</td>
<td>Social sciences, law</td>
</tr>
<tr class="even">
<td>sLDA</td>
<td>Supervised topic discovery</td>
<td>Prediction + interpretation</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, hLDA with gensim)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> hdpmodel</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim <span class="im">import</span> corpora</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> [</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Astronomy studies stars, galaxies, and planets"</span>,</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Space missions explore outer space"</span>,</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Cooking recipes include pasta, bread, and spices"</span>,</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"History and politics influence societies"</span></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Tokenize and build dictionary</span></span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>texts <span class="op">=</span> [doc.lower().split() <span class="cf">for</span> doc <span class="kw">in</span> docs]</span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>dictionary <span class="op">=</span> corpora.Dictionary(texts)</span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> [dictionary.doc2bow(text) <span class="cf">for</span> text <span class="kw">in</span> texts]</span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a><span class="co"># hLDA-like via HDP (nonparametric extension of LDA)</span></span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a>hdp <span class="op">=</span> hdpmodel.HdpModel(corpus, id2word<span class="op">=</span>dictionary)</span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-19"><a href="#cb57-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Example hierarchical topics:"</span>)</span>
<span id="cb57-20"><a href="#cb57-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, topic <span class="kw">in</span> <span class="bu">enumerate</span>(hdp.show_topics(num_topics<span class="op">=</span><span class="dv">3</span>, formatted<span class="op">=</span><span class="va">False</span>)):</span>
<span id="cb57-21"><a href="#cb57-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Topic </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">:"</span>, [w <span class="cf">for</span> w, _ <span class="kw">in</span> topic[<span class="dv">1</span>]])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-54" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-54">Why It Matters</h4>
<p>These extensions demonstrate how flexible the LDA framework is. Real-world text is rarely static, flat, or independent. By capturing time dynamics, hierarchies, and correlations, these models make topic modeling applicable to domains like scientific discovery, law, and social media.</p>
</section>
<section id="try-it-yourself-55" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-55">Try It Yourself</h4>
<ol type="1">
<li>Use Dynamic Topic Models on a news corpus. Do topics evolve logically over years?</li>
<li>Train hLDA on Wikipedia articles. Do subtopics align with categories?</li>
<li>Apply CTM to political texts. Do correlated topics cluster around ideological themes?</li>
<li>Compare LDA vs.&nbsp;sLDA on labeled documents. Does sLDA improve prediction accuracy?</li>
</ol>
</section>
</section>
<section id="neural-topic-models" class="level3">
<h3 class="anchored" data-anchor-id="neural-topic-models">857. Neural Topic Models</h3>
<p>Neural Topic Models (NTMs) extend classical topic modeling by leveraging deep learning architectures. Instead of relying purely on probabilistic graphical models, they use neural networks. often inspired by variational autoencoders (VAEs). to learn document–topic and topic–word distributions.</p>
<section id="picture-in-your-head-56" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-56">Picture in Your Head</h4>
<p>Imagine replacing a traditional librarian with a smart assistant that not only groups books by themes but also learns new genres by reading millions of online articles. Neural topic models do the same: they learn flexible, nonlinear topic representations directly from text.</p>
</section>
<section id="deep-dive-56" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-56">Deep Dive</h4>
<ul>
<li><p>Why Neural Models?</p>
<ul>
<li>Classic LDA assumes Dirichlet priors and bag-of-words.</li>
<li>Neural models allow more flexible distributions and integrate with embeddings.</li>
</ul></li>
<li><p>Core Approaches:</p>
<ul>
<li>Neural Variational Document Model (NVDM): VAE framework; latent topics as Gaussian variables.</li>
<li>ProdLDA: Replaces mixture of Dirichlets with a product-of-experts formulation.</li>
<li>Neural LDA: Uses amortized inference with neural networks to approximate posteriors.</li>
<li>Contextualized Topic Models (CTM): Combine pre-trained embeddings (BERT) with topic modeling.</li>
</ul></li>
<li><p>Strengths:</p>
<ul>
<li>Integrates with word embeddings and contextual models.</li>
<li>Scales better with stochastic gradient descent.</li>
<li>More expressive than traditional LDA.</li>
</ul></li>
<li><p>Limitations:</p>
<ul>
<li>Requires careful tuning, sensitive to neural network hyperparameters.</li>
<li>Topics may be less interpretable without constraints.</li>
<li>Higher computational cost than classical LDA.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 45%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>Key Idea</th>
<th>Benefit</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>NVDM</td>
<td>VAE for documents</td>
<td>End-to-end learning</td>
</tr>
<tr class="even">
<td>ProdLDA</td>
<td>Product-of-experts topic prior</td>
<td>Sharper, more distinct topics</td>
</tr>
<tr class="odd">
<td>CTM</td>
<td>Combines BERT + topic modeling</td>
<td>Semantically richer topics</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, ProdLDA with PyTorch &amp; sklearn vectorizer)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> contextualized_topic_models.models.neural_topic_model <span class="im">import</span> CombinedTM</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> contextualized_topic_models.utils.data_preparation <span class="im">import</span> TopicModelDataPreparation</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> [</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Astronomy explores stars and galaxies"</span>,</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Space missions study planets"</span>,</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Recipes for pasta, bread, and spices"</span>,</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Cooking food with fresh ingredients"</span></span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data</span></span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>vectorizer <span class="op">=</span> CountVectorizer(stop_words<span class="op">=</span><span class="st">"english"</span>)</span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> vectorizer.fit_transform(docs)</span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Neural topic model (ProdLDA via CombinedTM wrapper)</span></span>
<span id="cb58-17"><a href="#cb58-17" aria-hidden="true" tabindex="-1"></a>tp <span class="op">=</span> TopicModelDataPreparation(<span class="st">"bert-base-nli-mean-tokens"</span>)</span>
<span id="cb58-18"><a href="#cb58-18" aria-hidden="true" tabindex="-1"></a>training_dataset <span class="op">=</span> tp.fit(X, docs)</span>
<span id="cb58-19"><a href="#cb58-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-20"><a href="#cb58-20" aria-hidden="true" tabindex="-1"></a>ctm <span class="op">=</span> CombinedTM(bow_size<span class="op">=</span><span class="bu">len</span>(vectorizer.get_feature_names_out()), contextual_size<span class="op">=</span><span class="dv">768</span>, n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb58-21"><a href="#cb58-21" aria-hidden="true" tabindex="-1"></a>ctm.fit(training_dataset)</span>
<span id="cb58-22"><a href="#cb58-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-23"><a href="#cb58-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Topics:"</span>, ctm.get_topic_lists())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-55" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-55">Why It Matters</h4>
<p>Neural topic models bring topic modeling into the deep learning era. They can incorporate pretrained embeddings, nonlinear inference, and multimodal inputs, making them suitable for modern NLP tasks where interpretability and semantic richness must coexist with scalability.</p>
</section>
<section id="try-it-yourself-56" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-56">Try It Yourself</h4>
<ol type="1">
<li>Train NVDM on a large news dataset. Do latent topics capture meaningful themes?</li>
<li>Compare ProdLDA vs.&nbsp;classical LDA. Which produces sharper, less overlapping topics?</li>
<li>Use CTM with BERT embeddings. Do topics align better with human intuition?</li>
<li>Evaluate topic coherence across LDA, NTM, and CTM. Which performs best?</li>
</ol>
</section>
</section>
<section id="evaluation-metrics-for-topic-models-perplexity-coherence" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-metrics-for-topic-models-perplexity-coherence">858. Evaluation Metrics for Topic Models (Perplexity, Coherence)</h3>
<p>Evaluating topic models is challenging because there is no ground truth for “true” topics. Instead, metrics like perplexity and topic coherence are used to judge how well models capture structure and meaning in text.</p>
<section id="picture-in-your-head-57" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-57">Picture in Your Head</h4>
<p>Imagine asking two librarians to organize books. One groups them mathematically (perplexity), the other groups them so readers think the categories make sense (coherence). A good topic model balances both.</p>
</section>
<section id="deep-dive-57" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-57">Deep Dive</h4>
<ul>
<li><p>Perplexity (Statistical Fit):</p>
<ul>
<li><p>Measures how well a model predicts unseen words.</p></li>
<li><p>Lower perplexity = better generalization.</p></li>
<li><p>Formula:</p>
<p><span class="math display">\[
\text{Perplexity} = \exp \left( - \frac{1}{N} \sum_{d=1}^D \log P(w_d) \right)
\]</span></p></li>
<li><p>Weakness: lower perplexity does not always mean better human interpretability.</p></li>
</ul></li>
<li><p>Topic Coherence (Semantic Quality):</p>
<ul>
<li>Evaluates whether top words in a topic make sense together.</li>
<li>Uses co-occurrence statistics (PMI, NPMI, UMass).</li>
<li>Example: Topic words {“apple, banana, orange”} are more coherent than {“apple, war, galaxy”}.</li>
</ul></li>
<li><p>Human Evaluation:</p>
<ul>
<li>Direct inspection of topic word lists.</li>
<li>Intruder detection test: given a set of topic words, find the outlier.</li>
</ul></li>
<li><p>Tradeoff:</p>
<ul>
<li>Perplexity favors statistical accuracy.</li>
<li>Coherence favors human interpretability.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 30%">
<col style="width: 20%">
<col style="width: 31%">
</colgroup>
<thead>
<tr class="header">
<th>Metric</th>
<th>Captures</th>
<th>Strengths</th>
<th>Weaknesses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Perplexity</td>
<td>Predictive likelihood</td>
<td>Statistical rigor</td>
<td>Poor interpretability link</td>
</tr>
<tr class="even">
<td>Coherence (PMI)</td>
<td>Word semantic relatedness</td>
<td>Human-aligned</td>
<td>Computationally expensive</td>
</tr>
<tr class="odd">
<td>Human Eval</td>
<td>Human perception</td>
<td>Gold standard</td>
<td>Costly, subjective</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Coherence with gensim)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim <span class="im">import</span> corpora, models</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models.coherencemodel <span class="im">import</span> CoherenceModel</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> [</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Astronomy explores stars and galaxies"</span>,</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Space missions study planets"</span>,</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Cooking recipes include pasta and spices"</span>,</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Food and ingredients make delicious meals"</span></span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare corpus</span></span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a>texts <span class="op">=</span> [doc.lower().split() <span class="cf">for</span> doc <span class="kw">in</span> docs]</span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a>dictionary <span class="op">=</span> corpora.Dictionary(texts)</span>
<span id="cb59-14"><a href="#cb59-14" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> [dictionary.doc2bow(t) <span class="cf">for</span> t <span class="kw">in</span> texts]</span>
<span id="cb59-15"><a href="#cb59-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-16"><a href="#cb59-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Train LDA</span></span>
<span id="cb59-17"><a href="#cb59-17" aria-hidden="true" tabindex="-1"></a>lda <span class="op">=</span> models.LdaModel(corpus, num_topics<span class="op">=</span><span class="dv">2</span>, id2word<span class="op">=</span>dictionary, passes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb59-18"><a href="#cb59-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-19"><a href="#cb59-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute coherence</span></span>
<span id="cb59-20"><a href="#cb59-20" aria-hidden="true" tabindex="-1"></a>coherence <span class="op">=</span> CoherenceModel(model<span class="op">=</span>lda, texts<span class="op">=</span>texts, dictionary<span class="op">=</span>dictionary, coherence<span class="op">=</span><span class="st">'c_v'</span>)</span>
<span id="cb59-21"><a href="#cb59-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Topic coherence:"</span>, coherence.get_coherence())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-56" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-56">Why It Matters</h4>
<p>Evaluation determines whether topics are useful for analysis, search, and recommendation. Without coherence checks, models may optimize for perplexity but produce incoherent, unusable topics. Both quantitative and qualitative metrics guide practical topic modeling.</p>
</section>
<section id="try-it-yourself-57" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-57">Try It Yourself</h4>
<ol type="1">
<li>Train LDA with different numbers of topics. How do perplexity and coherence change?</li>
<li>Compare classical LDA vs.&nbsp;neural topic models. Which has higher coherence?</li>
<li>Conduct an intruder word test on topic lists. Do humans agree with the model?</li>
<li>Visualize coherence vs.&nbsp;topic count. Where is the best tradeoff?</li>
</ol>
</section>
</section>
<section id="applications-in-text-mining-and-beyond" class="level3">
<h3 class="anchored" data-anchor-id="applications-in-text-mining-and-beyond">859. Applications in Text Mining and Beyond</h3>
<p>Topic models are widely applied in text mining, recommendation, and exploratory analysis. They uncover hidden themes in large text collections, but their usefulness extends beyond text. into biology, social science, and software engineering.</p>
<section id="picture-in-your-head-58" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-58">Picture in Your Head</h4>
<p>Think of a massive archive of documents. Topic models act like an intelligent archivist, organizing content into labeled boxes such as “politics,” “sports,” or “cooking.” The same principle works in other domains: grouping genes, legal cases, or code snippets.</p>
</section>
<section id="deep-dive-58" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-58">Deep Dive</h4>
<ul>
<li><p>Text Mining &amp; NLP:</p>
<ul>
<li>Document clustering and categorization.</li>
<li>Information retrieval: improve search relevance by topic indexing.</li>
<li>Trend analysis in news and social media streams.</li>
</ul></li>
<li><p>Recommender Systems:</p>
<ul>
<li>Topics represent user interests and item properties.</li>
<li>Example: a user’s profile might be 30% “sports,” 50% “politics,” 20% “tech.”</li>
</ul></li>
<li><p>Social Sciences &amp; Humanities:</p>
<ul>
<li>Analyzing speeches, parliamentary debates, or historical archives.</li>
<li>Tracking evolution of discourse over time.</li>
</ul></li>
<li><p>Biology &amp; Medicine:</p>
<ul>
<li>Topic models applied to gene expression datasets.</li>
<li>Patient records organized into medical themes.</li>
</ul></li>
<li><p>Software Engineering:</p>
<ul>
<li>Mining GitHub repositories or bug reports.</li>
<li>Topics reveal software features, modules, or error patterns.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 45%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="header">
<th>Domain</th>
<th>Example Use Case</th>
<th>Method Often Used</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>News &amp; Media</td>
<td>Topic trends in journalism</td>
<td>LDA, DTM</td>
</tr>
<tr class="even">
<td>Social Media</td>
<td>Tracking online discourse</td>
<td>Online LDA</td>
</tr>
<tr class="odd">
<td>Biology</td>
<td>Clustering genes, patient records</td>
<td>LDA, NMF</td>
</tr>
<tr class="even">
<td>Recommenders</td>
<td>User–item profiling</td>
<td>Matrix factorization + LDA</td>
</tr>
<tr class="odd">
<td>Software Eng.</td>
<td>Mining bug reports, codebases</td>
<td>LDA, CTM</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, topic-based document clustering)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim <span class="im">import</span> corpora, models</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> [</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Astronomy explores galaxies and planets"</span>,</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Space missions study black holes"</span>,</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Cooking recipes use spices and bread"</span>,</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Food preparation includes pasta and cheese"</span>,</span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Politicians debate policies in parliament"</span>,</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Elections bring shifts in political power"</span></span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Tokenize and prepare corpus</span></span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>texts <span class="op">=</span> [doc.lower().split() <span class="cf">for</span> doc <span class="kw">in</span> docs]</span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a>dictionary <span class="op">=</span> corpora.Dictionary(texts)</span>
<span id="cb60-15"><a href="#cb60-15" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> [dictionary.doc2bow(t) <span class="cf">for</span> t <span class="kw">in</span> texts]</span>
<span id="cb60-16"><a href="#cb60-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-17"><a href="#cb60-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Train LDA</span></span>
<span id="cb60-18"><a href="#cb60-18" aria-hidden="true" tabindex="-1"></a>lda <span class="op">=</span> models.LdaModel(corpus, num_topics<span class="op">=</span><span class="dv">3</span>, id2word<span class="op">=</span>dictionary, passes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb60-19"><a href="#cb60-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-20"><a href="#cb60-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Assign topics to documents</span></span>
<span id="cb60-21"><a href="#cb60-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, row <span class="kw">in</span> <span class="bu">enumerate</span>(lda[corpus]):</span>
<span id="cb60-22"><a href="#cb60-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Doc </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> topic distribution:"</span>, row)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-57" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-57">Why It Matters</h4>
<p>Applications show that topic models are not just academic tools. they power real systems in search engines, digital libraries, health informatics, and recommender systems. They help humans and machines navigate overwhelming volumes of unstructured information.</p>
</section>
<section id="try-it-yourself-58" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-58">Try It Yourself</h4>
<ol type="1">
<li>Apply LDA to news articles from different years. Do discovered topics reveal historical trends?</li>
<li>Use topic models to cluster GitHub issue reports. Do topics align with bug categories?</li>
<li>Build a simple recommender by matching user-topic and item-topic distributions.</li>
<li>Apply topic modeling to medical abstracts. Can you identify disease subgroups?</li>
</ol>
</section>
</section>
<section id="challenges-interpretability-scalability-bias" class="level3">
<h3 class="anchored" data-anchor-id="challenges-interpretability-scalability-bias">860. Challenges: Interpretability, Scalability, Bias</h3>
<p>Despite their usefulness, topic models face challenges in interpretability, scalability, and bias. These issues limit reliability in critical domains like healthcare, law, and policy, where results must be trusted and explanations matter.</p>
<section id="picture-in-your-head-59" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-59">Picture in Your Head</h4>
<p>Imagine a machine that sorts thousands of books into labeled bins. Sometimes the labels make no sense (“banana politics”), sometimes the machine is too slow for a big library, and sometimes it reflects the biases of the books it was trained on. Topic models share these pitfalls.</p>
</section>
<section id="deep-dive-59" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-59">Deep Dive</h4>
<ul>
<li><p>Interpretability:</p>
<ul>
<li>Topics are probability distributions over words.</li>
<li>Top words may not form coherent, human-readable themes.</li>
<li>Ambiguity arises from overlapping or redundant topics.</li>
</ul></li>
<li><p>Scalability:</p>
<ul>
<li>Exact inference (VB, Gibbs Sampling) struggles with millions of documents.</li>
<li>Online and stochastic variational methods improve scalability.</li>
<li>GPU-accelerated neural topic models provide further speedups.</li>
</ul></li>
<li><p>Bias and Fairness:</p>
<ul>
<li>Input data biases propagate into discovered topics.</li>
<li>Example: occupational gender stereotypes in news datasets.</li>
<li>Sensitive to stopword handling, preprocessing, and vocabulary selection.</li>
</ul></li>
<li><p>Mitigation Strategies:</p>
<ul>
<li>Use topic coherence metrics for filtering.</li>
<li>Apply online or distributed inference for big corpora.</li>
<li>Conduct bias audits by inspecting topics for skewed associations.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 19%">
<col style="width: 37%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Challenge</th>
<th>Problem</th>
<th>Mitigation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Interpretability</td>
<td>Topics unclear or incoherent</td>
<td>Coherence metrics, human validation</td>
</tr>
<tr class="even">
<td>Scalability</td>
<td>Slow inference on large corpora</td>
<td>Online VB, distributed training</td>
</tr>
<tr class="odd">
<td>Bias</td>
<td>Encodes societal stereotypes</td>
<td>Preprocessing, debiasing, audits</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Online LDA for Scalability)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> LatentDirichletAllocation</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> [</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Astronomy explores stars and galaxies"</span>,</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Space missions study planets"</span>,</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Cooking recipes use pasta and bread"</span>,</span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Politics and elections shape society"</span></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Vectorize</span></span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a>vectorizer <span class="op">=</span> CountVectorizer(stop_words<span class="op">=</span><span class="st">"english"</span>)</span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> vectorizer.fit_transform(docs)</span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Online LDA for scalability</span></span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a>lda <span class="op">=</span> LatentDirichletAllocation(</span>
<span id="cb61-17"><a href="#cb61-17" aria-hidden="true" tabindex="-1"></a>    n_components<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb61-18"><a href="#cb61-18" aria-hidden="true" tabindex="-1"></a>    learning_method<span class="op">=</span><span class="st">"online"</span>,</span>
<span id="cb61-19"><a href="#cb61-19" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb61-20"><a href="#cb61-20" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb61-21"><a href="#cb61-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb61-22"><a href="#cb61-22" aria-hidden="true" tabindex="-1"></a>lda.fit(X)</span>
<span id="cb61-23"><a href="#cb61-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-24"><a href="#cb61-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Topics (top words):"</span>)</span>
<span id="cb61-25"><a href="#cb61-25" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, comp <span class="kw">in</span> <span class="bu">enumerate</span>(lda.components_):</span>
<span id="cb61-26"><a href="#cb61-26" aria-hidden="true" tabindex="-1"></a>    terms <span class="op">=</span> vectorizer.get_feature_names_out()</span>
<span id="cb61-27"><a href="#cb61-27" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> [terms[j] <span class="cf">for</span> j <span class="kw">in</span> comp.argsort()[<span class="op">-</span><span class="dv">5</span>:]]</span>
<span id="cb61-28"><a href="#cb61-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Topic </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">:"</span>, words)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-58" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-58">Why It Matters</h4>
<p>Acknowledging these challenges ensures topic models are applied responsibly. As they move into domains like policy analysis, biomedical research, and recommender systems, addressing interpretability, scalability, and bias is critical for building trustworthy AI systems.</p>
</section>
<section id="try-it-yourself-59" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-59">Try It Yourself</h4>
<ol type="1">
<li>Train LDA on a biased dataset (e.g., gendered job ads). Do stereotypes appear in topics?</li>
<li>Compare batch vs.&nbsp;online inference. Which scales better on large corpora?</li>
<li>Evaluate topic coherence at different topic counts. Which yields most interpretable topics?</li>
<li>Audit preprocessing choices (stopwords, stemming). How do they affect discovered topics?</li>
</ol>
</section>
</section>
</section>
<section id="chapter-87.-autoencoders-and-representation-learning" class="level2">
<h2 class="anchored" data-anchor-id="chapter-87.-autoencoders-and-representation-learning">Chapter 87. Autoencoders and representation learning</h2>
<section id="basics-of-autoencoders" class="level3">
<h3 class="anchored" data-anchor-id="basics-of-autoencoders">861. Basics of Autoencoders</h3>
<p>An autoencoder is a neural network trained to reconstruct its input. It learns a compressed latent representation (the bottleneck) that captures essential structure while discarding noise or redundancy. This latent code becomes a foundation for representation learning.</p>
<section id="picture-in-your-head-60" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-60">Picture in Your Head</h4>
<p>Think of a photocopier with a tiny internal memory chip. The machine compresses the original image into a minimal code, then expands it back to paper. If the copy looks accurate, the code must capture the key features of the input.</p>
</section>
<section id="deep-dive-60" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-60">Deep Dive</h4>
<ul>
<li><p>Architecture:</p>
<ul>
<li><p>Encoder: maps input <span class="math inline">\(x\)</span> to latent representation <span class="math inline">\(z\)</span>.</p>
<p><span class="math display">\[
z = f_\theta(x)
\]</span></p></li>
<li><p>Decoder: reconstructs input from latent <span class="math inline">\(z\)</span>.</p>
<p><span class="math display">\[
\hat{x} = g_\phi(z)
\]</span></p></li>
<li><p>Loss Function: minimize reconstruction error, e.g.</p>
<p><span class="math display">\[
L(x, \hat{x}) = \|x - \hat{x}\|^2
\]</span></p></li>
</ul></li>
<li><p>Key Properties:</p>
<ul>
<li>Learns unsupervised representations.</li>
<li>Bottleneck forces model to capture structure in data.</li>
<li>Can denoise, compress, or pretrain features for other tasks.</li>
</ul></li>
<li><p>Variants:</p>
<ul>
<li>Undercomplete AE: latent dimension smaller than input → compression.</li>
<li>Overcomplete AE: larger latent space, relies on regularization.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Component</th>
<th>Role</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Encoder</td>
<td>Compress input into latent</td>
</tr>
<tr class="even">
<td>Decoder</td>
<td>Reconstruct input from latent</td>
</tr>
<tr class="odd">
<td>Loss</td>
<td>Enforces similarity to input</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Simple Autoencoder in Keras)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers, models</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple autoencoder for MNIST digits</span></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>input_dim <span class="op">=</span> <span class="dv">784</span></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>encoding_dim <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Encoder</span></span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>input_img <span class="op">=</span> layers.Input(shape<span class="op">=</span>(input_dim,))</span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>encoded <span class="op">=</span> layers.Dense(encoding_dim, activation<span class="op">=</span><span class="st">'relu'</span>)(input_img)</span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Decoder</span></span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a>decoded <span class="op">=</span> layers.Dense(input_dim, activation<span class="op">=</span><span class="st">'sigmoid'</span>)(encoded)</span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Autoencoder model</span></span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a>autoencoder <span class="op">=</span> models.Model(input_img, decoded)</span>
<span id="cb62-17"><a href="#cb62-17" aria-hidden="true" tabindex="-1"></a>autoencoder.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>, loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>)</span>
<span id="cb62-18"><a href="#cb62-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-19"><a href="#cb62-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(autoencoder.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-59" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-59">Why It Matters</h4>
<p>Autoencoders introduced a neural approach to representation learning before deep generative models. They remain widely used for dimensionality reduction, anomaly detection, denoising, and pretraining. Their simplicity makes them a cornerstone in unsupervised learning.</p>
</section>
<section id="try-it-yourself-60" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-60">Try It Yourself</h4>
<ol type="1">
<li>Train a basic autoencoder on MNIST. Inspect the 32D latent space. do digits cluster by class?</li>
<li>Reduce latent dimension from 32 to 2. Can you visualize digits in 2D?</li>
<li>Add Gaussian noise to images and train the autoencoder. Does it denoise successfully?</li>
<li>Use latent codes as input to a classifier. Do they improve accuracy compared to raw pixels?</li>
</ol>
</section>
</section>
<section id="undercomplete-vs.-overcomplete-representations" class="level3">
<h3 class="anchored" data-anchor-id="undercomplete-vs.-overcomplete-representations">862. Undercomplete vs.&nbsp;Overcomplete Representations</h3>
<p>Autoencoders come in two main forms: undercomplete, where the latent space is smaller than the input, and overcomplete, where the latent space is larger. The choice shapes whether the model learns compact representations or risks simply copying the input.</p>
<section id="picture-in-your-head-61" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-61">Picture in Your Head</h4>
<p>Think of translating a book into a smaller notebook. If the notebook has only a few pages (undercomplete), you must summarize the main ideas. If the notebook is bigger (overcomplete), you might just copy everything word for word, unless rules force you to simplify.</p>
</section>
<section id="deep-dive-61" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-61">Deep Dive</h4>
<ul>
<li><p>Undercomplete Autoencoder:</p>
<ul>
<li>Latent dimension <span class="math inline">\(d_z &lt; d_x\)</span>.</li>
<li>Forces network to learn compressed, information-rich representations.</li>
<li>Naturally acts as dimensionality reduction (like nonlinear PCA).</li>
</ul></li>
<li><p>Overcomplete Autoencoder:</p>
<ul>
<li>Latent dimension <span class="math inline">\(d_z \geq d_x\)</span>.</li>
<li>Without constraints, network may just learn the identity function.</li>
<li>Needs regularization (sparsity, noise, dropout) to encourage meaningful structure.</li>
</ul></li>
<li><p>Regularization Techniques for Overcomplete AEs:</p>
<ul>
<li>Sparse Autoencoder: enforce sparsity penalty on activations.</li>
<li>Denoising Autoencoder: corrupt inputs, force reconstruction from partial info.</li>
<li>Contractive Autoencoder: penalize sensitivity to input perturbations.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 24%">
<col style="width: 26%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th>Type</th>
<th>Latent Size</th>
<th>Property</th>
<th>Risk / Benefit</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Undercomplete</td>
<td>Smaller than input</td>
<td>Compact encoding</td>
<td>Strong compression</td>
</tr>
<tr class="even">
<td>Overcomplete</td>
<td>Larger/equal</td>
<td>Needs regularization</td>
<td>Risk of trivial identity</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Undercomplete vs Overcomplete)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers, models</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Undercomplete AE: compress 784D -&gt; 32D</span></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>input_dim <span class="op">=</span> <span class="dv">784</span></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>under_latent <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>input_img <span class="op">=</span> layers.Input(shape<span class="op">=</span>(input_dim,))</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>encoded <span class="op">=</span> layers.Dense(under_latent, activation<span class="op">=</span><span class="st">'relu'</span>)(input_img)</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>decoded <span class="op">=</span> layers.Dense(input_dim, activation<span class="op">=</span><span class="st">'sigmoid'</span>)(encoded)</span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a>undercomplete <span class="op">=</span> models.Model(input_img, decoded)</span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Overcomplete AE: expand 784D -&gt; 1024D -&gt; 784D</span></span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a>over_latent <span class="op">=</span> <span class="dv">1024</span></span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a>encoded_over <span class="op">=</span> layers.Dense(over_latent, activation<span class="op">=</span><span class="st">'relu'</span>)(input_img)</span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a>decoded_over <span class="op">=</span> layers.Dense(input_dim, activation<span class="op">=</span><span class="st">'sigmoid'</span>)(encoded_over)</span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a>overcomplete <span class="op">=</span> models.Model(input_img, decoded_over)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-60" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-60">Why It Matters</h4>
<p>The distinction between undercomplete and overcomplete autoencoders illustrates the tradeoff between forced compression and flexible capacity. Overcomplete models underpin modern deep autoencoders and variational autoencoders, but only with proper constraints to avoid trivial solutions.</p>
</section>
<section id="try-it-yourself-61" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-61">Try It Yourself</h4>
<ol type="1">
<li>Train an undercomplete AE on MNIST with 2D latent space. Visualize embeddings.</li>
<li>Train an overcomplete AE without regularization. Does it just copy the input?</li>
<li>Add sparsity or dropout to the overcomplete AE. Do the representations improve?</li>
<li>Compare reconstruction errors between undercomplete and overcomplete setups. Which generalizes better?</li>
</ol>
</section>
</section>
<section id="variational-autoencoders-vaes" class="level3">
<h3 class="anchored" data-anchor-id="variational-autoencoders-vaes">863. Variational Autoencoders (VAEs)</h3>
<p>Variational Autoencoders (VAEs) extend autoencoders by introducing probabilistic latent variables. Instead of encoding an input to a single point in latent space, VAEs learn a distribution (mean and variance), enabling both representation learning and generative modeling.</p>
<section id="picture-in-your-head-62" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-62">Picture in Your Head</h4>
<p>Imagine not just storing a single compressed sketch of a face, but keeping a “recipe” with knobs you can adjust (nose length, eye size, smile curve). VAEs learn these recipes, so you can sample new faces by tweaking or drawing from the recipe distribution.</p>
</section>
<section id="deep-dive-62" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-62">Deep Dive</h4>
<ul>
<li><p>Latent Distributions:</p>
<ul>
<li><p>Encoder outputs parameters of a Gaussian:</p>
<p><span class="math display">\[
q_\phi(z|x) = \mathcal{N}(z; \mu(x), \sigma^2(x))
\]</span></p></li>
<li><p>Decoder samples from <span class="math inline">\(z\)</span> to reconstruct input.</p></li>
</ul></li>
<li><p>Reparameterization Trick:</p>
<ul>
<li><p>To allow backpropagation through randomness:</p>
<p><span class="math display">\[
z = \mu + \sigma \cdot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)
\]</span></p></li>
</ul></li>
<li><p>Loss Function:</p>
<ul>
<li><p>Reconstruction Loss: encourages accurate reconstruction of input.</p></li>
<li><p>KL Divergence: regularizes latent distribution toward standard normal.</p>
<p><span class="math display">\[
\mathcal{L} = \mathbb{E}_{q(z|x)}[\log p(x|z)] - D_{KL}[q(z|x) \| p(z)]
\]</span></p></li>
</ul></li>
<li><p>Benefits:</p>
<ul>
<li>Generative: can sample new data from latent space.</li>
<li>Continuous latent space enables interpolation.</li>
</ul></li>
<li><p>Limitations:</p>
<ul>
<li>Reconstructions blurrier than GANs.</li>
<li>Sensitive to choice of priors and network capacity.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Component</th>
<th>Role</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Encoder</td>
<td>Outputs mean &amp; variance of latent</td>
</tr>
<tr class="even">
<td>Reparameterization</td>
<td>Enables gradient-based training</td>
</tr>
<tr class="odd">
<td>Decoder</td>
<td>Reconstructs input from latent</td>
</tr>
<tr class="even">
<td>Loss</td>
<td>Balances reconstruction &amp; regularity</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, VAE in Keras)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Encoder</span></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> layers.Input(shape<span class="op">=</span>(<span class="dv">784</span>,))</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> layers.Dense(<span class="dv">256</span>, activation<span class="op">=</span><span class="st">"relu"</span>)(inputs)</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>z_mean <span class="op">=</span> layers.Dense(<span class="dv">2</span>)(h)</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>z_log_var <span class="op">=</span> layers.Dense(<span class="dv">2</span>)(h)</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Reparameterization</span></span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sampling(args):</span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a>    z_mean, z_log_var <span class="op">=</span> args</span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a>    epsilon <span class="op">=</span> tf.random.normal(shape<span class="op">=</span>(tf.shape(z_mean)[<span class="dv">0</span>], <span class="dv">2</span>))</span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> z_mean <span class="op">+</span> tf.exp(<span class="fl">0.5</span> <span class="op">*</span> z_log_var) <span class="op">*</span> epsilon</span>
<span id="cb64-15"><a href="#cb64-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-16"><a href="#cb64-16" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> layers.Lambda(sampling)([z_mean, z_log_var])</span>
<span id="cb64-17"><a href="#cb64-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-18"><a href="#cb64-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Decoder</span></span>
<span id="cb64-19"><a href="#cb64-19" aria-hidden="true" tabindex="-1"></a>decoder_h <span class="op">=</span> layers.Dense(<span class="dv">256</span>, activation<span class="op">=</span><span class="st">"relu"</span>)</span>
<span id="cb64-20"><a href="#cb64-20" aria-hidden="true" tabindex="-1"></a>decoder_out <span class="op">=</span> layers.Dense(<span class="dv">784</span>, activation<span class="op">=</span><span class="st">"sigmoid"</span>)</span>
<span id="cb64-21"><a href="#cb64-21" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> decoder_out(decoder_h(z))</span>
<span id="cb64-22"><a href="#cb64-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-23"><a href="#cb64-23" aria-hidden="true" tabindex="-1"></a>vae <span class="op">=</span> tf.keras.Model(inputs, outputs)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-61" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-61">Why It Matters</h4>
<p>VAEs bridged the gap between representation learning and generative modeling. They provided the first scalable deep generative models, inspiring modern architectures like β-VAE, VQ-VAE, and diffusion models. They remain foundational in unsupervised and semi-supervised learning.</p>
</section>
<section id="try-it-yourself-62" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-62">Try It Yourself</h4>
<ol type="1">
<li>Train a VAE on MNIST with 2D latent space. Visualize latent space colored by digit labels.</li>
<li>Interpolate between two digit embeddings in latent space. What do the generated digits look like?</li>
<li>Compare reconstructions of VAE vs.&nbsp;standard autoencoder. Are VAEs blurrier?</li>
<li>Sample random points from latent space. Do they produce valid digits?</li>
</ol>
</section>
</section>
<section id="denoising-and-robust-autoencoders" class="level3">
<h3 class="anchored" data-anchor-id="denoising-and-robust-autoencoders">864. Denoising and Robust Autoencoders</h3>
<p>Denoising Autoencoders (DAEs) extend the basic autoencoder by learning to reconstruct clean inputs from noisy or corrupted versions. This prevents trivial copying and forces the model to capture robust structure, making representations more generalizable.</p>
<section id="picture-in-your-head-63" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-63">Picture in Your Head</h4>
<p>Imagine giving a student a page with coffee stains and missing words, asking them to rewrite the original. To succeed, they must understand the meaning of the text, not just copy. DAEs train neural networks in the same way. by forcing them to ignore noise and recover essential patterns.</p>
</section>
<section id="deep-dive-63" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-63">Deep Dive</h4>
<ul>
<li><p>Training Procedure:</p>
<ol type="1">
<li>Corrupt input <span class="math inline">\(x\)</span> with noise → <span class="math inline">\(\tilde{x}\)</span>.</li>
<li>Encoder maps <span class="math inline">\(\tilde{x}\)</span> to latent representation <span class="math inline">\(z\)</span>.</li>
<li>Decoder reconstructs original <span class="math inline">\(x\)</span> from <span class="math inline">\(z\)</span>.</li>
<li>Loss = reconstruction error between <span class="math inline">\(x\)</span> and <span class="math inline">\(\hat{x}\)</span>.</li>
</ol></li>
<li><p>Noise Types:</p>
<ul>
<li>Gaussian noise: add small perturbations.</li>
<li>Masking noise: randomly set some inputs to zero.</li>
<li>Salt-and-pepper noise: randomly flip some input values.</li>
</ul></li>
<li><p>Benefits:</p>
<ul>
<li>Prevents overfitting and trivial identity learning.</li>
<li>Produces more robust latent features.</li>
<li>Improves downstream tasks like classification.</li>
</ul></li>
<li><p>Robust Autoencoders:</p>
<ul>
<li>Extend denoising with adversarial noise or structured corruption.</li>
<li>Goal: handle real-world imperfections (occlusions in images, missing data).</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Noise Type</th>
<th>Example Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Gaussian</td>
<td>Natural sensor noise</td>
</tr>
<tr class="even">
<td>Masking</td>
<td>Missing words/features</td>
</tr>
<tr class="odd">
<td>Salt-and-pepper</td>
<td>Pixel corruption in images</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Denoising Autoencoder)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers, models</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Add noise to input</span></span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> add_noise(x, noise_factor<span class="op">=</span><span class="fl">0.3</span>):</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>    x_noisy <span class="op">=</span> x <span class="op">+</span> noise_factor <span class="op">*</span> np.random.normal(loc<span class="op">=</span><span class="fl">0.0</span>, scale<span class="op">=</span><span class="fl">1.0</span>, size<span class="op">=</span>x.shape)</span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.clip(x_noisy, <span class="fl">0.</span>, <span class="fl">1.</span>)</span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple autoencoder</span></span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>input_dim <span class="op">=</span> <span class="dv">784</span></span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>encoding_dim <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>input_img <span class="op">=</span> layers.Input(shape<span class="op">=</span>(input_dim,))</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>encoded <span class="op">=</span> layers.Dense(encoding_dim, activation<span class="op">=</span><span class="st">"relu"</span>)(input_img)</span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a>decoded <span class="op">=</span> layers.Dense(input_dim, activation<span class="op">=</span><span class="st">"sigmoid"</span>)(encoded)</span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a>dae <span class="op">=</span> models.Model(input_img, decoded)</span>
<span id="cb65-19"><a href="#cb65-19" aria-hidden="true" tabindex="-1"></a>dae.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">"adam"</span>, loss<span class="op">=</span><span class="st">"binary_crossentropy"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-62" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-62">Why It Matters</h4>
<p>Denoising autoencoders helped shift focus from reconstruction to robust representation learning. They laid the groundwork for pretraining in deep networks and inspired modern self-supervised approaches like masked autoencoders (MAE) used in NLP and vision.</p>
</section>
<section id="try-it-yourself-63" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-63">Try It Yourself</h4>
<ol type="1">
<li>Train a DAE on MNIST with Gaussian noise. Compare clean vs.&nbsp;noisy vs.&nbsp;reconstructed digits.</li>
<li>Experiment with masking noise. zero out 20% of pixels. Does the DAE fill them in?</li>
<li>Compare latent features from AE vs.&nbsp;DAE when used for classification. Which improves accuracy?</li>
<li>Add adversarial perturbations to inputs. Does the DAE still reconstruct correctly?</li>
</ol>
</section>
</section>
<section id="sparse-and-contractive-autoencoders" class="level3">
<h3 class="anchored" data-anchor-id="sparse-and-contractive-autoencoders">865. Sparse and Contractive Autoencoders</h3>
<p>Sparse and Contractive Autoencoders introduce regularization to prevent trivial identity mappings and to encourage meaningful representations. Sparse autoencoders force most hidden units to remain inactive, while contractive autoencoders penalize sensitivity to small input changes.</p>
<section id="picture-in-your-head-64" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-64">Picture in Your Head</h4>
<p>Think of a panel of light switches. A sparse autoencoder ensures that, for any given input, only a few switches are turned on. A contractive autoencoder, meanwhile, ensures that tiny wobbles in the input don’t wildly flip the switches. Both strategies encourage the model to focus on essential patterns.</p>
</section>
<section id="deep-dive-64" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-64">Deep Dive</h4>
<ul>
<li><p>Sparse Autoencoders (SAE):</p>
<ul>
<li><p>Encourage hidden layer activations to be mostly zero.</p></li>
<li><p>Regularization term: KL divergence between average activation <span class="math inline">\(\hat{\rho}\)</span> and target sparsity <span class="math inline">\(\rho\)</span>.</p>
<p><span class="math display">\[
\Omega_{sparse} = \sum_j KL(\rho \,||\, \hat{\rho}_j)
\]</span></p></li>
<li><p>Effect: each hidden unit learns specialized features.</p></li>
</ul></li>
<li><p>Contractive Autoencoders (CAE):</p>
<ul>
<li><p>Add penalty on Jacobian of encoder activations wrt inputs.</p></li>
<li><p>Regularization term:</p>
<p><span class="math display">\[
\Omega_{contract} = \lambda \| \nabla_x h(x) \|^2
\]</span></p></li>
<li><p>Effect: enforces robustness, making features invariant to small input perturbations.</p></li>
</ul></li>
<li><p>Comparison:</p>
<ul>
<li>SAE → learns parts-based, interpretable features.</li>
<li>CAE → learns robust, stable features under noise.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 30%">
<col style="width: 48%">
</colgroup>
<thead>
<tr class="header">
<th>Type</th>
<th>Regularization Target</th>
<th>Outcome</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sparse AE</td>
<td>Hidden activations</td>
<td>Compact, parts-based features</td>
</tr>
<tr class="even">
<td>Contractive AE</td>
<td>Encoder sensitivity</td>
<td>Robustness to small perturbations</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Sparse Autoencoder)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers, models, regularizers</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>input_dim <span class="op">=</span> <span class="dv">784</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>encoding_dim <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>input_img <span class="op">=</span> layers.Input(shape<span class="op">=</span>(input_dim,))</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Add L1 regularization to encourage sparsity</span></span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>encoded <span class="op">=</span> layers.Dense(encoding_dim, activation<span class="op">=</span><span class="st">"relu"</span>,</span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>                       activity_regularizer<span class="op">=</span>regularizers.l1(<span class="fl">1e-5</span>))(input_img)</span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a>decoded <span class="op">=</span> layers.Dense(input_dim, activation<span class="op">=</span><span class="st">"sigmoid"</span>)(encoded)</span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a>sparse_ae <span class="op">=</span> models.Model(input_img, decoded)</span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a>sparse_ae.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">"adam"</span>, loss<span class="op">=</span><span class="st">"binary_crossentropy"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-63" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-63">Why It Matters</h4>
<p>Both approaches push autoencoders toward useful representations instead of trivial reconstructions. Sparse AEs inspired architectures like sparse coding and dictionary learning, while Contractive AEs influenced robust feature learning and paved the way for modern self-supervised methods.</p>
</section>
<section id="try-it-yourself-64" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-64">Try It Yourself</h4>
<ol type="1">
<li>Train a sparse AE on MNIST. Visualize hidden units. Do they resemble stroke-like features?</li>
<li>Compare reconstruction error between standard AE and sparse AE. Which generalizes better?</li>
<li>Implement contractive regularization (Jacobian penalty) on a toy dataset. Are embeddings smoother?</li>
<li>Apply noise to inputs and test robustness. Which AE resists degradation?</li>
</ol>
</section>
</section>
<section id="adversarial-autoencoders" class="level3">
<h3 class="anchored" data-anchor-id="adversarial-autoencoders">866. Adversarial Autoencoders</h3>
<p>Adversarial Autoencoders (AAEs) combine autoencoder reconstruction objectives with adversarial training. They use a discriminator (as in GANs) to match the latent code distribution to a target prior, turning the autoencoder into a generative model with controllable latent space.</p>
<section id="picture-in-your-head-65" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-65">Picture in Your Head</h4>
<p>Imagine a teacher (the discriminator) checking if a student’s notes (latent codes) look like they came from a real textbook (the prior distribution). The student (encoder) must write better notes until the teacher can’t tell the difference.</p>
</section>
<section id="deep-dive-65" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-65">Deep Dive</h4>
<ul>
<li><p>Architecture:</p>
<ul>
<li>Encoder: maps input <span class="math inline">\(x\)</span> to latent <span class="math inline">\(z\)</span>.</li>
<li>Decoder: reconstructs input from <span class="math inline">\(z\)</span>.</li>
<li>Discriminator: distinguishes between samples from prior <span class="math inline">\(p(z)\)</span> (real) and encoder’s <span class="math inline">\(q(z|x)\)</span> (fake).</li>
</ul></li>
<li><p>Loss Functions:</p>
<ul>
<li><p>Reconstruction Loss:</p>
<p><span class="math display">\[
L_{rec} = \|x - \hat{x}\|^2
\]</span></p></li>
<li><p>Adversarial Loss (GAN-style):</p>
<ul>
<li>Discriminator maximizes log-likelihood of real vs.&nbsp;fake.</li>
<li>Encoder minimizes discriminator’s ability to distinguish.</li>
</ul></li>
</ul></li>
<li><p>Effect:</p>
<ul>
<li>Enforces latent codes to match prior distribution.</li>
<li>Enables structured sampling, clustering, and semi-supervised learning.</li>
</ul></li>
<li><p>Applications:</p>
<ul>
<li>Generative modeling like VAEs but with adversarial alignment.</li>
<li>Semi-supervised learning: latent codes can include class labels.</li>
<li>Domain adaptation.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Component</th>
<th>Role</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Encoder</td>
<td>Maps input → latent <span class="math inline">\(z\)</span></td>
</tr>
<tr class="even">
<td>Decoder</td>
<td>Reconstructs input</td>
</tr>
<tr class="odd">
<td>Discriminator</td>
<td>Aligns <span class="math inline">\(z\)</span> with prior <span class="math inline">\(p(z)\)</span></td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (PyTorch, Sketch of AAE)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Encoder</span></span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Encoder(nn.Module):</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim, latent_dim):</span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Sequential(</span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a>            nn.Linear(input_dim, <span class="dv">256</span>), nn.ReLU(),</span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">256</span>, latent_dim)</span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x): <span class="cf">return</span> <span class="va">self</span>.fc(x)</span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Discriminator</span></span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Discriminator(nn.Module):</span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, latent_dim):</span>
<span id="cb67-17"><a href="#cb67-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb67-18"><a href="#cb67-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Sequential(</span>
<span id="cb67-19"><a href="#cb67-19" aria-hidden="true" tabindex="-1"></a>            nn.Linear(latent_dim, <span class="dv">128</span>), nn.ReLU(),</span>
<span id="cb67-20"><a href="#cb67-20" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">128</span>, <span class="dv">1</span>), nn.Sigmoid()</span>
<span id="cb67-21"><a href="#cb67-21" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb67-22"><a href="#cb67-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, z): <span class="cf">return</span> <span class="va">self</span>.fc(z)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-64" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-64">Why It Matters</h4>
<p>AAEs bridge autoencoders and GANs, creating models that are both reconstructive and generative. They opened pathways to structured latent spaces, semi-supervised learning, and controllable generative models. concepts that fuel today’s foundation models.</p>
</section>
<section id="try-it-yourself-65" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-65">Try It Yourself</h4>
<ol type="1">
<li>Train an AAE with Gaussian prior. Sample random latent vectors. do generated outputs look realistic?</li>
<li>Replace Gaussian prior with mixture of Gaussians. Does the AAE learn clustered latent codes?</li>
<li>Use AAE for semi-supervised classification (add labels to part of dataset). Does performance improve?</li>
<li>Compare AAE to VAE. Which gives sharper reconstructions?</li>
</ol>
</section>
</section>
<section id="representation-quality-and-latent-spaces" class="level3">
<h3 class="anchored" data-anchor-id="representation-quality-and-latent-spaces">867. Representation Quality and Latent Spaces</h3>
<p>The power of autoencoders lies in their latent space. the compressed representation between encoder and decoder. A good latent space captures meaningful structure, enabling clustering, interpolation, and generative modeling. Evaluating and shaping these representations is central to representation learning.</p>
<section id="picture-in-your-head-66" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-66">Picture in Your Head</h4>
<p>Think of a map: if landmarks (mountains, rivers, cities) are placed meaningfully, you can navigate easily. A poorly drawn map confuses distances and directions. The latent space is a map of your data. its quality determines how useful it is.</p>
</section>
<section id="deep-dive-66" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-66">Deep Dive</h4>
<ul>
<li><p>Qualities of a Good Latent Space:</p>
<ul>
<li>Compactness: fewer dimensions without losing key info.</li>
<li>Separability: different classes or patterns are distinguishable.</li>
<li>Smoothness: small changes in latent variables → smooth changes in reconstructions.</li>
<li>Disentanglement: latent dimensions correspond to independent factors of variation.</li>
</ul></li>
<li><p>Evaluation Techniques:</p>
<ul>
<li>Visualization: project latent codes to 2D (t-SNE, UMAP).</li>
<li>Clustering: measure how well clusters align with labels.</li>
<li>Downstream tasks: train classifiers on latent codes. high accuracy = informative features.</li>
<li>Reconstruction fidelity: balance between compression and reconstruction error.</li>
</ul></li>
<li><p>Shaping Latent Spaces:</p>
<ul>
<li>Regularization (sparsity, contractive penalties).</li>
<li>Probabilistic priors (VAEs, AAEs).</li>
<li>Self-supervised constraints (contrastive or predictive tasks).</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Quality</th>
<th>Benefit</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Compactness</td>
<td>Efficient storage &amp; processing</td>
</tr>
<tr class="even">
<td>Separability</td>
<td>Easier classification &amp; clustering</td>
</tr>
<tr class="odd">
<td>Smoothness</td>
<td>Interpolation, generative tasks</td>
</tr>
<tr class="even">
<td>Disentanglement</td>
<td>Interpretability of factors</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Latent Space Visualization)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume 'latent_codes' from encoder, shape (n_samples, latent_dim)</span></span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a><span class="co"># and labels for visualization</span></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>X_2d <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>).fit_transform(latent_codes)</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_2d[:,<span class="dv">0</span>], X_2d[:,<span class="dv">1</span>], c<span class="op">=</span>labels, cmap<span class="op">=</span><span class="st">"tab10"</span>, s<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Latent Space Visualization (t-SNE)"</span>)</span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-65" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-65">Why It Matters</h4>
<p>Latent spaces determine whether autoencoders are just compressors or true representation learners. A well-structured latent space fuels transfer learning, generative modeling, and interpretable AI. foundations for modern self-supervised and foundation models.</p>
</section>
<section id="try-it-yourself-66" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-66">Try It Yourself</h4>
<ol type="1">
<li>Train an autoencoder with 2D latent space. Visualize latent embeddings. do natural clusters appear?</li>
<li>Use latent codes as input to a logistic regression classifier. Is accuracy competitive with raw features?</li>
<li>Interpolate between two latent codes. Do reconstructions change smoothly?</li>
<li>Add sparsity regularization. Do latent features become more interpretable?</li>
</ol>
</section>
</section>
<section id="disentangled-representation-learning" class="level3">
<h3 class="anchored" data-anchor-id="disentangled-representation-learning">868. Disentangled Representation Learning</h3>
<p>Disentangled representation learning aims for latent spaces where each dimension captures a distinct, interpretable factor of variation. Instead of mixing features, the autoencoder learns axes like “rotation,” “size,” or “color,” making the latent space more human-readable and controllable.</p>
<section id="picture-in-your-head-67" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-67">Picture in Your Head</h4>
<p>Think of a sound mixer board. Each knob controls one property — bass, treble, or volume. Turning one knob changes only that property. A disentangled latent space works the same way: each coordinate adjusts one independent factor without affecting the others.</p>
</section>
<section id="deep-dive-67" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-67">Deep Dive</h4>
<ul>
<li><p>Why Disentanglement Matters:</p>
<ul>
<li>Interpretability: latent variables map to real-world factors.</li>
<li>Control: tweak one factor while holding others constant.</li>
<li>Transfer: disentangled features generalize across tasks.</li>
</ul></li>
<li><p>Methods for Disentanglement:</p>
<ul>
<li>β-VAE: increases weight on KL divergence to enforce more factorized latents.</li>
<li>FactorVAE: penalizes total correlation (reduces dependencies among latents).</li>
<li>InfoGAN: maximizes mutual information between latent codes and generated outputs.</li>
</ul></li>
<li><p>Tradeoffs:</p>
<ul>
<li>Stronger disentanglement often reduces reconstruction quality.</li>
<li>Requires assumptions about data (factors must exist and be independent).</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Model</th>
<th>Strategy</th>
<th>Outcome</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>β-VAE</td>
<td>KL divergence scaling</td>
<td>Axis-aligned factors</td>
</tr>
<tr class="even">
<td>FactorVAE</td>
<td>Penalize latent correlation</td>
<td>Independent components</td>
</tr>
<tr class="odd">
<td>InfoGAN</td>
<td>Mutual information maximization</td>
<td>Controlled generation</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> beta_vae_loss(x, x_recon, mu, logvar, beta<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>    recon_loss <span class="op">=</span> F.mse_loss(x_recon, x, reduction<span class="op">=</span><span class="st">"sum"</span>)</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>    kl_loss <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> torch.<span class="bu">sum</span>(<span class="dv">1</span> <span class="op">+</span> logvar <span class="op">-</span> mu.<span class="bu">pow</span>(<span class="dv">2</span>) <span class="op">-</span> logvar.exp())</span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> recon_loss <span class="op">+</span> beta <span class="op">*</span> kl_loss</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-66" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-66">Why It Matters</h4>
<p>Disentanglement connects machine learning to causal reasoning and interpretability. It allows us to understand how models encode information, and enables controllable generation — critical in fields like graphics, biology, and robotics.</p>
</section>
<section id="try-it-yourself-67" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-67">Try It Yourself</h4>
<ol type="1">
<li>Train a β-VAE on MNIST with different β values. Does latent space become more factorized?</li>
<li>Interpolate along one latent dimension. Does only one property of the digit change?</li>
<li>Compare VAE vs.&nbsp;β-VAE reconstructions. Which is sharper, which is more interpretable?</li>
<li>Use disentangled latents for transfer learning. Do features generalize better than entangled ones?</li>
</ol>
</section>
</section>
<section id="applications-compression-denoising-generation" class="level3">
<h3 class="anchored" data-anchor-id="applications-compression-denoising-generation">869. Applications: Compression, Denoising, Generation</h3>
<p>Autoencoders are versatile tools applied to data compression, noise reduction, and generative modeling. Each application leverages the latent space differently. as a compressed code, a denoised representation, or a source of new data.</p>
<section id="picture-in-your-head-68" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-68">Picture in Your Head</h4>
<p>Imagine three uses for shorthand writing. First, it saves space in your notebook (compression). Second, it lets you ignore scribbles and still recover meaning (denoising). Third, with enough shorthand rules, you can invent new sentences that sound natural (generation).</p>
</section>
<section id="deep-dive-68" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-68">Deep Dive</h4>
<ul>
<li><p>Compression:</p>
<ul>
<li>Undercomplete autoencoders learn efficient encodings.</li>
<li>Applied in image compression, medical scans, and IoT devices.</li>
<li>Competes with PCA, but nonlinear mappings capture richer structure.</li>
</ul></li>
<li><p>Denoising:</p>
<ul>
<li>Denoising autoencoders reconstruct clean signals from corrupted inputs.</li>
<li>Used in image restoration, speech enhancement, and sensor data recovery.</li>
</ul></li>
<li><p>Generation:</p>
<ul>
<li>VAEs and AAEs sample from latent distributions to create new data.</li>
<li>Useful in art, drug discovery, and synthetic training data.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 46%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th>Application</th>
<th>Role of Latent Space</th>
<th>Example Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Compression</td>
<td>Minimal encoding of input</td>
<td>Image &amp; video codecs</td>
</tr>
<tr class="even">
<td>Denoising</td>
<td>Noise-invariant representation</td>
<td>Speech enhancement</td>
</tr>
<tr class="odd">
<td>Generation</td>
<td>Sampling &amp; interpolation</td>
<td>Synthetic data creation</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Autoencoder for Compression &amp; Denoising)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers, models</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Compression AE</span></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>input_dim <span class="op">=</span> <span class="dv">784</span></span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>latent_dim <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>input_img <span class="op">=</span> layers.Input(shape<span class="op">=</span>(input_dim,))</span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>encoded <span class="op">=</span> layers.Dense(latent_dim, activation<span class="op">=</span><span class="st">"relu"</span>)(input_img)</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>decoded <span class="op">=</span> layers.Dense(input_dim, activation<span class="op">=</span><span class="st">"sigmoid"</span>)(encoded)</span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>compressor <span class="op">=</span> models.Model(input_img, decoded)</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Train with noisy data for denoising</span></span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> add_noise(x, factor<span class="op">=</span><span class="fl">0.2</span>):</span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tf.clip_by_value(x <span class="op">+</span> factor <span class="op">*</span> tf.random.normal(tf.shape(x)), <span class="fl">0.</span>, <span class="fl">1.</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-67" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-67">Why It Matters</h4>
<p>These applications show autoencoders are not just academic exercises. they compress real-world data, clean noisy signals, and generate new samples. This versatility makes them building blocks for both practical systems and advanced AI research.</p>
</section>
<section id="try-it-yourself-68" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-68">Try It Yourself</h4>
<ol type="1">
<li>Train an undercomplete AE on images and measure reconstruction size vs.&nbsp;JPEG.</li>
<li>Add Gaussian noise to MNIST digits and train a DAE. Compare noisy vs.&nbsp;reconstructed digits.</li>
<li>Train a VAE and interpolate between two images in latent space. Do transitions look smooth?</li>
<li>Use latent codes for anomaly detection (large reconstruction error = anomaly).</li>
</ol>
</section>
</section>
<section id="beyond-autoencoders-general-representation-learning" class="level3">
<h3 class="anchored" data-anchor-id="beyond-autoencoders-general-representation-learning">870. Beyond Autoencoders: General Representation Learning</h3>
<p>While autoencoders are a classic tool for unsupervised learning, modern representation learning has expanded far beyond them. Today’s methods leverage contrastive learning, predictive tasks, and large-scale self-supervision to learn powerful, general-purpose features.</p>
<section id="picture-in-your-head-69" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-69">Picture in Your Head</h4>
<p>Think of students learning. One memorizes by copying notes (autoencoder). Another learns by predicting missing words in a text or by comparing similar vs.&nbsp;different passages (self-supervised learning). The latter develops deeper understanding. this shift mirrors how modern ML moved beyond autoencoders.</p>
</section>
<section id="deep-dive-69" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-69">Deep Dive</h4>
<ul>
<li><p>Limitations of Autoencoders:</p>
<ul>
<li>Focus on reconstruction, not task-relevant features.</li>
<li>Latent codes sometimes entangled and uninterpretable.</li>
<li>Less scalable compared to modern contrastive/self-supervised methods.</li>
</ul></li>
<li><p>Next-Generation Methods:</p>
<ul>
<li>Contrastive Learning (e.g., SimCLR, MoCo): Learn representations by pulling similar pairs together and pushing apart dissimilar ones.</li>
<li>Predictive Masking (e.g., BERT, MAE): Predict missing parts of data (masked words, image patches).</li>
<li>Generative Self-Supervision (e.g., Diffusion Models): Learn features through generative objectives, beyond reconstruction.</li>
</ul></li>
<li><p>Integration with Autoencoders:</p>
<ul>
<li>Variational and adversarial autoencoders bridge toward generative models.</li>
<li>Hybrid methods combine reconstruction + contrastive losses.</li>
<li>Autoencoders remain relevant in compression, anomaly detection, and pretraining.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 26%">
<col style="width: 40%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th>Approach</th>
<th>Core Idea</th>
<th>Strengths</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Autoencoders</td>
<td>Reconstruct input</td>
<td>Simple, interpretable</td>
</tr>
<tr class="even">
<td>Contrastive Learning</td>
<td>Compare positive/negative pairs</td>
<td>Strong features, scalable</td>
</tr>
<tr class="odd">
<td>Masked Prediction</td>
<td>Predict missing parts</td>
<td>Language &amp; vision success</td>
</tr>
<tr class="even">
<td>Generative Models</td>
<td>Model data distribution</td>
<td>High-quality synthesis</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Hybrid AE + Contrastive Loss Sketch)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> hybrid_loss(x, x_recon, z, z_pos, z_neg, alpha<span class="op">=</span><span class="fl">0.5</span>):</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Reconstruction loss</span></span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>    recon_loss <span class="op">=</span> tf.reduce_mean(tf.square(x <span class="op">-</span> x_recon))</span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Contrastive loss (InfoNCE style)</span></span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>    pos_sim <span class="op">=</span> tf.reduce_sum(z <span class="op">*</span> z_pos, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>    neg_sim <span class="op">=</span> tf.reduce_sum(z <span class="op">*</span> z_neg, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a>    contrastive_loss <span class="op">=</span> <span class="op">-</span>tf.reduce_mean(tf.math.log(tf.exp(pos_sim) <span class="op">/</span> (tf.exp(pos_sim) <span class="op">+</span> tf.exp(neg_sim))))</span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> alpha <span class="op">*</span> recon_loss <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> alpha) <span class="op">*</span> contrastive_loss</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-68" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-68">Why It Matters</h4>
<p>Representation learning has become the core of modern AI, powering models like BERT, CLIP, and GPT. Autoencoders laid the groundwork, but the field evolved toward objectives that yield richer, task-agnostic embeddings. Understanding this progression explains how today’s foundation models emerged.</p>
</section>
<section id="try-it-yourself-69" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-69">Try It Yourself</h4>
<ol type="1">
<li>Train an autoencoder and a contrastive model on the same dataset. Which gives better features for classification?</li>
<li>Mask out parts of input data and train a predictive model. Compare with reconstruction-based AE.</li>
<li>Visualize embeddings from autoencoder vs.&nbsp;SimCLR. Which separates clusters better?</li>
<li>Combine AE with contrastive loss. Does hybrid training improve representation quality?</li>
</ol>
</section>
</section>
</section>
<section id="chapter-88.-contrastive-and-self-supervised-learning" class="level2">
<h2 class="anchored" data-anchor-id="chapter-88.-contrastive-and-self-supervised-learning">Chapter 88. Contrastive and self-supervised learning</h2>
<section id="why-self-supervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="why-self-supervised-learning">871. Why Self-Supervised Learning?</h3>
<p>Self-supervised learning (SSL) is a paradigm where models learn useful representations from unlabeled data by solving automatically generated tasks. Instead of requiring human-annotated labels, SSL creates <em>pretext tasks</em>. like predicting missing parts of data or distinguishing between transformed views. to teach the model structure.</p>
<section id="picture-in-your-head-70" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-70">Picture in Your Head</h4>
<p>Think of a child playing with puzzle pieces. No one tells them what the final picture is; by figuring out how the pieces fit, they learn about shapes and patterns. SSL does the same: it invents puzzles from raw data, and by solving them, the model learns powerful features.</p>
</section>
<section id="deep-dive-70" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-70">Deep Dive</h4>
<ul>
<li><p>Why It Emerged:</p>
<ul>
<li>Labeled data is expensive and scarce.</li>
<li>Unlabeled data (images, text, audio, logs) is abundant.</li>
<li>SSL unlocks learning from raw data without manual supervision.</li>
</ul></li>
<li><p>Core Pretext Tasks:</p>
<ul>
<li>Contrastive: bring augmented views of the same input closer in embedding space.</li>
<li>Predictive: predict missing parts (masked words, image patches).</li>
<li>Generative: reconstruct or generate plausible variations.</li>
</ul></li>
<li><p>Benefits:</p>
<ul>
<li>Reduces dependence on labels.</li>
<li>Produces transferable features for downstream tasks.</li>
<li>Scales with massive unlabeled corpora.</li>
</ul></li>
<li><p>Impact:</p>
<ul>
<li>NLP: BERT and GPT pretraining on unlabeled text.</li>
<li>Vision: SimCLR, MoCo, MAE.</li>
<li>Speech: wav2vec and HuBERT.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Domain</th>
<th>SSL Strategy</th>
<th>Breakthrough Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>NLP</td>
<td>Masked word prediction</td>
<td>BERT</td>
</tr>
<tr class="even">
<td>Vision</td>
<td>Contrastive, masking</td>
<td>SimCLR, MAE</td>
</tr>
<tr class="odd">
<td>Audio</td>
<td>Contrastive, predictive</td>
<td>wav2vec</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Masked Prediction Pretext Task)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: masking tokens in text</span></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> [<span class="st">"the"</span>, <span class="st">"sky"</span>, <span class="st">"is"</span>, <span class="st">"blue"</span>]</span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>mask_idx <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>masked_tokens <span class="op">=</span> tokens.copy()</span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>masked_tokens[mask_idx] <span class="op">=</span> <span class="st">"[MASK]"</span></span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Input:"</span>, masked_tokens)</span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Target:"</span>, tokens[mask_idx])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-69" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-69">Why It Matters</h4>
<p>SSL shifted AI from supervised learning bottlenecks to scalable pretraining. Modern foundation models owe their success to SSL, proving that models can discover structure from raw data itself.</p>
</section>
<section id="try-it-yourself-70" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-70">Try It Yourself</h4>
<ol type="1">
<li>Mask 15% of words in a sentence and train a simple model to predict them. Does it learn word relations?</li>
<li>Apply random crops/rotations to an image and train a contrastive model to recognize them as the same instance.</li>
<li>Compare features from supervised vs.&nbsp;self-supervised pretraining. Which transfers better to new tasks?</li>
<li>Collect unlabeled audio and train a model to predict missing waveform chunks. What does it capture?</li>
</ol>
</section>
</section>
<section id="contrastive-learning-objectives-infonce-triplet-loss" class="level3">
<h3 class="anchored" data-anchor-id="contrastive-learning-objectives-infonce-triplet-loss">872. Contrastive Learning Objectives (InfoNCE, Triplet Loss)</h3>
<p>Contrastive learning teaches models by comparing pairs of samples. The goal is to pull similar pairs together in latent space and push dissimilar pairs apart. This framework underlies modern self-supervised learning in vision, language, and audio.</p>
<section id="picture-in-your-head-71" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-71">Picture in Your Head</h4>
<p>Think of organizing photos. You put two pictures of the same person in one folder (positive pair), while keeping them apart from photos of other people (negative pairs). Contrastive learning automates this idea in representation space.</p>
</section>
<section id="deep-dive-71" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-71">Deep Dive</h4>
<ul>
<li><p>Triplet Loss:</p>
<ul>
<li><p>Uses anchor, positive, negative samples.</p></li>
<li><p>Objective:</p>
<p><span class="math display">\[
L = \max(0, d(a, p) - d(a, n) + \alpha)
\]</span></p>
<p>where <span class="math inline">\(d\)</span> is distance, <span class="math inline">\(\alpha\)</span> is margin.</p></li>
<li><p>Applied in face recognition (e.g., FaceNet).</p></li>
</ul></li>
<li><p>InfoNCE Loss:</p>
<ul>
<li><p>Foundation of SimCLR, MoCo, CLIP.</p></li>
<li><p>Given an anchor <span class="math inline">\(x\)</span>, positive <span class="math inline">\(x^+\)</span>, negatives <span class="math inline">\(\{x^-\}\)</span>:</p>
<p><span class="math display">\[
L = - \log \frac{\exp(\text{sim}(f(x), f(x^+)) / \tau)}{\sum_j \exp(\text{sim}(f(x), f(x_j)) / \tau)}
\]</span></p></li>
<li><p>Encourages high similarity for positives, low for negatives.</p></li>
</ul></li>
<li><p>Key Components:</p>
<ul>
<li>Similarity function: cosine similarity is standard.</li>
<li>Temperature (<span class="math inline">\(\tau\)</span>): sharpens or smooths distribution.</li>
<li>Batch size: larger = more negatives, better learning.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Objective</th>
<th>Structure</th>
<th>Application</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Triplet Loss</td>
<td>Anchor–Positive–Negative</td>
<td>Face verification</td>
</tr>
<tr class="even">
<td>InfoNCE</td>
<td>Softmax over many pairs</td>
<td>Vision, NLP, multimodal</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (PyTorch, InfoNCE Loss)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> info_nce_loss(anchor, positive, negatives, temperature<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize</span></span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a>    anchor <span class="op">=</span> F.normalize(anchor, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a>    positive <span class="op">=</span> F.normalize(positive, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a>    negatives <span class="op">=</span> F.normalize(negatives, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Positive similarity</span></span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a>    pos_sim <span class="op">=</span> torch.exp(torch.<span class="bu">sum</span>(anchor <span class="op">*</span> positive, dim<span class="op">=-</span><span class="dv">1</span>) <span class="op">/</span> temperature)</span>
<span id="cb73-12"><a href="#cb73-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-13"><a href="#cb73-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Negative similarity</span></span>
<span id="cb73-14"><a href="#cb73-14" aria-hidden="true" tabindex="-1"></a>    neg_sim <span class="op">=</span> torch.exp(anchor <span class="op">@</span> negatives.T <span class="op">/</span> temperature).<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb73-15"><a href="#cb73-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-16"><a href="#cb73-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># InfoNCE loss</span></span>
<span id="cb73-17"><a href="#cb73-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>torch.mean(torch.log(pos_sim <span class="op">/</span> (pos_sim <span class="op">+</span> neg_sim)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-70" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-70">Why It Matters</h4>
<p>Contrastive learning is the backbone of representation learning at scale. By structuring data through similarities, models learn semantic embeddings that generalize across tasks and modalities. It enabled breakthroughs like CLIP (vision–language) and SimCLR (vision).</p>
</section>
<section id="try-it-yourself-71" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-71">Try It Yourself</h4>
<ol type="1">
<li>Implement triplet loss for an image dataset (anchor = image, positive = augmented view, negative = different image).</li>
<li>Train with InfoNCE using different batch sizes. How does representation quality change?</li>
<li>Compare cosine similarity vs.&nbsp;Euclidean distance as similarity measures. Which performs better?</li>
<li>Apply InfoNCE loss to audio clips with different augmentations. Do embeddings cluster by speaker?</li>
</ol>
</section>
</section>
<section id="simclr-moco-byol-key-frameworks" class="level3">
<h3 class="anchored" data-anchor-id="simclr-moco-byol-key-frameworks">873. SimCLR, MoCo, BYOL: Key Frameworks</h3>
<p>Modern self-supervised learning in vision is powered by contrastive frameworks. SimCLR, MoCo, and BYOL each advance the idea of representation learning without labels, differing in how they form positive/negative pairs and stabilize training.</p>
<section id="picture-in-your-head-72" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-72">Picture in Your Head</h4>
<p>Imagine a classroom of students (images). SimCLR compares every student with every other in the same room. MoCo builds a memory bank of past students for richer comparisons. BYOL removes the need for explicit negatives, instead learning by aligning a student’s work with their own evolving notes.</p>
</section>
<section id="deep-dive-72" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-72">Deep Dive</h4>
<ul>
<li><p>SimCLR (Simple Contrastive Learning of Representations):</p>
<ul>
<li>Positive pairs: different augmentations of the same image.</li>
<li>Negatives: all other images in the batch.</li>
<li>Requires large batch sizes for many negatives.</li>
</ul></li>
<li><p>MoCo (Momentum Contrast):</p>
<ul>
<li>Uses a memory bank (queue) of representations for negatives.</li>
<li>Momentum encoder updates slowly to stabilize keys.</li>
<li>Scales well with smaller batch sizes.</li>
</ul></li>
<li><p>BYOL (Bootstrap Your Own Latent):</p>
<ul>
<li>Removes negatives entirely.</li>
<li>Learns by aligning online encoder with a slowly updated target encoder.</li>
<li>Prevents collapse via architectural tricks (stop-gradient, predictor network).</li>
</ul></li>
<li><p>Comparison:</p></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 15%">
<col style="width: 34%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th>Framework</th>
<th>Negatives</th>
<th>Stability Trick</th>
<th>Key Benefit</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>SimCLR</td>
<td>In-batch</td>
<td>Large batch sizes</td>
<td>Simplicity, strong baseline</td>
</tr>
<tr class="even">
<td>MoCo</td>
<td>Memory bank</td>
<td>Momentum encoder</td>
<td>Efficient with small batches</td>
</tr>
<tr class="odd">
<td>BYOL</td>
<td>None</td>
<td>Target encoder, predictor</td>
<td>Avoids negatives, simple</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (PyTorch, SimCLR-style positive pair generation)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> T</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> T.Compose([</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>    T.RandomResizedCrop(<span class="dv">224</span>),</span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>    T.RandomHorizontalFlip(),</span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>    T.ColorJitter(<span class="fl">0.4</span>, <span class="fl">0.4</span>, <span class="fl">0.4</span>, <span class="fl">0.1</span>),</span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>    T.RandomGrayscale(p<span class="op">=</span><span class="fl">0.2</span>),</span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a>    T.ToTensor()</span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(<span class="st">"sample.jpg"</span>)</span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a>x1, x2 <span class="op">=</span> transform(img), transform(img)  <span class="co"># two views of same image</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-71" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-71">Why It Matters</h4>
<p>These frameworks showed that label-free pretraining could rival supervised learning. They laid the foundation for vision transformers, multimodal models (CLIP, DALL·E), and speech models by proving self-supervision scales effectively.</p>
</section>
<section id="try-it-yourself-72" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-72">Try It Yourself</h4>
<ol type="1">
<li>Train a SimCLR model on CIFAR-10. How do features perform on linear probe classification?</li>
<li>Compare SimCLR with MoCo using small batch sizes. Which works better?</li>
<li>Train BYOL without negatives. Does it avoid representational collapse?</li>
<li>Visualize embeddings from SimCLR, MoCo, BYOL. Do clusters align with image classes?</li>
</ol>
</section>
</section>
<section id="negative-sampling-and-memory-banks" class="level3">
<h3 class="anchored" data-anchor-id="negative-sampling-and-memory-banks">874. Negative Sampling and Memory Banks</h3>
<p>Contrastive learning relies on negative samples to separate representations. Since enumerating all possible negatives is impossible, methods use strategies like in-batch negatives, memory banks, and momentum queues to approximate them efficiently.</p>
<section id="picture-in-your-head-73" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-73">Picture in Your Head</h4>
<p>Think of learning to recognize your friends in a crowd. You get better the more “distractors” you compare against. A memory bank works like a yearbook. you don’t need everyone in the room, you just need a stored collection of faces to contrast against.</p>
</section>
<section id="deep-dive-73" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-73">Deep Dive</h4>
<ul>
<li><p>In-Batch Negatives (SimCLR):</p>
<ul>
<li>Other samples in the minibatch act as negatives.</li>
<li>Simple and efficient, but requires large batches for diversity.</li>
</ul></li>
<li><p>Memory Bank (Wu et al., 2018):</p>
<ul>
<li>Stores embeddings from previous batches.</li>
<li>Expands the pool of negatives without huge batch sizes.</li>
<li>Risk: stale embeddings if bank is not updated well.</li>
</ul></li>
<li><p>Momentum Queue (MoCo):</p>
<ul>
<li>Maintains a queue of embeddings updated via a momentum encoder.</li>
<li>Ensures negatives remain consistent and fresh.</li>
<li>Scales to millions of negatives.</li>
</ul></li>
<li><p>Noise Contrastive Estimation (NCE):</p>
<ul>
<li>Early probabilistic formulation of negative sampling.</li>
<li>Approximates full softmax with sampled negatives.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 30%">
<col style="width: 24%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Source of Negatives</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>In-Batch</td>
<td>Same minibatch</td>
<td>Simple, fast</td>
<td>Needs big batches</td>
</tr>
<tr class="even">
<td>Memory Bank</td>
<td>Past embeddings</td>
<td>Large negative pool</td>
<td>May use stale vectors</td>
</tr>
<tr class="odd">
<td>Momentum Queue</td>
<td>Momentum encoder outputs</td>
<td>Stable, scalable</td>
<td>Extra encoder needed</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (PyTorch, Momentum Queue Sketch)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize queue</span></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>queue_size <span class="op">=</span> <span class="dv">1024</span></span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>latent_dim <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>queue <span class="op">=</span> torch.randn(queue_size, latent_dim)</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_queue(new_embeddings, queue):</span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add new embeddings and remove oldest</span></span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a>    queue <span class="op">=</span> torch.cat([new_embeddings, queue], dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> queue[:queue_size]</span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-13"><a href="#cb75-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb75-14"><a href="#cb75-14" aria-hidden="true" tabindex="-1"></a>new_batch <span class="op">=</span> torch.randn(<span class="dv">32</span>, latent_dim)</span>
<span id="cb75-15"><a href="#cb75-15" aria-hidden="true" tabindex="-1"></a>queue <span class="op">=</span> update_queue(new_batch, queue)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-72" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-72">Why It Matters</h4>
<p>Negative sampling is what makes contrastive learning scalable and effective. Without enough negatives, embeddings collapse. Memory banks and momentum queues solved the “batch size bottleneck,” enabling breakthroughs like MoCo and CLIP.</p>
</section>
<section id="try-it-yourself-73" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-73">Try It Yourself</h4>
<ol type="1">
<li>Train SimCLR with small vs.&nbsp;large batch sizes. How does feature quality change?</li>
<li>Implement a memory bank for contrastive loss. Does it improve over in-batch negatives?</li>
<li>Compare MoCo’s momentum queue vs.&nbsp;static memory bank. Which produces more stable training?</li>
<li>Reduce the number of negatives drastically. Do embeddings collapse?</li>
</ol>
</section>
</section>
<section id="bootstrap-and-predictive-methods" class="level3">
<h3 class="anchored" data-anchor-id="bootstrap-and-predictive-methods">875. Bootstrap and Predictive Methods</h3>
<p>Not all self-supervised learning requires negatives. Bootstrap and predictive methods learn by aligning multiple views of the same input or predicting masked parts of data. These approaches avoid the collapse problem with clever architectural tricks.</p>
<section id="picture-in-your-head-74" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-74">Picture in Your Head</h4>
<p>Imagine practicing handwriting. You cover parts of a word and try to fill them in (predictive). Or you rewrite the same word twice and compare. making sure both copies match (bootstrap). Both strategies help you learn structure without outside labels.</p>
</section>
<section id="deep-dive-74" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-74">Deep Dive</h4>
<ul>
<li><p>Bootstrap Approaches (e.g., BYOL, SimSiam):</p>
<ul>
<li>Train an online encoder to match a slowly updated target encoder.</li>
<li>No negatives required. collapse is prevented by asymmetry (e.g., predictor head, stop-gradient).</li>
<li>Learns robust features even without contrastive signals.</li>
</ul></li>
<li><p>Predictive Approaches:</p>
<ul>
<li>Masked autoencoders (MAE): mask image patches and predict missing pixels.</li>
<li>BERT: mask tokens and predict the original word.</li>
<li>Predictive coding: anticipate future frames in sequences.</li>
</ul></li>
<li><p>Advantages:</p>
<ul>
<li>No reliance on large negative sets.</li>
<li>Works well with smaller batch sizes.</li>
<li>Aligns with generative and reconstruction-style learning.</li>
</ul></li>
<li><p>Limitations:</p>
<ul>
<li>Risk of collapse if asymmetry not carefully designed.</li>
<li>Predictive tasks may bias toward low-level reconstruction instead of semantic meaning.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 19%">
<col style="width: 38%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Example</th>
<th>Key Trick</th>
<th>Application Domain</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Bootstrap</td>
<td>BYOL, SimSiam</td>
<td>Target encoder + stop-grad</td>
<td>Vision, speech</td>
</tr>
<tr class="even">
<td>Predictive</td>
<td>BERT, MAE</td>
<td>Masked input prediction</td>
<td>NLP, vision</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (PyTorch, Simple Bootstrap Loss Sketch)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> bootstrap_loss(p_online, z_target):</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize</span></span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>    p_online <span class="op">=</span> F.normalize(p_online, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a>    z_target <span class="op">=</span> F.normalize(z_target.detach(), dim<span class="op">=-</span><span class="dv">1</span>)  <span class="co"># stop-gradient</span></span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">2</span> <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> (p_online <span class="op">*</span> z_target).<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>).mean()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-73" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-73">Why It Matters</h4>
<p>Bootstrap and predictive methods removed the bottleneck of negatives, making self-supervised learning more practical and scalable. They directly inspired modern architectures like MAE in vision transformers and BERT in NLP, now foundational in AI systems.</p>
</section>
<section id="try-it-yourself-74" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-74">Try It Yourself</h4>
<ol type="1">
<li>Train a masked autoencoder on images. Visualize reconstructions. do missing patches recover?</li>
<li>Implement a simple bootstrap method with two encoders. Does it avoid collapse?</li>
<li>Compare BYOL vs.&nbsp;SimCLR on small batch sizes. Which is more stable?</li>
<li>Try predictive pretraining on time-series (predict next step). Does it improve downstream classification?</li>
</ol>
</section>
</section>
<section id="masked-prediction-approaches-bert-mae" class="level3">
<h3 class="anchored" data-anchor-id="masked-prediction-approaches-bert-mae">876. Masked Prediction Approaches (BERT, MAE)</h3>
<p>Masked prediction methods train models by hiding parts of the input and requiring the model to reconstruct or predict them. This forces the model to learn contextual representations, making it the foundation of modern NLP and vision pretraining.</p>
<section id="picture-in-your-head-75" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-75">Picture in Your Head</h4>
<p>Think of reading a sentence with some words blacked out. To guess the missing words, you must understand grammar and meaning. Or imagine a jigsaw puzzle with missing pieces. filling them in requires knowing the whole picture. Masked prediction turns this into a learning signal.</p>
</section>
<section id="deep-dive-75" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-75">Deep Dive</h4>
<ul>
<li><p>Masked Language Modeling (MLM, BERT):</p>
<ul>
<li>Randomly mask ~15% of tokens.</li>
<li>Train model to predict original tokens.</li>
<li>Encourages bidirectional context understanding.</li>
</ul></li>
<li><p>Masked Autoencoders (MAE, Vision):</p>
<ul>
<li>Mask large portions (up to 75%) of image patches.</li>
<li>Train encoder–decoder to reconstruct missing pixels.</li>
<li>Scales well with vision transformers (ViT).</li>
</ul></li>
<li><p>Variants and Extensions:</p>
<ul>
<li>Span masking: mask contiguous tokens (SpanBERT).</li>
<li>Denoising autoencoding: predict corrupted input (T5).</li>
<li>Cross-modal masking: mask across modalities (e.g., video–text, audio–text).</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Domain</th>
<th>Example</th>
<th>What Gets Masked</th>
<th>Outcome</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>NLP</td>
<td>BERT</td>
<td>Words/tokens</td>
<td>Contextual embeddings</td>
</tr>
<tr class="even">
<td>Vision</td>
<td>MAE</td>
<td>Image patches</td>
<td>Efficient ViT pretraining</td>
</tr>
<tr class="odd">
<td>Audio</td>
<td>HuBERT</td>
<td>Audio segments</td>
<td>Speech representations</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Simple MLM Data Prep)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> [<span class="st">"the"</span>, <span class="st">"cat"</span>, <span class="st">"sat"</span>, <span class="st">"on"</span>, <span class="st">"the"</span>, <span class="st">"mat"</span>]</span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>masked_tokens <span class="op">=</span> tokens.copy()</span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>mask_idx <span class="op">=</span> random.choice(<span class="bu">range</span>(<span class="bu">len</span>(tokens)))</span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a>masked_tokens[mask_idx] <span class="op">=</span> <span class="st">"[MASK]"</span></span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Input:"</span>, masked_tokens)</span>
<span id="cb77-9"><a href="#cb77-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Target:"</span>, tokens[mask_idx])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-74" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-74">Why It Matters</h4>
<p>Masked prediction transformed self-supervised learning into the default pretraining strategy for foundation models. From BERT in NLP to MAE in vision, it showed that predicting missing parts teaches models deep semantic and structural understanding.</p>
</section>
<section id="try-it-yourself-75" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-75">Try It Yourself</h4>
<ol type="1">
<li>Mask 15% of tokens in a text corpus and train a small Transformer to predict them. Do embeddings capture word relationships?</li>
<li>Train a masked autoencoder on CIFAR-10 images. How well can it reconstruct masked patches?</li>
<li>Compare random masking vs.&nbsp;span masking in text. Which gives richer embeddings?</li>
<li>Extend masked prediction to multimodal data (e.g., mask text when paired with images). Do features align across modalities?</li>
</ol>
</section>
</section>
<section id="alignment-vs.-uniformity-in-representations" class="level3">
<h3 class="anchored" data-anchor-id="alignment-vs.-uniformity-in-representations">877. Alignment vs.&nbsp;Uniformity in Representations</h3>
<p>Contrastive and self-supervised learning aim to build embedding spaces with two key properties: alignment (similar items are close) and uniformity (representations spread evenly across space). Balancing these ensures embeddings are both meaningful and diverse.</p>
<section id="picture-in-your-head-76" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-76">Picture in Your Head</h4>
<p>Imagine arranging magnets on a table. Alignment makes matching magnets stick together. Uniformity ensures they don’t all clump in one corner, but instead spread out evenly across the surface. Together, they create a well-structured layout.</p>
</section>
<section id="deep-dive-76" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-76">Deep Dive</h4>
<ul>
<li><p>Alignment:</p>
<ul>
<li>Pulls together embeddings of positive pairs (e.g., two views of the same image).</li>
<li>Encourages semantic similarity.</li>
<li>Metric: average distance between positive pairs.</li>
</ul></li>
<li><p>Uniformity:</p>
<ul>
<li>Pushes embeddings to cover the unit hypersphere uniformly.</li>
<li>Prevents collapse into trivial clusters.</li>
<li>Metric: log expected pairwise distance across all embeddings.</li>
</ul></li>
<li><p>Tension Between the Two:</p>
<ul>
<li>Too much alignment → collapse (all points overlap).</li>
<li>Too much uniformity → embeddings lose semantic grouping.</li>
<li>Modern SSL objectives balance both (e.g., InfoNCE approximates this tradeoff).</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 43%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th>Property</th>
<th>Effect on Embeddings</th>
<th>Risk if Overemphasized</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Alignment</td>
<td>Semantically similar = close</td>
<td>Collapse (no diversity)</td>
</tr>
<tr class="even">
<td>Uniformity</td>
<td>Spread across latent space</td>
<td>Loss of semantic structure</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (PyTorch, Alignment &amp; Uniformity Metrics)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> alignment(z1, z2):</span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (z1 <span class="op">-</span> z2).norm(dim<span class="op">=</span><span class="dv">1</span>).mean()</span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> uniformity(z):</span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.log(torch.pdist(F.normalize(z, dim<span class="op">=-</span><span class="dv">1</span>))<span class="dv">2</span>).mean()</span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: embeddings z1, z2 from positive pairs</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-75" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-75">Why It Matters</h4>
<p>Understanding alignment vs.&nbsp;uniformity gives theoretical insight into why contrastive learning works. It frames SSL as balancing semantic similarity with global diversity, guiding better loss design for embeddings in vision, language, and multimodal models.</p>
</section>
<section id="try-it-yourself-76" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-76">Try It Yourself</h4>
<ol type="1">
<li>Compute alignment and uniformity metrics for a trained SimCLR model. How do they change during training?</li>
<li>Train with stronger augmentations. Does alignment improve while uniformity decreases?</li>
<li>Experiment with smaller latent dimensions. Does uniformity collapse faster?</li>
<li>Visualize embeddings on a 2D dataset. Can you see the alignment/uniformity tradeoff?</li>
</ol>
</section>
</section>
<section id="evaluation-protocols-for-self-supervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-protocols-for-self-supervised-learning">878. Evaluation Protocols for Self-Supervised Learning</h3>
<p>Evaluating self-supervised learning (SSL) is different from supervised models. Since SSL does not optimize for a labeled objective directly, evaluation requires downstream tasks, transfer tests, and probing methods to judge representation quality.</p>
<section id="picture-in-your-head-77" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-77">Picture in Your Head</h4>
<p>Think of training an athlete by general exercises (SSL). To check progress, you don’t just measure how many push-ups they can do. you test performance in different sports. Similarly, SSL embeddings are tested across diverse tasks to see if they’re broadly useful.</p>
</section>
<section id="deep-dive-77" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-77">Deep Dive</h4>
<ul>
<li><p>Linear Probing:</p>
<ul>
<li>Train a simple linear classifier on frozen embeddings.</li>
<li>Tests linear separability of representations.</li>
<li>Standard in SimCLR, BYOL papers.</li>
</ul></li>
<li><p>Fine-Tuning:</p>
<ul>
<li>Unfreeze model and adapt to downstream task.</li>
<li>Evaluates transferability and adaptability.</li>
</ul></li>
<li><p>Clustering / k-NN Evaluation:</p>
<ul>
<li>Group embeddings into clusters and compare with labels.</li>
<li>k-NN accuracy as a lightweight test.</li>
</ul></li>
<li><p>Probing Tasks:</p>
<ul>
<li>Train shallow models on embeddings to predict linguistic, syntactic, or semantic properties.</li>
<li>Widely used in NLP (GLUE, SuperGLUE).</li>
</ul></li>
<li><p>Zero-Shot &amp; Few-Shot Evaluation:</p>
<ul>
<li>For multimodal SSL (e.g., CLIP), test models directly without retraining.</li>
<li>Example: zero-shot image classification by comparing embeddings to text prompts.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Protocol</th>
<th>What It Tests</th>
<th>Typical Domain</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Linear Probing</td>
<td>Representation separability</td>
<td>Vision, NLP</td>
</tr>
<tr class="even">
<td>Fine-Tuning</td>
<td>Adaptability</td>
<td>All domains</td>
</tr>
<tr class="odd">
<td>k-NN / Clustering</td>
<td>Structure &amp; consistency</td>
<td>Vision, speech</td>
</tr>
<tr class="even">
<td>Probing Tasks</td>
<td>Linguistic/semantic content</td>
<td>NLP</td>
</tr>
<tr class="odd">
<td>Zero/Few-Shot</td>
<td>Transfer without training</td>
<td>Multimodal</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (PyTorch, Linear Probe on SSL Features)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume ssl_model has produced embeddings X, labels y</span></span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LogisticRegression(max_iter<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a>clf.fit(X_train, y_train)</span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Linear probe accuracy:"</span>, accuracy_score(y_test, y_pred))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-76" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-76">Why It Matters</h4>
<p>SSL is only useful if representations transfer. Robust evaluation protocols reveal whether embeddings are general-purpose, task-agnostic, and semantically meaningful. This standardization is what made SSL comparable across models like SimCLR, BYOL, BERT, and CLIP.</p>
</section>
<section id="try-it-yourself-77" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-77">Try It Yourself</h4>
<ol type="1">
<li>Train a small SSL model on CIFAR-10. Evaluate embeddings with linear probing.</li>
<li>Compare linear probe vs.&nbsp;fine-tuning results. How much does tuning help?</li>
<li>Use k-NN evaluation on embeddings. Do nearest neighbors share the same label?</li>
<li>Run probing tasks on BERT embeddings (e.g., predict part of speech). Do features capture syntax?</li>
</ol>
</section>
</section>
<section id="scaling-self-supervised-models" class="level3">
<h3 class="anchored" data-anchor-id="scaling-self-supervised-models">879. Scaling Self-Supervised Models</h3>
<p>Self-supervised learning (SSL) thrives at scale. As datasets, model sizes, and compute grow, SSL methods like BERT, SimCLR, CLIP, and MAE reveal strong scaling laws, showing that bigger models trained longer on more unlabeled data yield more powerful general-purpose representations.</p>
<section id="picture-in-your-head-78" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-78">Picture in Your Head</h4>
<p>Think of learning a language by reading. With a handful of books, you only pick up basic phrases. With thousands of books, you gain deep fluency. SSL models behave the same way. scale turns weak learners into foundation models.</p>
</section>
<section id="deep-dive-78" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-78">Deep Dive</h4>
<ul>
<li><p>Data Scaling:</p>
<ul>
<li>Large corpora (Common Crawl for NLP, ImageNet-21k/JFT for vision) are critical.</li>
<li>Diverse, high-quality data reduces overfitting and improves transfer.</li>
</ul></li>
<li><p>Model Scaling:</p>
<ul>
<li>Transformers scale predictably with depth and width.</li>
<li>Larger models (billions of parameters) unlock richer latent spaces.</li>
</ul></li>
<li><p>Compute Scaling:</p>
<ul>
<li>Longer training with larger batch sizes improves contrastive methods (e.g., SimCLR).</li>
<li>Efficient training tricks (mixed precision, distributed training) make scaling feasible.</li>
</ul></li>
<li><p>Scaling Laws:</p>
<ul>
<li>Loss decreases smoothly with log of data, model size, and compute.</li>
<li>Tradeoff between data vs.&nbsp;parameters: small models saturate faster.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 22%">
<col style="width: 36%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Scaling Dimension</th>
<th>Example Models</th>
<th>Effect</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Data</td>
<td>BERT → RoBERTa</td>
<td>Improves coverage and diversity</td>
</tr>
<tr class="even">
<td>Model Size</td>
<td>ViT-B → ViT-H</td>
<td>Richer features, higher transfer</td>
</tr>
<tr class="odd">
<td>Compute</td>
<td>SimCLR (small → large batch)</td>
<td>Better contrastive performance</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (PyTorch, Distributed Training Sketch)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.distributed <span class="im">as</span> dist</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> setup_ddp():</span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a>    dist.init_process_group(<span class="st">"nccl"</span>)</span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a>    torch.cuda.set_device(dist.get_rank())</span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a><span class="co"># In practice: wrap model with torch.nn.parallel.DistributedDataParallel</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-77" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-77">Why It Matters</h4>
<p>Scaling is what transformed SSL into foundation models. BERT, GPT, CLIP, and MAE owe their success to training on massive unlabeled datasets with billions of parameters. SSL became practical not just because of clever objectives, but because it scaled predictably with resources.</p>
</section>
<section id="try-it-yourself-78" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-78">Try It Yourself</h4>
<ol type="1">
<li>Train SimCLR on CIFAR-10 vs.&nbsp;ImageNet. How does dataset size affect linear probe accuracy?</li>
<li>Increase model depth in an SSL transformer. Does representation quality keep improving?</li>
<li>Experiment with larger batch sizes in contrastive training. Does performance improve?</li>
<li>Compare training curves for small vs.&nbsp;large SSL models. Do scaling laws hold?</li>
</ol>
</section>
</section>
<section id="applications-across-modalities" class="level3">
<h3 class="anchored" data-anchor-id="applications-across-modalities">880. Applications Across Modalities</h3>
<p>Self-supervised learning (SSL) is not limited to text or images. Its principles. predicting, contrasting, or reconstructing. extend to speech, audio, video, multimodal data, and even scientific domains, enabling broad cross-disciplinary adoption.</p>
<section id="picture-in-your-head-79" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-79">Picture in Your Head</h4>
<p>Think of a universal toolkit: a hammer, screwdriver, and wrench that adapt to different tasks. SSL objectives are like this toolkit. the same principles (masking, contrast, prediction) can be reused whether the input is words, pixels, or sound waves.</p>
</section>
<section id="deep-dive-79" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-79">Deep Dive</h4>
<ul>
<li><p>Natural Language Processing (NLP):</p>
<ul>
<li>Masked language models (BERT, RoBERTa).</li>
<li>Autoregressive language models (GPT).</li>
<li>Applications: translation, QA, summarization.</li>
</ul></li>
<li><p>Vision:</p>
<ul>
<li>Contrastive (SimCLR, BYOL).</li>
<li>Masked autoencoders (MAE).</li>
<li>Applications: recognition, segmentation, retrieval.</li>
</ul></li>
<li><p>Speech &amp; Audio:</p>
<ul>
<li>Contrastive predictive coding (CPC).</li>
<li>wav2vec / HuBERT (masking on raw audio).</li>
<li>Applications: ASR, speaker ID, emotion recognition.</li>
</ul></li>
<li><p>Video:</p>
<ul>
<li>Temporal contrastive objectives.</li>
<li>Predicting missing or future frames.</li>
<li>Applications: action recognition, video understanding.</li>
</ul></li>
<li><p>Multimodal:</p>
<ul>
<li>CLIP: contrastive text–image alignment.</li>
<li>Flamingo / GPT-4V: cross-modal reasoning.</li>
<li>Applications: captioning, retrieval, VQA.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 24%">
<col style="width: 29%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th>Modality</th>
<th>Example Models</th>
<th>SSL Objective</th>
<th>Applications</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Text</td>
<td>BERT, GPT</td>
<td>Masking, autoregression</td>
<td>NLP tasks</td>
</tr>
<tr class="even">
<td>Vision</td>
<td>SimCLR, MAE</td>
<td>Contrastive, masking</td>
<td>Recognition, segmentation</td>
</tr>
<tr class="odd">
<td>Audio</td>
<td>wav2vec, HuBERT</td>
<td>Contrastive, masking</td>
<td>Speech, speaker recognition</td>
</tr>
<tr class="even">
<td>Video</td>
<td>TimeContrast, V-MAE</td>
<td>Temporal prediction</td>
<td>Action recognition</td>
</tr>
<tr class="odd">
<td>Multimodal</td>
<td>CLIP, ALIGN</td>
<td>Cross-modal contrast</td>
<td>Retrieval, captioning, VQA</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, CLIP-style Contrastive Loss Sketch)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> clip_loss(image_emb, text_emb, temperature<span class="op">=</span><span class="fl">0.07</span>):</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize embeddings</span></span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>    image_emb <span class="op">=</span> F.normalize(image_emb, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a>    text_emb <span class="op">=</span> F.normalize(text_emb, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Similarity matrix</span></span>
<span id="cb81-10"><a href="#cb81-10" aria-hidden="true" tabindex="-1"></a>    logits <span class="op">=</span> image_emb <span class="op">@</span> text_emb.T <span class="op">/</span> temperature</span>
<span id="cb81-11"><a href="#cb81-11" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> torch.arange(<span class="bu">len</span>(image_emb)).to(image_emb.device)</span>
<span id="cb81-12"><a href="#cb81-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-13"><a href="#cb81-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Symmetric cross-entropy loss</span></span>
<span id="cb81-14"><a href="#cb81-14" aria-hidden="true" tabindex="-1"></a>    loss_i <span class="op">=</span> F.cross_entropy(logits, labels)</span>
<span id="cb81-15"><a href="#cb81-15" aria-hidden="true" tabindex="-1"></a>    loss_t <span class="op">=</span> F.cross_entropy(logits.T, labels)</span>
<span id="cb81-16"><a href="#cb81-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (loss_i <span class="op">+</span> loss_t) <span class="op">/</span> <span class="dv">2</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-78" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-78">Why It Matters</h4>
<p>SSL became the unifying learning paradigm across modalities, enabling foundation models that understand language, vision, audio, and beyond. Its generality means progress in one domain often transfers to others, accelerating the field as a whole.</p>
</section>
<section id="try-it-yourself-79" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-79">Try It Yourself</h4>
<ol type="1">
<li>Mask spectrogram patches in audio data and train a model to reconstruct them. Do embeddings capture phonetics?</li>
<li>Train contrastive embeddings for paired text–image data. Can your model perform retrieval?</li>
<li>Apply temporal prediction SSL to video clips. Does it improve action classification?</li>
<li>Experiment with multimodal SSL by combining images and captions. Do embeddings align meaningfully?</li>
</ol>
</section>
</section>
</section>
<section id="chapter-89.-anomaly-and-novelty-detection" class="level2">
<h2 class="anchored" data-anchor-id="chapter-89.-anomaly-and-novelty-detection">Chapter 89. Anomaly and novelty detection</h2>
<section id="fundamentals-of-anomaly-detection" class="level3">
<h3 class="anchored" data-anchor-id="fundamentals-of-anomaly-detection">881. Fundamentals of Anomaly Detection</h3>
<p>Anomaly detection is the task of identifying data points that deviate significantly from expected patterns. These outliers can indicate critical events such as fraud, faults, attacks, or novel discoveries. The challenge lies in defining “normal” when only a small fraction of anomalies exist.</p>
<section id="picture-in-your-head-80" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-80">Picture in Your Head</h4>
<p>Imagine a factory conveyor belt producing identical bottles. Most bottles look the same (normal), but once in a while, a cracked one appears (anomaly). Anomaly detection is the inspector who flags the cracked bottle before it reaches the customer.</p>
</section>
<section id="deep-dive-80" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-80">Deep Dive</h4>
<ul>
<li><p>Types of Anomalies:</p>
<ul>
<li>Point Anomalies: a single instance significantly different (e.g., fraudulent credit card transaction).</li>
<li>Contextual Anomalies: abnormal only in specific context (e.g., high temperature at night).</li>
<li>Collective Anomalies: group of instances anomalous together (e.g., sudden spike in network traffic).</li>
</ul></li>
<li><p>Learning Paradigms:</p>
<ul>
<li>Supervised: requires labeled anomalies (rare, expensive).</li>
<li>Semi-supervised: train on normal data only, anomalies detected by deviation.</li>
<li>Unsupervised: assume anomalies are rare and different, no labels needed.</li>
</ul></li>
<li><p>Common Techniques:</p>
<ul>
<li>Statistical: z-scores, Gaussian models.</li>
<li>Distance-based: k-NN, clustering residuals.</li>
<li>Density-based: isolation forest, LOF (Local Outlier Factor).</li>
<li>Model-based: autoencoders, one-class SVM.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 36%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th>Type</th>
<th>Example Use Case</th>
<th>Method Often Used</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Point anomaly</td>
<td>Fraudulent transaction</td>
<td>Isolation Forest, One-Class SVM</td>
</tr>
<tr class="even">
<td>Contextual</td>
<td>Unusual seasonal behavior</td>
<td>Time-series models</td>
</tr>
<tr class="odd">
<td>Collective</td>
<td>DDoS attack traffic burst</td>
<td>Sequence/cluster analysis</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Simple z-Score Detection)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.array([<span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">200</span>])  <span class="co"># last point is anomaly</span></span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>mean, std <span class="op">=</span> np.mean(data), np.std(data)</span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>z_scores <span class="op">=</span> (data <span class="op">-</span> mean) <span class="op">/</span> std</span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a>anomalies <span class="op">=</span> np.where(np.<span class="bu">abs</span>(z_scores) <span class="op">&gt;</span> <span class="dv">3</span>)  <span class="co"># threshold at 3 std dev</span></span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Anomalies:"</span>, data[anomalies])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-79" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-79">Why It Matters</h4>
<p>Anomaly detection is crucial in domains where rare but impactful events occur: fraud detection in finance, fault detection in manufacturing, intrusion detection in cybersecurity, and disease outbreak monitoring in healthcare. Robust anomaly detection helps prevent losses and improves system reliability.</p>
</section>
<section id="try-it-yourself-80" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-80">Try It Yourself</h4>
<ol type="1">
<li>Generate synthetic data with Gaussian distribution. Inject outliers and detect them using z-scores.</li>
<li>Apply k-means clustering and flag points far from cluster centroids as anomalies.</li>
<li>Train a one-class SVM on normal MNIST digits. Test it with corrupted images. are they detected as anomalies?</li>
<li>Use reconstruction error from an autoencoder to detect anomalies in time-series data.</li>
</ol>
</section>
</section>
<section id="statistical-approaches-and-control-charts" class="level3">
<h3 class="anchored" data-anchor-id="statistical-approaches-and-control-charts">882. Statistical Approaches and Control Charts</h3>
<p>Statistical approaches detect anomalies by modeling the distribution of normal data and flagging points that deviate significantly. Control charts extend this idea to time-series, monitoring processes over time to detect shifts, drifts, or unusual events.</p>
<section id="picture-in-your-head-81" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-81">Picture in Your Head</h4>
<p>Think of a doctor tracking a patient’s temperature. If readings stay within 36–37.5°C, all is normal. But a sudden spike to 39°C signals a fever (anomaly). Control charts are like the doctor’s notepad, marking safe ranges and raising alarms when limits are breached.</p>
</section>
<section id="deep-dive-81" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-81">Deep Dive</h4>
<ul>
<li><p>Parametric Methods:</p>
<ul>
<li>Assume data follows a known distribution (e.g., Gaussian).</li>
<li>Outliers = points with low probability under estimated distribution.</li>
<li>Example: z-score, Grubbs’ test, Chi-square test.</li>
</ul></li>
<li><p>Non-Parametric Methods:</p>
<ul>
<li>No strong distribution assumptions.</li>
<li>Use ranks, quantiles, or kernel density estimation.</li>
<li>Example: Tukey’s fences (IQR method).</li>
</ul></li>
<li><p>Control Charts (SPC – Statistical Process Control):</p>
<ul>
<li>Developed for manufacturing quality control.</li>
<li>Shewhart Chart: monitors mean ± kσ limits.</li>
<li>CUSUM Chart: detects small shifts by cumulative sums.</li>
<li>EWMA Chart: exponentially weighted moving average, smooths trends.</li>
</ul></li>
<li><p>Tradeoffs:</p>
<ul>
<li>Simple, interpretable, low-cost.</li>
<li>Limited in high-dimensional or complex data.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 50%">
<col style="width: 31%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Idea</th>
<th>Application</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>z-score</td>
<td>Flag points &gt; k std dev from mean</td>
<td>Fraud, sensor monitoring</td>
</tr>
<tr class="even">
<td>IQR (Tukey)</td>
<td>Outliers outside Q1–1.5<em>IQR, Q3+1.5</em>IQR</td>
<td>Data cleaning</td>
</tr>
<tr class="odd">
<td>Shewhart Chart</td>
<td>Threshold on process mean ± σ</td>
<td>Factory defect detection</td>
</tr>
<tr class="even">
<td>CUSUM/EWMA</td>
<td>Detect gradual process drift</td>
<td>Industrial monitoring</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Shewhart Control Chart)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.array([<span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">13</span>, <span class="dv">20</span>])  <span class="co"># last value deviates</span></span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>mean, std <span class="op">=</span> np.mean(data), np.std(data)</span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>ucl, lcl <span class="op">=</span> mean <span class="op">+</span> <span class="dv">3</span><span class="op">*</span>std, mean <span class="op">-</span> <span class="dv">3</span><span class="op">*</span>std  <span class="co"># control limits</span></span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, val <span class="kw">in</span> <span class="bu">enumerate</span>(data):</span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> val <span class="op">&gt;</span> ucl <span class="kw">or</span> val <span class="op">&lt;</span> lcl:</span>
<span id="cb83-9"><a href="#cb83-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Point </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> = </span><span class="sc">{</span>val<span class="sc">}</span><span class="ss"> flagged as anomaly"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-80" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-80">Why It Matters</h4>
<p>Statistical approaches remain the foundation of anomaly detection in domains like manufacturing, finance, and healthcare. They are transparent and explainable, making them highly trusted in regulated industries where interpretability is essential.</p>
</section>
<section id="try-it-yourself-81" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-81">Try It Yourself</h4>
<ol type="1">
<li>Apply z-score anomaly detection on stock price data. Which points exceed 3σ?</li>
<li>Use IQR on a dataset with heavy-tailed noise. How robust is it compared to z-scores?</li>
<li>Simulate a production line with gradual drift. Compare Shewhart vs.&nbsp;CUSUM charts.</li>
<li>Implement EWMA on CPU monitoring data. Can it detect slow, creeping anomalies?</li>
</ol>
</section>
</section>
<section id="clustering-based-anomaly-detection" class="level3">
<h3 class="anchored" data-anchor-id="clustering-based-anomaly-detection">883. Clustering-Based Anomaly Detection</h3>
<p>Clustering-based methods detect anomalies by measuring how well data points fit into discovered clusters. Anomalies are typically far from cluster centroids or assigned to very small, sparse clusters.</p>
<section id="picture-in-your-head-82" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-82">Picture in Your Head</h4>
<p>Imagine sorting marbles by color. Most fall into big groups. red, blue, green. A few odd marbles with unusual shades don’t fit anywhere; these are anomalies. Clustering acts as the grouping mechanism, and misfits are flagged as outliers.</p>
</section>
<section id="deep-dive-82" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-82">Deep Dive</h4>
<ul>
<li><p>k-Means for Anomaly Detection:</p>
<ul>
<li>Train k-means on dataset.</li>
<li>Compute distance of each point to nearest centroid.</li>
<li>Large distances = potential anomalies.</li>
</ul></li>
<li><p>DBSCAN / Density-Based Clustering:</p>
<ul>
<li>Points in dense regions = normal.</li>
<li>Points in sparse or noise regions = anomalies.</li>
<li>Advantage: automatically detects noise/outliers.</li>
</ul></li>
<li><p>Hierarchical Clustering:</p>
<ul>
<li>Outliers often appear as singletons or small clusters.</li>
<li>Dendrogram cuts reveal unusual points.</li>
</ul></li>
<li><p>Strengths:</p>
<ul>
<li>Unsupervised. no labels needed.</li>
<li>Easy to implement and interpret.</li>
</ul></li>
<li><p>Limitations:</p>
<ul>
<li>Sensitive to choice of cluster number (k).</li>
<li>High-dimensional data reduces clustering effectiveness.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Method</th>
<th>Outlier Criterion</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>k-Means</td>
<td>Distance from centroid</td>
<td>Structured, low-dim data</td>
</tr>
<tr class="even">
<td>DBSCAN</td>
<td>Sparse/noisy points</td>
<td>Irregular densities</td>
</tr>
<tr class="odd">
<td>Hierarchical</td>
<td>Singleton/small clusters</td>
<td>Small to medium datasets</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, k-Means Anomaly Detection)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array([[<span class="dv">1</span>,<span class="dv">2</span>],[<span class="dv">1</span>,<span class="dv">1</span>],[<span class="dv">2</span>,<span class="dv">2</span>],[<span class="dv">8</span>,<span class="dv">8</span>],[<span class="dv">9</span>,<span class="dv">9</span>]])  <span class="co"># last two = anomalies</span></span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>).fit(X)</span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>distances <span class="op">=</span> np.<span class="bu">min</span>(kmeans.transform(X), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> np.percentile(distances, <span class="dv">90</span>)  <span class="co"># top 10% as anomalies</span></span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a>anomalies <span class="op">=</span> X[distances <span class="op">&gt;</span> threshold]</span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Anomalies:"</span>, anomalies)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-81" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-81">Why It Matters</h4>
<p>Clustering-based anomaly detection is widely used in network intrusion detection, market segmentation, and sensor monitoring, where anomalies naturally appear as misfits among normal groups. It provides an intuitive, unsupervised baseline before applying more complex models.</p>
</section>
<section id="try-it-yourself-82" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-82">Try It Yourself</h4>
<ol type="1">
<li>Apply k-means clustering to credit card transactions. Flag top 5% farthest from centroids as anomalies.</li>
<li>Use DBSCAN on GPS tracking data. Which points are marked as noise?</li>
<li>Perform hierarchical clustering on network traffic. Do singletons correspond to suspicious activity?</li>
<li>Compare anomaly detection performance between k-means and DBSCAN on synthetic data with irregular densities.</li>
</ol>
</section>
</section>
<section id="one-class-classification-e.g.-one-class-svm" class="level3">
<h3 class="anchored" data-anchor-id="one-class-classification-e.g.-one-class-svm">884. One-Class Classification (e.g., One-Class SVM)</h3>
<p>One-class classification methods learn a boundary around normal data and classify anything outside it as an anomaly. Unlike binary classifiers, they are trained only on “normal” examples, making them ideal when anomalies are rare or unknown during training.</p>
<section id="picture-in-your-head-83" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-83">Picture in Your Head</h4>
<p>Imagine drawing a fence around your sheep in a field. Anything outside the fence. whether a wolf or a stray goat. is treated as suspicious. The fence represents the decision boundary learned by a one-class classifier.</p>
</section>
<section id="deep-dive-83" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-83">Deep Dive</h4>
<ul>
<li><p>One-Class SVM:</p>
<ul>
<li>Learns a hypersphere or hyperplane that encloses most of the data.</li>
<li>Uses kernel tricks to capture nonlinear boundaries.</li>
<li>Objective: maximize margin from origin while minimizing outliers.</li>
</ul></li>
<li><p>Support Vector Data Description (SVDD):</p>
<ul>
<li>Explicitly fits a minimal-radius hypersphere around the data.</li>
<li>Similar to one-class SVM but optimized for compactness.</li>
</ul></li>
<li><p>Advantages:</p>
<ul>
<li>Works without labeled anomalies.</li>
<li>Flexible with kernels for non-linear patterns.</li>
</ul></li>
<li><p>Limitations:</p>
<ul>
<li>Sensitive to parameter settings (ν, kernel width).</li>
<li>Performance degrades in high dimensions or noisy data.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 30%">
<col style="width: 28%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Boundary Shape</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>One-Class SVM</td>
<td>Hyperplane / hypersphere</td>
<td>Flexible, kernel-based</td>
<td>Parameter sensitive</td>
</tr>
<tr class="even">
<td>SVDD</td>
<td>Minimal enclosing sphere</td>
<td>Compact boundary</td>
<td>Less scalable</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, One-Class SVM)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> OneClassSVM</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Normal data</span></span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> <span class="fl">0.3</span> <span class="op">*</span> np.random.randn(<span class="dv">100</span>, <span class="dv">2</span>)</span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> np.r_[X <span class="op">+</span> <span class="dv">2</span>, X <span class="op">-</span> <span class="dv">2</span>]  <span class="co"># clusters of normal data</span></span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Add anomalies</span></span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> np.r_[X_train, np.random.uniform(low<span class="op">=-</span><span class="dv">6</span>, high<span class="op">=</span><span class="dv">6</span>, size<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">2</span>))]</span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Train One-Class SVM</span></span>
<span id="cb85-12"><a href="#cb85-12" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> OneClassSVM(kernel<span class="op">=</span><span class="st">"rbf"</span>, gamma<span class="op">=</span><span class="fl">0.1</span>, nu<span class="op">=</span><span class="fl">0.05</span>).fit(X_train)</span>
<span id="cb85-13"><a href="#cb85-13" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb85-14"><a href="#cb85-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-15"><a href="#cb85-15" aria-hidden="true" tabindex="-1"></a><span class="co"># -1 = anomaly, 1 = normal</span></span>
<span id="cb85-16"><a href="#cb85-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Anomalies:"</span>, X_test[y_pred <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-82" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-82">Why It Matters</h4>
<p>One-class classification is widely used in fraud detection, cybersecurity intrusion detection, and medical diagnosis, where anomalies are rare, costly, or unknown. It provides a principled way to model “normality” without exhaustive negative examples.</p>
</section>
<section id="try-it-yourself-83" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-83">Try It Yourself</h4>
<ol type="1">
<li>Train a one-class SVM on clean network traffic. Test it with attack traffic. are intrusions flagged?</li>
<li>Apply SVDD on a small dataset with clusters. Visualize the hypersphere boundary.</li>
<li>Experiment with different ν values. How does anomaly sensitivity change?</li>
<li>Compare one-class SVM with k-means distance-based anomaly detection. Which is more robust?</li>
</ol>
</section>
</section>
<section id="density-based-and-isolation-forest-methods" class="level3">
<h3 class="anchored" data-anchor-id="density-based-and-isolation-forest-methods">885. Density-Based and Isolation Forest Methods</h3>
<p>Density-based and tree-based methods detect anomalies by exploiting the idea that normal points lie in dense regions, while anomalies appear in sparse, isolated areas. These approaches scale well and often outperform distance-based or statistical baselines.</p>
<section id="picture-in-your-head-84" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-84">Picture in Your Head</h4>
<p>Think of a bustling city. Most people live in crowded neighborhoods (normal points), but a lone house in the middle of the desert stands out (anomaly). Density-based methods measure neighborhood density, while Isolation Forests build random partitions that quickly separate outliers.</p>
</section>
<section id="deep-dive-84" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-84">Deep Dive</h4>
<ul>
<li><p>Local Outlier Factor (LOF):</p>
<ul>
<li>Compares local density of a point with its neighbors.</li>
<li>Outliers = significantly lower density than neighbors.</li>
<li>Sensitive to neighborhood size parameter <span class="math inline">\(k\)</span>.</li>
</ul></li>
<li><p>kNN Density Estimation:</p>
<ul>
<li>Points far from neighbors have low density → anomalies.</li>
<li>Simple but costly in large datasets.</li>
</ul></li>
<li><p>Isolation Forest:</p>
<ul>
<li>Builds an ensemble of random trees by recursively splitting features.</li>
<li>Anomalies are isolated faster → shorter path length in trees.</li>
<li>Scales to high-dimensional data, efficient for large datasets.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 37%">
<col style="width: 23%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Core Idea</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>LOF</td>
<td>Local density comparison</td>
<td>Captures local structure</td>
<td>Sensitive to parameters</td>
</tr>
<tr class="even">
<td>kNN Density</td>
<td>Distance to neighbors</td>
<td>Simple, interpretable</td>
<td>Expensive in high-dims</td>
</tr>
<tr class="odd">
<td>Isolation Forest</td>
<td>Random partitioning isolates anomalies</td>
<td>Scalable, fast</td>
<td>Less interpretable</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Isolation Forest)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> IsolationForest</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate synthetic data</span></span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.random.randn(<span class="dv">100</span>, <span class="dv">2</span>)  <span class="co"># normal data</span></span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.r_[X, np.random.uniform(low<span class="op">=-</span><span class="dv">6</span>, high<span class="op">=</span><span class="dv">6</span>, size<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">2</span>))]  <span class="co"># anomalies</span></span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Train Isolation Forest</span></span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> IsolationForest(contamination<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> clf.fit_predict(X)  <span class="co"># -1 = anomaly, 1 = normal</span></span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Anomalies:"</span>, X[y_pred <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-83" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-83">Why It Matters</h4>
<p>Density-based and Isolation Forest methods are practical for fraud detection, cybersecurity, industrial monitoring, and environmental data analysis. Their efficiency and accuracy make them go-to tools when dealing with large, complex, real-world datasets.</p>
</section>
<section id="try-it-yourself-84" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-84">Try It Yourself</h4>
<ol type="1">
<li>Train LOF on a dataset with clusters of varying density. Do anomalies cluster in sparse regions?</li>
<li>Compare Isolation Forest vs.&nbsp;one-class SVM on high-dimensional data. Which scales better?</li>
<li>Adjust Isolation Forest’s contamination parameter. How does sensitivity to anomalies change?</li>
<li>Apply Isolation Forest to real-world data (e.g., credit card transactions). Do anomalies align with suspicious activity?</li>
</ol>
</section>
</section>
<section id="deep-learning-for-anomaly-detection" class="level3">
<h3 class="anchored" data-anchor-id="deep-learning-for-anomaly-detection">886. Deep Learning for Anomaly Detection</h3>
<p>Deep learning methods use neural networks to detect anomalies by learning complex nonlinear patterns in data. Instead of relying on simple statistics or distances, these models capture high-dimensional structure, making them powerful for images, text, audio, and time-series.</p>
<section id="picture-in-your-head-85" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-85">Picture in Your Head</h4>
<p>Imagine a security guard trained with millions of photos of normal doors. After enough training, the guard instantly spots a door that looks unusual. a crack, a missing handle, or strange paint. even without having seen such defects before. Deep learning anomaly detectors work the same way.</p>
</section>
<section id="deep-dive-85" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-85">Deep Dive</h4>
<ul>
<li><p>Autoencoders for Anomaly Detection:</p>
<ul>
<li>Train on normal data to minimize reconstruction error.</li>
<li>High error on unseen or abnormal data → anomaly signal.</li>
<li>Variants: denoising autoencoders, variational autoencoders.</li>
</ul></li>
<li><p>Convolutional Neural Networks (CNNs):</p>
<ul>
<li>Used for visual anomaly detection (defects in manufacturing, medical imaging).</li>
<li>Learn spatial patterns of normal vs.&nbsp;abnormal regions.</li>
</ul></li>
<li><p>Recurrent Neural Networks (RNNs, LSTMs):</p>
<ul>
<li>Model time-series by predicting next step.</li>
<li>High prediction error = anomaly.</li>
<li>Applications: fraud detection, server monitoring.</li>
</ul></li>
<li><p>GAN-Based Anomaly Detection:</p>
<ul>
<li>Train GAN on normal data.</li>
<li>Anomalies detected by poor reconstruction or discriminator score.</li>
</ul></li>
<li><p>Self-Supervised Learning:</p>
<ul>
<li>Use proxy tasks (masking, rotation prediction) to learn normal features.</li>
<li>Anomalies are detected when representations fail to generalize.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 39%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="header">
<th>Model Type</th>
<th>Approach</th>
<th>Best Domain</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Autoencoder</td>
<td>Reconstruction error</td>
<td>General-purpose, time-series</td>
</tr>
<tr class="even">
<td>CNN</td>
<td>Image region features</td>
<td>Vision, medical imaging</td>
</tr>
<tr class="odd">
<td>LSTM / RNN</td>
<td>Sequence prediction</td>
<td>Fraud, logs, IoT data</td>
</tr>
<tr class="even">
<td>GAN</td>
<td>Generative reconstruction</td>
<td>Visual &amp; sensor data</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Autoencoder for Anomaly Detection)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers, models</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>input_dim <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a>encoding_dim <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Autoencoder</span></span>
<span id="cb87-8"><a href="#cb87-8" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> layers.Input(shape<span class="op">=</span>(input_dim,))</span>
<span id="cb87-9"><a href="#cb87-9" aria-hidden="true" tabindex="-1"></a>encoded <span class="op">=</span> layers.Dense(encoding_dim, activation<span class="op">=</span><span class="st">"relu"</span>)(inputs)</span>
<span id="cb87-10"><a href="#cb87-10" aria-hidden="true" tabindex="-1"></a>decoded <span class="op">=</span> layers.Dense(input_dim, activation<span class="op">=</span><span class="st">"sigmoid"</span>)(encoded)</span>
<span id="cb87-11"><a href="#cb87-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-12"><a href="#cb87-12" aria-hidden="true" tabindex="-1"></a>autoencoder <span class="op">=</span> models.Model(inputs, decoded)</span>
<span id="cb87-13"><a href="#cb87-13" aria-hidden="true" tabindex="-1"></a>autoencoder.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">"adam"</span>, loss<span class="op">=</span><span class="st">"mse"</span>)</span>
<span id="cb87-14"><a href="#cb87-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-15"><a href="#cb87-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Train on normal data only</span></span>
<span id="cb87-16"><a href="#cb87-16" aria-hidden="true" tabindex="-1"></a><span class="co"># autoencoder.fit(X_normal, X_normal, epochs=50, batch_size=32)</span></span>
<span id="cb87-17"><a href="#cb87-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-18"><a href="#cb87-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Later: high reconstruction error = anomaly</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-84" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-84">Why It Matters</h4>
<p>Deep learning enables anomaly detection in domains where patterns are complex and high-dimensional. from MRI scans to credit card fraud to industrial IoT sensors. These methods underpin modern smart manufacturing, healthcare diagnostics, and cybersecurity systems.</p>
</section>
<section id="try-it-yourself-85" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-85">Try It Yourself</h4>
<ol type="1">
<li>Train an autoencoder on normal sensor data. Test with faulty readings. does reconstruction error spike?</li>
<li>Use an LSTM to predict the next time-series value. Insert anomalies and measure prediction error.</li>
<li>Train a GAN on normal images. Test with anomalous images. does the generator fail to reconstruct them?</li>
<li>Compare traditional Isolation Forest vs.&nbsp;deep autoencoder on the same dataset. Which detects anomalies better?</li>
</ol>
</section>
</section>
<section id="novelty-detection-vs.-outlier-detection" class="level3">
<h3 class="anchored" data-anchor-id="novelty-detection-vs.-outlier-detection">887. Novelty Detection vs.&nbsp;Outlier Detection</h3>
<p>Although often used interchangeably, novelty detection and outlier detection are distinct tasks. Novelty detection focuses on identifying new but valid patterns unseen during training, while outlier detection flags invalid or erroneous points that don’t fit known data distributions.</p>
<section id="picture-in-your-head-86" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-86">Picture in Your Head</h4>
<p>Imagine a zoo database trained only on cats and dogs. If a wolf shows up, novelty detection should recognize it as a new but valid species. If the system sees a mislabeled barcode or a corrupted image, outlier detection should flag it as invalid noise.</p>
</section>
<section id="deep-dive-86" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-86">Deep Dive</h4>
<ul>
<li><p>Outlier Detection:</p>
<ul>
<li>Goal: flag abnormal points that may result from errors, noise, or fraud.</li>
<li>Examples: corrupted sensor readings, fraudulent credit transactions.</li>
<li>Typically unsupervised. assumes anomalies are rare and different.</li>
</ul></li>
<li><p>Novelty Detection:</p>
<ul>
<li>Goal: detect genuinely new categories or structures absent in training data.</li>
<li>Examples: new malware strain, new disease type, unseen product defect.</li>
<li>Often semi-supervised. model is trained on known normal classes only.</li>
</ul></li>
<li><p>Methodological Differences:</p>
<ul>
<li>Outlier detection uses statistical, clustering, or density-based techniques.</li>
<li>Novelty detection often employs one-class classification, domain adaptation, or open-set recognition.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 36%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th>Task</th>
<th>Focus</th>
<th>Typical Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Outlier Detection</td>
<td>Errors, noise, rare events</td>
<td>Fraud, corrupted data</td>
</tr>
<tr class="even">
<td>Novelty Detection</td>
<td>New valid patterns</td>
<td>New species, zero-shot tasks</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, One-Class SVM for Novelty Detection)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> OneClassSVM</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Training data (normal)</span></span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, (<span class="dv">100</span>, <span class="dv">2</span>))</span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Novelty: new distribution</span></span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a>X_new <span class="op">=</span> np.random.normal(<span class="dv">5</span>, <span class="dv">1</span>, (<span class="dv">20</span>, <span class="dv">2</span>))</span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> OneClassSVM(gamma<span class="op">=</span><span class="fl">0.1</span>, nu<span class="op">=</span><span class="fl">0.05</span>).fit(X_train)</span>
<span id="cb88-11"><a href="#cb88-11" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> clf.predict(X_new)</span>
<span id="cb88-12"><a href="#cb88-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-13"><a href="#cb88-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Novelty flags:"</span>, y_pred)  <span class="co"># -1 = novel, 1 = normal</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-85" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-85">Why It Matters</h4>
<p>Distinguishing novelty from outliers is vital in security, medicine, and AI safety. Outlier detection ensures robustness by filtering bad data, while novelty detection enables discovery of new phenomena and adaptation to evolving environments.</p>
</section>
<section id="try-it-yourself-86" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-86">Try It Yourself</h4>
<ol type="1">
<li>Train a one-class model on MNIST digits 0–8. Test it on digit 9. Is it flagged as novelty?</li>
<li>Add random noise images to the same test set. Are they flagged as outliers instead?</li>
<li>Compare clustering-based anomaly detection vs.&nbsp;one-class SVM. Which is better at novelty detection?</li>
<li>Apply novelty detection to log data from a server. Can it detect new attack patterns vs.&nbsp;random errors?</li>
</ol>
</section>
</section>
<section id="evaluation-metrics-precision-roc-pr-auc" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-metrics-precision-roc-pr-auc">888. Evaluation Metrics (Precision, ROC, PR, AUC)</h3>
<p>Evaluating anomaly detection is challenging because anomalies are rare and imbalanced compared to normal data. Standard accuracy is misleading; instead, specialized metrics such as precision, recall, ROC-AUC, and PR-AUC are used to measure detection quality.</p>
<section id="picture-in-your-head-87" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-87">Picture in Your Head</h4>
<p>Imagine airport security scanning 10,000 passengers. If only 10 are threats, catching 9 matters far more than quickly processing the other 9,990. Metrics for anomaly detection highlight the tradeoff between catching true anomalies and minimizing false alarms.</p>
</section>
<section id="deep-dive-87" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-87">Deep Dive</h4>
<ul>
<li><p>Confusion Matrix for Anomaly Detection:</p>
<ul>
<li>True Positive (TP): correctly flagged anomaly.</li>
<li>False Positive (FP): normal point incorrectly flagged.</li>
<li>True Negative (TN): correctly identified normal.</li>
<li>False Negative (FN): anomaly missed.</li>
</ul></li>
<li><p>Key Metrics:</p>
<ul>
<li>Precision = TP / (TP + FP): of flagged anomalies, how many are correct?</li>
<li>Recall = TP / (TP + FN): how many anomalies did we catch?</li>
<li>F1 Score = harmonic mean of precision and recall.</li>
<li>ROC Curve: plots TPR vs.&nbsp;FPR at different thresholds.</li>
<li>ROC-AUC: probability model ranks a random anomaly higher than a normal.</li>
<li>PR Curve: plots precision vs.&nbsp;recall.</li>
<li>PR-AUC: better than ROC-AUC under high imbalance.</li>
</ul></li>
<li><p>When to Use What:</p>
<ul>
<li>ROC-AUC: general discrimination ability.</li>
<li>PR-AUC: more informative when anomalies are very rare.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Metric</th>
<th>Focus</th>
<th>Good For</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Precision</td>
<td>Quality of anomaly flags</td>
<td>Reducing false alarms</td>
</tr>
<tr class="even">
<td>Recall</td>
<td>Coverage of anomalies</td>
<td>Safety-critical detection</td>
</tr>
<tr class="odd">
<td>ROC-AUC</td>
<td>Overall separability</td>
<td>Balanced datasets</td>
</tr>
<tr class="even">
<td>PR-AUC</td>
<td>Rare-event performance</td>
<td>Highly imbalanced data</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, PR &amp; ROC Evaluation)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_curve, roc_auc_score, auc</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: scores from anomaly detector</span></span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> np.array([<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>])  <span class="co"># 1=anomaly</span></span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>y_scores <span class="op">=</span> np.array([<span class="fl">0.1</span>,<span class="fl">0.2</span>,<span class="fl">0.3</span>,<span class="fl">0.4</span>,<span class="fl">0.9</span>,<span class="fl">0.2</span>,<span class="fl">0.8</span>,<span class="fl">0.3</span>,<span class="fl">0.1</span>,<span class="fl">0.95</span>])</span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a><span class="co"># ROC-AUC</span></span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a>roc_auc <span class="op">=</span> roc_auc_score(y_true, y_scores)</span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-11"><a href="#cb89-11" aria-hidden="true" tabindex="-1"></a><span class="co"># PR Curve</span></span>
<span id="cb89-12"><a href="#cb89-12" aria-hidden="true" tabindex="-1"></a>precision, recall, _ <span class="op">=</span> precision_recall_curve(y_true, y_scores)</span>
<span id="cb89-13"><a href="#cb89-13" aria-hidden="true" tabindex="-1"></a>pr_auc <span class="op">=</span> auc(recall, precision)</span>
<span id="cb89-14"><a href="#cb89-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-15"><a href="#cb89-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ROC-AUC:"</span>, roc_auc, <span class="st">"PR-AUC:"</span>, pr_auc)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-86" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-86">Why It Matters</h4>
<p>Without the right metrics, anomaly detectors may look good but fail in practice. For instance, a trivial classifier that always predicts “normal” can reach 99.9% accuracy in imbalanced data. but catch zero anomalies. Using precision, recall, and PR-AUC ensures evaluation reflects real-world effectiveness.</p>
</section>
<section id="try-it-yourself-87" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-87">Try It Yourself</h4>
<ol type="1">
<li>Create a dataset with 1% anomalies. Compare ROC-AUC vs.&nbsp;PR-AUC. Which is more informative?</li>
<li>Train an Isolation Forest. Vary threshold on anomaly score and plot ROC &amp; PR curves.</li>
<li>Compute F1 score at different thresholds. Where is the balance between precision and recall?</li>
<li>Evaluate two anomaly detectors: one high precision, one high recall. Which is better for fraud vs.&nbsp;medical diagnosis?</li>
</ol>
</section>
</section>
<section id="industrial-medical-and-security-applications" class="level3">
<h3 class="anchored" data-anchor-id="industrial-medical-and-security-applications">889. Industrial, Medical, and Security Applications</h3>
<p>Anomaly detection powers real-world systems where catching rare, abnormal events is critical. From predictive maintenance in factories, to early disease detection in medicine, to fraud and intrusion detection in cybersecurity. anomalies often signal events with high cost or high risk.</p>
<section id="picture-in-your-head-88" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-88">Picture in Your Head</h4>
<p>Think of anomaly detection as a set of watchdogs. In a factory, it barks when a machine vibrates oddly. In a hospital, it alerts when a patient’s heartbeat looks unusual. In cybersecurity, it raises alarms when network traffic behaves differently than usual.</p>
</section>
<section id="deep-dive-88" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-88">Deep Dive</h4>
<ul>
<li><p>Industrial Applications:</p>
<ul>
<li>Predictive maintenance: detect abnormal vibrations, temperatures, or pressures before breakdowns.</li>
<li>Quality control: identify defective products on assembly lines.</li>
<li>Energy monitoring: detect power surges or unusual consumption.</li>
</ul></li>
<li><p>Medical Applications:</p>
<ul>
<li>Radiology: spot unusual patterns in X-rays, MRIs, CT scans.</li>
<li>Cardiology: detect arrhythmias in ECG signals.</li>
<li>Genomics: flag rare mutations in sequencing data.</li>
<li>Patient monitoring: continuous anomaly alerts in ICU.</li>
</ul></li>
<li><p>Security Applications:</p>
<ul>
<li>Fraud detection: unusual transactions in credit card usage.</li>
<li>Intrusion detection: abnormal network packets or login behavior.</li>
<li>Malware detection: identifying suspicious processes.</li>
<li>Insider threat detection: deviations from typical employee activity.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 37%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Domain</th>
<th>Example Signal</th>
<th>Anomaly Detected</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Industry</td>
<td>Sensor vibration data</td>
<td>Bearing failure prediction</td>
</tr>
<tr class="even">
<td>Medicine</td>
<td>ECG / MRI scans</td>
<td>Cardiac arrhythmia, tumor spotting</td>
</tr>
<tr class="odd">
<td>Security</td>
<td>Transaction logs, traffic</td>
<td>Fraud, intrusion, malware</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Industrial Sensor Anomaly via Autoencoder)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers, models</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: sensor signals</span></span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a>X_normal <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, (<span class="dv">1000</span>, <span class="dv">20</span>))</span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a>X_anomalous <span class="op">=</span> np.random.normal(<span class="dv">5</span>, <span class="dv">1</span>, (<span class="dv">10</span>, <span class="dv">20</span>))  <span class="co"># anomalies</span></span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Autoencoder</span></span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> layers.Input(shape<span class="op">=</span>(<span class="dv">20</span>,))</span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a>encoded <span class="op">=</span> layers.Dense(<span class="dv">8</span>, activation<span class="op">=</span><span class="st">"relu"</span>)(inputs)</span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a>decoded <span class="op">=</span> layers.Dense(<span class="dv">20</span>, activation<span class="op">=</span><span class="st">"linear"</span>)(encoded)</span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a>autoencoder <span class="op">=</span> models.Model(inputs, decoded)</span>
<span id="cb90-14"><a href="#cb90-14" aria-hidden="true" tabindex="-1"></a>autoencoder.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">"adam"</span>, loss<span class="op">=</span><span class="st">"mse"</span>)</span>
<span id="cb90-15"><a href="#cb90-15" aria-hidden="true" tabindex="-1"></a>autoencoder.fit(X_normal, X_normal, epochs<span class="op">=</span><span class="dv">10</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb90-16"><a href="#cb90-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-17"><a href="#cb90-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Reconstruction error as anomaly score</span></span>
<span id="cb90-18"><a href="#cb90-18" aria-hidden="true" tabindex="-1"></a>recon_error <span class="op">=</span> np.mean(np.square(X_anomalous <span class="op">-</span> autoencoder.predict(X_anomalous)), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb90-19"><a href="#cb90-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Anomaly scores:"</span>, recon_error)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-87" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-87">Why It Matters</h4>
<p>These applications show anomaly detection is not theoretical. it’s mission-critical. Missing anomalies can cause equipment failures, misdiagnosed diseases, or massive financial losses. Conversely, too many false alarms can waste time and resources, highlighting the need for balanced detection systems.</p>
</section>
<section id="try-it-yourself-88" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-88">Try It Yourself</h4>
<ol type="1">
<li>Apply anomaly detection to ECG data (e.g., MIT-BIH dataset). Can you detect irregular heartbeats?</li>
<li>Simulate factory sensor data with injected anomalies. Train an autoencoder and test detection accuracy.</li>
<li>Use anomaly detection on credit card transactions (Kaggle dataset). Compare Isolation Forest vs.&nbsp;deep autoencoder.</li>
<li>Run anomaly detection on network traffic logs. Does it catch DoS or brute-force login attempts?</li>
</ol>
</section>
</section>
<section id="challenges-imbalance-concept-drift-explainability" class="level3">
<h3 class="anchored" data-anchor-id="challenges-imbalance-concept-drift-explainability">890. Challenges: Imbalance, Concept Drift, Explainability</h3>
<p>Real-world anomaly detection faces three persistent challenges: class imbalance (anomalies are extremely rare), concept drift (normal behavior changes over time), and explainability (users need to trust why a point is flagged). Addressing these is critical for practical deployment.</p>
<section id="picture-in-your-head-89" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-89">Picture in Your Head</h4>
<p>Think of airport security. Almost every passenger is normal (imbalance). Travel patterns shift over time with new routes or seasons (drift). When a passenger is flagged, security must explain why. otherwise, trust in the system breaks down (explainability).</p>
</section>
<section id="deep-dive-89" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-89">Deep Dive</h4>
<ul>
<li><p>Imbalance:</p>
<ul>
<li>Anomalies often &lt;1% of data.</li>
<li>Naive models can achieve 99% accuracy by labeling everything “normal.”</li>
<li>Solutions: resampling, anomaly score calibration, cost-sensitive learning.</li>
</ul></li>
<li><p>Concept Drift:</p>
<ul>
<li>Distribution of “normal” changes (e.g., new user behavior, updated machinery).</li>
<li>Models trained once may degrade.</li>
<li>Solutions: online learning, sliding windows, adaptive thresholds.</li>
</ul></li>
<li><p>Explainability:</p>
<ul>
<li>Users need interpretable reasons for anomaly alerts.</li>
<li>Black-box models (deep AEs, GANs) make trust difficult.</li>
<li>Solutions: feature attribution (SHAP, LIME), counterfactuals, visualization of latent space.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 19%">
<col style="width: 33%">
<col style="width: 46%">
</colgroup>
<thead>
<tr class="header">
<th>Challenge</th>
<th>Why It Happens</th>
<th>Possible Solutions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Imbalance</td>
<td>Anomalies are rare</td>
<td>Oversampling, cost-sensitive loss</td>
</tr>
<tr class="even">
<td>Concept Drift</td>
<td>Normal evolves over time</td>
<td>Online/continual learning</td>
</tr>
<tr class="odd">
<td>Explainability</td>
<td>Models are complex</td>
<td>Interpretable models, SHAP/LIME</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Handling Concept Drift with Sliding Window)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> deque</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Sliding window for online anomaly detection</span></span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>window_size <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>window <span class="op">=</span> deque(maxlen<span class="op">=</span>window_size)</span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_window(new_point):</span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a>    window.append(new_point)</span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a>    mean <span class="op">=</span> np.mean(window)</span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> np.std(window)</span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">abs</span>(new_point <span class="op">-</span> mean) <span class="op">&gt;</span> <span class="dv">3</span> <span class="op">*</span> std  <span class="co"># anomaly if &gt;3σ</span></span>
<span id="cb91-13"><a href="#cb91-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-14"><a href="#cb91-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Example stream</span></span>
<span id="cb91-15"><a href="#cb91-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> [<span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">9</span>, <span class="dv">12</span>, <span class="dv">50</span>]:  <span class="co"># last point is drift/anomaly</span></span>
<span id="cb91-16"><a href="#cb91-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> update_window(x):</span>
<span id="cb91-17"><a href="#cb91-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Anomaly detected: </span><span class="sc">{</span>x<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-88" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-88">Why It Matters</h4>
<p>Without addressing these challenges, anomaly detectors either miss true anomalies (imbalance), become obsolete (drift), or fail to be trusted (explainability). Tackling them ensures robust, reliable, and human-centered anomaly detection in the wild.</p>
</section>
<section id="try-it-yourself-89" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-89">Try It Yourself</h4>
<ol type="1">
<li>Train an Isolation Forest on imbalanced data (1% anomalies). Measure ROC-AUC vs.&nbsp;PR-AUC. which is more informative?</li>
<li>Simulate concept drift by gradually shifting data mean. Does a static model fail? Try a sliding window approach.</li>
<li>Use SHAP to explain anomaly scores in a trained autoencoder. Which features contributed most?</li>
<li>Test user trust: compare alerts with and without explanations. Do humans prefer interpretable anomaly reports?</li>
</ol>
</section>
</section>
</section>
<section id="chapter-90.-graph-representation-learning" class="level2">
<h2 class="anchored" data-anchor-id="chapter-90.-graph-representation-learning">Chapter 90. Graph representation learning</h2>
<section id="basics-of-graphs-and-graph-data" class="level3">
<h3 class="anchored" data-anchor-id="basics-of-graphs-and-graph-data">891. Basics of Graphs and Graph Data</h3>
<p>Graphs represent data as nodes (entities) and edges (relationships). Unlike tabular or image data, graphs explicitly capture structure, making them powerful for modeling social networks, molecules, knowledge bases, and transportation systems.</p>
<section id="picture-in-your-head-90" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-90">Picture in Your Head</h4>
<p>Think of a subway map: stations are nodes, and tracks are edges. You can study properties of individual stations (degree, centrality), entire lines (paths), or the whole network (connectivity). Graph representation learning generalizes this intuition to all structured data.</p>
</section>
<section id="deep-dive-90" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-90">Deep Dive</h4>
<ul>
<li><p>Graph Components:</p>
<ul>
<li>Nodes (Vertices): represent entities (e.g., people, proteins).</li>
<li>Edges: represent relationships (friendship, interaction).</li>
<li>Attributes: nodes/edges can have features (age, weight, type).</li>
<li>Adjacency Matrix: mathematical representation of connectivity.</li>
</ul></li>
<li><p>Graph Types:</p>
<ul>
<li>Directed vs.&nbsp;Undirected: one-way vs.&nbsp;bidirectional relationships.</li>
<li>Weighted vs.&nbsp;Unweighted: edge weights encode strength/capacity.</li>
<li>Homogeneous vs.&nbsp;Heterogeneous: single vs.&nbsp;multiple types of nodes/edges.</li>
<li>Static vs.&nbsp;Dynamic: fixed vs.&nbsp;time-evolving connections.</li>
</ul></li>
<li><p>Tasks on Graphs:</p>
<ul>
<li>Node-level: classification, regression (predict node labels).</li>
<li>Edge-level: link prediction, anomaly detection.</li>
<li>Graph-level: classification, clustering, generation.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Graph Type</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Social Network</td>
<td>Users = nodes, friendships = edges</td>
</tr>
<tr class="even">
<td>Molecular Graph</td>
<td>Atoms = nodes, bonds = edges</td>
</tr>
<tr class="odd">
<td>Knowledge Graph</td>
<td>Entities = nodes, relations = edges</td>
</tr>
<tr class="even">
<td>Transportation Net</td>
<td>Locations = nodes, roads = edges</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Simple Graph with NetworkX)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create graph</span></span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.Graph()</span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>G.add_nodes_from([<span class="st">"Alice"</span>, <span class="st">"Bob"</span>, <span class="st">"Carol"</span>])</span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>G.add_edges_from([(<span class="st">"Alice"</span>, <span class="st">"Bob"</span>), (<span class="st">"Bob"</span>, <span class="st">"Carol"</span>)])</span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Nodes:"</span>, G.nodes())</span>
<span id="cb92-9"><a href="#cb92-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Edges:"</span>, G.edges())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-89" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-89">Why It Matters</h4>
<p>Graphs are everywhere. from recommendation systems to drug discovery. Understanding their structure is the foundation for graph representation learning, which seeks to embed nodes and graphs into vector spaces for downstream machine learning tasks.</p>
</section>
<section id="try-it-yourself-90" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-90">Try It Yourself</h4>
<ol type="1">
<li>Construct a small friendship network in NetworkX. Visualize connections.</li>
<li>Add edge weights (e.g., frequency of interaction). How does this change analysis?</li>
<li>Create a directed graph (Twitter-like follows). Compare paths vs.&nbsp;undirected.</li>
<li>Compute degree centrality in a toy network. Which node is most connected?</li>
</ol>
</section>
</section>
<section id="node-embeddings-deepwalk-node2vec" class="level3">
<h3 class="anchored" data-anchor-id="node-embeddings-deepwalk-node2vec">892. Node Embeddings: DeepWalk, node2vec</h3>
<p>Node embedding methods map graph nodes into low-dimensional vectors while preserving structural relationships. These embeddings allow traditional ML models to work on graphs for tasks like classification, link prediction, and clustering.</p>
<section id="picture-in-your-head-91" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-91">Picture in Your Head</h4>
<p>Imagine translating a subway map into GPS coordinates. Each station (node) gets coordinates (embedding) such that nearby stations stay close in space, and long connections remain far apart. Now, you can use those coordinates in any standard algorithm.</p>
</section>
<section id="deep-dive-91" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-91">Deep Dive</h4>
<ul>
<li><p>Why Node Embeddings?</p>
<ul>
<li>Graphs are discrete and irregular → hard for standard ML.</li>
<li>Embeddings turn nodes into continuous vectors.</li>
<li>Goal: preserve proximity, neighborhood, or structural roles.</li>
</ul></li>
<li><p>DeepWalk (2014):</p>
<ul>
<li>Treats random walks on graph like sentences in NLP.</li>
<li>Applies skip-gram model (Word2Vec) to learn node embeddings.</li>
<li>Captures local neighborhood similarity.</li>
</ul></li>
<li><p>node2vec (2016):</p>
<ul>
<li><p>Extends DeepWalk with biased random walks.</p></li>
<li><p>Parameters <span class="math inline">\(p, q\)</span> control exploration:</p>
<ul>
<li>BFS-like → capture homophily (similar neighbors).</li>
<li>DFS-like → capture structural roles.</li>
</ul></li>
<li><p>More flexible, balances local vs.&nbsp;global structure.</p></li>
</ul></li>
<li><p>Applications:</p>
<ul>
<li>Node classification (e.g., predict user interests in social network).</li>
<li>Link prediction (e.g., recommend new friends).</li>
<li>Graph clustering (e.g., detect communities).</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 46%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Core Idea</th>
<th>Strengths</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>DeepWalk</td>
<td>Random walks + skip-gram</td>
<td>Simple, effective</td>
</tr>
<tr class="even">
<td>node2vec</td>
<td>Biased walks (BFS/DFS balance)</td>
<td>More expressive embeddings</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, node2vec with NetworkX + library)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> node2vec <span class="im">import</span> Node2Vec</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Build graph</span></span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.karate_club_graph()</span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Train node2vec</span></span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a>node2vec <span class="op">=</span> Node2Vec(G, dimensions<span class="op">=</span><span class="dv">16</span>, walk_length<span class="op">=</span><span class="dv">10</span>, num_walks<span class="op">=</span><span class="dv">100</span>, workers<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> node2vec.fit(window<span class="op">=</span><span class="dv">5</span>, min_count<span class="op">=</span><span class="dv">1</span>, batch_words<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Get embedding for node 0</span></span>
<span id="cb93-12"><a href="#cb93-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Embedding for node 0:"</span>, model.wv[<span class="st">'0'</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-90" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-90">Why It Matters</h4>
<p>Node embeddings bridged graph theory and machine learning, enabling the use of word embedding techniques for networks. This breakthrough paved the way for modern graph neural networks (GNNs) and large-scale graph representation learning.</p>
</section>
<section id="try-it-yourself-91" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-91">Try It Yourself</h4>
<ol type="1">
<li>Run DeepWalk on the Karate Club graph. Visualize embeddings with t-SNE. Do communities separate?</li>
<li>Experiment with node2vec’s <span class="math inline">\(p, q\)</span> parameters. How do embeddings change?</li>
<li>Use embeddings for link prediction: train logistic regression on dot products of node pairs.</li>
<li>Apply embeddings to a real dataset (e.g., citation network). Can you classify papers by field?</li>
</ol>
</section>
</section>
<section id="graph-neural-networks-gcn-gat-graphsage" class="level3">
<h3 class="anchored" data-anchor-id="graph-neural-networks-gcn-gat-graphsage">893. Graph Neural Networks (GCN, GAT, GraphSAGE)</h3>
<p>Graph Neural Networks (GNNs) extend deep learning to graphs by enabling message passing between nodes. Each node updates its embedding by aggregating features from its neighbors, allowing the model to capture both attributes and topology.</p>
<section id="picture-in-your-head-92" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-92">Picture in Your Head</h4>
<p>Think of a group project. Each student (node) has their own notes (features). Before writing the final report, they share and combine insights with their neighbors. After several rounds, every student has a richer understanding. That’s how GNNs update node representations.</p>
</section>
<section id="deep-dive-92" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-92">Deep Dive</h4>
<ul>
<li><p>Graph Convolutional Networks (GCN):</p>
<ul>
<li><p>Generalize convolution from grids (images) to graphs.</p></li>
<li><p>Each node embedding = normalized sum of neighbors’ features.</p></li>
<li><p>Formula:</p>
<p><span class="math display">\[
H^{(l+1)} = \sigma(\tilde{D}^{-1/2}\tilde{A}\tilde{D}^{-1/2} H^{(l)} W^{(l)})
\]</span></p></li>
</ul></li>
<li><p>Graph Attention Networks (GAT):</p>
<ul>
<li>Use attention to weight neighbors differently.</li>
<li>Learn which neighbors are more important.</li>
<li>Improves flexibility compared to uniform aggregation.</li>
</ul></li>
<li><p>GraphSAGE:</p>
<ul>
<li>Scalable inductive method (can handle unseen nodes).</li>
<li>Samples neighbors and aggregates via mean, pooling, or LSTM.</li>
<li>Designed for very large graphs.</li>
</ul></li>
<li><p>Applications:</p>
<ul>
<li>Node classification (e.g., social network profiles).</li>
<li>Link prediction (recommending new connections).</li>
<li>Graph-level classification (molecules, documents).</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Model</th>
<th>Aggregation Style</th>
<th>Key Advantage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>GCN</td>
<td>Normalized averaging</td>
<td>Simplicity, strong baseline</td>
</tr>
<tr class="even">
<td>GAT</td>
<td>Attention-weighted sum</td>
<td>Learns importance of neighbors</td>
</tr>
<tr class="odd">
<td>GraphSAGE</td>
<td>Sampled neighborhood</td>
<td>Scalable, inductive learning</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (PyTorch Geometric, GCN Layer)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch_geometric.nn <span class="im">import</span> GCNConv</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GCN(torch.nn.Module):</span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_channels, hidden_channels, out_channels):</span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> GCNConv(in_channels, hidden_channels)</span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> GCNConv(hidden_channels, out_channels)</span>
<span id="cb94-10"><a href="#cb94-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-11"><a href="#cb94-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, edge_index):</span>
<span id="cb94-12"><a href="#cb94-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(<span class="va">self</span>.conv1(x, edge_index))</span>
<span id="cb94-13"><a href="#cb94-13" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.conv2(x, edge_index)</span>
<span id="cb94-14"><a href="#cb94-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-91" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-91">Why It Matters</h4>
<p>GNNs revolutionized graph learning by unifying feature learning and structure learning. They power applications from recommendation systems (Pinterest, TikTok) to drug discovery (molecular property prediction) and are the backbone of modern graph AI.</p>
</section>
<section id="try-it-yourself-92" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-92">Try It Yourself</h4>
<ol type="1">
<li>Train a GCN on the Cora citation dataset. Can it classify papers by topic?</li>
<li>Compare GCN vs.&nbsp;GAT embeddings. Does attention improve accuracy?</li>
<li>Use GraphSAGE on a large social network. Can it generalize to unseen users?</li>
<li>Visualize learned embeddings with t-SNE. Do clusters align with communities?</li>
</ol>
</section>
</section>
<section id="message-passing-and-aggregation" class="level3">
<h3 class="anchored" data-anchor-id="message-passing-and-aggregation">894. Message Passing and Aggregation</h3>
<p>Message Passing is the core mechanism behind most Graph Neural Networks (GNNs). Each node updates its representation by collecting messages from its neighbors and combining them through an aggregation function. Repeating this over multiple layers captures multi-hop dependencies.</p>
<section id="picture-in-your-head-93" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-93">Picture in Your Head</h4>
<p>Think of a town hall meeting. Every person (node) listens to their neighbors (incoming messages), summarizes the input (aggregation), and updates their opinion (new embedding). After several rounds, information spreads through the entire community.</p>
</section>
<section id="deep-dive-93" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-93">Deep Dive</h4>
<ul>
<li><p>General Message Passing Framework:</p>
<ul>
<li><p>At each layer <span class="math inline">\(l\)</span>:</p>
<p><span class="math display">\[
h_v^{(l+1)} = \text{UPDATE}\Big(h_v^{(l)}, \text{AGGREGATE}(\{m_{u \to v}^{(l)} | u \in \mathcal{N}(v)\})\Big)
\]</span></p></li>
<li><p><span class="math inline">\(m_{u \to v}\)</span>: message from neighbor <span class="math inline">\(u\)</span>.</p></li>
<li><p>AGGREGATE: sum, mean, max, attention, or neural function.</p></li>
<li><p>UPDATE: combines old and new info (e.g., MLP).</p></li>
</ul></li>
<li><p>Aggregation Strategies:</p>
<ul>
<li>Sum: stable, permutation-invariant.</li>
<li>Mean: smooths representation.</li>
<li>Max pooling: highlights strongest signal.</li>
<li>Attention (GAT): weighted combination, learns importance.</li>
</ul></li>
<li><p>Depth vs.&nbsp;Over-Smoothing:</p>
<ul>
<li>Too many layers → all nodes converge to similar embeddings.</li>
<li>Solutions: residual connections, normalization, jumping knowledge.</li>
</ul></li>
<li><p>Expressive Power:</p>
<ul>
<li>Related to the Weisfeiler-Lehman (WL) test for graph isomorphism.</li>
<li>More expressive aggregators → stronger ability to distinguish graph structures.</li>
</ul></li>
</ul>
<!--
| Aggregator | Formula                | Strengths                    |             |                                |
| ---------- | ---------------------- | ---------------------------- | ----------- | ------------------------------ |
| Sum        | $\sum h_u$             | Strong discriminative power  |             |                                |
| Mean       | (\frac{1}{             | \mathcal{N}(v)               | }\sum h\_u) | Stable, smooth representations |
| Max Pool   | $\max h_u$             | Highlights dominant features |             |                                |
| Attention  | $\sum \alpha_{uv} h_u$ | Learns neighbor importance   |             |                                |
-->
<p>Tiny Code Recipe (PyTorch, Mean Aggregation Example)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Node features (3 nodes, 2-dim features)</span></span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([[<span class="fl">1.</span>, <span class="fl">0.</span>],</span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a>                  [<span class="fl">0.</span>, <span class="fl">1.</span>],</span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a>                  [<span class="fl">1.</span>, <span class="fl">1.</span>]])</span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjacency: node 0 connected to 1 &amp; 2</span></span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a>neighbors <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>]</span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Aggregate neighbor features (mean)</span></span>
<span id="cb95-11"><a href="#cb95-11" aria-hidden="true" tabindex="-1"></a>agg <span class="op">=</span> x[neighbors].mean(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb95-12"><a href="#cb95-12" aria-hidden="true" tabindex="-1"></a>new_repr <span class="op">=</span> x[<span class="dv">0</span>] <span class="op">+</span> agg</span>
<span id="cb95-13"><a href="#cb95-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Updated representation for node 0:"</span>, new_repr)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-92" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-92">Why It Matters</h4>
<p>Message passing unifies diverse GNN architectures under a single principle. By designing better aggregation and update functions, researchers create models that scale from molecules (drug discovery) to knowledge graphs (recommendation).</p>
</section>
<section id="try-it-yourself-93" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-93">Try It Yourself</h4>
<ol type="1">
<li>Implement sum, mean, and max aggregation on a toy graph. Compare results.</li>
<li>Visualize how increasing GNN layers spreads information across hops.</li>
<li>Train a GAT model with attention-based aggregation. Does it outperform mean?</li>
<li>Test over-smoothing by stacking many GCN layers. Do node embeddings collapse?</li>
</ol>
</section>
</section>
<section id="graph-autoencoders-and-variants" class="level3">
<h3 class="anchored" data-anchor-id="graph-autoencoders-and-variants">895. Graph Autoencoders and Variants</h3>
<p>Graph Autoencoders (GAEs) extend the autoencoder idea to graphs, learning low-dimensional node embeddings by reconstructing graph structure or attributes. Variants like Variational Graph Autoencoders (VGAEs) add probabilistic modeling for generative tasks.</p>
<section id="picture-in-your-head-94" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-94">Picture in Your Head</h4>
<p>Think of compressing a subway map into a pocket-sized sketch. The sketch (embedding) keeps enough structure so you can still tell which stations connect. GAEs learn such compressed sketches automatically.</p>
</section>
<section id="deep-dive-94" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-94">Deep Dive</h4>
<ul>
<li><p>Graph Autoencoder (GAE):</p>
<ul>
<li>Encoder: GCN or similar layers produce node embeddings.</li>
<li>Decoder: reconstruct adjacency (edges) from embeddings (e.g., dot product).</li>
<li>Objective: minimize reconstruction loss.</li>
</ul></li>
<li><p>Variational Graph Autoencoder (VGAE):</p>
<ul>
<li>Adds variational inference → embeddings are distributions, not points.</li>
<li>Enables sampling, uncertainty estimation, and generative graph tasks.</li>
</ul></li>
<li><p>Adversarial Graph Autoencoders (ARGA):</p>
<ul>
<li>Use adversarial regularization to align latent space with prior distribution.</li>
</ul></li>
<li><p>Applications:</p>
<ul>
<li>Link prediction (missing edges).</li>
<li>Node classification (semi-supervised).</li>
<li>Graph generation (drug molecules, knowledge graphs).</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Variant</th>
<th>Encoder</th>
<th>Decoder</th>
<th>Key Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>GAE</td>
<td>GCN layers</td>
<td>Dot-product</td>
<td>Link prediction</td>
</tr>
<tr class="even">
<td>VGAE</td>
<td>Probabilistic</td>
<td>Dot-product</td>
<td>Generative modeling</td>
</tr>
<tr class="odd">
<td>ARGA</td>
<td>GCN + adversary</td>
<td>Dot-product</td>
<td>Regularized embeddings</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (PyTorch Geometric, VGAE Sketch)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch_geometric.nn <span class="im">import</span> VGAE, GCNConv</span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-5"><a href="#cb96-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Encoder(torch.nn.Module):</span>
<span id="cb96-6"><a href="#cb96-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_channels, out_channels):</span>
<span id="cb96-7"><a href="#cb96-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb96-8"><a href="#cb96-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> GCNConv(in_channels, <span class="dv">2</span><span class="op">*</span>out_channels)</span>
<span id="cb96-9"><a href="#cb96-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-10"><a href="#cb96-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, edge_index):</span>
<span id="cb96-11"><a href="#cb96-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.conv1(x, edge_index)</span>
<span id="cb96-12"><a href="#cb96-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-13"><a href="#cb96-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: VGAE setup</span></span>
<span id="cb96-14"><a href="#cb96-14" aria-hidden="true" tabindex="-1"></a>in_channels, out_channels <span class="op">=</span> <span class="dv">16</span>, <span class="dv">8</span></span>
<span id="cb96-15"><a href="#cb96-15" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> Encoder(in_channels, out_channels)</span>
<span id="cb96-16"><a href="#cb96-16" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> VGAE(encoder)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-93" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-93">Why It Matters</h4>
<p>GAEs unify representation learning and generative modeling on graphs. They power practical tasks like recommendation (predicting friendships, products) and drug discovery (predicting molecule bonds), bridging unsupervised and generative AI on structured data.</p>
</section>
<section id="try-it-yourself-94" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-94">Try It Yourself</h4>
<ol type="1">
<li>Train a GAE on citation networks. Use embeddings for link prediction.</li>
<li>Compare GAE vs.&nbsp;VGAE on the same dataset. Which produces more robust embeddings?</li>
<li>Use VGAE to sample new node embeddings. Can they generate plausible new edges?</li>
<li>Visualize GAE embeddings with t-SNE. Do communities cluster together?</li>
</ol>
</section>
</section>
<section id="heterogeneous-graphs-and-knowledge-graph-embeddings" class="level3">
<h3 class="anchored" data-anchor-id="heterogeneous-graphs-and-knowledge-graph-embeddings">896. Heterogeneous Graphs and Knowledge Graph Embeddings</h3>
<p>Heterogeneous graphs contain multiple types of nodes and edges, unlike homogeneous graphs where all nodes/edges are the same. Knowledge Graph Embeddings (KGE) are specialized techniques to represent these heterogeneous relations in vector space for reasoning and prediction.</p>
<section id="picture-in-your-head-95" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-95">Picture in Your Head</h4>
<p>Think of an academic network. Authors write papers, papers cite other papers, and authors belong to institutions. This network mixes node types (authors, papers, institutions) and edge types (writes, cites, affiliated_with). A simple graph model can’t capture these nuances. heterogeneous methods are needed.</p>
</section>
<section id="deep-dive-95" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-95">Deep Dive</h4>
<ul>
<li><p>Heterogeneous Graphs:</p>
<ul>
<li>Nodes: multiple entity types.</li>
<li>Edges: multiple relation types.</li>
<li>Require type-aware aggregation and reasoning.</li>
</ul></li>
<li><p>Knowledge Graph Embeddings (KGE):</p>
<ul>
<li>Aim: represent entities and relations as vectors.</li>
<li>A triple <span class="math inline">\((h, r, t)\)</span> (head, relation, tail) should score high if valid.</li>
</ul></li>
<li><p>Popular KGE Models:</p>
<ul>
<li><p>TransE:</p>
<ul>
<li>Relation as translation: <span class="math inline">\(h + r \approx t\)</span>.</li>
<li>Simple, efficient, but struggles with complex relations.</li>
</ul></li>
<li><p>DistMult:</p>
<ul>
<li>Bilinear scoring: <span class="math inline">\(f(h, r, t) = h^T R t\)</span>.</li>
<li>Handles symmetry but not anti-symmetry.</li>
</ul></li>
<li><p>ComplEx:</p>
<ul>
<li>Uses complex-valued embeddings to model asymmetric relations.</li>
</ul></li>
<li><p>RotatE:</p>
<ul>
<li>Relations as rotations in complex space.</li>
</ul></li>
</ul></li>
<li><p>Applications:</p>
<ul>
<li>Knowledge graph completion (predict missing links).</li>
<li>Question answering over knowledge bases.</li>
<li>Recommendation systems.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 35%">
<col style="width: 25%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>Core Idea</th>
<th>Handles Symmetry?</th>
<th>Handles Asymmetry?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>TransE</td>
<td>Relations = translations</td>
<td>❌</td>
<td>Limited</td>
</tr>
<tr class="even">
<td>DistMult</td>
<td>Bilinear scoring</td>
<td>✅</td>
<td>❌</td>
</tr>
<tr class="odd">
<td>ComplEx</td>
<td>Complex embeddings</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr class="even">
<td>RotatE</td>
<td>Relations = rotations</td>
<td>✅</td>
<td>✅</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (PyKEEN, TransE Example)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pykeen.pipeline <span class="im">import</span> pipeline</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> pipeline(</span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a>    dataset<span class="op">=</span><span class="st">'Nations'</span>,</span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">'TransE'</span>,</span>
<span id="cb97-6"><a href="#cb97-6" aria-hidden="true" tabindex="-1"></a>    training_kwargs<span class="op">=</span><span class="bu">dict</span>(num_epochs<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb97-7"><a href="#cb97-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb97-8"><a href="#cb97-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-9"><a href="#cb97-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict missing links</span></span>
<span id="cb97-10"><a href="#cb97-10" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> result.model.predict_tails(<span class="st">'USA'</span>, <span class="st">'treaties'</span>)</span>
<span id="cb97-11"><a href="#cb97-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(predictions[:<span class="dv">5</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-94" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-94">Why It Matters</h4>
<p>Heterogeneous graphs and KGEs power some of the largest AI systems today, including Google Knowledge Graph, recommender systems, and biomedical discovery engines. They enable reasoning beyond homogeneous networks, capturing the richness of real-world relationships.</p>
</section>
<section id="try-it-yourself-95" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-95">Try It Yourself</h4>
<ol type="1">
<li>Train TransE on a small knowledge graph (e.g., Nations dataset). Predict missing links.</li>
<li>Compare DistMult vs.&nbsp;ComplEx on the same dataset. Which handles asymmetric relations better?</li>
<li>Build a heterogeneous academic graph (authors, papers, institutions). Run KGE for link prediction.</li>
<li>Apply RotatE on a recommendation dataset. Can it model user–item interactions better?</li>
</ol>
</section>
</section>
<section id="temporal-and-dynamic-graph-models" class="level3">
<h3 class="anchored" data-anchor-id="temporal-and-dynamic-graph-models">897. Temporal and Dynamic Graph Models</h3>
<p>Many real-world graphs are dynamic, evolving over time with new nodes, edges, and attributes. Temporal graph models extend graph learning by capturing time-dependent structure and evolution, enabling predictions about future links, events, or behaviors.</p>
<section id="picture-in-your-head-96" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-96">Picture in Your Head</h4>
<p>Think of a social network. Friendships form and dissolve, people join or leave groups, and interactions change daily. A static snapshot misses these shifts, but temporal graph models act like a time-lapse camera, tracking how the network evolves.</p>
</section>
<section id="deep-dive-96" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-96">Deep Dive</h4>
<ul>
<li><p>Types of Temporal Graphs:</p>
<ul>
<li>Discrete-time graphs: represented as snapshots at intervals.</li>
<li>Continuous-time graphs: events happen at irregular timestamps.</li>
<li>Attributed dynamic graphs: node/edge features also evolve.</li>
</ul></li>
<li><p>Modeling Approaches:</p>
<ul>
<li>Snapshot-based GNNs: train GNN on each snapshot; capture evolution with RNNs or temporal convolutions.</li>
<li>Temporal Point Process Models: model event occurrence probability over time.</li>
<li>Continuous-time Dynamic GNNs (e.g., TGAT, TGN): directly embed temporal information into GNNs.</li>
</ul></li>
<li><p>Key Models:</p>
<ul>
<li>TGAT (Temporal Graph Attention): time-aware attention mechanism.</li>
<li>TGN (Temporal Graph Networks): maintains memory for nodes that updates with events.</li>
<li>DyRep: models both association (links) and communication (messages) dynamics.</li>
</ul></li>
<li><p>Applications:</p>
<ul>
<li>Fraud detection in financial transactions.</li>
<li>Predicting future social connections.</li>
<li>Temporal knowledge graph completion.</li>
<li>Recommender systems with evolving preferences.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Model Type</th>
<th>Example</th>
<th>Key Idea</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Snapshot-based</td>
<td>DynGNN</td>
<td>RNN/Conv across snapshots</td>
</tr>
<tr class="even">
<td>Temporal attention</td>
<td>TGAT</td>
<td>Time-aware message passing</td>
</tr>
<tr class="odd">
<td>Memory-based</td>
<td>TGN</td>
<td>Node memory updated by events</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, PyTorch Geometric TGAT Layer)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch_geometric.nn <span class="im">import</span> TGNMemory</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: temporal memory for nodes</span></span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a>memory <span class="op">=</span> TGNMemory(</span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>    num_nodes<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a>    raw_message_dim<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a>    memory_dim<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb98-8"><a href="#cb98-8" aria-hidden="true" tabindex="-1"></a>    time_dim<span class="op">=</span><span class="dv">16</span></span>
<span id="cb98-9"><a href="#cb98-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb98-10"><a href="#cb98-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-11"><a href="#cb98-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Each new event updates node memory</span></span>
<span id="cb98-12"><a href="#cb98-12" aria-hidden="true" tabindex="-1"></a>src, dst, t <span class="op">=</span> <span class="dv">1</span>, <span class="dv">2</span>, <span class="fl">0.5</span></span>
<span id="cb98-13"><a href="#cb98-13" aria-hidden="true" tabindex="-1"></a>message <span class="op">=</span> memory.get_memory([src, dst])</span>
<span id="cb98-14"><a href="#cb98-14" aria-hidden="true" tabindex="-1"></a>memory.update_state([src, dst], message, t)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-95" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-95">Why It Matters</h4>
<p>Most graphs in reality are not static. Capturing temporal dynamics is essential for real-time systems like fraud detection, recommender systems, and epidemic modeling. Temporal GNNs extend the reach of graph learning to living, evolving networks.</p>
</section>
<section id="try-it-yourself-96" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-96">Try It Yourself</h4>
<ol type="1">
<li>Create snapshots of a citation network over decades. Predict future collaborations.</li>
<li>Train TGAT on social media interactions. Can it predict who will interact next?</li>
<li>Compare static GCN vs.&nbsp;dynamic TGN on transaction data. Which detects fraud better?</li>
<li>Build a temporal knowledge graph (e.g., events dataset). Use temporal embeddings to forecast missing links.</li>
</ol>
</section>
</section>
<section id="evaluation-of-graph-representations" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-of-graph-representations">898. Evaluation of Graph Representations</h3>
<p>Graph representation learning methods are evaluated by how well the learned embeddings support downstream tasks such as classification, link prediction, clustering, and visualization. Since graphs are diverse, multiple benchmarks and metrics are used to assess quality.</p>
<section id="picture-in-your-head-97" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-97">Picture in Your Head</h4>
<p>Think of learning a new shorthand. The real test isn’t how pretty the symbols look, but whether someone can read them to write essays, solve problems, or explain concepts. Similarly, graph embeddings must be judged by how useful they are in real tasks.</p>
</section>
<section id="deep-dive-97" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-97">Deep Dive</h4>
<ul>
<li><p>Node-Level Evaluation:</p>
<ul>
<li>Classification: train a simple classifier on node embeddings → predict node labels (e.g., communities, roles).</li>
<li>Link Prediction: measure accuracy in predicting missing or future edges.</li>
<li>Clustering: evaluate modularity or community detection quality.</li>
</ul></li>
<li><p>Graph-Level Evaluation:</p>
<ul>
<li>Classification: whole-graph embeddings → predict molecule property or document category.</li>
<li>Similarity Search: compare embedding distances between graphs.</li>
</ul></li>
<li><p>Unsupervised Metrics:</p>
<ul>
<li>Reconstruction Loss: how well embeddings reconstruct adjacency.</li>
<li>Graph statistics preservation: degree distribution, clustering coefficient.</li>
</ul></li>
<li><p>Common Benchmarks:</p>
<ul>
<li>Citation networks (Cora, Citeseer, Pubmed).</li>
<li>Social graphs (Reddit, BlogCatalog).</li>
<li>Molecular datasets (MUTAG, ZINC).</li>
<li>Knowledge graphs (FB15k, WN18).</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Evaluation Type</th>
<th>Example Task</th>
<th>Metric</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Node-level</td>
<td>Node classification</td>
<td>Accuracy, F1</td>
</tr>
<tr class="even">
<td>Edge-level</td>
<td>Link prediction</td>
<td>ROC-AUC, PR-AUC</td>
</tr>
<tr class="odd">
<td>Graph-level</td>
<td>Molecule classification</td>
<td>Accuracy, ROC-AUC</td>
</tr>
<tr class="even">
<td>Unsupervised</td>
<td>Adjacency reconstruction</td>
<td>MSE, likelihood</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Link Prediction with Dot Product)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Node embeddings</span></span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> torch.randn(<span class="dv">5</span>, <span class="dv">16</span>)  <span class="co"># 5 nodes, 16-dim</span></span>
<span id="cb99-6"><a href="#cb99-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-7"><a href="#cb99-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Example edge (u=0, v=3)</span></span>
<span id="cb99-8"><a href="#cb99-8" aria-hidden="true" tabindex="-1"></a>u, v <span class="op">=</span> <span class="dv">0</span>, <span class="dv">3</span></span>
<span id="cb99-9"><a href="#cb99-9" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> torch.sigmoid((z[u] <span class="op">*</span> z[v]).<span class="bu">sum</span>())</span>
<span id="cb99-10"><a href="#cb99-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Link score (0-3):"</span>, score.item())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-96" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-96">Why It Matters</h4>
<p>Without robust evaluation, embeddings risk being abstract vectors without utility. Systematic evaluation ensures representations are generalizable, task-relevant, and trustworthy, enabling deployment in domains like drug discovery, fraud detection, and recommendation.</p>
</section>
<section id="try-it-yourself-97" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-97">Try It Yourself</h4>
<ol type="1">
<li>Train node2vec on Cora. Evaluate embeddings with logistic regression for node classification.</li>
<li>Perform link prediction on citation networks using dot-product embeddings. Compare ROC-AUC across methods.</li>
<li>Test embeddings on clustering. Do they reveal community structure?</li>
<li>Evaluate GAE embeddings on MUTAG. Can they predict molecule properties better than hand-crafted features?</li>
</ol>
</section>
</section>
<section id="applications-in-social-biological-and-knowledge-graphs" class="level3">
<h3 class="anchored" data-anchor-id="applications-in-social-biological-and-knowledge-graphs">899. Applications in Social, Biological, and Knowledge Graphs</h3>
<p>Graph representation learning has widespread applications across social networks, biological systems, and knowledge graphs, where structure is as important as individual data points. Each domain uses graph embeddings for tasks like prediction, discovery, and reasoning.</p>
<section id="picture-in-your-head-98" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-98">Picture in Your Head</h4>
<p>Think of three maps: a Facebook friends map (social), a protein interaction map (biological), and a knowledge map of facts (knowledge graph). All three are networks of entities and relationships, and graph learning provides a universal toolkit to analyze them.</p>
</section>
<section id="deep-dive-98" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-98">Deep Dive</h4>
<ul>
<li><p>Social Graphs:</p>
<ul>
<li>Node classification: infer user interests, demographics.</li>
<li>Link prediction: friend recommendations.</li>
<li>Community detection: discover groups or influencers.</li>
<li>Example: Facebook, Twitter, LinkedIn.</li>
</ul></li>
<li><p>Biological Graphs:</p>
<ul>
<li>Protein–protein interaction networks.</li>
<li>Drug discovery: molecules as graphs of atoms and bonds.</li>
<li>Gene regulatory networks: predict novel interactions.</li>
<li>Example: AlphaFold uses graph ideas for protein folding.</li>
</ul></li>
<li><p>Knowledge Graphs:</p>
<ul>
<li>Entities = nodes, relations = edges.</li>
<li>Applications: search engines (Google Knowledge Graph), question answering, recommendation.</li>
<li>Tasks: knowledge graph completion, reasoning over relations.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Domain</th>
<th>Task Example</th>
<th>Benefit of Graph Learning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Social</td>
<td>Friend recommendation</td>
<td>Better personalization</td>
</tr>
<tr class="even">
<td>Biological</td>
<td>Drug discovery</td>
<td>Predict effective compounds</td>
</tr>
<tr class="odd">
<td>Knowledge</td>
<td>Question answering</td>
<td>Capture structured semantics</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Knowledge Graph Embedding with PyKEEN)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pykeen.pipeline <span class="im">import</span> pipeline</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> pipeline(</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>    dataset<span class="op">=</span><span class="st">"WN18RR"</span>,</span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">"ComplEx"</span>,</span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a>    training_kwargs<span class="op">=</span><span class="bu">dict</span>(num_epochs<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb100-7"><a href="#cb100-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb100-8"><a href="#cb100-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-9"><a href="#cb100-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict missing link</span></span>
<span id="cb100-10"><a href="#cb100-10" aria-hidden="true" tabindex="-1"></a>pred <span class="op">=</span> result.model.predict_tails(<span class="st">"dog"</span>, <span class="st">"is_a"</span>)</span>
<span id="cb100-11"><a href="#cb100-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pred[:<span class="dv">5</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-97" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-97">Why It Matters</h4>
<p>These applications show that graph learning is not niche but central to modern AI. From recommending friends, to curing diseases, to powering intelligent assistants, graph embeddings bring structure-aware intelligence into everyday technologies.</p>
</section>
<section id="try-it-yourself-98" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-98">Try It Yourself</h4>
<ol type="1">
<li>Build a small social network in NetworkX. Run node2vec and visualize communities.</li>
<li>Represent molecules as graphs. Train a GCN to classify solubility or toxicity.</li>
<li>Train TransE on a mini knowledge graph (e.g., family relations). Predict missing links.</li>
<li>Compare embeddings from social vs.&nbsp;biological vs.&nbsp;knowledge graphs. Do they share structural properties?</li>
</ol>
</section>
</section>
<section id="open-challenges-and-future-directions-in-graph-learning" class="level3">
<h3 class="anchored" data-anchor-id="open-challenges-and-future-directions-in-graph-learning">900. Open Challenges and Future Directions in Graph Learning</h3>
<p>Despite rapid progress, graph representation learning faces open challenges: scalability to massive graphs, dynamic and heterogeneous structures, interpretability, and integration with foundation models. Future directions aim to make graph learning more general, efficient, and explainable.</p>
<section id="picture-in-your-head-99" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-99">Picture in Your Head</h4>
<p>Imagine trying to map not just one subway system, but every city’s transport network worldwide. all evolving daily, with overlapping routes and new stations. Current methods struggle with this complexity; future graph learning seeks to handle it seamlessly.</p>
</section>
<section id="deep-dive-99" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-99">Deep Dive</h4>
<ul>
<li><p>Scalability:</p>
<ul>
<li>Billion-scale graphs (e.g., social networks, web graphs) exceed GPU memory.</li>
<li>Future work: distributed training, graph sampling, sparsity-aware models.</li>
</ul></li>
<li><p>Dynamic Graphs:</p>
<ul>
<li>Capturing evolving relationships remains hard.</li>
<li>Temporal GNNs (TGN, TGAT) are promising but still limited in long-term memory.</li>
</ul></li>
<li><p>Heterogeneity:</p>
<ul>
<li>Real-world graphs combine multiple node and edge types.</li>
<li>Challenge: unify heterogeneous and multimodal information.</li>
</ul></li>
<li><p>Expressivity vs.&nbsp;Efficiency:</p>
<ul>
<li>Many GNNs collapse under depth (over-smoothing).</li>
<li>Need architectures balancing power and scalability.</li>
</ul></li>
<li><p>Interpretability:</p>
<ul>
<li>Users need explanations: which neighbors or structures drive predictions?</li>
<li>Future: built-in explainability via attention, counterfactual reasoning.</li>
</ul></li>
<li><p>Foundation Models for Graphs:</p>
<ul>
<li>Pretraining GNNs on large heterogeneous datasets, similar to LLMs.</li>
<li>Integration with text, vision, and multimodal models.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 22%">
<col style="width: 40%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Challenge</th>
<th>Current Limitation</th>
<th>Future Direction</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Scalability</td>
<td>GPU/memory bottlenecks</td>
<td>Distributed + sampling</td>
</tr>
<tr class="even">
<td>Dynamics</td>
<td>Limited temporal memory</td>
<td>Continuous-time reasoning</td>
</tr>
<tr class="odd">
<td>Heterogeneity</td>
<td>Fragmented modeling</td>
<td>Unified multimodal GNNs</td>
</tr>
<tr class="even">
<td>Interpretability</td>
<td>Black-box predictions</td>
<td>Explainable GNN frameworks</td>
</tr>
<tr class="odd">
<td>Foundation Models</td>
<td>No universal pretrained graphs</td>
<td>Graph Transformers, GraphGPT</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, Graph Sampling Sketch)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Random node sampling for large graphs</span></span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_subgraph(G, k<span class="op">=</span><span class="dv">50</span>):</span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a>    nodes <span class="op">=</span> random.sample(G.nodes(), k)</span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> G.subgraph(nodes)</span>
<span id="cb101-8"><a href="#cb101-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-9"><a href="#cb101-9" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.barabasi_albert_graph(<span class="dv">1000</span>, <span class="dv">5</span>)</span>
<span id="cb101-10"><a href="#cb101-10" aria-hidden="true" tabindex="-1"></a>subG <span class="op">=</span> sample_subgraph(G, <span class="dv">50</span>)</span>
<span id="cb101-11"><a href="#cb101-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sampled subgraph size:"</span>, subG.number_of_nodes())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-98" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-98">Why It Matters</h4>
<p>Open challenges highlight that graph learning is still in its early days compared to NLP and vision. Addressing scalability, dynamics, and interpretability will unlock breakthroughs in biology, knowledge systems, finance, and multimodal AI. Graph foundation models may become as central as LLMs.</p>
</section>
<section id="try-it-yourself-99" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-99">Try It Yourself</h4>
<ol type="1">
<li>Experiment with GNNs on large graphs (e.g., Reddit dataset). Test scaling limits.</li>
<li>Implement a temporal GNN on transaction data. Can it forecast fraud better than static models?</li>
<li>Use explainability tools (e.g., GNNExplainer) to interpret a GNN’s prediction. Do results make sense?</li>
<li>Brainstorm: how would you pretrain a foundation GNN across domains (molecules, social, knowledge graphs)?</li>
</ol>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../books/en-US/volume_8.html" class="pagination-link" aria-label="Volume 8. Supervised Learning Systems">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Volume 8. Supervised Learning Systems</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->




</body></html>