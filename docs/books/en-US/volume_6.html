<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.23">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Volume 6. Probabilistic Modeling and Inference – The Little Book of Artificial Intelligence</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../books/en-US/volume_7.html" rel="next">
<link href="../../books/en-US/volume_5.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-1fe81d0376b2c50856e68e651e390326.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-27c261d06b905028a18691de25d09dde.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../books/en-US/volume_6.html"><span class="chapter-title">Volume 6. Probabilistic Modeling and Inference</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../../index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">The Little Book of Artificial Intelligence</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Contents</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../books/en-US/volume_1.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Volume 1. First principles of Artificial Intelligence</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../books/en-US/volume_2.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Volume 2. Mathematicial Foundations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../books/en-US/volume_3.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Volume 3. Data and Representation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../books/en-US/volume_4.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Volume 4. Search and Planning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../books/en-US/volume_5.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Volume 5. Logic and Knowledge</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../books/en-US/volume_6.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Volume 6. Probabilistic Modeling and Inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../books/en-US/volume_7.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Volume 7. Machine Learning Theory and Practice</span></a>
  </div>
</li>
    </ul>
    </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#chapter-51.-bayesian-inference-basics" id="toc-chapter-51.-bayesian-inference-basics" class="nav-link active" data-scroll-target="#chapter-51.-bayesian-inference-basics">Chapter 51. Bayesian Inference Basics</a>
  <ul class="collapse">
  <li><a href="#probability-as-belief-vs.-frequency" id="toc-probability-as-belief-vs.-frequency" class="nav-link" data-scroll-target="#probability-as-belief-vs.-frequency">501. Probability as Belief vs.&nbsp;Frequency</a></li>
  <li><a href="#bayes-theorem-and-updating" id="toc-bayes-theorem-and-updating" class="nav-link" data-scroll-target="#bayes-theorem-and-updating">502. Bayes’ Theorem and Updating</a></li>
  <li><a href="#priors-informative-vs.-noninformative" id="toc-priors-informative-vs.-noninformative" class="nav-link" data-scroll-target="#priors-informative-vs.-noninformative">503. Priors: Informative vs.&nbsp;Noninformative</a></li>
  <li><a href="#likelihood-and-evidence" id="toc-likelihood-and-evidence" class="nav-link" data-scroll-target="#likelihood-and-evidence">504. Likelihood and Evidence</a></li>
  <li><a href="#posterior-distributions" id="toc-posterior-distributions" class="nav-link" data-scroll-target="#posterior-distributions">505. Posterior Distributions</a></li>
  <li><a href="#conjugacy-and-analytical-tractability" id="toc-conjugacy-and-analytical-tractability" class="nav-link" data-scroll-target="#conjugacy-and-analytical-tractability">506. Conjugacy and Analytical Tractability</a></li>
  <li><a href="#map-vs.-full-bayesian-inference" id="toc-map-vs.-full-bayesian-inference" class="nav-link" data-scroll-target="#map-vs.-full-bayesian-inference">507. MAP vs.&nbsp;Full Bayesian Inference</a></li>
  <li><a href="#bayesian-model-comparison" id="toc-bayesian-model-comparison" class="nav-link" data-scroll-target="#bayesian-model-comparison">508. Bayesian Model Comparison</a></li>
  <li><a href="#predictive-distributions" id="toc-predictive-distributions" class="nav-link" data-scroll-target="#predictive-distributions">509. Predictive Distributions</a></li>
  <li><a href="#philosophical-debates-bayesianism-vs.-frequentism" id="toc-philosophical-debates-bayesianism-vs.-frequentism" class="nav-link" data-scroll-target="#philosophical-debates-bayesianism-vs.-frequentism">510. Philosophical Debates: Bayesianism vs.&nbsp;Frequentism</a></li>
  </ul></li>
  <li><a href="#chapter-52.-directed-graphical-modesl-bayesian-networks" id="toc-chapter-52.-directed-graphical-modesl-bayesian-networks" class="nav-link" data-scroll-target="#chapter-52.-directed-graphical-modesl-bayesian-networks">Chapter 52. Directed Graphical Modesl (bayesian networks)</a>
  <ul class="collapse">
  <li><a href="#nodes-edges-and-conditional-independence" id="toc-nodes-edges-and-conditional-independence" class="nav-link" data-scroll-target="#nodes-edges-and-conditional-independence">511. Nodes, Edges, and Conditional Independence</a></li>
  <li><a href="#factorization-of-joint-distributions" id="toc-factorization-of-joint-distributions" class="nav-link" data-scroll-target="#factorization-of-joint-distributions">512. Factorization of Joint Distributions</a></li>
  <li><a href="#d-separation-and-graphical-criteria" id="toc-d-separation-and-graphical-criteria" class="nav-link" data-scroll-target="#d-separation-and-graphical-criteria">513. D-Separation and Graphical Criteria</a></li>
  <li><a href="#common-structures-chains-forks-colliders" id="toc-common-structures-chains-forks-colliders" class="nav-link" data-scroll-target="#common-structures-chains-forks-colliders">514. Common Structures: Chains, Forks, Colliders</a></li>
  <li><a href="#naïve-bayes-as-a-bayesian-network" id="toc-naïve-bayes-as-a-bayesian-network" class="nav-link" data-scroll-target="#naïve-bayes-as-a-bayesian-network">515. Naïve Bayes as a Bayesian Network</a></li>
  <li><a href="#hidden-markov-models-as-dags" id="toc-hidden-markov-models-as-dags" class="nav-link" data-scroll-target="#hidden-markov-models-as-dags">516. Hidden Markov Models as DAGs</a></li>
  <li><a href="#parameter-learning-in-bns" id="toc-parameter-learning-in-bns" class="nav-link" data-scroll-target="#parameter-learning-in-bns">517. Parameter Learning in BNs</a></li>
  <li><a href="#structure-learning-from-data" id="toc-structure-learning-from-data" class="nav-link" data-scroll-target="#structure-learning-from-data">518. Structure Learning from Data</a></li>
  <li><a href="#inference-in-bayesian-networks" id="toc-inference-in-bayesian-networks" class="nav-link" data-scroll-target="#inference-in-bayesian-networks">519. Inference in Bayesian Networks</a></li>
  <li><a href="#applications-medicine-diagnosis-expert-systems" id="toc-applications-medicine-diagnosis-expert-systems" class="nav-link" data-scroll-target="#applications-medicine-diagnosis-expert-systems">520. Applications: Medicine, Diagnosis, Expert Systems</a></li>
  </ul></li>
  <li><a href="#chapter-53.-undirected-graphical-models-mrfs-crfs" id="toc-chapter-53.-undirected-graphical-models-mrfs-crfs" class="nav-link" data-scroll-target="#chapter-53.-undirected-graphical-models-mrfs-crfs">Chapter 53. Undirected Graphical Models (MRFs, CRFs)</a>
  <ul class="collapse">
  <li><a href="#markov-random-fields-potentials-and-cliques" id="toc-markov-random-fields-potentials-and-cliques" class="nav-link" data-scroll-target="#markov-random-fields-potentials-and-cliques">521. Markov Random Fields: Potentials and Cliques</a></li>
  <li><a href="#conditional-random-fields-for-structured-prediction" id="toc-conditional-random-fields-for-structured-prediction" class="nav-link" data-scroll-target="#conditional-random-fields-for-structured-prediction">522. Conditional Random Fields for Structured Prediction</a></li>
  <li><a href="#factor-graphs-and-hybrid-representations" id="toc-factor-graphs-and-hybrid-representations" class="nav-link" data-scroll-target="#factor-graphs-and-hybrid-representations">523. Factor Graphs and Hybrid Representations</a></li>
  <li><a href="#hammersleyclifford-theorem" id="toc-hammersleyclifford-theorem" class="nav-link" data-scroll-target="#hammersleyclifford-theorem">524. Hammersley–Clifford Theorem</a></li>
  <li><a href="#energy-based-interpretations" id="toc-energy-based-interpretations" class="nav-link" data-scroll-target="#energy-based-interpretations">525. Energy-Based Interpretations</a></li>
  <li><a href="#contrast-with-directed-models" id="toc-contrast-with-directed-models" class="nav-link" data-scroll-target="#contrast-with-directed-models">526. Contrast with Directed Models</a></li>
  <li><a href="#learning-parameters-in-crfs" id="toc-learning-parameters-in-crfs" class="nav-link" data-scroll-target="#learning-parameters-in-crfs">527. Learning Parameters in CRFs</a></li>
  <li><a href="#approximate-inference-in-mrfs" id="toc-approximate-inference-in-mrfs" class="nav-link" data-scroll-target="#approximate-inference-in-mrfs">528. Approximate Inference in MRFs</a></li>
  <li><a href="#deep-crfs-and-neural-potentials" id="toc-deep-crfs-and-neural-potentials" class="nav-link" data-scroll-target="#deep-crfs-and-neural-potentials">529. Deep CRFs and Neural Potentials</a></li>
  <li><a href="#real-world-uses-nlp-vision-bioinformatics" id="toc-real-world-uses-nlp-vision-bioinformatics" class="nav-link" data-scroll-target="#real-world-uses-nlp-vision-bioinformatics">530. Real-World Uses: NLP, Vision, Bioinformatics</a></li>
  </ul></li>
  <li><a href="#chapter-54.-exact-inference-variable-elimination-junction-tree" id="toc-chapter-54.-exact-inference-variable-elimination-junction-tree" class="nav-link" data-scroll-target="#chapter-54.-exact-inference-variable-elimination-junction-tree">Chapter 54. Exact Inference (Variable Elimination, Junction Tree)</a>
  <ul class="collapse">
  <li><a href="#exact-inference-problem-setup" id="toc-exact-inference-problem-setup" class="nav-link" data-scroll-target="#exact-inference-problem-setup">531. Exact Inference Problem Setup</a></li>
  <li><a href="#variable-elimination-algorithm" id="toc-variable-elimination-algorithm" class="nav-link" data-scroll-target="#variable-elimination-algorithm">532. Variable Elimination Algorithm</a></li>
  <li><a href="#complexity-and-ordering-heuristics" id="toc-complexity-and-ordering-heuristics" class="nav-link" data-scroll-target="#complexity-and-ordering-heuristics">533. Complexity and Ordering Heuristics</a></li>
  <li><a href="#message-passing-and-belief-propagation" id="toc-message-passing-and-belief-propagation" class="nav-link" data-scroll-target="#message-passing-and-belief-propagation">534. Message Passing and Belief Propagation</a></li>
  <li><a href="#sum-product-vs.-max-product" id="toc-sum-product-vs.-max-product" class="nav-link" data-scroll-target="#sum-product-vs.-max-product">535. Sum-Product vs.&nbsp;Max-Product</a></li>
  <li><a href="#junction-tree-algorithm-basics" id="toc-junction-tree-algorithm-basics" class="nav-link" data-scroll-target="#junction-tree-algorithm-basics">536. Junction Tree Algorithm Basics</a></li>
  <li><a href="#clique-formation-and-triangulation" id="toc-clique-formation-and-triangulation" class="nav-link" data-scroll-target="#clique-formation-and-triangulation">537. Clique Formation and Triangulation</a></li>
  <li><a href="#computational-tradeoffs" id="toc-computational-tradeoffs" class="nav-link" data-scroll-target="#computational-tradeoffs">538. Computational Tradeoffs</a></li>
  <li><a href="#exact-inference-in-practice" id="toc-exact-inference-in-practice" class="nav-link" data-scroll-target="#exact-inference-in-practice">539. Exact Inference in Practice</a></li>
  <li><a href="#limits-of-exact-approaches" id="toc-limits-of-exact-approaches" class="nav-link" data-scroll-target="#limits-of-exact-approaches">540. Limits of Exact Approaches</a></li>
  </ul></li>
  <li><a href="#chapter-55.-approximate-inference-sampling-variational" id="toc-chapter-55.-approximate-inference-sampling-variational" class="nav-link" data-scroll-target="#chapter-55.-approximate-inference-sampling-variational">Chapter 55. Approximate Inference (sampling, Variational)</a>
  <ul class="collapse">
  <li><a href="#why-approximation-is-needed" id="toc-why-approximation-is-needed" class="nav-link" data-scroll-target="#why-approximation-is-needed">541. Why Approximation is Needed</a></li>
  <li><a href="#monte-carlo-estimation-basics" id="toc-monte-carlo-estimation-basics" class="nav-link" data-scroll-target="#monte-carlo-estimation-basics">542. Monte Carlo Estimation Basics</a></li>
  <li><a href="#importance-sampling-and-reweighting" id="toc-importance-sampling-and-reweighting" class="nav-link" data-scroll-target="#importance-sampling-and-reweighting">543. Importance Sampling and Reweighting</a></li>
  <li><a href="#markov-chain-monte-carlo-mcmc" id="toc-markov-chain-monte-carlo-mcmc" class="nav-link" data-scroll-target="#markov-chain-monte-carlo-mcmc">544. Markov Chain Monte Carlo (MCMC)</a></li>
  <li><a href="#gibbs-sampling-and-metropolis-hastings" id="toc-gibbs-sampling-and-metropolis-hastings" class="nav-link" data-scroll-target="#gibbs-sampling-and-metropolis-hastings">545. Gibbs Sampling and Metropolis-Hastings</a></li>
  <li><a href="#variational-inference-overview" id="toc-variational-inference-overview" class="nav-link" data-scroll-target="#variational-inference-overview">546. Variational Inference Overview</a></li>
  <li><a href="#mean-field-approximation" id="toc-mean-field-approximation" class="nav-link" data-scroll-target="#mean-field-approximation">547. Mean-Field Approximation</a></li>
  <li><a href="#variational-autoencoders-as-inference-machines" id="toc-variational-autoencoders-as-inference-machines" class="nav-link" data-scroll-target="#variational-autoencoders-as-inference-machines">548. Variational Autoencoders as Inference Machines</a></li>
  <li><a href="#hybrid-methods-sampling-variational" id="toc-hybrid-methods-sampling-variational" class="nav-link" data-scroll-target="#hybrid-methods-sampling-variational">549. Hybrid Methods: Sampling + Variational</a></li>
  <li><a href="#tradeoffs-in-accuracy-efficiency-and-scalability" id="toc-tradeoffs-in-accuracy-efficiency-and-scalability" class="nav-link" data-scroll-target="#tradeoffs-in-accuracy-efficiency-and-scalability">550. Tradeoffs in Accuracy, Efficiency, and Scalability</a></li>
  </ul></li>
  <li><a href="#chapter-56.-latent-variable-models-and-em" id="toc-chapter-56.-latent-variable-models-and-em" class="nav-link" data-scroll-target="#chapter-56.-latent-variable-models-and-em">Chapter 56. Latent Variable Models and EM</a>
  <ul class="collapse">
  <li><a href="#latent-vs.-observed-variables" id="toc-latent-vs.-observed-variables" class="nav-link" data-scroll-target="#latent-vs.-observed-variables">551. Latent vs.&nbsp;Observed Variables</a></li>
  <li><a href="#mixture-models-as-latent-variable-models" id="toc-mixture-models-as-latent-variable-models" class="nav-link" data-scroll-target="#mixture-models-as-latent-variable-models">552. Mixture Models as Latent Variable Models</a></li>
  <li><a href="#expectation-maximization-em-algorithm" id="toc-expectation-maximization-em-algorithm" class="nav-link" data-scroll-target="#expectation-maximization-em-algorithm">553. Expectation-Maximization (EM) Algorithm</a></li>
  <li><a href="#e-step-posterior-expectations" id="toc-e-step-posterior-expectations" class="nav-link" data-scroll-target="#e-step-posterior-expectations">554. E-Step: Posterior Expectations</a></li>
  <li><a href="#m-step-parameter-maximization" id="toc-m-step-parameter-maximization" class="nav-link" data-scroll-target="#m-step-parameter-maximization">555. M-Step: Parameter Maximization</a></li>
  <li><a href="#convergence-properties-of-em" id="toc-convergence-properties-of-em" class="nav-link" data-scroll-target="#convergence-properties-of-em">556. Convergence Properties of EM</a></li>
  <li><a href="#extensions-generalized-em-online-em" id="toc-extensions-generalized-em-online-em" class="nav-link" data-scroll-target="#extensions-generalized-em-online-em">557. Extensions: Generalized EM, Online EM</a></li>
  <li><a href="#em-in-gaussian-mixture-models" id="toc-em-in-gaussian-mixture-models" class="nav-link" data-scroll-target="#em-in-gaussian-mixture-models">558. EM in Gaussian Mixture Models</a></li>
  <li><a href="#em-in-hidden-markov-models" id="toc-em-in-hidden-markov-models" class="nav-link" data-scroll-target="#em-in-hidden-markov-models">559. EM in Hidden Markov Models</a></li>
  <li><a href="#variants-and-alternatives-to-em" id="toc-variants-and-alternatives-to-em" class="nav-link" data-scroll-target="#variants-and-alternatives-to-em">560. Variants and Alternatives to EM</a></li>
  </ul></li>
  <li><a href="#chapter-57.-sequential-models-hmms-kalman-particle-filters" id="toc-chapter-57.-sequential-models-hmms-kalman-particle-filters" class="nav-link" data-scroll-target="#chapter-57.-sequential-models-hmms-kalman-particle-filters">Chapter 57. Sequential Models (HMMs, Kalman, Particle Filters)</a>
  <ul class="collapse">
  <li><a href="#temporal-structure-in-probabilistic-models" id="toc-temporal-structure-in-probabilistic-models" class="nav-link" data-scroll-target="#temporal-structure-in-probabilistic-models">561. Temporal Structure in Probabilistic Models</a></li>
  <li><a href="#hidden-markov-models-hmms-overview" id="toc-hidden-markov-models-hmms-overview" class="nav-link" data-scroll-target="#hidden-markov-models-hmms-overview">562. Hidden Markov Models (HMMs) Overview</a></li>
  <li><a href="#forward-backward-algorithm" id="toc-forward-backward-algorithm" class="nav-link" data-scroll-target="#forward-backward-algorithm">563. Forward-Backward Algorithm</a></li>
  <li><a href="#viterbi-decoding-for-sequences" id="toc-viterbi-decoding-for-sequences" class="nav-link" data-scroll-target="#viterbi-decoding-for-sequences">564. Viterbi Decoding for Sequences</a></li>
  <li><a href="#kalman-filters-for-linear-gaussian-systems" id="toc-kalman-filters-for-linear-gaussian-systems" class="nav-link" data-scroll-target="#kalman-filters-for-linear-gaussian-systems">565. Kalman Filters for Linear Gaussian Systems</a></li>
  <li><a href="#extended-and-unscented-kalman-filters" id="toc-extended-and-unscented-kalman-filters" class="nav-link" data-scroll-target="#extended-and-unscented-kalman-filters">566. Extended and Unscented Kalman Filters</a></li>
  <li><a href="#particle-filtering-for-nonlinear-systems" id="toc-particle-filtering-for-nonlinear-systems" class="nav-link" data-scroll-target="#particle-filtering-for-nonlinear-systems">567. Particle Filtering for Nonlinear Systems</a></li>
  <li><a href="#sequential-monte-carlo-methods" id="toc-sequential-monte-carlo-methods" class="nav-link" data-scroll-target="#sequential-monte-carlo-methods">568. Sequential Monte Carlo Methods</a></li>
  <li><a href="#hybrid-models-neural-probabilistic" id="toc-hybrid-models-neural-probabilistic" class="nav-link" data-scroll-target="#hybrid-models-neural-probabilistic">569. Hybrid Models: Neural + Probabilistic</a></li>
  <li><a href="#applications-speech-tracking-finance" id="toc-applications-speech-tracking-finance" class="nav-link" data-scroll-target="#applications-speech-tracking-finance">570. Applications: Speech, Tracking, Finance</a></li>
  </ul></li>
  <li><a href="#chapter-58.-decision-theory-and-influence-diagrams" id="toc-chapter-58.-decision-theory-and-influence-diagrams" class="nav-link" data-scroll-target="#chapter-58.-decision-theory-and-influence-diagrams">Chapter 58. Decision Theory and Influence Diagrams</a>
  <ul class="collapse">
  <li><a href="#utility-and-preferences" id="toc-utility-and-preferences" class="nav-link" data-scroll-target="#utility-and-preferences">571. Utility and Preferences</a></li>
  <li><a href="#rational-decision-making-under-uncertainty" id="toc-rational-decision-making-under-uncertainty" class="nav-link" data-scroll-target="#rational-decision-making-under-uncertainty">572. Rational Decision-Making under Uncertainty</a></li>
  <li><a href="#expected-utility-theory" id="toc-expected-utility-theory" class="nav-link" data-scroll-target="#expected-utility-theory">573. Expected Utility Theory</a></li>
  <li><a href="#risk-aversion-and-utility-curves" id="toc-risk-aversion-and-utility-curves" class="nav-link" data-scroll-target="#risk-aversion-and-utility-curves">574. Risk Aversion and Utility Curves</a></li>
  <li><a href="#influence-diagrams-structure-and-semantics" id="toc-influence-diagrams-structure-and-semantics" class="nav-link" data-scroll-target="#influence-diagrams-structure-and-semantics">575. Influence Diagrams: Structure and Semantics</a></li>
  <li><a href="#combining-probabilistic-and-utility-models" id="toc-combining-probabilistic-and-utility-models" class="nav-link" data-scroll-target="#combining-probabilistic-and-utility-models">576. Combining Probabilistic and Utility Models</a></li>
  <li><a href="#multi-stage-decision-problems" id="toc-multi-stage-decision-problems" class="nav-link" data-scroll-target="#multi-stage-decision-problems">577. Multi-Stage Decision Problems</a></li>
  <li><a href="#decision-theoretic-inference-algorithms" id="toc-decision-theoretic-inference-algorithms" class="nav-link" data-scroll-target="#decision-theoretic-inference-algorithms">578. Decision-Theoretic Inference Algorithms</a></li>
  <li><a href="#ai-applications-diagnosis-planning-games" id="toc-ai-applications-diagnosis-planning-games" class="nav-link" data-scroll-target="#ai-applications-diagnosis-planning-games">579. AI Applications: Diagnosis, Planning, Games</a></li>
  <li><a href="#limitations-of-classical-decision-theory" id="toc-limitations-of-classical-decision-theory" class="nav-link" data-scroll-target="#limitations-of-classical-decision-theory">580. Limitations of Classical Decision Theory</a></li>
  </ul></li>
  <li><a href="#chapter-59.-probabilistic-programming-languages" id="toc-chapter-59.-probabilistic-programming-languages" class="nav-link" data-scroll-target="#chapter-59.-probabilistic-programming-languages">Chapter 59. Probabilistic Programming Languages</a>
  <ul class="collapse">
  <li><a href="#motivation-for-probabilistic-programming" id="toc-motivation-for-probabilistic-programming" class="nav-link" data-scroll-target="#motivation-for-probabilistic-programming">581. Motivation for Probabilistic Programming</a></li>
  <li><a href="#declarative-vs.-generative-models" id="toc-declarative-vs.-generative-models" class="nav-link" data-scroll-target="#declarative-vs.-generative-models">582. Declarative vs.&nbsp;Generative Models</a></li>
  <li><a href="#key-languages-and-frameworks-overview" id="toc-key-languages-and-frameworks-overview" class="nav-link" data-scroll-target="#key-languages-and-frameworks-overview">583. Key Languages and Frameworks (overview)</a></li>
  <li><a href="#sampling-semantics-of-probabilistic-programs" id="toc-sampling-semantics-of-probabilistic-programs" class="nav-link" data-scroll-target="#sampling-semantics-of-probabilistic-programs">584. Sampling Semantics of Probabilistic Programs</a></li>
  <li><a href="#automatic-inference-engines" id="toc-automatic-inference-engines" class="nav-link" data-scroll-target="#automatic-inference-engines">585. Automatic Inference Engines</a></li>
  <li><a href="#expressivity-vs.-tractability-tradeoffs" id="toc-expressivity-vs.-tractability-tradeoffs" class="nav-link" data-scroll-target="#expressivity-vs.-tractability-tradeoffs">586. Expressivity vs.&nbsp;Tractability Tradeoffs</a></li>
  <li><a href="#applications-in-ai-research" id="toc-applications-in-ai-research" class="nav-link" data-scroll-target="#applications-in-ai-research">587. Applications in AI Research</a></li>
  <li><a href="#industrial-and-scientific-case-studies" id="toc-industrial-and-scientific-case-studies" class="nav-link" data-scroll-target="#industrial-and-scientific-case-studies">588. Industrial and Scientific Case Studies</a></li>
  <li><a href="#integration-with-deep-learning" id="toc-integration-with-deep-learning" class="nav-link" data-scroll-target="#integration-with-deep-learning">589. Integration with Deep Learning</a></li>
  <li><a href="#open-challenges-in-probabilistic-programming" id="toc-open-challenges-in-probabilistic-programming" class="nav-link" data-scroll-target="#open-challenges-in-probabilistic-programming">590. Open Challenges in Probabilistic Programming</a></li>
  </ul></li>
  <li><a href="#chapter-60.-calibration-uncertainty-quantification-reliability" id="toc-chapter-60.-calibration-uncertainty-quantification-reliability" class="nav-link" data-scroll-target="#chapter-60.-calibration-uncertainty-quantification-reliability">Chapter 60. Calibration, Uncertainty Quantification Reliability</a>
  <ul class="collapse">
  <li><a href="#what-is-calibration-reliability-diagrams" id="toc-what-is-calibration-reliability-diagrams" class="nav-link" data-scroll-target="#what-is-calibration-reliability-diagrams">591. What is Calibration? Reliability Diagrams</a></li>
  <li><a href="#confidence-intervals-and-credible-intervals" id="toc-confidence-intervals-and-credible-intervals" class="nav-link" data-scroll-target="#confidence-intervals-and-credible-intervals">592. Confidence Intervals and Credible Intervals</a></li>
  <li><a href="#quantifying-aleatoric-vs.-epistemic-uncertainty" id="toc-quantifying-aleatoric-vs.-epistemic-uncertainty" class="nav-link" data-scroll-target="#quantifying-aleatoric-vs.-epistemic-uncertainty">593. Quantifying Aleatoric vs.&nbsp;Epistemic Uncertainty</a></li>
  <li><a href="#bayesian-model-averaging" id="toc-bayesian-model-averaging" class="nav-link" data-scroll-target="#bayesian-model-averaging">594. Bayesian Model Averaging</a></li>
  <li><a href="#conformal-prediction-methods" id="toc-conformal-prediction-methods" class="nav-link" data-scroll-target="#conformal-prediction-methods">595. Conformal Prediction Methods</a></li>
  <li><a href="#ensembles-for-uncertainty-estimation" id="toc-ensembles-for-uncertainty-estimation" class="nav-link" data-scroll-target="#ensembles-for-uncertainty-estimation">596. Ensembles for Uncertainty Estimation</a></li>
  <li><a href="#robustness-in-deployed-systems" id="toc-robustness-in-deployed-systems" class="nav-link" data-scroll-target="#robustness-in-deployed-systems">597. Robustness in Deployed Systems</a></li>
  <li><a href="#uncertainty-in-human-in-the-loop-systems" id="toc-uncertainty-in-human-in-the-loop-systems" class="nav-link" data-scroll-target="#uncertainty-in-human-in-the-loop-systems">598. Uncertainty in Human-in-the-Loop Systems</a></li>
  <li><a href="#safety-critical-reliability-requirements" id="toc-safety-critical-reliability-requirements" class="nav-link" data-scroll-target="#safety-critical-reliability-requirements">599. Safety-Critical Reliability Requirements</a></li>
  <li><a href="#future-of-trustworthy-ai-with-uq" id="toc-future-of-trustworthy-ai-with-uq" class="nav-link" data-scroll-target="#future-of-trustworthy-ai-with-uq">600. Future of Trustworthy AI with UQ</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">Volume 6. Probabilistic Modeling and Inference</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">Coins</span> spin in the air,</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ex">probabilities</span> whisper,</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="ex">outcomes</span> find their weight.</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<section id="chapter-51.-bayesian-inference-basics" class="level2">
<h2 class="anchored" data-anchor-id="chapter-51.-bayesian-inference-basics">Chapter 51. Bayesian Inference Basics</h2>
<section id="probability-as-belief-vs.-frequency" class="level3">
<h3 class="anchored" data-anchor-id="probability-as-belief-vs.-frequency">501. Probability as Belief vs.&nbsp;Frequency</h3>
<p>Probability can be understood in two main traditions. The <em>frequentist</em> view defines probability as the long-run frequency of events after many trials. The <em>Bayesian</em> view interprets probability as a measure of belief or uncertainty about a statement, given available information. These two interpretations lead to different ways of thinking about inference, evidence, and learning from data.</p>
<section id="picture-in-your-head" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head">Picture in Your Head</h4>
<p>Imagine flipping a coin. A frequentist says: <em>“The probability of heads is 0.5 because in infinite flips, half will be heads.”</em> A Bayesian says: <em>“The probability of heads is 0.5 because that’s my degree of belief given no other evidence.”</em> Both predict the same outcome distribution but for different reasons.</p>
</section>
<section id="deep-dive" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive">Deep Dive</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 39%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="header">
<th>Aspect</th>
<th>Frequentist</th>
<th>Bayesian</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Definition</td>
<td>Probability = limiting frequency in repeated trials</td>
<td>Probability = subjective degree of belief</td>
</tr>
<tr class="even">
<td>Unknown Parameters</td>
<td>Fixed but unknown quantities</td>
<td>Random variables with prior distributions</td>
</tr>
<tr class="odd">
<td>Evidence Update</td>
<td>Based on likelihood and estimators</td>
<td>Based on Bayes’ theorem (prior → posterior)</td>
</tr>
<tr class="even">
<td>Example</td>
<td>“This drug works in 70% of cases” (empirical proportion)</td>
<td>“Given current data, I believe there’s a 70% chance this drug works”</td>
</tr>
</tbody>
</table>
<p>These views are not just philosophical: they shape how we design experiments, choose models, and update knowledge. Modern AI often combines both, using frequentist tools (e.g.&nbsp;hypothesis testing, confidence intervals) with Bayesian perspectives (uncertainty quantification, posterior distributions).</p>
</section>
<section id="tiny-code" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Frequentist: simulate coin flips</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>flips <span class="op">=</span> [random.choice([<span class="st">"H"</span>, <span class="st">"T"</span>]) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>)]</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>freq_heads <span class="op">=</span> flips.count(<span class="st">"H"</span>) <span class="op">/</span> <span class="bu">len</span>(flips)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Frequentist probability (estimate):"</span>, freq_heads)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Bayesian: prior belief updated with data</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fractions <span class="im">import</span> Fraction</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>prior_heads <span class="op">=</span> Fraction(<span class="dv">1</span>, <span class="dv">2</span>)  <span class="co"># prior belief = 0.5</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>observed_heads <span class="op">=</span> flips.count(<span class="st">"H"</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>observed_tails <span class="op">=</span> flips.count(<span class="st">"T"</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Using a simple Beta(1,1) prior updated with data</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>posterior_heads <span class="op">=</span> Fraction(<span class="dv">1</span> <span class="op">+</span> observed_heads, <span class="dv">2</span> <span class="op">+</span> observed_heads <span class="op">+</span> observed_tails)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Bayesian posterior probability:"</span>, <span class="bu">float</span>(posterior_heads))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters">Why It Matters</h4>
<p>The interpretation of probability shapes AI systems at their core. Frequentist reasoning dominates classical statistics and guarantees objectivity in large data regimes. Bayesian reasoning allows flexible adaptation when data is scarce, integrating prior knowledge and updating beliefs continuously. Together, they provide the foundation for inference in modern machine learning.</p>
</section>
<section id="try-it-yourself" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself">Try It Yourself</h4>
<ol type="1">
<li>Flip a coin 20 times. Estimate the probability of heads in both frequentist and Bayesian ways. Do your results converge as trials increase?</li>
<li>Suppose you believe a coin is fair, but in 5 flips you see 5 heads. How would a frequentist interpret this? How would a Bayesian update their belief?</li>
<li>For AI safety: why is belief-based probability useful when reasoning about rare but high-stakes events (e.g., self-driving car failures)?</li>
</ol>
</section>
</section>
<section id="bayes-theorem-and-updating" class="level3">
<h3 class="anchored" data-anchor-id="bayes-theorem-and-updating">502. Bayes’ Theorem and Updating</h3>
<p>Bayes’ theorem provides the rule for updating beliefs when new evidence arrives. It links prior probability (what you believed before), likelihood (how compatible the evidence is with a hypothesis), and posterior probability (your new belief after seeing the evidence). This update is proportional: hypotheses that explain the data better get higher posterior weight.</p>
<section id="picture-in-your-head-1" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-1">Picture in Your Head</h4>
<p>Think of a courtroom. The prior is your initial assumption about the defendant’s guilt (maybe 50/50). The likelihood is how strongly the presented evidence supports guilt versus innocence. The posterior is your updated judgment after weighing the prior and the evidence together.</p>
</section>
<section id="deep-dive-1" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-1">Deep Dive</h4>
<p>The formula is simple but powerful:</p>
<p><span class="math display">\[
P(H \mid D) = \frac{P(D \mid H) \cdot P(H)}{P(D)}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(H\)</span> = hypothesis</li>
<li><span class="math inline">\(D\)</span> = data (evidence)</li>
<li><span class="math inline">\(P(H)\)</span> = prior probability</li>
<li><span class="math inline">\(P(D \mid H)\)</span> = likelihood</li>
<li><span class="math inline">\(P(D)\)</span> = marginal probability of data (normalization)</li>
<li><span class="math inline">\(P(H \mid D)\)</span> = posterior probability</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 34%">
<col style="width: 55%">
</colgroup>
<thead>
<tr class="header">
<th>Component</th>
<th>Meaning</th>
<th>Example (Disease Testing)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Prior</td>
<td>Base rate of disease</td>
<td>1% of people have disease</td>
</tr>
<tr class="even">
<td>Likelihood</td>
<td>Test sensitivity/specificity</td>
<td>90% accurate test</td>
</tr>
<tr class="odd">
<td>Posterior</td>
<td>Updated belief given test result</td>
<td>Probability person has disease after a positive test</td>
</tr>
</tbody>
</table>
<p>Bayesian updating generalizes to continuous distributions, hierarchical models, and streaming data where beliefs evolve over time.</p>
</section>
<section id="tiny-code-1" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-1">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Disease testing example</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>prior <span class="op">=</span> <span class="fl">0.01</span>                <span class="co"># prior probability of disease</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>sensitivity <span class="op">=</span> <span class="fl">0.9</span>           <span class="co"># P(test+ | disease)</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>specificity <span class="op">=</span> <span class="fl">0.9</span>           <span class="co"># P(test- | no disease)</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>test_positive <span class="op">=</span> <span class="va">True</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Likelihoods</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>p_test_pos <span class="op">=</span> sensitivity <span class="op">*</span> prior <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> specificity) <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> prior)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>posterior <span class="op">=</span> (sensitivity <span class="op">*</span> prior) <span class="op">/</span> p_test_pos</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Posterior probability of disease after positive test:"</span>, posterior)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-1" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-1">Why It Matters</h4>
<p>Bayes’ theorem is the foundation of probabilistic reasoning in AI. It allows systems to incorporate prior knowledge, continuously refine beliefs as data arrives, and quantify uncertainty. From spam filters to self-driving cars, Bayesian updating governs how evidence shifts decisions under uncertainty.</p>
</section>
<section id="try-it-yourself-1" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-1">Try It Yourself</h4>
<ol type="1">
<li>Suppose a coin has a 60% chance of being biased toward heads. You flip it twice and see two tails. Use Bayes’ theorem to update your belief.</li>
<li>In the medical test example, compute the posterior probability if the test is repeated and both results are positive.</li>
<li>Think about real-world systems: how could a robot navigating with noisy sensors use Bayesian updating to maintain a map of its environment?</li>
</ol>
</section>
</section>
<section id="priors-informative-vs.-noninformative" class="level3">
<h3 class="anchored" data-anchor-id="priors-informative-vs.-noninformative">503. Priors: Informative vs.&nbsp;Noninformative</h3>
<p>A prior encodes what we believe before seeing any data. Priors can be informative, carrying strong domain knowledge, or noninformative, designed to have minimal influence so the data “speaks for itself.” The choice of prior shapes the posterior, especially when data is limited.</p>
<section id="picture-in-your-head-2" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-2">Picture in Your Head</h4>
<p>Imagine predicting tomorrow’s weather. If you just moved to a desert, your informative prior might favor “no rain.” If you know nothing about the climate, you might assign equal probability to “rain” or “no rain” as a noninformative prior. As forecasts arrive, both priors will update, but they start from different assumptions.</p>
</section>
<section id="deep-dive-2" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-2">Deep Dive</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 41%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="header">
<th>Type of Prior</th>
<th>Description</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Informative</td>
<td>Encodes real prior knowledge or strong beliefs</td>
<td>A medical expert knows a disease prevalence is ~5%</td>
</tr>
<tr class="even">
<td>Weakly Informative</td>
<td>Provides mild guidance to regularize models</td>
<td>Setting normal(0,10) for regression weights</td>
</tr>
<tr class="odd">
<td>Noninformative</td>
<td>Tries not to bias results, often flat or improper</td>
<td>Uniform distribution over all values</td>
</tr>
<tr class="even">
<td>Reference Prior</td>
<td>Designed to maximize information gain from data</td>
<td>Jeffreys prior in parameter estimation</td>
</tr>
</tbody>
</table>
<p>Choosing a prior is both art and science. Informative priors are valuable when expertise exists, while noninformative priors are common in exploratory modeling. Weakly informative priors help stabilize estimation without overwhelming the evidence.</p>
</section>
<section id="tiny-code-2" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-2">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> beta</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Noninformative prior: Beta(1,1) = uniform</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>uninformative <span class="op">=</span> beta.pdf(x, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Informative prior: Beta(10,2) = strong belief in high probability</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>informative <span class="op">=</span> beta.pdf(x, <span class="dv">10</span>, <span class="dv">2</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>plt.plot(x, uninformative, label<span class="op">=</span><span class="st">"Noninformative (Beta(1,1))"</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>plt.plot(x, informative, label<span class="op">=</span><span class="st">"Informative (Beta(10,2))"</span>)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Informative vs. Noninformative Priors"</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-2" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-2">Why It Matters</h4>
<p>Priors determine how models behave in data-scarce regimes, which is common in AI applications like rare disease detection or anomaly detection in security. Informative priors allow experts to guide models with real-world knowledge. Noninformative priors are useful when neutrality is desired. The right prior balances knowledge and flexibility, influencing both interpretability and robustness.</p>
</section>
<section id="try-it-yourself-2" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-2">Try It Yourself</h4>
<ol type="1">
<li>Construct a uniform prior for coin bias, then update it after observing 3 heads and 1 tail.</li>
<li>Compare results if you start with a strong prior belief that the coin is fair.</li>
<li>Discuss when a weakly informative prior might prevent overfitting in a machine learning model.</li>
</ol>
</section>
</section>
<section id="likelihood-and-evidence" class="level3">
<h3 class="anchored" data-anchor-id="likelihood-and-evidence">504. Likelihood and Evidence</h3>
<p>The likelihood measures how probable the observed data is under different hypotheses or parameter values. It is not a probability of the parameters themselves, but a function of them given the data. The evidence (or marginal likelihood) normalizes across all possible hypotheses, ensuring posteriors sum to one.</p>
<section id="picture-in-your-head-3" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-3">Picture in Your Head</h4>
<p>Think of playing detective. The likelihood is how well each suspect’s story explains the clues. The evidence is the combined plausibility of all stories—used to fairly weigh which suspect is most consistent with reality.</p>
</section>
<section id="deep-dive-3" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-3">Deep Dive</h4>
<p>The Bayesian update relies on both:</p>
<p><span class="math display">\[
P(H \mid D) = \frac{P(D \mid H)\,P(H)}{P(D)}
\]</span></p>
<ul>
<li>Likelihood <span class="math inline">\(P(D \mid H)\)</span>: “If this hypothesis were true, how likely would we see the data?”</li>
<li>Evidence <span class="math inline">\(P(D)\)</span>: weighted average of likelihoods across all hypotheses, <span class="math inline">\(P(D) = \sum_H P(D \mid H)P(H)\)</span>.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 30%">
<col style="width: 56%">
</colgroup>
<thead>
<tr class="header">
<th>Term</th>
<th>Role in Inference</th>
<th>Example (Coin Bias)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Likelihood</td>
<td>Fits model to data</td>
<td><span class="math inline">\(P(3\text{ heads} \mid p=0.7)\)</span></td>
</tr>
<tr class="even">
<td>Evidence</td>
<td>Normalizes probabilities</td>
<td>Probability of 3 heads under all possible <span class="math inline">\(p\)</span></td>
</tr>
</tbody>
</table>
<p>Likelihood tells us which hypotheses are favored by the data, while evidence ensures the result is a valid probability distribution.</p>
</section>
<section id="tiny-code-3" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-3">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> binom</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: 3 heads in 5 flips</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>data_heads <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>n_flips <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Likelihoods under two hypotheses</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>p1, p2 <span class="op">=</span> <span class="fl">0.5</span>, <span class="fl">0.7</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>likelihood_p1 <span class="op">=</span> binom.pmf(data_heads, n_flips, p1)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>likelihood_p2 <span class="op">=</span> binom.pmf(data_heads, n_flips, p2)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Evidence: integrate over possible biases with uniform prior</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>p_grid <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>likelihoods <span class="op">=</span> binom.pmf(data_heads, n_flips, p_grid)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>evidence <span class="op">=</span> likelihoods.mean()  <span class="co"># approximated by grid average</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Likelihood (p=0.5):"</span>, likelihood_p1)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Likelihood (p=0.7):"</span>, likelihood_p2)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Evidence (approx.):"</span>, evidence)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-3" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-3">Why It Matters</h4>
<p>Likelihood is the workhorse of both Bayesian and frequentist inference. It drives maximum likelihood estimation, hypothesis testing, and Bayesian posterior updating. Evidence is crucial for model comparison—helping decide which model class better explains data, not just which parameters fit best.</p>
</section>
<section id="try-it-yourself-3" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-3">Try It Yourself</h4>
<ol type="1">
<li>Flip a coin 10 times, observe 7 heads. Compute the likelihood for <span class="math inline">\(p=0.5\)</span> and <span class="math inline">\(p=0.7\)</span>. Which is more supported by the data?</li>
<li>Estimate evidence for the same experiment using a uniform prior over <span class="math inline">\(p\)</span>.</li>
<li>Reflect: why is evidence often hard to compute for complex models, and how does this motivate approximate inference methods?</li>
</ol>
</section>
</section>
<section id="posterior-distributions" class="level3">
<h3 class="anchored" data-anchor-id="posterior-distributions">505. Posterior Distributions</h3>
<p>The posterior distribution represents updated beliefs about unknown parameters after observing data. It combines the prior with the likelihood, balancing what we believed before with what the evidence suggests. The posterior is the central object of Bayesian inference: it tells us not just a single estimate but the entire range of plausible parameter values and their probabilities.</p>
<section id="picture-in-your-head-4" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-4">Picture in Your Head</h4>
<p>Imagine aiming at a dartboard in the dark. The prior is your guess about where the target might be. Each dart you throw and hear land gives new clues (likelihood). With every throw, your mental “heat map” of where the target probably is becomes sharper—that evolving heat map is your posterior.</p>
</section>
<section id="deep-dive-4" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-4">Deep Dive</h4>
<p>Mathematically:</p>
<p><span class="math display">\[
P(\theta \mid D) = \frac{P(D \mid \theta) \, P(\theta)}{P(D)}
\]</span></p>
<ul>
<li><span class="math inline">\(\theta\)</span>: parameters or hypotheses</li>
<li><span class="math inline">\(P(\theta)\)</span>: prior</li>
<li><span class="math inline">\(P(D \mid \theta)\)</span>: likelihood</li>
<li><span class="math inline">\(P(\theta \mid D)\)</span>: posterior</li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Element</th>
<th>Role</th>
<th>Example (Coin Flips)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Prior</td>
<td>Initial belief</td>
<td>Uniform Beta(1,1) over bias <span class="math inline">\(p\)</span></td>
</tr>
<tr class="even">
<td>Likelihood</td>
<td>Fit to data</td>
<td>7 heads, 3 tails in 10 flips</td>
</tr>
<tr class="odd">
<td>Posterior</td>
<td>Updated belief</td>
<td>Beta(8,4), skewed toward head bias</td>
</tr>
</tbody>
</table>
<p>The posterior distribution is itself a probability distribution. We can summarize it with means, modes, medians, or credible intervals.</p>
</section>
<section id="tiny-code-4" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-4">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> beta</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Prior: uniform Beta(1,1)</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>alpha_prior, beta_prior <span class="op">=</span> <span class="dv">1</span>, <span class="dv">1</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Data: 7 heads, 3 tails</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>heads, tails <span class="op">=</span> <span class="dv">7</span>, <span class="dv">3</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior: Beta(alpha+heads, beta+tails)</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>alpha_post <span class="op">=</span> alpha_prior <span class="op">+</span> heads</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>beta_post <span class="op">=</span> beta_prior <span class="op">+</span> tails</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>plt.plot(x, beta.pdf(x, alpha_prior, beta_prior), label<span class="op">=</span><span class="st">"Prior Beta(1,1)"</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>plt.plot(x, beta.pdf(x, alpha_post, beta_post), label<span class="op">=</span><span class="ss">f"Posterior Beta(</span><span class="sc">{</span>alpha_post<span class="sc">}</span><span class="ss">,</span><span class="sc">{</span>beta_post<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Posterior Distribution after 7H/3T"</span>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-4" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-4">Why It Matters</h4>
<p>Posterior distributions allow AI systems to reason under uncertainty, quantify confidence, and adapt as new data arrives. Unlike point estimates, they express the full range of plausible outcomes, which is crucial in safety-critical domains like medicine, robotics, and finance.</p>
</section>
<section id="try-it-yourself-4" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-4">Try It Yourself</h4>
<ol type="1">
<li>Compute the posterior for 2 heads in 2 flips starting with a uniform prior.</li>
<li>Compare posteriors when starting with a strong prior belief that the coin is fair (Beta(50,50)).</li>
<li>Discuss: why might credible intervals from posteriors be more useful than frequentist confidence intervals in small-data settings?</li>
</ol>
</section>
</section>
<section id="conjugacy-and-analytical-tractability" class="level3">
<h3 class="anchored" data-anchor-id="conjugacy-and-analytical-tractability">506. Conjugacy and Analytical Tractability</h3>
<p>A conjugate prior is one that, when combined with a likelihood, produces a posterior of the same functional form. Conjugacy makes Bayesian updating mathematically neat and computationally simple, avoiding difficult integrals. While not always realistic, conjugate families provide intuition and closed-form solutions for many classic problems.</p>
<section id="picture-in-your-head-5" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-5">Picture in Your Head</h4>
<p>Think of puzzle pieces that fit perfectly together. A conjugate prior is shaped so that when you combine it with the likelihood piece, the posterior snaps into place with the same overall outline—only the parameters shift.</p>
</section>
<section id="deep-dive-5" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-5">Deep Dive</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 37%">
<col style="width: 19%">
<col style="width: 25%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th>Likelihood Model</th>
<th>Conjugate Prior</th>
<th>Posterior</th>
<th>Example Use</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Bernoulli/Binomial</td>
<td>Beta(<span class="math inline">\(\alpha,\beta\)</span>)</td>
<td>Beta(<span class="math inline">\(\alpha+x,\beta+n-x\)</span>)</td>
<td>Coin flips</td>
</tr>
<tr class="even">
<td>Gaussian (mean known, variance unknown)</td>
<td>Inverse-Gamma</td>
<td>Inverse-Gamma</td>
<td>Variance estimation</td>
</tr>
<tr class="odd">
<td>Gaussian (variance known, mean unknown)</td>
<td>Gaussian</td>
<td>Gaussian</td>
<td>Regression weights</td>
</tr>
<tr class="even">
<td>Poisson</td>
<td>Gamma</td>
<td>Gamma</td>
<td>Event counts</td>
</tr>
<tr class="odd">
<td>Multinomial</td>
<td>Dirichlet</td>
<td>Dirichlet</td>
<td>Text classification</td>
</tr>
</tbody>
</table>
<p>Conjugate families ensure posteriors can be updated by simply adjusting hyperparameters. This is why Beta, Gamma, and Dirichlet distributions appear so often in Bayesian statistics.</p>
</section>
<section id="tiny-code-5" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-5">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> beta</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Prior: Beta(2,2) ~ symmetric belief</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>alpha_prior, beta_prior <span class="op">=</span> <span class="dv">2</span>, <span class="dv">2</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Data: 8 heads out of 10 flips</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>heads, tails <span class="op">=</span> <span class="dv">8</span>, <span class="dv">2</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior hyperparameters</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>alpha_post <span class="op">=</span> alpha_prior <span class="op">+</span> heads</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>beta_post <span class="op">=</span> beta_prior <span class="op">+</span> tails</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>plt.plot(x, beta.pdf(x, alpha_prior, beta_prior), label<span class="op">=</span><span class="st">"Prior Beta(2,2)"</span>)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>plt.plot(x, beta.pdf(x, alpha_post, beta_post), label<span class="op">=</span><span class="ss">f"Posterior Beta(</span><span class="sc">{</span>alpha_post<span class="sc">}</span><span class="ss">,</span><span class="sc">{</span>beta_post<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Conjugacy: Beta Prior with Binomial Likelihood"</span>)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-5" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-5">Why It Matters</h4>
<p>Conjugacy provides closed-form updates, which are critical for online learning, real-time inference, and teaching intuition. While modern AI often relies on approximate inference, conjugate models remain the foundation for probabilistic reasoning and inspire algorithms like variational inference.</p>
</section>
<section id="try-it-yourself-5" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-5">Try It Yourself</h4>
<ol type="1">
<li>Start with a Beta(1,1) prior. Update it with 5 heads and 3 tails. Write down the posterior parameters.</li>
<li>Compare Beta(2,2) vs.&nbsp;Beta(20,20) priors with the same data. How does prior strength affect the posterior?</li>
<li>Explain why conjugate priors might be less realistic in complex, high-dimensional AI models.</li>
</ol>
</section>
</section>
<section id="map-vs.-full-bayesian-inference" class="level3">
<h3 class="anchored" data-anchor-id="map-vs.-full-bayesian-inference">507. MAP vs.&nbsp;Full Bayesian Inference</h3>
<p>There are two common ways to extract information from the posterior distribution:</p>
<ul>
<li>MAP (Maximum A Posteriori): pick the single parameter value with the highest posterior probability.</li>
<li>Full Bayesian Inference: keep the entire posterior distribution, using summaries like means, variances, or credible intervals.</li>
</ul>
<p>MAP is like taking the most likely guess, while full Bayesian inference preserves the whole range of uncertainty.</p>
<section id="picture-in-your-head-6" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-6">Picture in Your Head</h4>
<p>Imagine you’re hiking and looking at a valley’s shape. MAP is choosing the lowest point of the valley—the single “best” spot. Full Bayesian inference is looking at the entire valley landscape—its width, depth, and possible alternative paths.</p>
</section>
<section id="deep-dive-6" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-6">Deep Dive</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 8%">
<col style="width: 37%">
<col style="width: 27%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Description</th>
<th>Strengths</th>
<th>Weaknesses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>MAP</td>
<td><span class="math inline">\(\hat{\theta}_{MAP} = \arg\max_\theta P(\theta \mid D)\)</span></td>
<td>Simple, efficient, point estimate</td>
<td>Ignores uncertainty, can be misleading</td>
</tr>
<tr class="even">
<td>Full Bayesian</td>
<td>Use full posterior distribution</td>
<td>Captures uncertainty, richer predictions</td>
<td>More computationally expensive</td>
</tr>
</tbody>
</table>
<p>MAP is often equivalent to maximum likelihood estimation (MLE) with a prior. Full Bayesian inference allows predictive distributions, model averaging, and robust decision-making under uncertainty.</p>
</section>
<section id="tiny-code-6" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-6">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> beta</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior: Beta(8,4) after 7 heads, 3 tails with uniform prior</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>a, b <span class="op">=</span> <span class="dv">8</span>, <span class="dv">4</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>posterior <span class="op">=</span> beta(a, b)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># MAP estimate (mode of Beta)</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>map_est <span class="op">=</span> (a <span class="op">-</span> <span class="dv">1</span>) <span class="op">/</span> (a <span class="op">+</span> b <span class="op">-</span> <span class="dv">2</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>mean_est <span class="op">=</span> posterior.mean()</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MAP estimate:"</span>, map_est)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Full Bayesian mean:"</span>, mean_est)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-6" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-6">Why It Matters</h4>
<p>In AI, MAP is useful for quick estimates (e.g., classification). But relying only on MAP can hide uncertainty and lead to overconfident decisions. Full Bayesian inference, though costlier, enables uncertainty-aware systems—critical in medicine, autonomous driving, and financial forecasting.</p>
</section>
<section id="try-it-yourself-6" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-6">Try It Yourself</h4>
<ol type="1">
<li>Compute both MAP and posterior mean for Beta(3,3) after observing 2 heads and 1 tail.</li>
<li>Compare how MAP vs.&nbsp;full Bayesian predictions behave when the sample size is small.</li>
<li>Think of a real-world AI application (e.g., medical diagnosis): why might MAP be dangerous compared to using the full posterior?</li>
</ol>
</section>
</section>
<section id="bayesian-model-comparison" class="level3">
<h3 class="anchored" data-anchor-id="bayesian-model-comparison">508. Bayesian Model Comparison</h3>
<p>Bayesian model comparison evaluates how well different models explain observed data. Instead of just comparing parameter estimates, it compares the marginal likelihood (or model evidence) of each model, integrating over all possible parameters. This penalizes overly complex models while rewarding those that balance fit and simplicity.</p>
<section id="picture-in-your-head-7" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-7">Picture in Your Head</h4>
<p>Imagine several chefs cooking different dishes for the same set of judges. Likelihood measures how well a single dish matches the judges’ tastes. Model evidence, by contrast, considers the <em>whole menu</em> of possible dishes each chef could make. A chef with a flexible but disciplined style (not too many extravagant dishes) scores best overall.</p>
</section>
<section id="deep-dive-7" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-7">Deep Dive</h4>
<p>For model <span class="math inline">\(M\)</span>:</p>
<p><span class="math display">\[
P(M \mid D) \propto P(D \mid M) P(M)
\]</span></p>
<ul>
<li>Prior over models: <span class="math inline">\(P(M)\)</span></li>
<li>Evidence (marginal likelihood):</li>
</ul>
<p><span class="math display">\[
P(D \mid M) = \int P(D \mid \theta, M) P(\theta \mid M)\, d\theta
\]</span></p>
<ul>
<li>Posterior model probability: relative weight of each model given data</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 22%">
<col style="width: 44%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th>Approach</th>
<th>Idea</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Bayes Factor</td>
<td>Ratio of evidences between two models</td>
<td>Compare linear vs.&nbsp;quadratic regression</td>
</tr>
<tr class="even">
<td>Posterior Model Probability</td>
<td>Normalize across candidate models</td>
<td>Choose best classifier for a dataset</td>
</tr>
<tr class="odd">
<td>Model Averaging</td>
<td>Combine predictions weighted by posterior probability</td>
<td>Ensemble of Bayesian models</td>
</tr>
</tbody>
</table>
<p>This naturally incorporates Occam’s razor: complex models are penalized unless the data strongly justifies them.</p>
</section>
<section id="tiny-code-7" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-7">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare two models: data from N(0,1)</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.array([<span class="fl">0.2</span>, <span class="op">-</span><span class="fl">0.1</span>, <span class="fl">0.4</span>, <span class="fl">0.0</span>])</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 1: mean=0 fixed</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>evidence_m1 <span class="op">=</span> np.prod(norm.pdf(data, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 2: mean unknown, prior ~ N(0,1)</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Approximate evidence with integration grid</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>mu_vals <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">200</span>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>prior <span class="op">=</span> norm.pdf(mu_vals, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>likelihoods <span class="op">=</span> [np.prod(norm.pdf(data, loc<span class="op">=</span>mu, scale<span class="op">=</span><span class="dv">1</span>)) <span class="cf">for</span> mu <span class="kw">in</span> mu_vals]</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>evidence_m2 <span class="op">=</span> np.trapz(prior <span class="op">*</span> likelihoods, mu_vals)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>bayes_factor <span class="op">=</span> evidence_m1 <span class="op">/</span> evidence_m2</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Evidence M1:"</span>, evidence_m1)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Evidence M2:"</span>, evidence_m2)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Bayes Factor (M1/M2):"</span>, bayes_factor)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-7" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-7">Why It Matters</h4>
<p>Bayesian model comparison prevents overfitting and allows principled model selection. Instead of relying on ad hoc penalties (like AIC or BIC), it integrates uncertainty about parameters and reflects how much predictive support the data gives each model. This is vital for AI systems that must choose between competing explanations or architectures.</p>
</section>
<section id="try-it-yourself-7" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-7">Try It Yourself</h4>
<ol type="1">
<li>Compare a coin-flip model with bias <span class="math inline">\(p=0.5\)</span> vs.&nbsp;a model with unknown <span class="math inline">\(p\)</span> (uniform prior). Which has higher evidence after observing 8 heads, 2 tails?</li>
<li>Compute a Bayes factor for two regression models: linear vs.&nbsp;quadratic, given a small dataset.</li>
<li>Reflect: why is Bayesian model averaging often more reliable than picking a single “best” model?</li>
</ol>
</section>
</section>
<section id="predictive-distributions" class="level3">
<h3 class="anchored" data-anchor-id="predictive-distributions">509. Predictive Distributions</h3>
<p>A predictive distribution describes the probability of future or unseen data given what has already been observed. Instead of just estimating parameters, Bayesian inference integrates over the entire posterior, producing forecasts that naturally include uncertainty.</p>
<section id="picture-in-your-head-8" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-8">Picture in Your Head</h4>
<p>Think of predicting tomorrow’s weather. Instead of saying “it will rain with 70% chance because that’s the most likely parameter estimate,” the predictive distribution says: “based on all possible weather models weighted by our current beliefs, here’s the full distribution of tomorrow’s rainfall.”</p>
</section>
<section id="deep-dive-8" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-8">Deep Dive</h4>
<p>The formula is:</p>
<p><span class="math display">\[
P(D_{\text{new}} \mid D) = \int P(D_{\text{new}} \mid \theta)\, P(\theta \mid D)\, d\theta
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(D\)</span>: observed data</li>
<li><span class="math inline">\(D_{\text{new}}\)</span>: new or future data</li>
<li><span class="math inline">\(\theta\)</span>: model parameters</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 31%">
<col style="width: 53%">
</colgroup>
<thead>
<tr class="header">
<th>Step</th>
<th>Role</th>
<th>Example (Coin Flips)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Prior</td>
<td>Initial belief</td>
<td>Beta(1,1) over bias <span class="math inline">\(p\)</span></td>
</tr>
<tr class="even">
<td>Posterior</td>
<td>Updated belief</td>
<td>Beta(8,4) after 7H/3T</td>
</tr>
<tr class="odd">
<td>Predictive</td>
<td>Forecast new outcomes</td>
<td>Probability next flip = heads ≈ 0.67</td>
</tr>
</tbody>
</table>
<p>This predictive integrates over parameter uncertainty rather than relying on a single estimate.</p>
</section>
<section id="tiny-code-8" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-8">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> beta</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior after 7 heads, 3 tails: Beta(8,4)</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>alpha_post, beta_post <span class="op">=</span> <span class="dv">8</span>, <span class="dv">4</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictive probability next flip = expected value of p</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>predictive_prob_heads <span class="op">=</span> alpha_post <span class="op">/</span> (alpha_post <span class="op">+</span> beta_post)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predictive probability of heads:"</span>, predictive_prob_heads)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-8" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-8">Why It Matters</h4>
<p>Predictive distributions are essential in AI because they directly answer the question: <em>“What will happen next?”</em> They are used in forecasting, anomaly detection, reinforcement learning, and active decision-making. Unlike point estimates, predictive distributions capture both data variability and parameter uncertainty, leading to safer and more calibrated systems.</p>
</section>
<section id="try-it-yourself-8" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-8">Try It Yourself</h4>
<ol type="1">
<li>Compute the predictive probability of heads after observing 2 heads and 2 tails with a uniform prior.</li>
<li>Simulate predictive distributions for future coin flips (say, 10 more) using posterior sampling.</li>
<li>Think: in reinforcement learning, why does sampling from the predictive distribution (instead of greedy estimates) encourage better exploration?</li>
</ol>
</section>
</section>
<section id="philosophical-debates-bayesianism-vs.-frequentism" class="level3">
<h3 class="anchored" data-anchor-id="philosophical-debates-bayesianism-vs.-frequentism">510. Philosophical Debates: Bayesianism vs.&nbsp;Frequentism</h3>
<p>The divide between Bayesian and frequentist statistics is not just technical—it reflects different philosophies of probability and inference. Frequentists view probability as long-run frequencies of events, while Bayesians see it as a degree of belief that updates with evidence. This shapes how each approach handles parameters, uncertainty, and decision-making.</p>
<section id="picture-in-your-head-9" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-9">Picture in Your Head</h4>
<p>Imagine two doctors interpreting a diagnostic test. The frequentist says: <em>“If we tested infinite patients, this disease would appear 5% of the time.”</em> The Bayesian says: <em>“Given current evidence, there’s a 5% chance this patient has the disease.”</em> Both use the same data but answer subtly different questions.</p>
</section>
<section id="deep-dive-9" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-9">Deep Dive</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 42%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Dimension</th>
<th>Frequentist View</th>
<th>Bayesian View</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Probability</td>
<td>Long-run frequency of outcomes</td>
<td>Degree of belief, subjective or objective</td>
</tr>
<tr class="even">
<td>Parameters</td>
<td>Fixed but unknown</td>
<td>Random variables with distributions</td>
</tr>
<tr class="odd">
<td>Inference</td>
<td>Estimators, p-values, confidence intervals</td>
<td>Priors, likelihoods, posteriors</td>
</tr>
<tr class="even">
<td>Uncertainty</td>
<td>Comes from sampling variation</td>
<td>Comes from limited knowledge</td>
</tr>
<tr class="odd">
<td>Decision-Making</td>
<td>Often detached from inference</td>
<td>Integrated with utility and risk</td>
</tr>
</tbody>
</table>
<p>Frequentist methods dominate classical statistics and large-sample inference, where asymptotic properties shine. Bayesian methods excel in small data regimes, hierarchical modeling, and cases requiring prior knowledge. In practice, many modern AI systems combine both traditions.</p>
</section>
<section id="tiny-code-9" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-9">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm, beta</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Frequentist confidence interval for mean</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.array([<span class="fl">2.1</span>, <span class="fl">2.0</span>, <span class="fl">1.9</span>, <span class="fl">2.2</span>])</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> np.mean(data)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>se <span class="op">=</span> np.std(data, ddof<span class="op">=</span><span class="dv">1</span>) <span class="op">/</span> np.sqrt(<span class="bu">len</span>(data))</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>conf_int <span class="op">=</span> (mean <span class="op">-</span> <span class="fl">1.96</span><span class="op">*</span>se, mean <span class="op">+</span> <span class="fl">1.96</span><span class="op">*</span>se)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Bayesian credible interval for same data</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume prior ~ Normal(0, 1), likelihood ~ Normal(mean, sigma)</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>alpha_post <span class="op">=</span> <span class="dv">1</span> <span class="op">+</span> <span class="bu">len</span>(data)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>mu_post <span class="op">=</span> (<span class="dv">0</span> <span class="op">+</span> np.<span class="bu">sum</span>(data)) <span class="op">/</span> alpha_post</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>sigma_post <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> np.sqrt(alpha_post)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>credible_int <span class="op">=</span> (mu_post <span class="op">-</span> <span class="fl">1.96</span><span class="op">*</span>sigma_post, mu_post <span class="op">+</span> <span class="fl">1.96</span><span class="op">*</span>sigma_post)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Frequentist 95% CI:"</span>, conf_int)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Bayesian 95% Credible Interval:"</span>, credible_int)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-9" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-9">Why It Matters</h4>
<p>Understanding the philosophical split helps explain why methods differ, when they agree, and where each is best applied. In AI, frequentist tools give reliable guarantees for large datasets, while Bayesian methods provide principled uncertainty handling. Hybrid approaches—such as empirical Bayes or Bayesian deep learning—draw strength from both camps.</p>
</section>
<section id="try-it-yourself-9" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-9">Try It Yourself</h4>
<ol type="1">
<li>Compare how a frequentist vs.&nbsp;a Bayesian would phrase the conclusion of a medical trial showing a treatment effect.</li>
<li>For a coin flipped 10 times with 7 heads, write the frequentist estimate (MLE) and Bayesian posterior (with uniform prior). How do they differ?</li>
<li>Reflect: in AI safety, why might Bayesian reasoning be better suited for rare but high-impact risks?</li>
</ol>
</section>
</section>
</section>
<section id="chapter-52.-directed-graphical-modesl-bayesian-networks" class="level2">
<h2 class="anchored" data-anchor-id="chapter-52.-directed-graphical-modesl-bayesian-networks">Chapter 52. Directed Graphical Modesl (bayesian networks)</h2>
<section id="nodes-edges-and-conditional-independence" class="level3">
<h3 class="anchored" data-anchor-id="nodes-edges-and-conditional-independence">511. Nodes, Edges, and Conditional Independence</h3>
<p>Directed graphical models, or Bayesian networks, represent complex probability distributions using nodes (random variables) and edges (dependencies). The key idea is conditional independence: a variable is independent of others given its parents in the graph. This structure allows compact representation of high-dimensional distributions.</p>
<section id="picture-in-your-head-10" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-10">Picture in Your Head</h4>
<p>Think of a family tree. Each child’s traits depend on their parents, but once you know the parents, the grandparents add no further predictive power. Similarly, in a Bayesian network, edges carry influence, and conditional independence tells us when extra information no longer matters.</p>
</section>
<section id="deep-dive-10" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-10">Deep Dive</h4>
<p>A Bayesian network factorizes the joint distribution:</p>
<p><span class="math display">\[
P(X_1, \dots, X_n) = \prod_{i=1}^n P(X_i \mid \text{Parents}(X_i))
\]</span></p>
<ul>
<li>Nodes: random variables</li>
<li>Edges: direct dependencies</li>
<li>Parents: direct influencers of a node</li>
<li>Markov condition: each variable is independent of its non-descendants given its parents</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 36%">
<col style="width: 27%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="header">
<th>Structure</th>
<th>Conditional Independence</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Chain <span class="math inline">\(A \to B \to C\)</span></td>
<td><span class="math inline">\(A \perp C \mid B\)</span></td>
<td>Weather → Road Wet → Accident</td>
</tr>
<tr class="even">
<td>Fork <span class="math inline">\(A \leftarrow B \to C\)</span></td>
<td><span class="math inline">\(A \perp C \mid B\)</span></td>
<td>Genetics → Height, Weight</td>
</tr>
<tr class="odd">
<td>Collider <span class="math inline">\(A \to C \leftarrow B\)</span></td>
<td><span class="math inline">\(A \not\perp C \mid B\)</span></td>
<td>Studying → Grade ← Test Anxiety</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-10" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-10">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple Bayesian Network: A -&gt; B -&gt; C</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.DiGraph()</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>G.add_edges_from([(<span class="st">"A"</span>, <span class="st">"B"</span>), (<span class="st">"B"</span>, <span class="st">"C"</span>)])</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>pos <span class="op">=</span> nx.spring_layout(G)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>nx.draw(G, pos, with_labels<span class="op">=</span><span class="va">True</span>, node_size<span class="op">=</span><span class="dv">2000</span>, node_color<span class="op">=</span><span class="st">"lightblue"</span>, arrows<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Bayesian Network: A → B → C"</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-10" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-10">Why It Matters</h4>
<p>Conditional independence is the backbone of efficient reasoning. Instead of storing or computing the full joint distribution, Bayesian networks exploit structure to make inference tractable. In AI, this enables diagnosis systems, natural language models, and decision support where reasoning with uncertainty is required.</p>
</section>
<section id="try-it-yourself-10" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-10">Try It Yourself</h4>
<ol type="1">
<li>Write down the joint distribution for three binary variables <span class="math inline">\(A, B, C\)</span> arranged in a chain. How many parameters are needed with and without conditional independence?</li>
<li>Construct a fork structure with one parent and two children. Verify that the children are independent given the parent.</li>
<li>Reflect: why does conditioning on a collider (e.g., grades) create dependence between otherwise unrelated causes (e.g., studying and test anxiety)?</li>
</ol>
</section>
</section>
<section id="factorization-of-joint-distributions" class="level3">
<h3 class="anchored" data-anchor-id="factorization-of-joint-distributions">512. Factorization of Joint Distributions</h3>
<p>The power of Bayesian networks lies in their ability to break down a complex joint probability distribution into a product of local conditional distributions. Instead of modeling every possible combination of variables directly, the network structure specifies how to factorize the distribution efficiently.</p>
<section id="picture-in-your-head-11" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-11">Picture in Your Head</h4>
<p>Imagine trying to describe every possible meal by listing all full plates. That’s overwhelming. Instead, you describe meals by choosing from categories—main dish, side, and drink. The factorization principle does the same: it organizes the joint distribution into smaller, manageable pieces.</p>
</section>
<section id="deep-dive-11" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-11">Deep Dive</h4>
<p>General rule for a Bayesian network with nodes <span class="math inline">\(X_1, \dots, X_n\)</span>:</p>
<p><span class="math display">\[
P(X_1, X_2, \dots, X_n) = \prod_{i=1}^n P(X_i \mid \text{Parents}(X_i))
\]</span></p>
<p>Example. Three-node chain <span class="math inline">\(A \to B \to C\)</span>:</p>
<p><span class="math display">\[
P(A, B, C) = P(A) \cdot P(B \mid A) \cdot P(C \mid B)
\]</span></p>
<p>Without factorization:</p>
<ul>
<li>If all three are binary → <span class="math inline">\(2^3 - 1 = 7\)</span> independent parameters needed. With factorization:</li>
<li><span class="math inline">\(P(A)\)</span>: 1 parameter</li>
<li><span class="math inline">\(P(B \mid A)\)</span>: 2 parameters</li>
<li><span class="math inline">\(P(C \mid B)\)</span>: 2 parameters → Total = 5 parameters, not 7.</li>
</ul>
<p>This reduction scales dramatically in larger systems, where conditional independence can save exponential effort.</p>
</section>
<section id="tiny-code-11" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-11">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Factorization example: P(A)*P(B|A)*P(C|B)</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>P_A <span class="op">=</span> {<span class="dv">0</span>: <span class="fl">0.6</span>, <span class="dv">1</span>: <span class="fl">0.4</span>}</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>P_B_given_A <span class="op">=</span> {(<span class="dv">0</span>,<span class="dv">0</span>):<span class="fl">0.7</span>, (<span class="dv">0</span>,<span class="dv">1</span>):<span class="fl">0.3</span>, (<span class="dv">1</span>,<span class="dv">0</span>):<span class="fl">0.2</span>, (<span class="dv">1</span>,<span class="dv">1</span>):<span class="fl">0.8</span>}</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>P_C_given_B <span class="op">=</span> {(<span class="dv">0</span>,<span class="dv">0</span>):<span class="fl">0.9</span>, (<span class="dv">0</span>,<span class="dv">1</span>):<span class="fl">0.1</span>, (<span class="dv">1</span>,<span class="dv">0</span>):<span class="fl">0.4</span>, (<span class="dv">1</span>,<span class="dv">1</span>):<span class="fl">0.6</span>}</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> joint(a,b,c):</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (P_A[a] <span class="op">*</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>            P_B_given_A[(a,b)] <span class="op">*</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>            P_C_given_B[(b,c)])</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute full joint distribution</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>joint_dist <span class="op">=</span> {(a,b,c): joint(a,b,c) <span class="cf">for</span> a,b,c <span class="kw">in</span> itertools.product([<span class="dv">0</span>,<span class="dv">1</span>],[<span class="dv">0</span>,<span class="dv">1</span>],[<span class="dv">0</span>,<span class="dv">1</span>])}</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(joint_dist)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-11" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-11">Why It Matters</h4>
<p>Factorization makes inference and learning feasible in high-dimensional spaces. It underpins algorithms for reasoning in expert systems, natural language parsing, and robotics perception. By capturing dependencies only where they exist, Bayesian networks avoid combinatorial explosion.</p>
</section>
<section id="try-it-yourself-11" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-11">Try It Yourself</h4>
<ol type="1">
<li>For a fork structure <span class="math inline">\(A \to B, A \to C\)</span>, write down the joint factorization.</li>
<li>Compare parameter counts for a 5-node fully connected system vs.&nbsp;a chain. How many savings do you get?</li>
<li>Reflect: how does factorization relate to the design of neural networks, where layers enforce structured dependencies?</li>
</ol>
</section>
</section>
<section id="d-separation-and-graphical-criteria" class="level3">
<h3 class="anchored" data-anchor-id="d-separation-and-graphical-criteria">513. D-Separation and Graphical Criteria</h3>
<p>D-separation is the graphical test that tells us whether two sets of variables are conditionally independent given a third set in a Bayesian network. Instead of calculating probabilities directly, we can “read off” independence relations by inspecting the graph’s structure.</p>
<section id="picture-in-your-head-12" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-12">Picture in Your Head</h4>
<p>Imagine a system of pipes carrying information. Some paths are open, allowing influence to flow; others are blocked, stopping dependence. Conditioning on certain nodes either blocks or unblocks these paths. D-separation is the rulebook for figuring out which paths are active.</p>
</section>
<section id="deep-dive-12" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-12">Deep Dive</h4>
<p>Three key structures:</p>
<ol type="1">
<li><p>Chain: <span class="math inline">\(A \to B \to C\)</span></p>
<ul>
<li><span class="math inline">\(A \perp C \mid B\)</span></li>
<li>Conditioning on the middle blocks influence.</li>
</ul></li>
<li><p>Fork: <span class="math inline">\(A \leftarrow B \to C\)</span></p>
<ul>
<li><span class="math inline">\(A \perp C \mid B\)</span></li>
<li>Once the parent is known, the children are independent.</li>
</ul></li>
<li><p>Collider: <span class="math inline">\(A \to C \leftarrow B\)</span></p>
<ul>
<li><span class="math inline">\(A \not\perp C\)</span> unconditionally.</li>
<li>Conditioning on <span class="math inline">\(C\)</span> <em>creates</em> dependence between <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>.</li>
</ul></li>
</ol>
<p>D-separation formalizes this:</p>
<ul>
<li><p>A path is blocked if there’s a node where:</p>
<ul>
<li>The node is a chain or fork, and it is conditioned on.</li>
<li>The node is a collider, and neither it nor its descendants are conditioned on.</li>
</ul></li>
</ul>
<p>If <em>all</em> paths between two sets are blocked, the sets are d-separated (conditionally independent).</p>
</section>
<section id="tiny-code-12" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-12">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Collider example: A -&gt; C &lt;- B</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.DiGraph()</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>G.add_edges_from([(<span class="st">"A"</span>,<span class="st">"C"</span>),(<span class="st">"B"</span>,<span class="st">"C"</span>)])</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>pos <span class="op">=</span> nx.spring_layout(G, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>nx.draw(G, pos, with_labels<span class="op">=</span><span class="va">True</span>, node_size<span class="op">=</span><span class="dv">2000</span>, node_color<span class="op">=</span><span class="st">"lightgreen"</span>, arrows<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Collider Structure: A → C ← B"</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-12" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-12">Why It Matters</h4>
<p>D-separation allows inference without brute-force computation of probabilities. It lets AI systems decide which variables matter, which don’t, and when dependencies emerge. This is crucial in causal reasoning, feature selection, and designing efficient probabilistic models.</p>
</section>
<section id="try-it-yourself-12" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-12">Try It Yourself</h4>
<ol type="1">
<li>For a chain <span class="math inline">\(X \to Y \to Z\)</span>, are <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span> independent? What happens when conditioning on <span class="math inline">\(Y\)</span>?</li>
<li>In a collider <span class="math inline">\(X \to Z \leftarrow Y\)</span>, explain why observing <span class="math inline">\(Z\)</span> makes <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> dependent.</li>
<li>Draw a 4-node Bayesian network and practice identifying d-separated variable sets.</li>
</ol>
</section>
</section>
<section id="common-structures-chains-forks-colliders" class="level3">
<h3 class="anchored" data-anchor-id="common-structures-chains-forks-colliders">514. Common Structures: Chains, Forks, Colliders</h3>
<p>Bayesian networks are built from three primitive structures—chains, forks, and colliders. These patterns determine how information and dependencies flow between variables. Understanding them is essential for reading independence relations and designing probabilistic models.</p>
<section id="picture-in-your-head-13" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-13">Picture in Your Head</h4>
<p>Visualize water pipes again. In a chain, water flows straight through. In a fork, one source splits into two streams. In a collider, two separate streams collide into a junction. Whether water flows depends on which pipes are opened (conditioned on).</p>
</section>
<section id="deep-dive-13" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-13">Deep Dive</h4>
<ol type="1">
<li><p>Chain (<span class="math inline">\(A \to B \to C\)</span>)</p>
<ul>
<li><span class="math inline">\(A\)</span> influences <span class="math inline">\(C\)</span> through <span class="math inline">\(B\)</span>.</li>
<li><span class="math inline">\(A \perp C \mid B\)</span>.</li>
<li>Example: <em>Weather → Road Condition → Accident</em>.</li>
</ul></li>
<li><p>Fork (<span class="math inline">\(A \leftarrow B \to C\)</span>)</p>
<ul>
<li><span class="math inline">\(B\)</span> is a common cause of <span class="math inline">\(A\)</span> and <span class="math inline">\(C\)</span>.</li>
<li><span class="math inline">\(A \perp C \mid B\)</span>.</li>
<li>Example: <em>Genetics → Height, Weight</em>.</li>
</ul></li>
<li><p>Collider (<span class="math inline">\(A \to C \leftarrow B\)</span>)</p>
<ul>
<li><span class="math inline">\(C\)</span> is a common effect of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>.</li>
<li><span class="math inline">\(A \not\perp C\)</span> unconditionally.</li>
<li>Conditioning on <span class="math inline">\(C\)</span> induces dependence: <span class="math inline">\(A \not\perp C \mid B\)</span>.</li>
<li>Example: <em>Studying → Exam Grade ← Test Anxiety</em>.</li>
</ul></li>
</ol>
<table class="caption-top table">
<colgroup>
<col style="width: 8%">
<col style="width: 38%">
<col style="width: 52%">
</colgroup>
<thead>
<tr class="header">
<th>Structure</th>
<th>Independence Rule</th>
<th>Everyday Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Chain</td>
<td>Ends independent given middle</td>
<td>Weather blocks → Wet roads → Accidents</td>
</tr>
<tr class="even">
<td>Fork</td>
<td>Children independent given parent</td>
<td>Genetics explains both height and weight</td>
</tr>
<tr class="odd">
<td>Collider</td>
<td>Causes independent unless effect observed</td>
<td>Studying and anxiety become linked if we know exam grade</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-13" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-13">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>structures <span class="op">=</span> {</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Chain"</span>: [(<span class="st">"A"</span>,<span class="st">"B"</span>),(<span class="st">"B"</span>,<span class="st">"C"</span>)],</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Fork"</span>: [(<span class="st">"B"</span>,<span class="st">"A"</span>),(<span class="st">"B"</span>,<span class="st">"C"</span>)],</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Collider"</span>: [(<span class="st">"A"</span>,<span class="st">"C"</span>),(<span class="st">"B"</span>,<span class="st">"C"</span>)]</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">3</span>))</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax, (title, edges) <span class="kw">in</span> <span class="bu">zip</span>(axes, structures.items()):</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    G <span class="op">=</span> nx.DiGraph()</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    G.add_edges_from(edges)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    pos <span class="op">=</span> nx.spring_layout(G, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    nx.draw(G, pos, with_labels<span class="op">=</span><span class="va">True</span>, node_size<span class="op">=</span><span class="dv">1500</span>,</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>            node_color<span class="op">=</span><span class="st">"lightcoral"</span>, arrows<span class="op">=</span><span class="va">True</span>, ax<span class="op">=</span>ax)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    ax.set_title(title)</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-13" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-13">Why It Matters</h4>
<p>These three structures are the DNA of Bayesian networks. Every complex graph can be decomposed into them. By mastering chains, forks, and colliders, we can quickly assess conditional independencies, detect spurious correlations, and build interpretable probabilistic models.</p>
</section>
<section id="try-it-yourself-13" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-13">Try It Yourself</h4>
<ol type="1">
<li>Write the joint distribution factorization for each of the three structures.</li>
<li>For the collider case, simulate binary data and show how conditioning on the collider introduces correlation between the parent variables.</li>
<li>Reflect: how does misunderstanding collider bias lead to errors in real-world studies (e.g., selection bias in medical research)?</li>
</ol>
</section>
</section>
<section id="naïve-bayes-as-a-bayesian-network" class="level3">
<h3 class="anchored" data-anchor-id="naïve-bayes-as-a-bayesian-network">515. Naïve Bayes as a Bayesian Network</h3>
<p>Naïve Bayes is a simple but powerful Bayesian network where a single class variable directly influences all feature variables, assuming conditional independence between features given the class. Despite its unrealistic independence assumption, it often works surprisingly well in practice.</p>
<section id="picture-in-your-head-14" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-14">Picture in Your Head</h4>
<p>Imagine a teacher (the class variable) handing out homework assignments (features). Each student’s assignment depends only on the teacher’s choice of topic, not on the other students. Even if students actually influence each other in real life, the model pretends they don’t—yet it still predicts exam scores pretty well.</p>
</section>
<section id="deep-dive-14" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-14">Deep Dive</h4>
<p>Structure:</p>
<p><span class="math display">\[
C \to X_1, C \to X_2, \dots, C \to X_n
\]</span></p>
<p>Joint distribution:</p>
<p><span class="math display">\[
P(C, X_1, \dots, X_n) = P(C) \prod_{i=1}^n P(X_i \mid C)
\]</span></p>
<p>Key points:</p>
<ul>
<li>Assumption: features are independent given the class.</li>
<li>Learning: estimate conditional probabilities from data.</li>
<li>Prediction: use Bayes’ theorem to compute posterior class probabilities.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 30%">
<col style="width: 39%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="header">
<th>Strengths</th>
<th>Weaknesses</th>
<th>Applications</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Fast to train, requires little data</td>
<td>Assumes conditional independence</td>
<td>Spam filtering</td>
</tr>
<tr class="even">
<td>Robust to irrelevant features</td>
<td>Struggles when features are highly correlated</td>
<td>Document classification</td>
</tr>
<tr class="odd">
<td>Easy to interpret</td>
<td>Produces biased probability estimates</td>
<td>Medical diagnosis (early systems)</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-14" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-14">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> MultinomialNB</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: classify documents as spam/ham based on word counts</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array([[<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>], [<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">3</span>], [<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>], [<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>]])  <span class="co"># word features</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.array([<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>])  <span class="co"># 0=ham, 1=spam</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MultinomialNB()</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>model.fit(X, y)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> np.array([[<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>]])  <span class="co"># new doc</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted class:"</span>, model.predict(test))</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Posterior probs:"</span>, model.predict_proba(test))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-14" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-14">Why It Matters</h4>
<p>Naïve Bayes shows how Bayesian networks can be simplified into practical classifiers. It illustrates the trade-off between model assumptions and computational efficiency. Even with unrealistic independence assumptions, its predictive success demonstrates the power of probabilistic reasoning in AI.</p>
</section>
<section id="try-it-yourself-14" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-14">Try It Yourself</h4>
<ol type="1">
<li>Draw the Bayesian network structure for Naïve Bayes with one class variable and three features.</li>
<li>Train a Naïve Bayes classifier on a toy dataset (e.g., fruit classification by color, weight, shape). Compare predicted vs.&nbsp;actual outcomes.</li>
<li>Reflect: why does Naïve Bayes often perform well even when its independence assumption is violated?</li>
</ol>
</section>
</section>
<section id="hidden-markov-models-as-dags" class="level3">
<h3 class="anchored" data-anchor-id="hidden-markov-models-as-dags">516. Hidden Markov Models as DAGs</h3>
<p>Hidden Markov Models (HMMs) are a special case of Bayesian networks where hidden states form a chain, and each state emits an observation. The states are not directly observed but can be inferred through their probabilistic relationship with the visible outputs.</p>
<section id="picture-in-your-head-15" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-15">Picture in Your Head</h4>
<p>Imagine watching someone walk through rooms in a house, but you can’t see the person—only hear noises (footsteps, doors closing, water running). The hidden states are the rooms, the sounds are the observations. By piecing together the sequence of sounds, you infer the most likely path through the house.</p>
</section>
<section id="deep-dive-15" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-15">Deep Dive</h4>
<p>Structure:</p>
<ul>
<li>Hidden states: <span class="math inline">\(Z_1 \to Z_2 \to \dots \to Z_T\)</span> (Markov chain)</li>
<li>Observations: each <span class="math inline">\(Z_t \to X_t\)</span></li>
</ul>
<p>Factorization:</p>
<p><span class="math display">\[
P(Z_{1:T}, X_{1:T}) = P(Z_1) \prod_{t=2}^T P(Z_t \mid Z_{t-1}) \prod_{t=1}^T P(X_t \mid Z_t)
\]</span></p>
<p>Key components:</p>
<ul>
<li>Transition model: <span class="math inline">\(P(Z_t \mid Z_{t-1})\)</span></li>
<li>Emission model: <span class="math inline">\(P(X_t \mid Z_t)\)</span></li>
<li>Initial distribution: <span class="math inline">\(P(Z_1)\)</span></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Algorithm</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Forward-Backward</td>
<td>Computes marginals (filtering, smoothing)</td>
</tr>
<tr class="even">
<td>Viterbi</td>
<td>Finds most likely hidden state sequence</td>
</tr>
<tr class="odd">
<td>Baum-Welch (EM)</td>
<td>Learns parameters from data</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-15" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-15">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> hmmlearn <span class="im">import</span> hmm</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: 2 hidden states, 3 possible observations</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> hmm.MultinomialHMM(n_components<span class="op">=</span><span class="dv">2</span>, n_iter<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Transition, emission, and initial probabilities</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>model.startprob_ <span class="op">=</span> np.array([<span class="fl">0.6</span>, <span class="fl">0.4</span>])</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>model.transmat_ <span class="op">=</span> np.array([[<span class="fl">0.7</span>, <span class="fl">0.3</span>],</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>                            [<span class="fl">0.4</span>, <span class="fl">0.6</span>]])</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>model.emissionprob_ <span class="op">=</span> np.array([[<span class="fl">0.5</span>, <span class="fl">0.4</span>, <span class="fl">0.1</span>],</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>                                [<span class="fl">0.1</span>, <span class="fl">0.3</span>, <span class="fl">0.6</span>]])</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate sequence</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>X, Z <span class="op">=</span> model.sample(<span class="dv">10</span>)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Observations:"</span>, X.ravel())</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Hidden states:"</span>, Z)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-15" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-15">Why It Matters</h4>
<p>Viewing HMMs as DAGs connects sequential modeling with general probabilistic reasoning. This perspective helps extend HMMs into richer models like Dynamic Bayesian Networks, Kalman filters, and modern sequence-to-sequence architectures. HMMs remain foundational in speech recognition, bioinformatics, and time series analysis.</p>
</section>
<section id="try-it-yourself-15" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-15">Try It Yourself</h4>
<ol type="1">
<li>Draw the Bayesian network structure for a 3-step HMM with hidden states <span class="math inline">\(Z_1, Z_2, Z_3\)</span> and observations <span class="math inline">\(X_1, X_2, X_3\)</span>.</li>
<li>Simulate a short sequence of hidden states and observations. Compute the joint probability manually using the factorization.</li>
<li>Reflect: how does the assumption of the Markov property (dependence only on the previous state) simplify inference?</li>
</ol>
</section>
</section>
<section id="parameter-learning-in-bns" class="level3">
<h3 class="anchored" data-anchor-id="parameter-learning-in-bns">517. Parameter Learning in BNs</h3>
<p>Parameter learning in Bayesian networks means estimating the conditional probability tables (CPTs) that govern each node’s behavior given its parents. Depending on whether data is complete (all variables observed) or incomplete (some hidden), learning can be straightforward or require iterative algorithms.</p>
<section id="picture-in-your-head-16" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-16">Picture in Your Head</h4>
<p>Think of filling in recipe cards for a cookbook. Each recipe card (CPT) tells you how likely different ingredients (child variable outcomes) are, given the choice of base flavor (parent variable values). If you have full notes from past meals, writing the cards is easy. If some notes are missing, you have to guess and refine iteratively.</p>
</section>
<section id="deep-dive-16" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-16">Deep Dive</h4>
<ul>
<li><p>Complete data: parameter learning reduces to frequency counting.</p>
<ul>
<li>Example: if <span class="math inline">\(P(B \mid A)\)</span> is required, count how often each value of <span class="math inline">\(B\)</span> occurs given <span class="math inline">\(A\)</span>.</li>
</ul></li>
<li><p>Incomplete/hidden data: requires Expectation-Maximization (EM) or Bayesian estimation with priors.</p></li>
<li><p>Smoothing: use priors (like Dirichlet) to avoid zero probabilities.</p></li>
</ul>
<p>Formally:</p>
<p><span class="math display">\[
\hat{P}(X_i \mid \text{Parents}(X_i)) = \frac{\text{Count}(X_i, \text{Parents}(X_i))}{\text{Count}(\text{Parents}(X_i))}
\]</span></p>
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 39%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Case</th>
<th>Method</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Complete data</td>
<td>Maximum likelihood via counts</td>
<td>Disease → Symptom from patient records</td>
</tr>
<tr class="even">
<td>Missing data</td>
<td>EM algorithm</td>
<td>Hidden disease state, observed symptoms</td>
</tr>
<tr class="odd">
<td>Bayesian learning</td>
<td>Prior (Dirichlet) + data → posterior</td>
<td>Text classification with sparse counts</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-16" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-16">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example dataset: A -&gt; B</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"A"</span>: [<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>],</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"B"</span>: [<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>]</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate P(B|A)</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>cpt <span class="op">=</span> data.groupby(<span class="st">"A"</span>)[<span class="st">"B"</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>).unstack()</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Conditional Probability Table (P(B|A)):</span><span class="ch">\n</span><span class="st">"</span>, cpt)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-16" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-16">Why It Matters</h4>
<p>Parameter learning turns abstract network structures into working models. In AI applications like medical diagnosis, fault detection, or user modeling, the reliability of predictions hinges on accurate CPTs. Handling missing data gracefully is especially important in real-world systems where observations are rarely complete.</p>
</section>
<section id="try-it-yourself-16" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-16">Try It Yourself</h4>
<ol type="1">
<li>Given data for a network <span class="math inline">\(A \to B\)</span>, calculate <span class="math inline">\(P(B=1 \mid A=0)\)</span> and <span class="math inline">\(P(B=1 \mid A=1)\)</span>.</li>
<li>Add Laplace smoothing by assuming a Dirichlet(1,1) prior for each conditional distribution. Compare results.</li>
<li>Reflect: why is EM necessary when hidden variables (like unobserved disease states) are part of the network?</li>
</ol>
</section>
</section>
<section id="structure-learning-from-data" class="level3">
<h3 class="anchored" data-anchor-id="structure-learning-from-data">518. Structure Learning from Data</h3>
<p>Structure learning in Bayesian networks is the task of discovering the graph—nodes and edges—that best represents dependencies in the data. Unlike parameter learning, where the structure is fixed and only probabilities are estimated, structure learning tries to infer “who influences whom.”</p>
<section id="picture-in-your-head-17" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-17">Picture in Your Head</h4>
<p>Imagine you’re mapping out a family tree, but all you have are pictures of relatives. You notice resemblances—eye color, height, facial features—and use them to guess the parent-child links. Structure learning works the same way: it detects statistical dependencies and builds a plausible network.</p>
</section>
<section id="deep-dive-17" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-17">Deep Dive</h4>
<p>There are three main approaches:</p>
<ol type="1">
<li><p>Constraint-based methods</p>
<ul>
<li>Use conditional independence tests to accept or reject edges.</li>
<li>Example: PC algorithm.</li>
</ul></li>
<li><p>Score-based methods</p>
<ul>
<li>Define a scoring function (e.g., BIC, AIC, marginal likelihood) for candidate structures.</li>
<li>Search over graph space using greedy search, hill climbing, or MCMC.</li>
</ul></li>
<li><p>Hybrid methods</p>
<ul>
<li>Combine independence tests with scoring for efficiency and accuracy.</li>
</ul></li>
</ol>
<p>Challenges:</p>
<ul>
<li>Search space grows super-exponentially with variables.</li>
<li>Need to avoid overfitting with limited data.</li>
<li>Domain knowledge can guide or restrict possible edges.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 44%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th>Approach</th>
<th>Advantage</th>
<th>Weakness</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Constraint-based</td>
<td>Clear independence interpretation</td>
<td>Sensitive to noisy tests</td>
</tr>
<tr class="even">
<td>Score-based</td>
<td>Flexible, compares models</td>
<td>Computationally expensive</td>
</tr>
<tr class="odd">
<td>Hybrid</td>
<td>Balances both</td>
<td>Still heuristic, not exact</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-17" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-17">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.estimators <span class="im">import</span> HillClimbSearch, BicScore</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Example data</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"A"</span>: [<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>],</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"B"</span>: [<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>],</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"C"</span>: [<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>]</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Score-based structure learning</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>hc <span class="op">=</span> HillClimbSearch(data)</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>best_model <span class="op">=</span> hc.estimate(scoring_method<span class="op">=</span>BicScore(data))</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Learned structure edges:"</span>, best_model.edges())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-17" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-17">Why It Matters</h4>
<p>Structure learning allows AI systems to uncover causal and probabilistic relationships automatically, instead of relying solely on expert-designed networks. This is vital in domains like genomics, neuroscience, and finance, where hidden dependencies can reveal new knowledge.</p>
</section>
<section id="try-it-yourself-17" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-17">Try It Yourself</h4>
<ol type="1">
<li>For three variables <span class="math inline">\(A, B, C\)</span>, compute correlations and sketch a candidate Bayesian network.</li>
<li>Run a score-based search with different scoring functions (AIC vs.&nbsp;BIC). How does the learned structure change?</li>
<li>Reflect: why is structure learning often seen as a bridge between machine learning and causal discovery?</li>
</ol>
</section>
</section>
<section id="inference-in-bayesian-networks" class="level3">
<h3 class="anchored" data-anchor-id="inference-in-bayesian-networks">519. Inference in Bayesian Networks</h3>
<p>Inference in Bayesian networks means answering probabilistic queries: computing the probability of some variables given evidence about others. This involves propagating information through the network using the conditional independence encoded in its structure.</p>
<section id="picture-in-your-head-18" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-18">Picture in Your Head</h4>
<p>Think of a rumor spreading in a social network. If you learn that one person knows the rumor (evidence), you can update your beliefs about who else might know it by tracing paths of influence. Bayesian networks work the same way: evidence at one node ripples through the graph.</p>
</section>
<section id="deep-dive-18" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-18">Deep Dive</h4>
<p>Types of queries:</p>
<ul>
<li>Marginal probability: <span class="math inline">\(P(X)\)</span></li>
<li>Conditional probability: <span class="math inline">\(P(X \mid E)\)</span></li>
<li>Most probable explanation (MPE): find the most likely assignment to all variables given evidence</li>
<li>MAP query: find the most likely assignment to a subset of variables given evidence</li>
</ul>
<p>Algorithms:</p>
<ul>
<li><p>Exact methods:</p>
<ul>
<li>Variable elimination</li>
<li>Belief propagation (message passing)</li>
<li>Junction tree algorithm</li>
</ul></li>
<li><p>Approximate methods:</p>
<ul>
<li>Monte Carlo sampling (likelihood weighting, Gibbs sampling)</li>
<li>Variational inference</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 28%">
<col style="width: 31%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Strength</th>
<th>Limitation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Variable elimination</td>
<td>Simple, exact</td>
<td>Exponential in worst case</td>
</tr>
<tr class="even">
<td>Belief propagation</td>
<td>Efficient in trees</td>
<td>Approximate in loopy graphs</td>
</tr>
<tr class="odd">
<td>Sampling</td>
<td>Scales to large graphs</td>
<td>Can converge slowly</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-18" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-18">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.models <span class="im">import</span> BayesianNetwork</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.inference <span class="im">import</span> VariableElimination</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple BN: A -&gt; B -&gt; C</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> BayesianNetwork([(<span class="st">"A"</span>,<span class="st">"B"</span>),(<span class="st">"B"</span>,<span class="st">"C"</span>)])</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>model.fit([[<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>],[<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>],[<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>],[<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>]], estimator<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform inference</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>inference <span class="op">=</span> VariableElimination(model)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> inference.query(variables<span class="op">=</span>[<span class="st">"C"</span>], evidence<span class="op">=</span>{<span class="st">"A"</span>:<span class="dv">1</span>})</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(result)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-18" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-18">Why It Matters</h4>
<p>Inference is the reason we build Bayesian networks: to answer real questions under uncertainty. Whether diagnosing diseases, detecting faults in engineering systems, or parsing natural language, inference allows AI systems to connect evidence to hidden causes and predictions.</p>
</section>
<section id="try-it-yourself-18" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-18">Try It Yourself</h4>
<ol type="1">
<li>Build a small 3-node Bayesian network and compute <span class="math inline">\(P(C \mid A=1)\)</span>.</li>
<li>Compare results of exact inference (variable elimination) with sampling-based approximation.</li>
<li>Reflect: why do approximate methods dominate in large-scale AI systems even though exact inference exists?</li>
</ol>
</section>
</section>
<section id="applications-medicine-diagnosis-expert-systems" class="level3">
<h3 class="anchored" data-anchor-id="applications-medicine-diagnosis-expert-systems">520. Applications: Medicine, Diagnosis, Expert Systems</h3>
<p>Bayesian networks have long been used in domains where reasoning under uncertainty is crucial. By encoding causal and probabilistic relationships, they allow systematic diagnosis, prediction, and decision support. Medicine, fault detection, and expert systems were among the earliest real-world applications.</p>
<section id="picture-in-your-head-19" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-19">Picture in Your Head</h4>
<p>Think of a doctor with a mental map of diseases and symptoms. Each disease probabilistically leads to certain symptoms. When a patient presents evidence (observed symptoms), the doctor updates their belief about possible diseases. A Bayesian network is the formal version of this reasoning process.</p>
</section>
<section id="deep-dive-19" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-19">Deep Dive</h4>
<p>Classic applications:</p>
<ul>
<li>Medical diagnosis: networks like PATHFINDER (hematopathology) and QMR-DT (Quick Medical Reference) modeled diseases, findings, and test results.</li>
<li>Fault diagnosis: in engineering systems (e.g., aircraft, power grids), networks connect sensor readings to possible failure modes.</li>
<li>Expert systems: early AI used rule-based systems; Bayesian networks added probabilistic reasoning, making them more robust to uncertainty.</li>
</ul>
<p>Workflow:</p>
<ol type="1">
<li>Encode domain knowledge as structure (diseases → symptoms).</li>
<li>Collect prior probabilities and conditional dependencies.</li>
<li>Use inference to update beliefs given observed evidence.</li>
</ol>
<table class="caption-top table">
<colgroup>
<col style="width: 9%">
<col style="width: 39%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Domain</th>
<th>Benefit</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Medicine</td>
<td>Probabilistic diagnosis, explainable reasoning</td>
<td>Predicting cancer likelihood from symptoms and test results</td>
</tr>
<tr class="even">
<td>Engineering</td>
<td>Fault detection, proactive maintenance</td>
<td>Aircraft sensor anomalies → failure probabilities</td>
</tr>
<tr class="odd">
<td>Ecology</td>
<td>Modeling interactions in ecosystems</td>
<td>Weather → crop yields → food supply</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-19" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-19">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.models <span class="im">import</span> BayesianNetwork</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.inference <span class="im">import</span> VariableElimination</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Disease -&gt; Symptom</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> BayesianNetwork([(<span class="st">"Disease"</span>, <span class="st">"Symptom"</span>)])</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Define CPTs</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>cpt_disease <span class="op">=</span> pd.DataFrame([{<span class="st">"Disease"</span>:<span class="dv">0</span>,<span class="st">"p"</span>:<span class="fl">0.99</span>},{<span class="st">"Disease"</span>:<span class="dv">1</span>,<span class="st">"p"</span>:<span class="fl">0.01</span>}])</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>cpt_symptom <span class="op">=</span> pd.DataFrame([</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"Disease"</span>:<span class="dv">0</span>,<span class="st">"Symptom"</span>:<span class="dv">0</span>,<span class="st">"p"</span>:<span class="fl">0.95</span>},</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"Disease"</span>:<span class="dv">0</span>,<span class="st">"Symptom"</span>:<span class="dv">1</span>,<span class="st">"p"</span>:<span class="fl">0.05</span>},</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"Disease"</span>:<span class="dv">1</span>,<span class="st">"Symptom"</span>:<span class="dv">0</span>,<span class="st">"p"</span>:<span class="fl">0.1</span>},</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"Disease"</span>:<span class="dv">1</span>,<span class="st">"Symptom"</span>:<span class="dv">1</span>,<span class="st">"p"</span>:<span class="fl">0.9</span>}</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>model.fit([{<span class="st">"Disease"</span>:<span class="dv">0</span>,<span class="st">"Symptom"</span>:<span class="dv">0</span>}], estimator<span class="op">=</span><span class="va">None</span>)  <span class="co"># placeholder</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>inference <span class="op">=</span> VariableElimination(model)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Query: probability of disease given symptom=1</span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a><span class="co"># (pseudo-example; real CPTs must be added properly)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-19" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-19">Why It Matters</h4>
<p>Applications show why Bayesian networks remain relevant. They provide interpretable reasoning, can combine expert knowledge with data, and remain competitive in domains where trust and uncertainty quantification are essential. Modern systems often combine them with machine learning for hybrid approaches.</p>
</section>
<section id="try-it-yourself-19" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-19">Try It Yourself</h4>
<ol type="1">
<li>Draw a small Bayesian network with three diseases and overlapping symptoms. Run inference for a patient with two symptoms.</li>
<li>Consider a fault detection system: how would conditional independence reduce the number of probabilities you must estimate?</li>
<li>Reflect: why are Bayesian networks particularly valued in domains like healthcare, where interpretability and uncertainty are as important as accuracy?</li>
</ol>
</section>
</section>
</section>
<section id="chapter-53.-undirected-graphical-models-mrfs-crfs" class="level2">
<h2 class="anchored" data-anchor-id="chapter-53.-undirected-graphical-models-mrfs-crfs">Chapter 53. Undirected Graphical Models (MRFs, CRFs)</h2>
<section id="markov-random-fields-potentials-and-cliques" class="level3">
<h3 class="anchored" data-anchor-id="markov-random-fields-potentials-and-cliques">521. Markov Random Fields: Potentials and Cliques</h3>
<p>A Markov Random Field (MRF) is an undirected graphical model where dependencies between variables are captured through cliques—fully connected subsets of nodes. Instead of conditional probabilities along directed edges, MRFs use potential functions over cliques to define how strongly configurations of variables are favored.</p>
<section id="picture-in-your-head-20" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-20">Picture in Your Head</h4>
<p>Think of a neighborhood where each house (variable) only interacts with its immediate neighbors. There’s no notion of “direction” in who influences whom—everyone just influences each other mutually. The strength of these interactions is encoded in the potential functions, like how much neighbors like to match paint colors on their houses.</p>
</section>
<section id="deep-dive-20" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-20">Deep Dive</h4>
<ul>
<li>Undirected graph: no parent–child relations, just mutual constraints.</li>
<li>Clique: a subset of nodes where every pair is connected.</li>
<li>Potential function <span class="math inline">\(\phi(C)\)</span>: assigns a non-negative weight to each possible configuration of variables in clique <span class="math inline">\(C\)</span>.</li>
<li>Joint distribution:</li>
</ul>
<p><span class="math display">\[
P(X_1, \dots, X_n) = \frac{1}{Z} \prod_{C \in \mathcal{C}} \phi_C(X_C)
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mathcal{C}\)</span> = set of cliques</li>
<li><span class="math inline">\(Z\)</span> = partition function (normalization constant):</li>
</ul>
<p><span class="math display">\[
Z = \sum_x \prod_{C \in \mathcal{C}} \phi_C(x_C)
\]</span></p>
<table class="caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 34%">
<col style="width: 52%">
</colgroup>
<thead>
<tr class="header">
<th>Term</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Node</td>
<td>Random variable</td>
<td>Pixel intensity</td>
</tr>
<tr class="even">
<td>Edge</td>
<td>Dependency between nodes</td>
<td>Neighboring pixels</td>
</tr>
<tr class="odd">
<td>Clique</td>
<td>Fully connected subgraph</td>
<td>2×2 patch of pixels</td>
</tr>
<tr class="even">
<td>Potential</td>
<td>Compatibility score</td>
<td>Similar colors in neighboring pixels</td>
</tr>
</tbody>
</table>
<p>MRFs are particularly suited to domains where local interactions dominate, such as images, spatial data, or grids.</p>
</section>
<section id="tiny-code-20" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-20">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple pairwise MRF: two binary variables X1, X2</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Clique potential: prefer same values</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>phi <span class="op">=</span> {(<span class="dv">0</span>,<span class="dv">0</span>):<span class="fl">2.0</span>, (<span class="dv">0</span>,<span class="dv">1</span>):<span class="fl">1.0</span>, (<span class="dv">1</span>,<span class="dv">0</span>):<span class="fl">1.0</span>, (<span class="dv">1</span>,<span class="dv">1</span>):<span class="fl">2.0</span>}</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute unnormalized probabilities</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>unnormalized <span class="op">=</span> {x: phi[x] <span class="cf">for</span> x <span class="kw">in</span> phi}</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Partition function</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> <span class="bu">sum</span>(unnormalized.values())</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalized distribution</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>P <span class="op">=</span> {x: val<span class="op">/</span>Z <span class="cf">for</span> x, val <span class="kw">in</span> unnormalized.items()}</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Joint distribution:"</span>, P)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-20" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-20">Why It Matters</h4>
<p>MRFs provide a flexible framework for modeling spatially structured data and problems where influence is symmetric. They are widely used in computer vision (image denoising, segmentation), natural language processing, and statistical physics (Ising models). Understanding potentials and cliques sets the stage for inference and learning in undirected models.</p>
</section>
<section id="try-it-yourself-20" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-20">Try It Yourself</h4>
<ol type="1">
<li>Construct a 3-node chain MRF with binary variables. Assign clique potentials that favor agreement between neighbors. Write down the joint distribution.</li>
<li>Compute the partition function for a small MRF with 2–3 variables. How does it scale with graph size?</li>
<li>Reflect: why do MRFs rely on unnormalized potentials instead of direct probabilities like Bayesian networks?</li>
</ol>
</section>
</section>
<section id="conditional-random-fields-for-structured-prediction" class="level3">
<h3 class="anchored" data-anchor-id="conditional-random-fields-for-structured-prediction">522. Conditional Random Fields for Structured Prediction</h3>
<p>Conditional Random Fields (CRFs) are undirected graphical models designed for predicting structured outputs. Unlike MRFs, which model joint distributions <span class="math inline">\(P(X,Y)\)</span>, CRFs directly model the conditional distribution <span class="math inline">\(P(Y \mid X)\)</span>, where <span class="math inline">\(X\)</span> are inputs (observed features) and <span class="math inline">\(Y\)</span> are outputs (labels). This makes CRFs discriminative models, focusing only on what matters for prediction.</p>
<section id="picture-in-your-head-21" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-21">Picture in Your Head</h4>
<p>Imagine labeling words in a sentence with parts of speech. Each word depends not only on its own features (like spelling or capitalization) but also on the labels of its neighbors. A CRF is like a “team decision” process where each label is chosen with awareness of adjacent labels, ensuring consistency across the sequence.</p>
</section>
<section id="deep-dive-21" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-21">Deep Dive</h4>
<p>For CRFs, the conditional probability is:</p>
<p><span class="math display">\[
P(Y \mid X) = \frac{1}{Z(X)} \prod_{C \in \mathcal{C}} \phi_C(Y_C, X)
\]</span></p>
<ul>
<li><span class="math inline">\(X\)</span>: observed input sequence/features</li>
<li><span class="math inline">\(Y\)</span>: output labels</li>
<li><span class="math inline">\(\phi_C\)</span>: potential functions over cliques (dependent on both <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>)</li>
<li><span class="math inline">\(Z(X)\)</span>: normalization constant specific to input <span class="math inline">\(X\)</span></li>
</ul>
<p>Types of CRFs:</p>
<ul>
<li>Linear-chain CRFs: used for sequences (POS tagging, NER).</li>
<li>General CRFs: for arbitrary graph structures (image segmentation, relational data).</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 40%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="header">
<th>Aspect</th>
<th>MRF</th>
<th>CRF</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Distribution</td>
<td>Joint <span class="math inline">\(P(X,Y)\)</span></td>
<td>Conditional <span class="math inline">\(P(Y \mid X)\)</span></td>
</tr>
<tr class="even">
<td>Use case</td>
<td>Modeling data generatively</td>
<td>Prediction tasks</td>
</tr>
<tr class="odd">
<td>Features</td>
<td>Limited to node/edge variables</td>
<td>Can use arbitrary input features</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-21" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-21">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn_crfsuite <span class="im">import</span> CRF</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: POS tagging</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> [[{<span class="st">"word"</span>:<span class="st">"dog"</span>}, {<span class="st">"word"</span>:<span class="st">"runs"</span>}],</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>           [{<span class="st">"word"</span>:<span class="st">"cat"</span>}, {<span class="st">"word"</span>:<span class="st">"sleeps"</span>}]]</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> [[<span class="st">"NOUN"</span>,<span class="st">"VERB"</span>], [<span class="st">"NOUN"</span>,<span class="st">"VERB"</span>]]</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>crf <span class="op">=</span> CRF(algorithm<span class="op">=</span><span class="st">"lbfgs"</span>, max_iterations<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>crf.fit(X_train, y_train)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> [[{<span class="st">"word"</span>:<span class="st">"bird"</span>}, {<span class="st">"word"</span>:<span class="st">"flies"</span>}]]</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Prediction:"</span>, crf.predict(X_test))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-21" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-21">Why It Matters</h4>
<p>CRFs are central to structured prediction tasks in AI. They allow us to model interdependencies among outputs while incorporating rich, overlapping input features. This flexibility made CRFs dominant in NLP before deep learning and they remain widely used in hybrid neural-symbolic systems.</p>
</section>
<section id="try-it-yourself-21" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-21">Try It Yourself</h4>
<ol type="1">
<li>Implement a linear-chain CRF for named entity recognition on a small text dataset.</li>
<li>Compare predictions from logistic regression (independent labels) vs.&nbsp;a CRF (dependent labels).</li>
<li>Reflect: why does conditioning on inputs <span class="math inline">\(X\)</span> free CRFs from modeling the often intractable distribution of inputs?</li>
</ol>
</section>
</section>
<section id="factor-graphs-and-hybrid-representations" class="level3">
<h3 class="anchored" data-anchor-id="factor-graphs-and-hybrid-representations">523. Factor Graphs and Hybrid Representations</h3>
<p>A factor graph is a bipartite representation of a probabilistic model. Instead of connecting variables directly, it introduces factor nodes that represent functions (potentials) over subsets of variables. Factor graphs unify directed and undirected models, making inference algorithms like belief propagation easier to describe.</p>
<section id="picture-in-your-head-22" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-22">Picture in Your Head</h4>
<p>Think of a group project where students (variables) don’t just influence each other directly. Instead, they interact through shared tasks (factors). Each task ties together the students working on it, and the project outcome depends on how all tasks are performed collectively.</p>
</section>
<section id="deep-dive-22" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-22">Deep Dive</h4>
<ul>
<li>Variables: circles in the graph.</li>
<li>Factors: squares (functions over subsets of variables).</li>
<li>Edges: connect factors to variables they involve.</li>
</ul>
<p>Joint distribution factorizes as:</p>
<p><span class="math display">\[
P(X_1, \dots, X_n) = \frac{1}{Z} \prod_{f \in \mathcal{F}} f(X_{N(f)})
\]</span></p>
<p>where <span class="math inline">\(N(f)\)</span> are the variables connected to factor <span class="math inline">\(f\)</span>.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 51%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Representation</th>
<th>Characteristics</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Bayesian Network</td>
<td>Directed edges, conditional probabilities</td>
<td><span class="math inline">\(P(A)P(B\mid A)\)</span></td>
</tr>
<tr class="even">
<td>MRF</td>
<td>Undirected edges, clique potentials</td>
<td>Image grids</td>
</tr>
<tr class="odd">
<td>Factor Graph</td>
<td>Bipartite: variables ↔︎ factors</td>
<td>General-purpose, hybrid</td>
</tr>
</tbody>
</table>
<p>Factor graphs are particularly useful in coding theory (LDPC, turbo codes) and probabilistic inference (message passing).</p>
</section>
<section id="tiny-code-22" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-22">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Factor graph with variables {A,B,C}, factors {f1,f2}</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.Graph()</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>G.add_nodes_from([<span class="st">"A"</span>,<span class="st">"B"</span>,<span class="st">"C"</span>], bipartite<span class="op">=</span><span class="dv">0</span>)  <span class="co"># variables</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>G.add_nodes_from([<span class="st">"f1"</span>,<span class="st">"f2"</span>], bipartite<span class="op">=</span><span class="dv">1</span>)    <span class="co"># factors</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Connect factors to variables</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>G.add_edges_from([(<span class="st">"f1"</span>,<span class="st">"A"</span>),(<span class="st">"f1"</span>,<span class="st">"B"</span>),(<span class="st">"f2"</span>,<span class="st">"B"</span>),(<span class="st">"f2"</span>,<span class="st">"C"</span>)])</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>pos <span class="op">=</span> nx.spring_layout(G, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>nx.draw(G, pos, with_labels<span class="op">=</span><span class="va">True</span>, node_size<span class="op">=</span><span class="dv">1500</span>,</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>        node_color<span class="op">=</span>[<span class="st">"lightblue"</span> <span class="cf">if</span> n <span class="kw">in</span> [<span class="st">"A"</span>,<span class="st">"B"</span>,<span class="st">"C"</span>] <span class="cf">else</span> <span class="st">"lightgreen"</span> <span class="cf">for</span> n <span class="kw">in</span> G.nodes()])</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Factor Graph: variables ↔ factors"</span>)</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-22" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-22">Why It Matters</h4>
<p>Factor graphs provide a unifying language across probabilistic models. They clarify how local factors combine to form global distributions and enable scalable inference algorithms like sum-product and max-product. This makes them indispensable in AI domains ranging from error-correcting codes to computer vision.</p>
</section>
<section id="try-it-yourself-22" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-22">Try It Yourself</h4>
<ol type="1">
<li>Draw the factor graph for a simple chain <span class="math inline">\(A \to B \to C\)</span>. How does it compare to the Bayesian network form?</li>
<li>Implement sum-product message passing on a factor graph with three binary variables.</li>
<li>Reflect: why are factor graphs preferred in coding theory, where efficient message passing is critical?</li>
</ol>
</section>
</section>
<section id="hammersleyclifford-theorem" class="level3">
<h3 class="anchored" data-anchor-id="hammersleyclifford-theorem">524. Hammersley–Clifford Theorem</h3>
<p>The Hammersley–Clifford theorem provides the theoretical foundation for Markov Random Fields (MRFs). It states that a positive joint probability distribution satisfies the Markov properties of an undirected graph if and only if it can be factorized into a product of potential functions over the graph’s cliques.</p>
<section id="picture-in-your-head-23" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-23">Picture in Your Head</h4>
<p>Imagine a city map where intersections are variables and roads are connections. The theorem says: if traffic flow (probabilities) respects the neighborhood structure (Markov properties), then you can always describe the whole city’s traffic pattern as a combination of local road flows (clique potentials).</p>
</section>
<section id="deep-dive-23" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-23">Deep Dive</h4>
<p>Formally:</p>
<ul>
<li><p>Given an undirected graph <span class="math inline">\(G = (V,E)\)</span> and a strictly positive distribution <span class="math inline">\(P(X)\)</span>, the following are equivalent:</p>
<ol type="1">
<li><p><span class="math inline">\(P(X)\)</span> satisfies the Markov properties of <span class="math inline">\(G\)</span>.</p></li>
<li><p><span class="math inline">\(P(X)\)</span> factorizes over cliques of <span class="math inline">\(G\)</span>:</p>
<p><span class="math display">\[
P(X) = \frac{1}{Z} \prod_{C \in \mathcal{C}} \phi_C(X_C)
\]</span></p></li>
</ol></li>
</ul>
<p>Key points:</p>
<ul>
<li>Strict positivity (no zero probabilities) is required for the equivalence.</li>
<li>It connects graph separation (conditional independence) with algebraic factorization (potentials).</li>
<li>Provides the guarantee that graphical structures truly represent conditional independencies.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 45%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th>Part</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Markov property</td>
<td>Separation in graph ⇒ independence</td>
<td><span class="math inline">\(A \perp C \mid B\)</span> in chain <span class="math inline">\(A-B-C\)</span></td>
</tr>
<tr class="even">
<td>Factorization</td>
<td>Joint = product of clique potentials</td>
<td><span class="math inline">\(P(A,B,C) = \phi(A,B)\phi(B,C)\)</span></td>
</tr>
<tr class="odd">
<td>Equivalence</td>
<td>Both views describe the same distributions</td>
<td>Image pixels in an MRF</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-23" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-23">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple 3-node chain MRF: A-B-C</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Clique potentials</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>phi_AB <span class="op">=</span> {(<span class="dv">0</span>,<span class="dv">0</span>):<span class="dv">2</span>, (<span class="dv">0</span>,<span class="dv">1</span>):<span class="dv">1</span>, (<span class="dv">1</span>,<span class="dv">0</span>):<span class="dv">1</span>, (<span class="dv">1</span>,<span class="dv">1</span>):<span class="dv">2</span>}</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>phi_BC <span class="op">=</span> {(<span class="dv">0</span>,<span class="dv">0</span>):<span class="dv">3</span>, (<span class="dv">0</span>,<span class="dv">1</span>):<span class="dv">1</span>, (<span class="dv">1</span>,<span class="dv">0</span>):<span class="dv">1</span>, (<span class="dv">1</span>,<span class="dv">1</span>):<span class="dv">3</span>}</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute joint distribution via factorization</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>unnormalized <span class="op">=</span> {}</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> A,B,C <span class="kw">in</span> itertools.product([<span class="dv">0</span>,<span class="dv">1</span>],[<span class="dv">0</span>,<span class="dv">1</span>],[<span class="dv">0</span>,<span class="dv">1</span>]):</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>    val <span class="op">=</span> phi_AB[(A,B)] <span class="op">*</span> phi_BC[(B,C)]</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>    unnormalized[(A,B,C)] <span class="op">=</span> val</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> <span class="bu">sum</span>(unnormalized.values())</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>P <span class="op">=</span> {k: v<span class="op">/</span>Z <span class="cf">for</span> k,v <span class="kw">in</span> unnormalized.items()}</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Normalized distribution:"</span>, P)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-23" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-23">Why It Matters</h4>
<p>The theorem legitimizes the entire field of undirected graphical models: it assures us that if a distribution obeys the independence structure implied by a graph, then it can always be represented compactly with clique potentials. This connection underpins algorithms in computer vision, spatial statistics, and physics (Ising and Potts models).</p>
</section>
<section id="try-it-yourself-23" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-23">Try It Yourself</h4>
<ol type="1">
<li>Take a 4-node cycle graph. Write a factorization using clique potentials. Verify that the conditional independencies match the graph.</li>
<li>Explore what goes wrong if probabilities are not strictly positive (zeros break equivalence).</li>
<li>Reflect: why does the theorem matter for designing probabilistic AI systems that must encode local constraints faithfully?</li>
</ol>
</section>
</section>
<section id="energy-based-interpretations" class="level3">
<h3 class="anchored" data-anchor-id="energy-based-interpretations">525. Energy-Based Interpretations</h3>
<p>Markov Random Fields (MRFs) can also be understood through the lens of energy functions. Instead of thinking in terms of probabilities and potentials, we assign an “energy” to each configuration of variables. Lower energy states are more probable, and the distribution is given by a Boltzmann-like formulation.</p>
<section id="picture-in-your-head-24" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-24">Picture in Your Head</h4>
<p>Think of marbles rolling in a landscape of hills and valleys. Valleys represent low-energy (high-probability) states, while hills represent high-energy (low-probability) states. The marbles (system states) are most likely to settle in the valleys, though noise may push them around.</p>
</section>
<section id="deep-dive-24" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-24">Deep Dive</h4>
<p>An MRF distribution can be written as:</p>
<p><span class="math display">\[
P(x) = \frac{1}{Z} e^{-E(x)}
\]</span></p>
<ul>
<li><span class="math inline">\(E(x)\)</span>: energy function (lower = better)</li>
<li><span class="math inline">\(Z = \sum_x e^{-E(x)}\)</span>: partition function (normalization)</li>
<li>Connection: potentials <span class="math inline">\(\phi_C(x_C)\)</span> relate to energy by <span class="math inline">\(\phi_C(x_C) = e^{-E_C(x_C)}\)</span></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 47%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th>View</th>
<th>Formula</th>
<th>Intuition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Potentials</td>
<td><span class="math inline">\(P(x) \propto \prod_C \phi_C(x_C)\)</span></td>
<td>Local compatibility functions</td>
</tr>
<tr class="even">
<td>Energy</td>
<td><span class="math inline">\(P(x) \propto e^{-\sum_C E_C(x_C)}\)</span></td>
<td>Global “energy landscape”</td>
</tr>
</tbody>
</table>
<p>Common in:</p>
<ul>
<li>Ising model: binary spins with neighbor interactions.</li>
<li>Boltzmann machines: neural networks formulated as energy-based models.</li>
<li>Computer vision: energy minimization for denoising, segmentation.</li>
</ul>
</section>
<section id="tiny-code-24" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-24">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple Ising-like pairwise MRF</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> energy(x1, x2, w<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>w <span class="op">*</span> (<span class="dv">1</span> <span class="cf">if</span> x1 <span class="op">==</span> x2 <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute distribution over {±1} spins</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>states <span class="op">=</span> [(<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>),(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>),(<span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>),(<span class="dv">1</span>,<span class="dv">1</span>)]</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>energies <span class="op">=</span> {s: energy(<span class="op">*</span>s) <span class="cf">for</span> s <span class="kw">in</span> states}</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>unnormalized <span class="op">=</span> {s: np.exp(<span class="op">-</span>E) <span class="cf">for</span> s,E <span class="kw">in</span> energies.items()}</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> <span class="bu">sum</span>(unnormalized.values())</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>P <span class="op">=</span> {s: val<span class="op">/</span>Z <span class="cf">for</span> s,val <span class="kw">in</span> unnormalized.items()}</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Energies:"</span>, energies)</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Probabilities:"</span>, P)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-24" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-24">Why It Matters</h4>
<p>The energy-based perspective connects probabilistic AI with physics and optimization. Many modern models (e.g., deep energy-based models, contrastive divergence training) are rooted in this interpretation. It provides intuition: learning shapes the energy landscape so that desirable configurations lie in valleys, while implausible ones lie in peaks.</p>
</section>
<section id="try-it-yourself-24" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-24">Try It Yourself</h4>
<ol type="1">
<li>Write down the energy function for a 3-node Ising model chain. Compute probabilities from energies.</li>
<li>Explore how changing interaction weight <span class="math inline">\(w\)</span> affects correlations between nodes.</li>
<li>Reflect: why is the energy formulation useful in machine learning when designing models like Boltzmann machines or modern diffusion models?</li>
</ol>
</section>
</section>
<section id="contrast-with-directed-models" class="level3">
<h3 class="anchored" data-anchor-id="contrast-with-directed-models">526. Contrast with Directed Models</h3>
<p>Undirected graphical models (MRFs/CRFs) and directed graphical models (Bayesian networks) both capture dependencies, but they differ fundamentally in representation, semantics, and use cases. Directed models encode causal or generative processes, while undirected models capture mutual constraints and symmetric relationships.</p>
<section id="picture-in-your-head-25" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-25">Picture in Your Head</h4>
<p>Imagine two ways of explaining a friendship network. In one (directed), you say <em>“Alice influences Bob, who influences Carol.”</em> In the other (undirected), you just note <em>“Alice, Bob, and Carol are friends”</em> without specifying who leads the interaction. Both describe relationships, but in different languages.</p>
</section>
<section id="deep-dive-25" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-25">Deep Dive</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 45%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Aspect</th>
<th>Directed Models (BNs)</th>
<th>Undirected Models (MRFs/CRFs)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Edges</td>
<td>Arrows (causal direction)</td>
<td>Lines (symmetric relation)</td>
</tr>
<tr class="even">
<td>Factorization</td>
<td>Conditionals: <span class="math inline">\(\prod_i P(X_i \mid Parents(X_i))\)</span></td>
<td>Potentials: <span class="math inline">\(\prod_C \phi_C(X_C)\)</span></td>
</tr>
<tr class="odd">
<td>Semantics</td>
<td>Often causal, generative</td>
<td>Constraints, correlations</td>
</tr>
<tr class="even">
<td>Inference</td>
<td>Exact in trees; hard in dense graphs</td>
<td>Often requires approximate inference</td>
</tr>
<tr class="odd">
<td>Applications</td>
<td>Causal reasoning, diagnosis, planning</td>
<td>Image modeling, spatial dependencies, physics</td>
</tr>
</tbody>
</table>
<p>Key contrasts:</p>
<ul>
<li>Normalization: Directed models normalize locally (conditionals sum to 1). Undirected models normalize globally via partition function <span class="math inline">\(Z\)</span>.</li>
<li>Learning: Bayesian networks are easier when data is complete. MRFs/CRFs often require heavy computation due to <span class="math inline">\(Z\)</span>.</li>
<li>Flexibility: CRFs allow arbitrary features of observed data, while BNs require probabilistic semantics for each edge.</li>
</ul>
</section>
<section id="tiny-code-25" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-25">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Directed vs Undirected graph for A-B-C</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">3</span>))</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Directed: A -&gt; B -&gt; C</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>G1 <span class="op">=</span> nx.DiGraph()</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>G1.add_edges_from([(<span class="st">"A"</span>,<span class="st">"B"</span>),(<span class="st">"B"</span>,<span class="st">"C"</span>)])</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>nx.draw(G1, with_labels<span class="op">=</span><span class="va">True</span>, ax<span class="op">=</span>axes[<span class="dv">0</span>],</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>        node_color<span class="op">=</span><span class="st">"lightblue"</span>, arrows<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">"Bayesian Network"</span>)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Undirected: A - B - C</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>G2 <span class="op">=</span> nx.Graph()</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>G2.add_edges_from([(<span class="st">"A"</span>,<span class="st">"B"</span>),(<span class="st">"B"</span>,<span class="st">"C"</span>)])</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>nx.draw(G2, with_labels<span class="op">=</span><span class="va">True</span>, ax<span class="op">=</span>axes[<span class="dv">1</span>],</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>        node_color<span class="op">=</span><span class="st">"lightgreen"</span>)</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">"Markov Random Field"</span>)</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-25" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-25">Why It Matters</h4>
<p>Comparing directed and undirected models clarifies when each is appropriate. Directed models shine when causal or sequential processes are central. Undirected models excel where symmetry and local interactions dominate, such as in image grids or physics-inspired systems. Many modern AI systems combine both—e.g., using directed models for generative processes and undirected models for refinement or structured prediction.</p>
</section>
<section id="try-it-yourself-25" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-25">Try It Yourself</h4>
<ol type="1">
<li>Write the factorization for a 3-node chain in both BN and MRF form. Compare the parameter counts.</li>
<li>Consider image segmentation: why is an undirected model (CRF) more natural than a BN?</li>
<li>Reflect: how does the need for global normalization in MRFs make training harder than in BNs?</li>
</ol>
</section>
</section>
<section id="learning-parameters-in-crfs" class="level3">
<h3 class="anchored" data-anchor-id="learning-parameters-in-crfs">527. Learning Parameters in CRFs</h3>
<p>In Conditional Random Fields (CRFs), parameter learning means estimating the weights of feature functions that define the clique potentials. Since CRFs model conditional distributions <span class="math inline">\(P(Y \mid X)\)</span>, the training objective is to maximize the conditional log-likelihood of labeled data.</p>
<section id="picture-in-your-head-26" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-26">Picture in Your Head</h4>
<p>Imagine training referees for a sports game. Each referee (feature function) votes based on certain cues—player position, ball movement, or crowd noise. The learning process adjusts how much weight each referee’s opinion carries, so that together they predict the correct outcome consistently.</p>
</section>
<section id="deep-dive-26" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-26">Deep Dive</h4>
<p>CRF probability:</p>
<p><span class="math display">\[
P(Y \mid X) = \frac{1}{Z(X)} \exp\left(\sum_k \theta_k f_k(Y,X)\right)
\]</span></p>
<ul>
<li><span class="math inline">\(f_k(Y,X)\)</span>: feature functions (indicator or real-valued)</li>
<li><span class="math inline">\(\theta_k\)</span>: parameters (weights to learn)</li>
<li><span class="math inline">\(Z(X)\)</span>: partition function, depends on input <span class="math inline">\(X\)</span></li>
</ul>
<p>Learning:</p>
<ul>
<li><p>Objective: maximize conditional log-likelihood</p>
<p><span class="math display">\[
\ell(\theta) = \sum_i \log P(Y^{(i)} \mid X^{(i)};\theta)
\]</span></p></li>
<li><p>Gradient: difference between empirical feature counts and expected feature counts under the model.</p></li>
<li><p>Optimization: gradient ascent, L-BFGS, SGD.</p></li>
<li><p>Regularization: L2 penalty to prevent overfitting.</p></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 31%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="header">
<th>Step</th>
<th>Role</th>
<th>Example (NER task)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Define features</td>
<td>Word capitalization, suffixes</td>
<td>“John” starts with capital → PERSON</td>
</tr>
<tr class="even">
<td>Assign weights</td>
<td>Adjust influence of features</td>
<td>High weight for capitalized proper nouns</td>
</tr>
<tr class="odd">
<td>Maximize likelihood</td>
<td>Fit model to labeled text</td>
<td>Predict consistent sequences of entity tags</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-26" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-26">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn_crfsuite <span class="im">import</span> CRF</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Training data: sequence labeling (NER)</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> [[{<span class="st">"word"</span>:<span class="st">"Paris"</span>}, {<span class="st">"word"</span>:<span class="st">"is"</span>}, {<span class="st">"word"</span>:<span class="st">"beautiful"</span>}]]</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> [[<span class="st">"LOC"</span>,<span class="st">"O"</span>,<span class="st">"O"</span>]]</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>crf <span class="op">=</span> CRF(algorithm<span class="op">=</span><span class="st">"lbfgs"</span>, max_iterations<span class="op">=</span><span class="dv">100</span>, all_possible_transitions<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>crf.fit(X_train, y_train)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Learned parameters (first 5):"</span>)</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> feat, weight <span class="kw">in</span> <span class="bu">list</span>(crf.state_features_.items())[:<span class="dv">5</span>]:</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(feat, weight)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-26" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-26">Why It Matters</h4>
<p>Parameter learning is what makes CRFs effective for structured prediction. By combining arbitrary, overlapping features with global normalization, CRFs outperform simpler models like logistic regression or HMMs in tasks such as part-of-speech tagging, named entity recognition, and image segmentation.</p>
</section>
<section id="try-it-yourself-26" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-26">Try It Yourself</h4>
<ol type="1">
<li>Define feature functions for a toy sequence labeling problem (like POS tagging). Try training a CRF and inspecting the learned weights.</li>
<li>Compare CRF training time with logistic regression on the same dataset. Why is CRF slower?</li>
<li>Reflect: why is computing the partition function <span class="math inline">\(Z(X)\)</span> challenging, and how do dynamic programming algorithms (e.g., forward-backward for linear chains) solve this?</li>
</ol>
</section>
</section>
<section id="approximate-inference-in-mrfs" class="level3">
<h3 class="anchored" data-anchor-id="approximate-inference-in-mrfs">528. Approximate Inference in MRFs</h3>
<p>Inference in Markov Random Fields (MRFs) often requires computing marginals or MAP states. Exact inference is intractable for large or densely connected graphs because the partition function involves summing over exponentially many states. Approximate inference methods trade exactness for scalability, using sampling or variational techniques.</p>
<section id="picture-in-your-head-27" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-27">Picture in Your Head</h4>
<p>Think of trying to count every grain of sand on a beach (exact inference). Instead, you scoop a few buckets and estimate the total (sampling), or you fit a smooth curve that approximates the beach’s shape (variational methods). Both give useful answers without doing the impossible.</p>
</section>
<section id="deep-dive-27" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-27">Deep Dive</h4>
<p>Approximate inference methods:</p>
<ol type="1">
<li><p>Sampling-based</p>
<ul>
<li>Gibbs sampling: update variables one at a time conditioned on neighbors.</li>
<li>Metropolis–Hastings: propose moves and accept/reject based on probability ratio.</li>
<li>Importance sampling: reweight samples from an easier distribution.</li>
</ul></li>
<li><p>Variational methods</p>
<ul>
<li>Mean-field approximation: assume independence, minimize KL divergence.</li>
<li>Loopy belief propagation: extend message passing to graphs with cycles.</li>
<li>Structured variational approximations: richer families than mean-field.</li>
</ul></li>
</ol>
<table class="caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 35%">
<col style="width: 27%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Idea</th>
<th>Strength</th>
<th>Limitation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Gibbs sampling</td>
<td>Iteratively resample variables</td>
<td>Simple, asymptotically exact</td>
<td>Slow mixing in complex graphs</td>
</tr>
<tr class="even">
<td>Loopy BP</td>
<td>Pass messages even with cycles</td>
<td>Fast, often accurate in practice</td>
<td>No guarantees of convergence</td>
</tr>
<tr class="odd">
<td>Mean-field</td>
<td>Approximate with independent distributions</td>
<td>Scales well</td>
<td>May oversimplify dependencies</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-27" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-27">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Gibbs sampling for a simple Ising model (2 nodes)</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gibbs_step(state, w<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(state)):</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># conditional probability given neighbor</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>        neighbor <span class="op">=</span> state[<span class="dv">1</span><span class="op">-</span>i]</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>        p1 <span class="op">=</span> np.exp(w <span class="op">*</span> (<span class="dv">1</span> <span class="cf">if</span> neighbor<span class="op">==</span><span class="dv">1</span> <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>        p0 <span class="op">=</span> np.exp(w <span class="op">*</span> (<span class="dv">1</span> <span class="cf">if</span> neighbor<span class="op">==</span><span class="dv">0</span> <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>        prob <span class="op">=</span> p1 <span class="op">/</span> (p0 <span class="op">+</span> p1)</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>        state[i] <span class="op">=</span> np.random.rand() <span class="op">&lt;</span> prob</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> state</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Run sampler</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>state <span class="op">=</span> [<span class="dv">0</span>,<span class="dv">1</span>]</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> []</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>    state <span class="op">=</span> gibbs_step(state)</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>    samples.append(<span class="bu">tuple</span>(state))</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sampled states (first 10):"</span>, samples[:<span class="dv">10</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-27" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-27">Why It Matters</h4>
<p>Approximate inference makes MRFs usable in real-world AI. From image segmentation to protein structure prediction, exact inference is impossible. Approximate methods provide tractable solutions that balance speed and accuracy, enabling structured probabilistic reasoning at scale.</p>
</section>
<section id="try-it-yourself-27" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-27">Try It Yourself</h4>
<ol type="1">
<li>Implement Gibbs sampling for a 3-node Ising chain. Track the empirical distribution and compare with the true distribution (small enough to compute exactly).</li>
<li>Apply loopy belief propagation on a small graph and observe convergence (or divergence).</li>
<li>Reflect: why is approximate inference unavoidable in modern AI models with thousands or millions of variables?</li>
</ol>
</section>
</section>
<section id="deep-crfs-and-neural-potentials" class="level3">
<h3 class="anchored" data-anchor-id="deep-crfs-and-neural-potentials">529. Deep CRFs and Neural Potentials</h3>
<p>Deep Conditional Random Fields (Deep CRFs) extend traditional CRFs by replacing hand-crafted feature functions with neural networks. Instead of manually defining features, a deep model (e.g., CNN, RNN, Transformer) learns rich, task-specific representations that feed into the CRF’s potential functions.</p>
<section id="picture-in-your-head-28" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-28">Picture in Your Head</h4>
<p>Imagine assigning roles in a play. A traditional CRF uses predefined cues like costume color or script lines (hand-crafted features). A Deep CRF instead asks a neural network to “watch” the actors and automatically learn which patterns matter, then applies CRF structure to ensure role assignments remain consistent across the cast.</p>
</section>
<section id="deep-dive-28" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-28">Deep Dive</h4>
<p>CRF probability with neural potentials:</p>
<p><span class="math display">\[
P(Y \mid X) = \frac{1}{Z(X)} \exp\Big( \sum_{t} \theta^\top f(y_t, X, t) + \sum_{t} \psi(y_t, y_{t+1}, X) \Big)
\]</span></p>
<ul>
<li>Feature functions <span class="math inline">\(f\)</span>: extracted by neural nets from input <span class="math inline">\(X\)</span>.</li>
<li>Unary potentials: scores for each label at position <span class="math inline">\(t\)</span>.</li>
<li>Pairwise potentials: transition scores between neighboring labels.</li>
<li>End-to-end training: neural net + CRF jointly optimized with backpropagation.</li>
</ul>
<p>Applications:</p>
<ul>
<li>NLP: sequence labeling (NER, POS tagging, segmentation).</li>
<li>Vision: semantic segmentation (CNN features + CRF for spatial smoothing).</li>
<li>Speech: phoneme recognition with temporal consistency.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 54%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>Strength</th>
<th>Weakness</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Standard CRF</td>
<td>Transparent, interpretable</td>
<td>Needs manual features</td>
</tr>
<tr class="even">
<td>Deep CRF</td>
<td>Rich features, state-of-the-art accuracy</td>
<td>Heavier training cost</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-28" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-28">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchcrf <span class="im">import</span> CRF  <span class="co"># pip install pytorch-crf</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: BiLSTM + CRF for sequence labeling</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BiLSTM_CRF(nn.Module):</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, vocab_size, tagset_size, hidden_dim<span class="op">=</span><span class="dv">32</span>):</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embedding <span class="op">=</span> nn.Embedding(vocab_size, <span class="dv">16</span>)</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lstm <span class="op">=</span> nn.LSTM(<span class="dv">16</span>, hidden_dim<span class="op">//</span><span class="dv">2</span>, bidirectional<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(hidden_dim, tagset_size)</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.crf <span class="op">=</span> CRF(tagset_size, batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, tags<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>        embeds <span class="op">=</span> <span class="va">self</span>.embedding(x)</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>        lstm_out, _ <span class="op">=</span> <span class="va">self</span>.lstm(embeds)</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>        emissions <span class="op">=</span> <span class="va">self</span>.fc(lstm_out)</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> tags <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="op">-</span><span class="va">self</span>.crf(emissions, tags)  <span class="co"># loss</span></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.crf.decode(emissions)</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Dummy usage</span></span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> BiLSTM_CRF(vocab_size<span class="op">=</span><span class="dv">100</span>, tagset_size<span class="op">=</span><span class="dv">5</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-28" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-28">Why It Matters</h4>
<p>Deep CRFs combine the best of both worlds: expressive power of neural networks with structured prediction of CRFs. They achieve state-of-the-art performance in tasks where both local evidence (features) and global structure (dependencies) matter.</p>
</section>
<section id="try-it-yourself-28" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-28">Try It Yourself</h4>
<ol type="1">
<li>Implement a Deep CRF for part-of-speech tagging using BiLSTMs as feature extractors.</li>
<li>Compare results with a plain BiLSTM classifier—what improvements does the CRF layer bring?</li>
<li>Reflect: why do CRFs remain relevant even in the deep learning era, especially for tasks requiring label consistency?</li>
</ol>
</section>
</section>
<section id="real-world-uses-nlp-vision-bioinformatics" class="level3">
<h3 class="anchored" data-anchor-id="real-world-uses-nlp-vision-bioinformatics">530. Real-World Uses: NLP, Vision, Bioinformatics</h3>
<p>Undirected graphical models—MRFs, CRFs, and their deep extensions—have been widely applied in domains where structure, context, and dependencies matter as much as individual predictions. They thrive in problems where outputs are interdependent and must respect global consistency.</p>
<section id="picture-in-your-head-29" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-29">Picture in Your Head</h4>
<p>Think of labeling a puzzle: each piece (variable) has its own features, but the full solution only makes sense if all pieces fit together. MRFs and CRFs enforce these “fit” rules so that local predictions align with the bigger picture.</p>
</section>
<section id="deep-dive-29" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-29">Deep Dive</h4>
<p>Natural Language Processing (NLP):</p>
<ul>
<li>Part-of-speech tagging: CRFs enforce sequence consistency across words.</li>
<li>Named Entity Recognition (NER): CRFs ensure entity labels don’t break mid-span.</li>
<li>Information extraction: combine lexical features with global structure.</li>
</ul>
<p>Computer Vision:</p>
<ul>
<li>Image segmentation: pixels are locally correlated, MRFs/CRFs smooth noisy predictions.</li>
<li>Object recognition: CRFs combine CNN outputs with spatial constraints.</li>
<li>Image denoising: MRF priors encourage neighboring pixels to align.</li>
</ul>
<p>Bioinformatics:</p>
<ul>
<li>Gene prediction: CRFs capture sequential dependencies in DNA sequences.</li>
<li>Protein structure: MRFs model residue-residue interactions.</li>
<li>Pathway modeling: graphical models represent networks of biological interactions.</li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Domain</th>
<th>Example Application</th>
<th>Model Used</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>NLP</td>
<td>Named Entity Recognition</td>
<td>Linear-chain CRF</td>
</tr>
<tr class="even">
<td>Vision</td>
<td>Semantic segmentation</td>
<td>CNN + CRF</td>
</tr>
<tr class="odd">
<td>Bioinformatics</td>
<td>Protein contact maps</td>
<td>MRFs</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-29" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-29">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: using CRF for sequence labeling in NLP</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn_crfsuite <span class="im">import</span> CRF</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Training data: words with simple features</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> [[{<span class="st">"word"</span>: <span class="st">"Paris"</span>}, {<span class="st">"word"</span>: <span class="st">"is"</span>}, {<span class="st">"word"</span>: <span class="st">"nice"</span>}]]</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> [[<span class="st">"LOC"</span>,<span class="st">"O"</span>,<span class="st">"O"</span>]]</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>crf <span class="op">=</span> CRF(algorithm<span class="op">=</span><span class="st">"lbfgs"</span>, max_iterations<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>crf.fit(X_train, y_train)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Prediction:"</span>, crf.predict([[{<span class="st">"word"</span>: <span class="st">"Berlin"</span>}, {<span class="st">"word"</span>: <span class="st">"is"</span>}]]))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-29" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-29">Why It Matters</h4>
<p>These applications show why undirected models remain relevant. They embed domain knowledge (like spatial smoothness in images or sequential order in text) into probabilistic reasoning. Even as deep learning dominates, CRFs and MRFs are often layered on top of neural models to enforce structure.</p>
</section>
<section id="try-it-yourself-29" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-29">Try It Yourself</h4>
<ol type="1">
<li>Build a linear-chain CRF for NER on a toy text dataset. Compare with logistic regression.</li>
<li>Add a CRF layer on top of CNN-based semantic segmentation outputs. Observe how boundaries sharpen.</li>
<li>Reflect: why are undirected models so powerful in domains where outputs must be consistent with neighbors?</li>
</ol>
</section>
</section>
</section>
<section id="chapter-54.-exact-inference-variable-elimination-junction-tree" class="level2">
<h2 class="anchored" data-anchor-id="chapter-54.-exact-inference-variable-elimination-junction-tree">Chapter 54. Exact Inference (Variable Elimination, Junction Tree)</h2>
<section id="exact-inference-problem-setup" class="level3">
<h3 class="anchored" data-anchor-id="exact-inference-problem-setup">531. Exact Inference Problem Setup</h3>
<p>Exact inference in probabilistic graphical models means computing marginal or conditional probabilities exactly, without approximation. For small or tree-structured graphs, this is feasible, but for large or loopy graphs it quickly becomes intractable. Setting up the inference problem requires clarifying what we want to compute and how the graph factorization can be exploited.</p>
<section id="picture-in-your-head-30" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-30">Picture in Your Head</h4>
<p>Think of a detective story. You have a map of suspects, alibis, and evidence (the graph). Exact inference is like going through every possible scenario meticulously to find the exact probabilities of guilt, innocence, or hidden connections—tedious but precise.</p>
</section>
<section id="deep-dive-30" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-30">Deep Dive</h4>
<p>Types of inference queries:</p>
<ul>
<li><p>Marginals: <span class="math inline">\(P(X_i)\)</span> or <span class="math inline">\(P(X_i \mid E)\)</span> for evidence <span class="math inline">\(E\)</span>.</p></li>
<li><p>Conditionals: full distribution <span class="math inline">\(P(Q \mid E)\)</span> for query variables <span class="math inline">\(Q\)</span>.</p></li>
<li><p>MAP (Maximum a Posteriori): <span class="math inline">\(\arg\max_X P(X \mid E)\)</span>, best assignment.</p></li>
<li><p>Partition function:</p>
<p><span class="math display">\[
Z = \sum_X \prod_{C \in \mathcal{C}} \phi_C(X_C)
\]</span></p>
<p>needed for normalization.</p></li>
</ul>
<p>Challenges:</p>
<ul>
<li>Complexity is exponential in graph treewidth.</li>
<li>In dense graphs, inference is #P-hard.</li>
<li>Still, exact inference is possible in restricted cases (chains, trees).</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 54%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th>Query</th>
<th>Example</th>
<th>Method</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Marginal</td>
<td>Probability of disease given symptoms</td>
<td>Variable elimination</td>
</tr>
<tr class="even">
<td>Conditional</td>
<td>Probability of accident given rain</td>
<td>Belief propagation</td>
</tr>
<tr class="odd">
<td>MAP</td>
<td>Most likely pixel labeling in an image</td>
<td>Max-product algorithm</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-30" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-30">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.models <span class="im">import</span> BayesianNetwork</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.factors.discrete <span class="im">import</span> TabularCPD</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.inference <span class="im">import</span> VariableElimination</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple BN: A -&gt; B</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> BayesianNetwork([(<span class="st">"A"</span>,<span class="st">"B"</span>)])</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>cpd_a <span class="op">=</span> TabularCPD(<span class="st">"A"</span>, <span class="dv">2</span>, [[<span class="fl">0.6</span>],[<span class="fl">0.4</span>]])</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>cpd_b <span class="op">=</span> TabularCPD(<span class="st">"B"</span>, <span class="dv">2</span>, [[<span class="fl">0.7</span>,<span class="fl">0.2</span>],[<span class="fl">0.3</span>,<span class="fl">0.8</span>]], evidence<span class="op">=</span>[<span class="st">"A"</span>], evidence_card<span class="op">=</span>[<span class="dv">2</span>])</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>model.add_cpds(cpd_a, cpd_b)</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>inference <span class="op">=</span> VariableElimination(model)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(inference.query(variables<span class="op">=</span>[<span class="st">"B"</span>], evidence<span class="op">=</span>{<span class="st">"A"</span>:<span class="dv">1</span>}))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-30" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-30">Why It Matters</h4>
<p>Framing inference problems is the first step toward designing efficient algorithms. It clarifies whether exact methods (like elimination or junction trees) are possible, or if approximation is required. Understanding the setup also highlights where structure in the graph can be exploited to make inference tractable.</p>
</section>
<section id="try-it-yourself-30" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-30">Try It Yourself</h4>
<ol type="1">
<li>Write the partition function for a 3-node chain MRF with binary variables. Compute it by hand.</li>
<li>Set up a conditional probability query in a Bayesian network with 3 nodes. Identify which variables must be summed out.</li>
<li>Reflect: why does treewidth, not just graph size, determine feasibility of exact inference?</li>
</ol>
</section>
</section>
<section id="variable-elimination-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="variable-elimination-algorithm">532. Variable Elimination Algorithm</h3>
<p>Variable elimination is a systematic way to perform exact inference in graphical models. Instead of summing over all possible assignments at once (which is exponential), it eliminates variables one by one, reusing intermediate results (factors). This reduces redundant computation and exploits graph structure.</p>
<section id="picture-in-your-head-31" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-31">Picture in Your Head</h4>
<p>Imagine solving a big jigsaw puzzle. Instead of laying out all pieces at once, you group small chunks (factors), solve them locally, and then merge them step by step until the full picture emerges. Variable elimination works the same way with probabilities.</p>
</section>
<section id="deep-dive-31" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-31">Deep Dive</h4>
<p>Steps:</p>
<ol type="1">
<li><p>Start with factors from conditional probabilities (BN) or potentials (MRF).</p></li>
<li><p>Choose an elimination order for hidden variables (those not in query or evidence).</p></li>
<li><p>For each variable:</p>
<ul>
<li>Multiply all factors involving that variable.</li>
<li>Sum out (marginalize) the variable.</li>
<li>Add the new factor back to the pool.</li>
</ul></li>
<li><p>Normalize at the end (if needed).</p></li>
</ol>
<p>Example: Query <span class="math inline">\(P(C \mid A)\)</span> in chain <span class="math inline">\(A \to B \to C\)</span>.</p>
<ul>
<li>Factors: <span class="math inline">\(P(A), P(B \mid A), P(C \mid B)\)</span>.</li>
<li>Eliminate <span class="math inline">\(B\)</span>: form factor <span class="math inline">\(f(B) = \sum_B P(B \mid A)P(C \mid B)\)</span>.</li>
<li>Result: <span class="math inline">\(P(C \mid A) \propto P(A) f(C, A)\)</span>.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 36%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th>Step</th>
<th>Operation</th>
<th>Intuition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Multiply factors</td>
<td>Combine local information</td>
<td>Gather clues</td>
</tr>
<tr class="even">
<td>Sum out variable</td>
<td>Remove unwanted variable</td>
<td>Forget irrelevant details</td>
</tr>
<tr class="odd">
<td>Repeat</td>
<td>Shrinks problem size</td>
<td>Solve puzzle chunk by chunk</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-31" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-31">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.models <span class="im">import</span> BayesianNetwork</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.factors.discrete <span class="im">import</span> TabularCPD</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.inference <span class="im">import</span> VariableElimination</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co"># BN: A -&gt; B -&gt; C</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> BayesianNetwork([(<span class="st">"A"</span>,<span class="st">"B"</span>),(<span class="st">"B"</span>,<span class="st">"C"</span>)])</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>cpd_a <span class="op">=</span> TabularCPD(<span class="st">"A"</span>, <span class="dv">2</span>, [[<span class="fl">0.5</span>],[<span class="fl">0.5</span>]])</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>cpd_b <span class="op">=</span> TabularCPD(<span class="st">"B"</span>, <span class="dv">2</span>, [[<span class="fl">0.7</span>,<span class="fl">0.2</span>],[<span class="fl">0.3</span>,<span class="fl">0.8</span>]], evidence<span class="op">=</span>[<span class="st">"A"</span>], evidence_card<span class="op">=</span>[<span class="dv">2</span>])</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>cpd_c <span class="op">=</span> TabularCPD(<span class="st">"C"</span>, <span class="dv">2</span>, [[<span class="fl">0.9</span>,<span class="fl">0.4</span>],[<span class="fl">0.1</span>,<span class="fl">0.6</span>]], evidence<span class="op">=</span>[<span class="st">"B"</span>], evidence_card<span class="op">=</span>[<span class="dv">2</span>])</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>model.add_cpds(cpd_a, cpd_b, cpd_c)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>inference <span class="op">=</span> VariableElimination(model)</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(inference.query(variables<span class="op">=</span>[<span class="st">"C"</span>], evidence<span class="op">=</span>{<span class="st">"A"</span>:<span class="dv">1</span>}))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-31" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-31">Why It Matters</h4>
<p>Variable elimination is the foundation for many inference algorithms, including belief propagation and junction trees. It shows how independence and graph structure can be exploited to avoid exponential blow-up. Choosing a good elimination order can mean the difference between feasible and impossible inference.</p>
</section>
<section id="try-it-yourself-31" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-31">Try It Yourself</h4>
<ol type="1">
<li>For a 3-node chain <span class="math inline">\(A \to B \to C\)</span>, compute <span class="math inline">\(P(C \mid A)\)</span> by hand using variable elimination.</li>
<li>Try two different elimination orders. Do they give the same result? How does the computational cost differ?</li>
<li>Reflect: why does variable elimination still become exponential for graphs with high treewidth?</li>
</ol>
</section>
</section>
<section id="complexity-and-ordering-heuristics" class="level3">
<h3 class="anchored" data-anchor-id="complexity-and-ordering-heuristics">533. Complexity and Ordering Heuristics</h3>
<p>The efficiency of variable elimination depends not just on the graph, but on the order in which variables are eliminated. A poor order can create very large intermediate factors, making the algorithm exponential in practice. Ordering heuristics aim to minimize this cost.</p>
<section id="picture-in-your-head-32" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-32">Picture in Your Head</h4>
<p>Think of dismantling a tower of blocks. If you pull blocks at random, the tower might collapse into a mess (huge factors). But if you carefully pick blocks from the top or weak points, you keep the structure manageable. Variable elimination works the same: elimination order determines complexity.</p>
</section>
<section id="deep-dive-32" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-32">Deep Dive</h4>
<ul>
<li><p>Induced width (treewidth): the maximum size of a clique created during elimination.</p>
<ul>
<li>Complexity = exponential in treewidth, not total number of nodes.</li>
</ul></li>
<li><p>Optimal ordering: finding the best order is NP-hard.</p></li>
<li><p>Heuristics: practical strategies for choosing elimination order:</p>
<ol type="1">
<li>Min-degree: eliminate the node with fewest neighbors.</li>
<li>Min-fill: eliminate the node that adds the fewest extra edges.</li>
<li>Weighted heuristics: consider domain sizes as well.</li>
</ol></li>
</ul>
<p>Example: Chain <span class="math inline">\(A-B-C-D\)</span>.</p>
<ul>
<li>Eliminate <span class="math inline">\(B\)</span>: introduces edge <span class="math inline">\(A-C\)</span>.</li>
<li>Eliminate <span class="math inline">\(C\)</span>: introduces edge <span class="math inline">\(A-D\)</span>.</li>
<li>Induced graph width = 2.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 33%">
<col style="width: 28%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th>Heuristic</th>
<th>Idea</th>
<th>Strength</th>
<th>Weakness</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Min-degree</td>
<td>Pick node with fewest neighbors</td>
<td>Fast, simple</td>
<td>Not always optimal</td>
</tr>
<tr class="even">
<td>Min-fill</td>
<td>Minimize added edges</td>
<td>Often better in practice</td>
<td>More expensive to compute</td>
</tr>
<tr class="odd">
<td>Weighted</td>
<td>Incorporates factor sizes</td>
<td>Better for non-binary vars</td>
<td>Harder to tune</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-32" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-32">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example graph: A-B-C-D (chain)</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.Graph()</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>G.add_edges_from([(<span class="st">"A"</span>,<span class="st">"B"</span>),(<span class="st">"B"</span>,<span class="st">"C"</span>),(<span class="st">"C"</span>,<span class="st">"D"</span>)])</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute degrees (min-degree heuristic)</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>order <span class="op">=</span> []</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>H <span class="op">=</span> G.copy()</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> H.nodes():</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>    node <span class="op">=</span> <span class="bu">min</span>(H.nodes(), key<span class="op">=</span><span class="kw">lambda</span> n: H.degree[n])</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>    order.append(node)</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># connect neighbors (fill-in)</span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>    nbrs <span class="op">=</span> <span class="bu">list</span>(H.neighbors(node))</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(nbrs)):</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i<span class="op">+</span><span class="dv">1</span>, <span class="bu">len</span>(nbrs)):</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>            H.add_edge(nbrs[i], nbrs[j])</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>    H.remove_node(node)</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Elimination order (min-degree):"</span>, order)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-32" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-32">Why It Matters</h4>
<p>Inference complexity is governed by treewidth, not raw graph size. Good elimination orders make exact inference feasible in domains like medical diagnosis, natural language parsing, and error-correcting codes. Poor choices can make inference intractable even for modestly sized graphs.</p>
</section>
<section id="try-it-yourself-32" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-32">Try It Yourself</h4>
<ol type="1">
<li>Take a 4-node cycle <span class="math inline">\(A-B-C-D-A\)</span>. Try eliminating variables in different orders. Count how many fill-in edges are created.</li>
<li>Compare complexity growth when eliminating in random vs.&nbsp;min-fill order.</li>
<li>Reflect: why does the treewidth of a graph determine whether exact inference is practical?</li>
</ol>
</section>
</section>
<section id="message-passing-and-belief-propagation" class="level3">
<h3 class="anchored" data-anchor-id="message-passing-and-belief-propagation">534. Message Passing and Belief Propagation</h3>
<p>Belief propagation (BP) is an algorithm for performing exact inference on tree-structured graphical models and approximate inference on graphs with cycles (“loopy BP”). It works by passing messages between nodes that summarize local evidence and neighbor influences.</p>
<section id="picture-in-your-head-33" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-33">Picture in Your Head</h4>
<p>Imagine a group of friends trying to decide on dinner. Each person gathers input from their neighbors (“I like pizza, but only if you’re okay with it”) and sends back a message that reflects their combined preferences. After enough exchanges, everyone settles on consistent beliefs about what’s most likely.</p>
</section>
<section id="deep-dive-33" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-33">Deep Dive</h4>
<ul>
<li><p>Works on factor graphs (bipartite: variables ↔︎ factors).</p></li>
<li><p>Messages are functions passed along edges.</p></li>
<li><p>Variable-to-factor message:</p>
<p><span class="math display">\[
m_{X \to f}(X) = \prod_{h \in \text{nb}(X)\setminus f} m_{h \to X}(X)
\]</span></p></li>
<li><p>Factor-to-variable message:</p>
<p><span class="math display">\[
m_{f \to X}(X) = \sum_{Y \setminus X} f(Y) \prod_{Y' \in \text{nb}(f)\setminus X} m_{Y' \to f}(Y')
\]</span></p></li>
<li><p>Belief at variable <span class="math inline">\(X\)</span>:</p>
<p><span class="math display">\[
b(X) \propto \prod_{f \in \text{nb}(X)} m_{f \to X}(X)
\]</span></p></li>
</ul>
<p>Key points:</p>
<ul>
<li>Exact on trees: produces true marginals.</li>
<li>Loopy BP: often converges to good approximations, widely used in practice (e.g., LDPC codes).</li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Property</th>
<th>Tree Graphs</th>
<th>Graphs with Cycles</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Correctness</td>
<td>Exact marginals</td>
<td>Approximate only</td>
</tr>
<tr class="even">
<td>Convergence</td>
<td>Guaranteed</td>
<td>Not always guaranteed</td>
</tr>
<tr class="odd">
<td>Applications</td>
<td>Diagnosis, parsing</td>
<td>Computer vision, coding theory</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-33" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-33">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pgmpy.models <span class="im">as</span> pgm</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.inference <span class="im">import</span> BeliefPropagation</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple BN: A -&gt; B -&gt; C</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.models <span class="im">import</span> BayesianNetwork</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.factors.discrete <span class="im">import</span> TabularCPD</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> BayesianNetwork([(<span class="st">"A"</span>,<span class="st">"B"</span>),(<span class="st">"B"</span>,<span class="st">"C"</span>)])</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>cpd_a <span class="op">=</span> TabularCPD(<span class="st">"A"</span>, <span class="dv">2</span>, [[<span class="fl">0.5</span>],[<span class="fl">0.5</span>]])</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>cpd_b <span class="op">=</span> TabularCPD(<span class="st">"B"</span>, <span class="dv">2</span>, [[<span class="fl">0.7</span>,<span class="fl">0.2</span>],[<span class="fl">0.3</span>,<span class="fl">0.8</span>]], evidence<span class="op">=</span>[<span class="st">"A"</span>], evidence_card<span class="op">=</span>[<span class="dv">2</span>])</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>cpd_c <span class="op">=</span> TabularCPD(<span class="st">"C"</span>, <span class="dv">2</span>, [[<span class="fl">0.9</span>,<span class="fl">0.4</span>],[<span class="fl">0.1</span>,<span class="fl">0.6</span>]], evidence<span class="op">=</span>[<span class="st">"B"</span>], evidence_card<span class="op">=</span>[<span class="dv">2</span>])</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>model.add_cpds(cpd_a, cpd_b, cpd_c)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>bp <span class="op">=</span> BeliefPropagation(model)</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(bp.query(variables<span class="op">=</span>[<span class="st">"C"</span>], evidence<span class="op">=</span>{<span class="st">"A"</span>:<span class="dv">1</span>}))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-33" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-33">Why It Matters</h4>
<p>Message passing makes inference scalable by exploiting local structure—nodes only communicate with neighbors. It underlies many modern AI methods, from error-correcting codes and vision models to approximate inference in large probabilistic systems.</p>
</section>
<section id="try-it-yourself-33" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-33">Try It Yourself</h4>
<ol type="1">
<li>Draw a small factor graph with three variables in a chain. Perform one round of variable-to-factor and factor-to-variable messages by hand.</li>
<li>Run loopy BP on a small cycle graph. Compare results with exact inference.</li>
<li>Reflect: why does message passing succeed in domains like error-correcting codes, even though the graphs contain many loops?</li>
</ol>
</section>
</section>
<section id="sum-product-vs.-max-product" class="level3">
<h3 class="anchored" data-anchor-id="sum-product-vs.-max-product">535. Sum-Product vs.&nbsp;Max-Product</h3>
<p>Belief propagation can be specialized into two main flavors: the sum-product algorithm for computing marginal probabilities, and the max-product algorithm (a.k.a. max-sum in log-space) for computing the most likely assignment (MAP). Both follow the same message-passing framework but differ in the operation used at factor nodes.</p>
<section id="picture-in-your-head-34" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-34">Picture in Your Head</h4>
<p>Think of planning a trip. The sum-product version is like calculating all possible routes and weighting them by likelihood—asking, “What’s the probability I end up in each city?” The max-product version is like finding just the single best route—asking, “Which city is most likely given the evidence?”</p>
</section>
<section id="deep-dive-34" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-34">Deep Dive</h4>
<ul>
<li><p>Sum-Product (marginals): Messages combine neighbor influences by summing over possibilities.</p>
<p><span class="math display">\[
m_{f \to X}(x) = \sum_{y \setminus x} f(x,y) \prod m_{Y \to f}(y)
\]</span></p></li>
<li><p>Max-Product (MAP): Replace summation with maximization.</p>
<p><span class="math display">\[
m_{f \to X}(x) = \max_{y \setminus x} f(x,y) \prod m_{Y \to f}(y)
\]</span></p></li>
<li><p>Log domain (Max-Sum): Products become sums, max-product becomes max-sum, avoiding underflow.</p></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 33%">
<col style="width: 53%">
</colgroup>
<thead>
<tr class="header">
<th>Algorithm</th>
<th>Output</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sum-Product</td>
<td>Marginal distributions</td>
<td>Belief estimation, uncertainty quantification</td>
</tr>
<tr class="even">
<td>Max-Product</td>
<td>Most likely assignment (MAP)</td>
<td>Decoding, structured prediction</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-34" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-34">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.models <span class="im">import</span> MarkovModel</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.factors.discrete <span class="im">import</span> DiscreteFactor</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.inference <span class="im">import</span> BeliefPropagation</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple MRF: A-B</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MarkovModel([(<span class="st">"A"</span>,<span class="st">"B"</span>)])</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>phi_ab <span class="op">=</span> DiscreteFactor([<span class="st">"A"</span>,<span class="st">"B"</span>], [<span class="dv">2</span>,<span class="dv">2</span>],</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>                        [<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>])  <span class="co"># higher when A=B</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>model.add_factors(phi_ab)</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>bp <span class="op">=</span> BeliefPropagation(model)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Sum-Product: marginals</span></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Marginals:"</span>, bp.query(variables<span class="op">=</span>[<span class="st">"A"</span>]))</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Max-Product: MAP estimate</span></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>map_assignment <span class="op">=</span> bp.map_query(variables<span class="op">=</span>[<span class="st">"A"</span>,<span class="st">"B"</span>])</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MAP assignment:"</span>, map_assignment)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-34" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-34">Why It Matters</h4>
<p>The choice between sum-product and max-product reflects two kinds of inference: reasoning under uncertainty (marginals) versus finding the single best explanation (MAP). Many applications—error-correcting codes, speech recognition, vision—use one or the other depending on whether uncertainty quantification or hard decisions are needed.</p>
</section>
<section id="try-it-yourself-34" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-34">Try It Yourself</h4>
<ol type="1">
<li>On a chain of 3 binary variables, compute marginals with sum-product and compare with brute-force enumeration.</li>
<li>Run max-product on the same chain and verify it finds the MAP assignment.</li>
<li>Reflect: why might a system in medicine prefer sum-product inference, while one in communications decoding might prefer max-product?</li>
</ol>
</section>
</section>
<section id="junction-tree-algorithm-basics" class="level3">
<h3 class="anchored" data-anchor-id="junction-tree-algorithm-basics">536. Junction Tree Algorithm Basics</h3>
<p>The junction tree algorithm transforms a general graph into a tree-structured graph of cliques so that exact inference can be done efficiently using message passing. It extends belief propagation (which is exact only on trees) to arbitrary graphs by reorganizing them into a tree of clusters.</p>
<section id="picture-in-your-head-35" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-35">Picture in Your Head</h4>
<p>Imagine a group of overlapping committees (cliques). Each committee discusses its shared members’ information and then passes summaries to neighboring committees. The junction tree ensures that if two committees share a member, they stay consistent about that member’s status.</p>
</section>
<section id="deep-dive-35" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-35">Deep Dive</h4>
<p>Steps in building and using a junction tree:</p>
<ol type="1">
<li>Moralization (for Bayesian networks): make graph undirected, connect all parents of a node.</li>
<li>Triangulation: add edges to eliminate cycles without chords, preparing for tree construction.</li>
<li>Identify cliques: find maximal cliques in triangulated graph.</li>
<li>Build junction tree: arrange cliques into a tree structure, ensuring the running intersection property: if a variable appears in two cliques, it must appear in all cliques along the path between them.</li>
<li>Message passing: pass marginals between cliques until convergence.</li>
</ol>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 39%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="header">
<th>Step</th>
<th>Purpose</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Moralization</td>
<td>Convert directed BN to undirected</td>
<td>Parents of same child connected</td>
</tr>
<tr class="even">
<td>Triangulation</td>
<td>Make graph chordal</td>
<td>Break large cycles</td>
</tr>
<tr class="odd">
<td>Cliques</td>
<td>Group variables for factorization</td>
<td>{A,B,C}, {B,C,D}</td>
</tr>
<tr class="even">
<td>Running intersection</td>
<td>Maintain consistency</td>
<td>B,C appear in both cliques</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-35" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-35">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.models <span class="im">import</span> BayesianNetwork</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.inference <span class="im">import</span> JunctionTreeInference</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.factors.discrete <span class="im">import</span> TabularCPD</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="co"># BN: A-&gt;B, A-&gt;C, B-&gt;D, C-&gt;D</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> BayesianNetwork([(<span class="st">"A"</span>,<span class="st">"B"</span>),(<span class="st">"A"</span>,<span class="st">"C"</span>),(<span class="st">"B"</span>,<span class="st">"D"</span>),(<span class="st">"C"</span>,<span class="st">"D"</span>)])</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>cpd_a <span class="op">=</span> TabularCPD(<span class="st">"A"</span>, <span class="dv">2</span>, [[<span class="fl">0.5</span>],[<span class="fl">0.5</span>]])</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>cpd_b <span class="op">=</span> TabularCPD(<span class="st">"B"</span>, <span class="dv">2</span>, [[<span class="fl">0.7</span>,<span class="fl">0.2</span>],[<span class="fl">0.3</span>,<span class="fl">0.8</span>]], evidence<span class="op">=</span>[<span class="st">"A"</span>], evidence_card<span class="op">=</span>[<span class="dv">2</span>])</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>cpd_c <span class="op">=</span> TabularCPD(<span class="st">"C"</span>, <span class="dv">2</span>, [[<span class="fl">0.6</span>,<span class="fl">0.4</span>],[<span class="fl">0.4</span>,<span class="fl">0.6</span>]], evidence<span class="op">=</span>[<span class="st">"A"</span>], evidence_card<span class="op">=</span>[<span class="dv">2</span>])</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>cpd_d <span class="op">=</span> TabularCPD(<span class="st">"D"</span>, <span class="dv">2</span>, [[<span class="fl">0.9</span>,<span class="fl">0.2</span>,<span class="fl">0.3</span>,<span class="fl">0.1</span>],[<span class="fl">0.1</span>,<span class="fl">0.8</span>,<span class="fl">0.7</span>,<span class="fl">0.9</span>]],</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>                   evidence<span class="op">=</span>[<span class="st">"B"</span>,<span class="st">"C"</span>], evidence_card<span class="op">=</span>[<span class="dv">2</span>,<span class="dv">2</span>])</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>model.add_cpds(cpd_a, cpd_b, cpd_c, cpd_d)</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>jt <span class="op">=</span> JunctionTreeInference(model)</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(jt.query(variables<span class="op">=</span>[<span class="st">"D"</span>], evidence<span class="op">=</span>{<span class="st">"A"</span>:<span class="dv">1</span>}))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-35" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-35">Why It Matters</h4>
<p>The junction tree algorithm makes exact inference possible for complex graphs by transforming them into a tree structure. It is foundational in probabilistic AI, enabling reasoning in networks with loops such as genetic networks, fault diagnosis, and relational models.</p>
</section>
<section id="try-it-yourself-35" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-35">Try It Yourself</h4>
<ol type="1">
<li>Construct a Bayesian network with a cycle and manually moralize + triangulate it to form a chordal graph.</li>
<li>Identify the cliques and build a junction tree. Verify the running intersection property.</li>
<li>Reflect: why does triangulation (adding edges) sometimes increase computational cost, even though it makes inference feasible?</li>
</ol>
</section>
</section>
<section id="clique-formation-and-triangulation" class="level3">
<h3 class="anchored" data-anchor-id="clique-formation-and-triangulation">537. Clique Formation and Triangulation</h3>
<p>Clique formation and triangulation are the preparatory steps for turning a complex graph into a junction tree suitable for exact inference. Triangulation ensures that the graph is chordal (every cycle of four or more nodes has a shortcut edge), which guarantees that cliques can be arranged into a tree that satisfies the running intersection property.</p>
<section id="picture-in-your-head-36" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-36">Picture in Your Head</h4>
<p>Imagine drawing a road map. If you leave long circular routes with no shortcuts, traffic (messages) can get stuck. By adding a few extra roads (edges), you ensure that every loop has a shortcut, making it possible to navigate efficiently. These shortcuts correspond to triangulation, and the resulting intersections of roads form cliques.</p>
</section>
<section id="deep-dive-36" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-36">Deep Dive</h4>
<p>Steps:</p>
<ol type="1">
<li><p>Moralization (for Bayesian networks): connect all parents of each node and drop edge directions.</p></li>
<li><p>Triangulation: add fill-in edges to break chordless cycles.</p>
<ul>
<li>Example: cycle <span class="math inline">\(A-B-C-D-A\)</span>. Without triangulation, it has no chord. Adding edge <span class="math inline">\(A-C\)</span> or <span class="math inline">\(B-D\)</span> makes it chordal.</li>
</ul></li>
<li><p>Maximal cliques: find the largest fully connected subsets after triangulation.</p>
<ul>
<li>Example: from triangulated graph, cliques might be <span class="math inline">\(\{A,B,C\}\)</span> and <span class="math inline">\(\{C,D\}\)</span>.</li>
</ul></li>
<li><p>Build clique tree: connect cliques while ensuring the running intersection property.</p></li>
</ol>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 45%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Step</th>
<th>Role</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Moralization</td>
<td>Ensure undirected structure</td>
<td>Parents of child connected</td>
</tr>
<tr class="even">
<td>Triangulation</td>
<td>Add chords to cycles</td>
<td>Add edge <span class="math inline">\(A-C\)</span> in cycle</td>
</tr>
<tr class="odd">
<td>Clique formation</td>
<td>Identify clusters for factorization</td>
<td>Clique {A,B,C}</td>
</tr>
<tr class="even">
<td>Clique tree</td>
<td>Arrange cliques as tree</td>
<td>{A,B,C} – {C,D}</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-36" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-36">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: cycle A-B-C-D-A</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.Graph()</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>G.add_edges_from([(<span class="st">"A"</span>,<span class="st">"B"</span>),(<span class="st">"B"</span>,<span class="st">"C"</span>),(<span class="st">"C"</span>,<span class="st">"D"</span>),(<span class="st">"D"</span>,<span class="st">"A"</span>)])</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Triangulation: add edge A-C</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>G.add_edge(<span class="st">"A"</span>,<span class="st">"C"</span>)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Find cliques</span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>cliques <span class="op">=</span> <span class="bu">list</span>(nx.find_cliques(G))</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Maximal cliques:"</span>, cliques)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-36" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-36">Why It Matters</h4>
<p>Triangulation and clique formation determine the complexity of junction tree inference. The size of the largest clique (treewidth + 1) dictates how hard inference will be. Good triangulation keeps cliques small, balancing tractability with correctness.</p>
</section>
<section id="try-it-yourself-36" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-36">Try It Yourself</h4>
<ol type="1">
<li>Take a 5-node cycle graph and perform triangulation manually. How many fill-in edges are needed?</li>
<li>Identify the maximal cliques after triangulation.</li>
<li>Reflect: why does poor triangulation lead to unnecessarily large cliques and higher computational cost?</li>
</ol>
</section>
</section>
<section id="computational-tradeoffs" class="level3">
<h3 class="anchored" data-anchor-id="computational-tradeoffs">538. Computational Tradeoffs</h3>
<p>Exact inference using variable elimination or the junction tree algorithm comes with steep computational tradeoffs. While theoretically sound, the efficiency depends on the graph’s treewidth—the size of the largest clique minus one. Small treewidth graphs are tractable, but as treewidth grows, inference becomes exponentially expensive.</p>
<section id="picture-in-your-head-37" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-37">Picture in Your Head</h4>
<p>Imagine organizing a town hall meeting. If people sit in small groups (low treewidth), it’s easy to manage conversations. But if every group overlaps heavily (large cliques), discussions become chaotic, and you need exponentially more coordination.</p>
</section>
<section id="deep-dive-37" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-37">Deep Dive</h4>
<ul>
<li><p>Time complexity:</p>
<p><span class="math display">\[
O(n \cdot d^{w+1})
\]</span></p>
<p>where <span class="math inline">\(n\)</span> = number of variables, <span class="math inline">\(d\)</span> = domain size, <span class="math inline">\(w\)</span> = treewidth.</p></li>
<li><p>Space complexity: storing large clique potentials requires memory exponential in clique size.</p></li>
<li><p>Tradeoff: exact inference is feasible for chains, trees, and low-treewidth graphs; approximate inference is needed otherwise.</p></li>
</ul>
<p>Examples:</p>
<ul>
<li>Chain or tree: inference is linear in number of nodes.</li>
<li>Grid (e.g., image models): treewidth grows with grid width, making exact inference impractical.</li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Graph Structure</th>
<th>Treewidth</th>
<th>Inference Cost</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Chain of length n</td>
<td>1</td>
<td>Linear</td>
</tr>
<tr class="even">
<td>Star graph</td>
<td>1</td>
<td>Linear</td>
</tr>
<tr class="odd">
<td>Grid 10×10</td>
<td>10</td>
<td>Exponential in 11</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-37" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-37">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Build a 3x3 grid graph</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.grid_2d_graph(<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Nodes:"</span>, <span class="bu">len</span>(G.nodes()))</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Edges:"</span>, <span class="bu">len</span>(G.edges()))</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Approximate treewidth (not exact)</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> networkx.algorithms.approximation <span class="im">import</span> treewidth_min_fill_in</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>tw, _ <span class="op">=</span> treewidth_min_fill_in(G)</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Approximate treewidth of 3x3 grid:"</span>, tw)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-37" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-37">Why It Matters</h4>
<p>Understanding computational tradeoffs helps decide whether to use exact or approximate inference. In AI applications like vision or language, where models involve large grids or densely connected graphs, exact inference is often impossible—forcing reliance on approximation or specialized structure exploitation.</p>
</section>
<section id="try-it-yourself-37" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-37">Try It Yourself</h4>
<ol type="1">
<li>Compute the treewidth of a chain graph with 5 nodes. Compare with a 5-node cycle.</li>
<li>Estimate how memory requirements grow when clique size doubles.</li>
<li>Reflect: why does treewidth, not just the number of variables, dictate inference feasibility?</li>
</ol>
</section>
</section>
<section id="exact-inference-in-practice" class="level3">
<h3 class="anchored" data-anchor-id="exact-inference-in-practice">539. Exact Inference in Practice</h3>
<p>While exact inference algorithms like variable elimination and junction trees are elegant, their practical use depends on the problem’s size and structure. In many real-world applications, exact inference is only feasible in small-scale or carefully structured models. Otherwise, practitioners resort to hybrid approaches or approximations.</p>
<section id="picture-in-your-head-38" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-38">Picture in Your Head</h4>
<p>Think of balancing a budget: if you only track a few categories (small model), you can calculate everything precisely. But if you try to track every cent across thousands of accounts (large model), exact bookkeeping becomes impossible—you switch to estimates, summaries, or audits.</p>
</section>
<section id="deep-dive-38" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-38">Deep Dive</h4>
<p>Scenarios where exact inference is used:</p>
<ul>
<li>Small or tree-structured networks: medical diagnosis networks, fault trees.</li>
<li>Hidden Markov Models (HMMs): dynamic programming (forward–backward, Viterbi) provides efficient exact inference.</li>
<li>Low treewidth domains: chain-structured CRFs, simple relational models.</li>
<li>Symbolic reasoning systems: exactness needed for guarantees.</li>
</ul>
<p>Scenarios where it fails:</p>
<ul>
<li>Image models (grids): treewidth scales with grid width → exponential cost.</li>
<li>Large relational or social networks: too many dependencies.</li>
<li>Dense Bayesian networks: moralization + triangulation creates huge cliques.</li>
</ul>
<p>Hybrid strategies:</p>
<ul>
<li>Exact + approximate: run exact inference on a subgraph, approximate elsewhere.</li>
<li>Exploiting sparsity: prune edges or simplify factors.</li>
<li>Caching/memoization: reuse intermediate factors across multiple queries.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 26%">
<col style="width: 30%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="header">
<th>Domain</th>
<th>Exact Inference Feasible?</th>
<th>Why/Why Not</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>HMMs</td>
<td>Yes</td>
<td>Chain structure, dynamic programming</td>
</tr>
<tr class="even">
<td>Image segmentation</td>
<td>No</td>
<td>Grid treewidth too large</td>
</tr>
<tr class="odd">
<td>Medical expert systems</td>
<td>Sometimes</td>
<td>Small, tree-like models</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-38" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-38">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.models <span class="im">import</span> BayesianNetwork</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.inference <span class="im">import</span> VariableElimination</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pgmpy.factors.discrete <span class="im">import</span> TabularCPD</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Simple medical diagnosis network</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> BayesianNetwork([(<span class="st">"Disease"</span>,<span class="st">"Symptom"</span>)])</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>cpd_d <span class="op">=</span> TabularCPD(<span class="st">"Disease"</span>, <span class="dv">2</span>, [[<span class="fl">0.99</span>],[<span class="fl">0.01</span>]])</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>cpd_s <span class="op">=</span> TabularCPD(<span class="st">"Symptom"</span>, <span class="dv">2</span>,</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>                   [[<span class="fl">0.9</span>,<span class="fl">0.2</span>],[<span class="fl">0.1</span>,<span class="fl">0.8</span>]],</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>                   evidence<span class="op">=</span>[<span class="st">"Disease"</span>], evidence_card<span class="op">=</span>[<span class="dv">2</span>])</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>model.add_cpds(cpd_d, cpd_s)</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>inference <span class="op">=</span> VariableElimination(model)</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(inference.query(variables<span class="op">=</span>[<span class="st">"Disease"</span>], evidence<span class="op">=</span>{<span class="st">"Symptom"</span>:<span class="dv">1</span>}))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-38" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-38">Why It Matters</h4>
<p>Exact inference remains essential in applications that demand certainty and guarantees—like medicine, safety, or law. At the same time, recognizing its computational limits prevents wasted effort on intractable models and encourages use of approximations where necessary.</p>
</section>
<section id="try-it-yourself-38" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-38">Try It Yourself</h4>
<ol type="1">
<li>Take a chain CRF with 5 nodes and compute marginals exactly using dynamic programming.</li>
<li>Attempt the same with a 3×3 grid MRF. How does computation scale?</li>
<li>Reflect: why do certain domains (e.g., sequence models) permit efficient exact inference, while others (e.g., vision grids) do not?</li>
</ol>
</section>
</section>
<section id="limits-of-exact-approaches" class="level3">
<h3 class="anchored" data-anchor-id="limits-of-exact-approaches">540. Limits of Exact Approaches</h3>
<p>Exact inference algorithms are powerful but face hard limits. For arbitrary graphs, inference is NP-hard, and computing the partition function is #P-hard. This means that beyond small or specially structured models, exact methods are computationally infeasible, forcing the use of approximations.</p>
<section id="picture-in-your-head-39" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-39">Picture in Your Head</h4>
<p>Think of trying to compute every possible chess game outcome. For a few moves, it’s doable. For the full game tree, the possibilities explode astronomically. Exact inference in large probabilistic models faces the same combinatorial explosion.</p>
</section>
<section id="deep-dive-39" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-39">Deep Dive</h4>
<ul>
<li><p>Complexity results:</p>
<ul>
<li>General inference = NP-hard (decision problems).</li>
<li>Partition function computation = #P-hard (counting problems).</li>
</ul></li>
<li><p>Treewidth barrier: complexity grows exponentially with graph treewidth.</p></li>
<li><p>Numerical issues: even when feasible, exact inference can suffer from underflow or overflow in probability computations.</p></li>
<li><p>Scalability: real-world models in vision, NLP, or genomics often have thousands or millions of variables—well beyond exact methods.</p></li>
</ul>
<p>Examples of failure cases:</p>
<ul>
<li>Grid-structured models (images): treewidth scales with grid width → exponential blowup.</li>
<li>Dense social networks: highly connected → cliques of large size.</li>
<li>Large CRFs: partition function becomes intractable.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 34%">
<col style="width: 39%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th>Limitation</th>
<th>Effect</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>NP-hardness</td>
<td>Worst-case intractability</td>
<td>Arbitrary BN inference</td>
</tr>
<tr class="even">
<td>Treewidth</td>
<td>Exponential blowup</td>
<td>10×10 image grid</td>
</tr>
<tr class="odd">
<td>Partition function (#P-hard)</td>
<td>Impossible to normalize directly</td>
<td>Boltzmann machines</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-39" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-39">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Brute-force inference on a 4-node fully connected binary MRF</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> brute_force_marginal():</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>    states <span class="op">=</span> <span class="bu">list</span>(itertools.product([<span class="dv">0</span>,<span class="dv">1</span>], repeat<span class="op">=</span><span class="dv">4</span>))</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>    phi <span class="op">=</span> <span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> <span class="bu">sum</span>(x)<span class="op">%</span><span class="dv">2</span><span class="op">==</span><span class="dv">0</span> <span class="cf">else</span> <span class="dv">2</span>  <span class="co"># toy potential</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">=</span> [phi(s) <span class="cf">for</span> s <span class="kw">in</span> states]</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> <span class="bu">sum</span>(weights)</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>    marg_A1 <span class="op">=</span> <span class="bu">sum</span>(w <span class="cf">for</span> s,w <span class="kw">in</span> <span class="bu">zip</span>(states,weights) <span class="cf">if</span> s[<span class="dv">0</span>]<span class="op">==</span><span class="dv">1</span>)<span class="op">/</span>Z</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> marg_A1</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Marginal P(A=1):"</span>, brute_force_marginal())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This brute-force approach works only for tiny graphs—already infeasible for more than ~20 binary variables.</p>
</section>
<section id="why-it-matters-39" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-39">Why It Matters</h4>
<p>Recognizing the limits of exact inference is critical for AI practice. It motivates approximate inference (sampling, variational methods) and hybrid strategies that make large-scale probabilistic modeling possible. Without this awareness, one might design models that are beautiful on paper but impossible to compute with in reality.</p>
</section>
<section id="try-it-yourself-39" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-39">Try It Yourself</h4>
<ol type="1">
<li>Compute the partition function for a 4-node fully connected binary MRF. How many states are required?</li>
<li>Estimate how the computation scales with 10 nodes.</li>
<li>Reflect: why does the complexity barrier make approximate inference the default choice in modern AI systems?</li>
</ol>
</section>
</section>
</section>
<section id="chapter-55.-approximate-inference-sampling-variational" class="level2">
<h2 class="anchored" data-anchor-id="chapter-55.-approximate-inference-sampling-variational">Chapter 55. Approximate Inference (sampling, Variational)</h2>
<section id="why-approximation-is-needed" class="level3">
<h3 class="anchored" data-anchor-id="why-approximation-is-needed">541. Why Approximation is Needed</h3>
<p>Exact inference in probabilistic models quickly becomes computationally intractable. Computing marginals, conditionals, or partition functions requires summing over exponentially many states when the graph is dense or high-dimensional. Approximate inference methods—sampling, variational, or hybrids—are the only way to scale probabilistic reasoning to real-world AI systems.</p>
<section id="picture-in-your-head-40" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-40">Picture in Your Head</h4>
<p>Think of weather forecasting. To get an exact prediction, you would need to simulate every molecule in the atmosphere—a hopeless task. Instead, meteorologists rely on approximations: numerical simulations, statistical models, and ensembles. They don’t capture everything exactly, but they’re good enough to guide real decisions.</p>
</section>
<section id="deep-dive-40" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-40">Deep Dive</h4>
<p>Why exact inference fails in practice:</p>
<ul>
<li>Exponential blowup: complexity grows with graph treewidth, not just size.</li>
<li>Partition function problem: computing <span class="math inline">\(Z = \sum_x e^{-E(x)}\)</span> is #P-hard in general.</li>
<li>Dense dependencies: cliques form easily in real-world networks (vision, NLP, biology).</li>
<li>Dynamic and streaming data: inference must run online, making exact solutions impractical.</li>
</ul>
<p>When approximation is essential:</p>
<ul>
<li>Large-scale Bayesian networks with thousands of variables.</li>
<li>Markov random fields in vision (image segmentation).</li>
<li>Latent-variable models like topic models or deep generative models.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 37%">
<col style="width: 27%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th>Limitation of Exact Methods</th>
<th>Consequence</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Treewidth grows with model</td>
<td>Exponential complexity</td>
<td>Grid-structured MRFs</td>
</tr>
<tr class="even">
<td>Partition function intractable</td>
<td>Cannot normalize</td>
<td>Boltzmann machines</td>
</tr>
<tr class="odd">
<td>Dense connectivity</td>
<td>Huge cliques</td>
<td>Social networks</td>
</tr>
<tr class="even">
<td>Need for online inference</td>
<td>Too slow</td>
<td>Realtime speech recognition</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-40" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-40">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Brute force marginal in a 5-node binary model (impractical beyond ~20 nodes)</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>states <span class="op">=</span> <span class="bu">list</span>(itertools.product([<span class="dv">0</span>,<span class="dv">1</span>], repeat<span class="op">=</span><span class="dv">5</span>))</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> joint_prob(state):</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># toy joint: probability proportional to number of 1s</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">2</span>  <span class="bu">sum</span>(state)</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> <span class="bu">sum</span>(joint_prob(s) <span class="cf">for</span> s <span class="kw">in</span> states)</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>marg <span class="op">=</span> <span class="bu">sum</span>(joint_prob(s) <span class="cf">for</span> s <span class="kw">in</span> states <span class="cf">if</span> s[<span class="dv">0</span>]<span class="op">==</span><span class="dv">1</span>) <span class="op">/</span> Z</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"P(X1=1):"</span>, marg)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This brute-force approach explodes exponentially—already 2^20 ≈ 1 million states for just 20 binary variables.</p>
</section>
<section id="why-it-matters-40" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-40">Why It Matters</h4>
<p>Approximate inference is not a luxury but a necessity in AI. Without it, probabilistic models would remain theoretical curiosities. Approximations strike a balance: they sacrifice exactness for feasibility, enabling structured reasoning in domains with billions of parameters.</p>
</section>
<section id="try-it-yourself-40" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-40">Try It Yourself</h4>
<ol type="1">
<li>Compute the exact partition function for a 4-node binary MRF. Now scale to 10 nodes—why does it become impossible?</li>
<li>Implement Gibbs sampling for the same 10-node system and compare approximate vs.&nbsp;exact marginals.</li>
<li>Reflect: why do practitioners accept approximate answers in probabilistic AI, while demanding exactness in areas like symbolic logic?</li>
</ol>
</section>
</section>
<section id="monte-carlo-estimation-basics" class="level3">
<h3 class="anchored" data-anchor-id="monte-carlo-estimation-basics">542. Monte Carlo Estimation Basics</h3>
<p>Monte Carlo methods approximate expectations or probabilities by drawing random samples from a distribution and averaging. Instead of summing or integrating over all possible states, which is often intractable, Monte Carlo replaces the computation with randomized approximations that converge as the number of samples increases.</p>
<section id="picture-in-your-head-41" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-41">Picture in Your Head</h4>
<p>Imagine estimating the area of an irregular lake. Instead of measuring it exactly, you throw stones randomly into a bounding box and count how many land in the water. The fraction gives an approximate area, and the more stones you throw, the better your estimate.</p>
</section>
<section id="deep-dive-41" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-41">Deep Dive</h4>
<ul>
<li><p>Core idea: For a function <span class="math inline">\(f(x)\)</span> under distribution <span class="math inline">\(p(x)\)</span>:</p>
<p><span class="math display">\[
\mathbb{E}[f(X)] = \sum_x f(x)p(x) \approx \frac{1}{N} \sum_{i=1}^N f(x^{(i)}), \quad x^{(i)} \sim p(x)
\]</span></p></li>
<li><p>Law of Large Numbers: guarantees convergence of the estimate as <span class="math inline">\(N \to \infty\)</span>.</p></li>
<li><p>Variance matters: more samples reduce error as <span class="math inline">\(O(1/\sqrt{N})\)</span>.</p></li>
<li><p>Use cases in AI:</p>
<ul>
<li>Estimating marginal probabilities.</li>
<li>Approximating integrals in Bayesian inference.</li>
<li>Training generative models with likelihood-free objectives.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 30%">
<col style="width: 27%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Purpose</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Crude Monte Carlo</td>
<td>Estimate expectations</td>
<td>Estimate mean of random variable</td>
</tr>
<tr class="even">
<td>Monte Carlo Integration</td>
<td>Approximate integrals</td>
<td>Bayesian posterior predictive</td>
</tr>
<tr class="odd">
<td>Simulation</td>
<td>Model complex systems</td>
<td>Queueing, reinforcement learning</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-41" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-41">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate E[X^2] where X ~ N(0,1)</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100000</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> np.random.normal(<span class="dv">0</span>,<span class="dv">1</span>,N)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>estimate <span class="op">=</span> np.mean(samples2)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Monte Carlo estimate of E[X^2]:"</span>, estimate)</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"True value:"</span>, <span class="fl">1.0</span>)  <span class="co"># variance of N(0,1)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-41" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-41">Why It Matters</h4>
<p>Monte Carlo is the workhorse of approximate inference. It allows us to sidestep intractable sums or integrals and instead rely on random sampling. This makes it the foundation for methods like importance sampling, Markov Chain Monte Carlo (MCMC), and particle filtering.</p>
</section>
<section id="try-it-yourself-41" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-41">Try It Yourself</h4>
<ol type="1">
<li>Use Monte Carlo to estimate <span class="math inline">\(\pi\)</span> by sampling points in a square and checking if they fall inside a circle.</li>
<li>Compare Monte Carlo estimates of <span class="math inline">\(\mathbb{E}[X^4]\)</span> for <span class="math inline">\(X \sim N(0,1)\)</span> with the analytic result (3).</li>
<li>Reflect: why does the error in Monte Carlo shrink slowly (<span class="math inline">\(1/\sqrt{N}\)</span>) compared to deterministic numerical integration?</li>
</ol>
</section>
</section>
<section id="importance-sampling-and-reweighting" class="level3">
<h3 class="anchored" data-anchor-id="importance-sampling-and-reweighting">543. Importance Sampling and Reweighting</h3>
<p>Importance sampling is a Monte Carlo technique for estimating expectations when it’s difficult to sample directly from the target distribution. Instead, we sample from a simpler proposal distribution and then reweight the samples to correct for the mismatch.</p>
<section id="picture-in-your-head-42" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-42">Picture in Your Head</h4>
<p>Imagine surveying people in a city where some neighborhoods are easier to access than others. If you oversample the easy neighborhoods, you can still get an unbiased city-wide estimate by giving more weight to underrepresented neighborhoods and less to overrepresented ones.</p>
</section>
<section id="deep-dive-42" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-42">Deep Dive</h4>
<p>We want to compute:</p>
<p><span class="math display">\[
\mathbb{E}_p[f(X)] = \sum_x f(x) p(x)
\]</span></p>
<p>If direct sampling from <span class="math inline">\(p(x)\)</span> is hard, sample from a proposal <span class="math inline">\(q(x)\)</span>:</p>
<p><span class="math display">\[
\mathbb{E}_p[f(X)] = \sum_x f(x) \frac{p(x)}{q(x)} q(x) \approx \frac{1}{N} \sum_{i=1}^N f(x^{(i)}) w(x^{(i)})
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(x^{(i)} \sim q(x)\)</span></li>
<li><span class="math inline">\(w(x^{(i)}) = \frac{p(x^{(i)})}{q(x^{(i)})}\)</span> are importance weights</li>
</ul>
<p>Key considerations:</p>
<ul>
<li><p>Support: <span class="math inline">\(q(x)\)</span> must cover all regions where <span class="math inline">\(p(x)\)</span> has probability mass.</p></li>
<li><p>Variance: poor choice of <span class="math inline">\(q(x)\)</span> leads to high variance in weights.</p></li>
<li><p>Normalized weights: often use</p>
<p><span class="math display">\[
\hat{w}_i = \frac{w(x^{(i)})}{\sum_j w(x^{(j)})}
\]</span></p></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 31%">
<col style="width: 36%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th>Term</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Target distribution <span class="math inline">\(p\)</span></td>
<td>True distribution of interest</td>
<td>Bayesian posterior</td>
</tr>
<tr class="even">
<td>Proposal distribution <span class="math inline">\(q\)</span></td>
<td>Easy-to-sample distribution</td>
<td>Gaussian approximation</td>
</tr>
<tr class="odd">
<td>Importance weights</td>
<td>Correct for mismatch</td>
<td>Rebalancing survey samples</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-42" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-42">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Target: N(0,1), Proposal: N(0,2^2)</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100000</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>proposal <span class="op">=</span> np.random.normal(<span class="dv">0</span>,<span class="dv">2</span>,N)</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>target_pdf <span class="op">=</span> <span class="kw">lambda</span> x: np.exp(<span class="op">-</span>x2<span class="op">/</span><span class="dv">2</span>)<span class="op">/</span>np.sqrt(<span class="dv">2</span><span class="op">*</span>np.pi)</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>proposal_pdf <span class="op">=</span> <span class="kw">lambda</span> x: np.exp(<span class="op">-</span>x2<span class="op">/</span><span class="dv">8</span>)<span class="op">/</span>np.sqrt(<span class="dv">8</span><span class="op">*</span>np.pi)</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> target_pdf(proposal) <span class="op">/</span> proposal_pdf(proposal)</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate E[X^2] under target</span></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>estimate <span class="op">=</span> np.<span class="bu">sum</span>(weights <span class="op">*</span> proposal2) <span class="op">/</span> np.<span class="bu">sum</span>(weights)</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Importance Sampling estimate of E[X^2]:"</span>, estimate)</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"True value:"</span>, <span class="fl">1.0</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-42" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-42">Why It Matters</h4>
<p>Importance sampling makes inference possible when direct sampling is hard. It underpins advanced algorithms like sequential Monte Carlo (particle filters) and variational inference hybrids. It’s especially powerful for Bayesian inference, where posteriors are often intractable but can be reweighted from simpler proposals.</p>
</section>
<section id="try-it-yourself-42" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-42">Try It Yourself</h4>
<ol type="1">
<li>Estimate <span class="math inline">\(\pi\)</span> using importance sampling with a uniform proposal over a square and weights for points inside the circle.</li>
<li>Compare performance when <span class="math inline">\(q(x)\)</span> is close to <span class="math inline">\(p(x)\)</span> versus when it is far. How does variance behave?</li>
<li>Reflect: why is choosing a good proposal distribution often the hardest part of importance sampling?</li>
</ol>
</section>
</section>
<section id="markov-chain-monte-carlo-mcmc" class="level3">
<h3 class="anchored" data-anchor-id="markov-chain-monte-carlo-mcmc">544. Markov Chain Monte Carlo (MCMC)</h3>
<p>Markov Chain Monte Carlo (MCMC) methods generate samples from a target distribution <span class="math inline">\(p(x)\)</span> by constructing a Markov chain whose stationary distribution is <span class="math inline">\(p(x)\)</span>. Instead of drawing independent samples directly (often impossible), MCMC takes correlated steps that eventually explore the entire distribution.</p>
<section id="picture-in-your-head-43" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-43">Picture in Your Head</h4>
<p>Imagine wandering through a city at night. You don’t teleport randomly (independent samples); instead, you walk from block to block, choosing each step based on your current location. Over time, your path covers the whole city in proportion to how popular each area is—that’s the stationary distribution.</p>
</section>
<section id="deep-dive-43" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-43">Deep Dive</h4>
<ul>
<li>Goal: approximate expectations under <span class="math inline">\(p(x)\)</span>.</li>
<li>Core idea: build a Markov chain with transition kernel <span class="math inline">\(T(x' \mid x)\)</span> such that <span class="math inline">\(p(x)\)</span> is invariant.</li>
<li>Ergodicity: ensures that long-run averages converge to expectations under <span class="math inline">\(p(x)\)</span>.</li>
<li>Burn-in: discard early samples before the chain reaches stationarity.</li>
<li>Thinning: sometimes keep every <span class="math inline">\(k\)</span>-th sample to reduce correlation.</li>
</ul>
<p>Common MCMC algorithms:</p>
<ul>
<li><p>Metropolis–Hastings: propose new state, accept/reject with probability:</p>
<p><span class="math display">\[
\alpha = \min\left(1, \frac{p(x')q(x\mid x')}{p(x)q(x'\mid x)}\right)
\]</span></p></li>
<li><p>Gibbs Sampling: update one variable at a time from its conditional distribution.</p></li>
<li><p>Hamiltonian Monte Carlo (HMC): use gradient information for efficient moves.</p></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 26%">
<col style="width: 44%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Strength</th>
<th>Limitation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Metropolis–Hastings</td>
<td>General, flexible</td>
<td>Can mix slowly</td>
</tr>
<tr class="even">
<td>Gibbs Sampling</td>
<td>Simple if conditionals are known</td>
<td>Not always applicable</td>
</tr>
<tr class="odd">
<td>HMC</td>
<td>Efficient in high dimensions</td>
<td>Requires gradients</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-43" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-43">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Target: standard normal via MCMC (Metropolis-Hastings)</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> target_pdf(x):</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.exp(<span class="op">-</span>x2<span class="op">/</span><span class="dv">2</span>)<span class="op">/</span>np.sqrt(<span class="dv">2</span><span class="op">*</span>np.pi)</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">50000</span></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> []</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>    x_new <span class="op">=</span> x <span class="op">+</span> np.random.normal(<span class="dv">0</span>,<span class="dv">1</span>)  <span class="co"># proposal: Gaussian step</span></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> <span class="bu">min</span>(<span class="dv">1</span>, target_pdf(x_new)<span class="op">/</span>target_pdf(x))</span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> np.random.rand() <span class="op">&lt;</span> alpha:</span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x_new</span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>    samples.append(x)</span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MCMC estimate of E[X^2]:"</span>, np.mean(np.array(samples)<span class="dv">2</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-43" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-43">Why It Matters</h4>
<p>MCMC is the backbone of Bayesian computation. It allows sampling from complex, high-dimensional distributions where direct methods fail. From topic models to probabilistic programming to physics simulations, MCMC makes Bayesian reasoning feasible in practice.</p>
</section>
<section id="try-it-yourself-43" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-43">Try It Yourself</h4>
<ol type="1">
<li>Implement Gibbs sampling for a two-variable joint distribution with known conditionals.</li>
<li>Compare the variance of estimates between independent Monte Carlo and MCMC.</li>
<li>Reflect: why is diagnosing convergence one of the hardest parts of using MCMC in practice?</li>
</ol>
</section>
</section>
<section id="gibbs-sampling-and-metropolis-hastings" class="level3">
<h3 class="anchored" data-anchor-id="gibbs-sampling-and-metropolis-hastings">545. Gibbs Sampling and Metropolis-Hastings</h3>
<p>Two of the most widely used MCMC algorithms are Metropolis–Hastings (MH) and Gibbs sampling. MH is a general-purpose framework for constructing Markov chains, while Gibbs is a special case that exploits conditional distributions to simplify sampling.</p>
<section id="picture-in-your-head-44" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-44">Picture in Your Head</h4>
<p>Think of exploring a landscape at night with a flashlight. With MH, you propose a step in a random direction and then decide whether to take it based on how good the new spot looks. With Gibbs, you don’t wander randomly—you cycle through coordinates (x, y, z), adjusting one dimension at a time according to the local terrain.</p>
</section>
<section id="deep-dive-44" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-44">Deep Dive</h4>
<ul>
<li><p>Metropolis–Hastings (MH):</p>
<ul>
<li><p>Propose <span class="math inline">\(x' \sim q(x' \mid x)\)</span>.</p></li>
<li><p>Accept with probability:</p>
<p><span class="math display">\[
\alpha = \min \left( 1, \frac{p(x')q(x \mid x')}{p(x)q(x' \mid x)} \right)
\]</span></p></li>
<li><p>If rejected, stay at <span class="math inline">\(x\)</span>.</p></li>
</ul></li>
<li><p>Gibbs Sampling:</p>
<ul>
<li><p>Special case of MH where proposals come from exact conditional distributions.</p></li>
<li><p>Cycle through variables:</p>
<p><span class="math display">\[
x_i^{(t+1)} \sim p(x_i \mid x_{\setminus i}^{(t)})
\]</span></p></li>
<li><p>Always accepted → efficient when conditionals are known.</p></li>
</ul></li>
</ul>
<p>Comparison:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 26%">
<col style="width: 31%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="header">
<th>Algorithm</th>
<th>Pros</th>
<th>Cons</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Metropolis–Hastings</td>
<td>General, works with any target</td>
<td>May reject proposals, can mix slowly</td>
<td>Complex posteriors</td>
</tr>
<tr class="even">
<td>Gibbs Sampling</td>
<td>Simpler, no rejections</td>
<td>Needs closed-form conditionals</td>
<td>Bayesian hierarchical models</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-44" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-44">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Gibbs sampling for P(x,y) ~ N(0,1) independent normals</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> []</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>x, y <span class="op">=</span> <span class="fl">0.0</span>, <span class="fl">0.0</span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sample x | y (independent, so just N(0,1))</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.random.normal(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sample y | x (independent, so just N(0,1))</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> np.random.normal(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>    samples.append((x,y))</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Empirical mean of x:"</span>, np.mean([s[<span class="dv">0</span>] <span class="cf">for</span> s <span class="kw">in</span> samples]))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-44" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-44">Why It Matters</h4>
<p>MH and Gibbs sampling are the workhorses of Bayesian inference. MH provides flexibility when conditional distributions are unknown, while Gibbs is efficient when they are tractable. Many real-world probabilistic models (topic models, hierarchical Bayes, image priors) rely on one or both.</p>
</section>
<section id="try-it-yourself-44" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-44">Try It Yourself</h4>
<ol type="1">
<li>Implement MH to sample from a bimodal distribution (mixture of Gaussians). Compare histogram with true PDF.</li>
<li>Implement Gibbs sampling for a bivariate Gaussian with correlated variables.</li>
<li>Reflect: why does Gibbs sampling sometimes mix faster than MH, and when might MH be the only option?</li>
</ol>
</section>
</section>
<section id="variational-inference-overview" class="level3">
<h3 class="anchored" data-anchor-id="variational-inference-overview">546. Variational Inference Overview</h3>
<p>Variational Inference (VI) turns the problem of approximate inference into an optimization task. Instead of sampling from the true posterior <span class="math inline">\(p(z \mid x)\)</span>, we pick a simpler family of distributions <span class="math inline">\(q(z;\theta)\)</span> and optimize <span class="math inline">\(\theta\)</span> so that <span class="math inline">\(q\)</span> is as close as possible to <span class="math inline">\(p\)</span>.</p>
<section id="picture-in-your-head-45" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-45">Picture in Your Head</h4>
<p>Imagine trying to fit a key into a complex lock. Instead of carving a perfect copy of the lock’s shape (intractable posterior), you choose a simpler key design (variational family) and file it down until it fits well enough to open the door.</p>
</section>
<section id="deep-dive-45" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-45">Deep Dive</h4>
<ul>
<li><p>Goal: approximate intractable posterior <span class="math inline">\(p(z \mid x)\)</span>.</p></li>
<li><p>Approach: choose variational family <span class="math inline">\(q(z;\theta)\)</span>.</p></li>
<li><p>Objective: minimize KL divergence:</p>
<p><span class="math display">\[
\text{KL}(q(z;\theta) \parallel p(z \mid x))
\]</span></p></li>
<li><p>Equivalent formulation: maximize Evidence Lower Bound (ELBO):</p>
<p><span class="math display">\[
\log p(x) \geq \mathbb{E}_{q(z)}[\log p(x,z) - \log q(z)]
\]</span></p></li>
<li><p>Optimization: gradient ascent, stochastic optimization, reparameterization trick.</p></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 46%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th>Term</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Variational family</td>
<td>Class of approximating distributions</td>
<td>Mean-field Gaussians</td>
</tr>
<tr class="even">
<td>ELBO</td>
<td>Optimized objective</td>
<td>Proxy for log-likelihood</td>
</tr>
<tr class="odd">
<td>Reparameterization</td>
<td>Trick for gradients</td>
<td>VAE training</td>
</tr>
</tbody>
</table>
<p>Applications:</p>
<ul>
<li>Topic models (variational LDA).</li>
<li>Variational autoencoders (VAEs).</li>
<li>Bayesian deep learning for scalable inference.</li>
</ul>
</section>
<section id="tiny-code-45" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-45">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.distributions <span class="im">as</span> dist</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Toy VI: approximate posterior of N(0,1) with N(mu, sigma^2)</span></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> dist.Normal(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> torch.tensor(<span class="fl">0.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>log_sigma <span class="op">=</span> torch.tensor(<span class="fl">0.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam([mu, log_sigma], lr<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">200</span>):</span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> torch.exp(log_sigma)</span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a>    q <span class="op">=</span> dist.Normal(mu, sigma)</span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> q.rsample((<span class="dv">1000</span>,))  <span class="co"># reparameterization trick</span></span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>    elbo <span class="op">=</span> (target.log_prob(samples) <span class="op">-</span> q.log_prob(samples)).mean()</span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="op">-</span>elbo</span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-21"><a href="#cb47-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Learned mu, sigma:"</span>, mu.item(), torch.exp(log_sigma).item())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-45" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-45">Why It Matters</h4>
<p>VI scales Bayesian inference to large datasets and complex models, where MCMC would be too slow. It’s the foundation for modern deep generative models like VAEs and is widely used in probabilistic programming systems.</p>
</section>
<section id="try-it-yourself-45" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-45">Try It Yourself</h4>
<ol type="1">
<li>Use mean-field VI to approximate a 2D Gaussian posterior with correlation. Compare results to exact.</li>
<li>Derive the ELBO for a simple mixture of Gaussians model.</li>
<li>Reflect: why is VI often preferred in large-scale AI, even if it introduces bias compared to MCMC?</li>
</ol>
</section>
</section>
<section id="mean-field-approximation" class="level3">
<h3 class="anchored" data-anchor-id="mean-field-approximation">547. Mean-Field Approximation</h3>
<p>Mean-field variational inference simplifies inference by assuming that the posterior distribution factorizes across variables. Instead of modeling dependencies, each variable is treated as independent under the variational approximation, making optimization tractable but at the cost of ignoring correlations.</p>
<section id="picture-in-your-head-46" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-46">Picture in Your Head</h4>
<p>Think of a group of friends planning a trip. In reality, their choices (flights, hotels, meals) are interdependent. A mean-field approach assumes each friend makes decisions completely independently. This simplification makes planning easy, but it misses the fact that they usually coordinate.</p>
</section>
<section id="deep-dive-46" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-46">Deep Dive</h4>
<ul>
<li><p>Assumption:</p>
<p><span class="math display">\[
q(z) = \prod_i q_i(z_i)
\]</span></p></li>
<li><p>Update rule (coordinate ascent VI): Each factor <span class="math inline">\(q_i(z_i)\)</span> is updated as:</p>
<p><span class="math display">\[
\log q_i^*(z_i) \propto \mathbb{E}_{j \neq i}[\log p(z,x)]
\]</span></p></li>
<li><p>Advantages:</p>
<ul>
<li>Scales to large models.</li>
<li>Easy to implement.</li>
</ul></li>
<li><p>Disadvantages:</p>
<ul>
<li>Ignores correlations between latent variables.</li>
<li>Can lead to underestimation of uncertainty.</li>
</ul></li>
</ul>
<p>Examples:</p>
<ul>
<li>Latent Dirichlet Allocation (LDA): mean-field VI for topic modeling.</li>
<li>Bayesian networks: variational approximations when exact posteriors are intractable.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 36%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th>Aspect</th>
<th>Benefit</th>
<th>Cost</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Factorization</td>
<td>Simplifies optimization</td>
<td>Misses dependencies</td>
</tr>
<tr class="even">
<td>Scalability</td>
<td>Efficient updates</td>
<td>Approximation bias</td>
</tr>
<tr class="odd">
<td>Interpretability</td>
<td>Easy to implement</td>
<td>Overconfident posteriors</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-46" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-46">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.distributions <span class="im">as</span> dist</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Approximate correlated Gaussian with mean-field</span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>true <span class="op">=</span> dist.MultivariateNormal(torch.zeros(<span class="dv">2</span>), torch.tensor([[<span class="fl">1.0</span>,<span class="fl">0.8</span>],[<span class="fl">0.8</span>,<span class="fl">1.0</span>]]))</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Mean-field: independent Gaussians q(z1)*q(z2)</span></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> torch.zeros(<span class="dv">2</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>log_sigma <span class="op">=</span> torch.zeros(<span class="dv">2</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam([mu, log_sigma], lr<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2000</span>):</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> torch.exp(log_sigma)</span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>    q <span class="op">=</span> dist.Normal(mu, sigma)</span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> q.rsample((<span class="dv">1000</span>,<span class="dv">2</span>))</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>    log_q <span class="op">=</span> q.log_prob(samples).<span class="bu">sum</span>(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>    log_p <span class="op">=</span> true.log_prob(samples)</span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a>    elbo <span class="op">=</span> (log_p <span class="op">-</span> log_q).mean()</span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="op">-</span>elbo</span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb48-22"><a href="#cb48-22" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb48-23"><a href="#cb48-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-24"><a href="#cb48-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Learned mean:"</span>, mu.data, <span class="st">"Learned sigma:"</span>, torch.exp(log_sigma).data)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-46" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-46">Why It Matters</h4>
<p>Mean-field is the simplest and most widely used form of variational inference. While crude, it enables scalable approximate Bayesian inference in settings where exact methods or even MCMC would be too slow. It is the starting point for more sophisticated structured variational approximations.</p>
</section>
<section id="try-it-yourself-46" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-46">Try It Yourself</h4>
<ol type="1">
<li>Apply mean-field VI to approximate a bivariate Gaussian with correlation 0.9. Compare marginals with the true distribution.</li>
<li>Derive the coordinate ascent updates for a Gaussian mixture model.</li>
<li>Reflect: why does mean-field often lead to underestimating posterior variance?</li>
</ol>
</section>
</section>
<section id="variational-autoencoders-as-inference-machines" class="level3">
<h3 class="anchored" data-anchor-id="variational-autoencoders-as-inference-machines">548. Variational Autoencoders as Inference Machines</h3>
<p>Variational Autoencoders (VAEs) combine deep learning with variational inference to approximate complex posteriors. They introduce an encoder network to generate variational parameters and a decoder network to model data likelihood. Training uses the ELBO objective with the reparameterization trick for gradient-based optimization.</p>
<section id="picture-in-your-head-47" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-47">Picture in Your Head</h4>
<p>Imagine compressing a photo into a code. The encoder guesses a distribution over possible codes (latent variables), while the decoder reconstructs the photo from that code. By training end-to-end, the system learns both how to encode efficiently and how to decode realistically, guided by probabilistic principles.</p>
</section>
<section id="deep-dive-47" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-47">Deep Dive</h4>
<ul>
<li><p>Generative model:</p>
<p><span class="math display">\[
p_\theta(x,z) = p(z) p_\theta(x \mid z)
\]</span></p>
<p>where <span class="math inline">\(p(z)\)</span> is a prior (e.g., standard normal).</p></li>
<li><p>Inference model (encoder):</p>
<p><span class="math display">\[
q_\phi(z \mid x) \approx p_\theta(z \mid x)
\]</span></p></li>
<li><p>Objective (ELBO):</p>
<p><span class="math display">\[
\mathcal{L} = \mathbb{E}_{q_\phi(z \mid x)}[\log p_\theta(x \mid z)] - \text{KL}(q_\phi(z \mid x) \parallel p(z))
\]</span></p></li>
<li><p>Reparameterization trick: For Gaussian <span class="math inline">\(q_\phi(z \mid x) = \mathcal{N}(\mu, \sigma^2)\)</span>:</p>
<p><span class="math display">\[
z = \mu + \sigma \cdot \epsilon, \quad \epsilon \sim \mathcal{N}(0,1)
\]</span></p></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 31%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Component</th>
<th>Role</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Encoder (inference net)</td>
<td>Outputs variational parameters</td>
<td>Neural net mapping <span class="math inline">\(x \to (\mu, \sigma)\)</span></td>
</tr>
<tr class="even">
<td>Decoder (generative net)</td>
<td>Models likelihood</td>
<td>Neural net mapping <span class="math inline">\(z \to x\)</span></td>
</tr>
<tr class="odd">
<td>Latent prior</td>
<td>Regularizer</td>
<td><span class="math inline">\(p(z) = \mathcal{N}(0,I)\)</span></td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, PyTorch)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> VAE(nn.Module):</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim<span class="op">=</span><span class="dv">784</span>, latent_dim<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(input_dim, <span class="dv">400</span>)</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc_mu <span class="op">=</span> nn.Linear(<span class="dv">400</span>, latent_dim)</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc_logvar <span class="op">=</span> nn.Linear(<span class="dv">400</span>, latent_dim)</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(latent_dim, <span class="dv">400</span>)</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc3 <span class="op">=</span> nn.Linear(<span class="dv">400</span>, input_dim)</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> encode(<span class="va">self</span>, x):</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> F.relu(<span class="va">self</span>.fc1(x))</span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.fc_mu(h), <span class="va">self</span>.fc_logvar(h)</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> reparameterize(<span class="va">self</span>, mu, logvar):</span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a>        std <span class="op">=</span> torch.exp(<span class="fl">0.5</span><span class="op">*</span>logvar)</span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a>        eps <span class="op">=</span> torch.randn_like(std)</span>
<span id="cb49-21"><a href="#cb49-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> mu <span class="op">+</span> eps<span class="op">*</span>std</span>
<span id="cb49-22"><a href="#cb49-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-23"><a href="#cb49-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> decode(<span class="va">self</span>, z):</span>
<span id="cb49-24"><a href="#cb49-24" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> F.relu(<span class="va">self</span>.fc2(z))</span>
<span id="cb49-25"><a href="#cb49-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.fc3(h))</span>
<span id="cb49-26"><a href="#cb49-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-27"><a href="#cb49-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb49-28"><a href="#cb49-28" aria-hidden="true" tabindex="-1"></a>        mu, logvar <span class="op">=</span> <span class="va">self</span>.encode(x)</span>
<span id="cb49-29"><a href="#cb49-29" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.reparameterize(mu, logvar)</span>
<span id="cb49-30"><a href="#cb49-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.decode(z), mu, logvar</span>
<span id="cb49-31"><a href="#cb49-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-32"><a href="#cb49-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> vae_loss(recon_x, x, mu, logvar):</span>
<span id="cb49-33"><a href="#cb49-33" aria-hidden="true" tabindex="-1"></a>    BCE <span class="op">=</span> F.binary_cross_entropy(recon_x, x, reduction<span class="op">=</span><span class="st">"sum"</span>)</span>
<span id="cb49-34"><a href="#cb49-34" aria-hidden="true" tabindex="-1"></a>    KLD <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> torch.<span class="bu">sum</span>(<span class="dv">1</span> <span class="op">+</span> logvar <span class="op">-</span> mu.<span class="bu">pow</span>(<span class="dv">2</span>) <span class="op">-</span> logvar.exp())</span>
<span id="cb49-35"><a href="#cb49-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> BCE <span class="op">+</span> KLD</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-47" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-47">Why It Matters</h4>
<p>VAEs bridge probabilistic inference and deep learning. They enable scalable latent-variable modeling with neural networks, powering applications from generative art to semi-supervised learning and anomaly detection. They exemplify how inference can be automated by amortizing it into neural architectures.</p>
</section>
<section id="try-it-yourself-47" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-47">Try It Yourself</h4>
<ol type="1">
<li>Train a simple VAE on MNIST digits and visualize samples from the latent space.</li>
<li>Experiment with latent dimensions (2 vs.&nbsp;20). How does expressivity change?</li>
<li>Reflect: why is the KL divergence term essential in preventing the encoder from collapsing into a deterministic autoencoder?</li>
</ol>
</section>
</section>
<section id="hybrid-methods-sampling-variational" class="level3">
<h3 class="anchored" data-anchor-id="hybrid-methods-sampling-variational">549. Hybrid Methods: Sampling + Variational</h3>
<p>Hybrid inference methods combine sampling (e.g., MCMC) with variational inference (VI) to balance scalability and accuracy. Variational methods provide fast but biased approximations, while sampling methods are asymptotically exact but often slow. Hybrids use one to compensate for the weaknesses of the other.</p>
<section id="picture-in-your-head-48" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-48">Picture in Your Head</h4>
<p>Think of estimating the size of a forest. Variational inference is like flying a drone overhead to sketch a quick map (fast but approximate). Sampling is like sending hikers to measure trees on the ground (slow but accurate). A hybrid approach combines both—the drone map guides the hikers, and the hikers correct the drone’s errors.</p>
</section>
<section id="deep-dive-48" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-48">Deep Dive</h4>
<p>Key hybrid strategies:</p>
<ul>
<li>Variational initialization for MCMC: use VI to find a good proposal distribution or starting point for sampling, reducing burn-in.</li>
<li>MCMC within variational inference: augment the variational family with MCMC steps to improve flexibility (e.g., Hamiltonian variational inference).</li>
<li>Importance-weighted VI: combine sampling-based corrections with variational bounds.</li>
<li>Stochastic variational inference (SVI): use minibatch stochastic gradients + Monte Carlo estimates of expectations.</li>
</ul>
<p>Formulation example:</p>
<p><span class="math display">\[
\mathcal{L}_K = \mathbb{E}_{z^{(1)}, \dots, z^{(K)} \sim q_\phi} \left[ \log \frac{1}{K} \sum_{k=1}^K \frac{p(x, z^{(k)})}{q_\phi(z^{(k)} \mid x)} \right]
\]</span></p>
<p>This importance-weighted ELBO (IWAE) tightens the standard variational bound by reweighting multiple samples.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 35%">
<col style="width: 28%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th>Hybrid Method</th>
<th>Idea</th>
<th>Benefit</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>VI → MCMC</td>
<td>Use VI to warm-start MCMC</td>
<td>Faster convergence</td>
<td>Bayesian neural nets</td>
</tr>
<tr class="even">
<td>MCMC → VI</td>
<td>Use MCMC samples to refine VI</td>
<td>More accurate approximations</td>
<td>Hamiltonian VI</td>
</tr>
<tr class="odd">
<td>IWAE</td>
<td>Multi-sample variational objective</td>
<td>Tighter bound</td>
<td>Deep generative models</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-47" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-47">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.distributions <span class="im">as</span> dist</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Importance Weighted Estimate of log p(x)</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> iwae_bound(x, q, p, K<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>    z_samples <span class="op">=</span> [q.rsample() <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(K)]</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">=</span> [p.log_prob(x) <span class="op">+</span> p.log_prob(z) <span class="op">-</span> q.log_prob(z) <span class="cf">for</span> z <span class="kw">in</span> z_samples]</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>    log_w <span class="op">=</span> torch.stack(weights)</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.logsumexp(log_w, dim<span class="op">=</span><span class="dv">0</span>) <span class="op">-</span> torch.log(torch.tensor(K, dtype<span class="op">=</span>torch.<span class="bu">float</span>))</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Gaussian latent variable model</span></span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>q <span class="op">=</span> dist.Normal(torch.tensor(<span class="fl">0.0</span>), torch.tensor(<span class="fl">1.0</span>))</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> dist.Normal(torch.tensor(<span class="fl">0.0</span>), torch.tensor(<span class="fl">1.0</span>))</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">1.0</span>)</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"IWAE bound:"</span>, iwae_bound(x, q, p, K<span class="op">=</span><span class="dv">10</span>).item())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-48" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-48">Why It Matters</h4>
<p>Hybrid methods enable inference in settings where pure VI or pure MCMC fails. They provide a practical balance: fast approximate learning with VI, corrected by sampling to reduce bias. This is especially important in high-dimensional AI systems like Bayesian neural networks and deep generative models.</p>
</section>
<section id="try-it-yourself-48" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-48">Try It Yourself</h4>
<ol type="1">
<li>Train a VAE with an IWAE bound and compare its sample quality to a standard VAE.</li>
<li>Use VI to initialize a Bayesian regression model, then refine with Gibbs sampling.</li>
<li>Reflect: why do hybrids often provide the best of both worlds in large-scale probabilistic modeling?</li>
</ol>
</section>
</section>
<section id="tradeoffs-in-accuracy-efficiency-and-scalability" class="level3">
<h3 class="anchored" data-anchor-id="tradeoffs-in-accuracy-efficiency-and-scalability">550. Tradeoffs in Accuracy, Efficiency, and Scalability</h3>
<p>Approximate inference methods differ in how they balance accuracy, computational efficiency, and scalability. No single method is best in all situations: Monte Carlo methods are flexible but slow, while variational methods are fast and scalable but biased. Understanding these tradeoffs helps practitioners choose the right tool for the task.</p>
<section id="picture-in-your-head-49" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-49">Picture in Your Head</h4>
<p>Imagine different ways to measure the height of a mountain. Using a laser scanner (accurate but slow and expensive), pacing it step by step (scalable but imprecise), or flying a drone (fast but approximate). Each method has strengths and weaknesses depending on what matters most.</p>
</section>
<section id="deep-dive-49" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-49">Deep Dive</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 8%">
<col style="width: 13%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Accuracy</th>
<th>Efficiency</th>
<th>Scalability</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Monte Carlo (MC)</td>
<td>Asymptotically exact</td>
<td>Low</td>
<td>Poor–moderate</td>
<td>Needs many samples, variance shrinks as <span class="math inline">\(1/\sqrt{N}\)</span></td>
</tr>
<tr class="even">
<td>MCMC</td>
<td>High (in the limit)</td>
<td>Moderate–low</td>
<td>Poor for large data</td>
<td>Burn-in + correlation hurt speed</td>
</tr>
<tr class="odd">
<td>Gibbs Sampling</td>
<td>High (in structured models)</td>
<td>Moderate</td>
<td>Limited</td>
<td>Works when conditionals are tractable</td>
</tr>
<tr class="even">
<td>Variational Inference (VI)</td>
<td>Biased but controlled</td>
<td>High</td>
<td>Excellent</td>
<td>Optimizable with SGD, scalable to big data</td>
</tr>
<tr class="odd">
<td>Hybrid (IWAE, VI+MCMC)</td>
<td>Balanced</td>
<td>Moderate</td>
<td>Good</td>
<td>Corrects biases at extra cost</td>
</tr>
</tbody>
</table>
<p>Key considerations:</p>
<ul>
<li>Accuracy vs.&nbsp;speed: MCMC can approximate the truth closely but at high cost; VI is faster but may underestimate uncertainty.</li>
<li>Scalability: VI handles massive datasets (minibatch gradients, amortized inference).</li>
<li>Bias–variance tradeoff: MC is unbiased but high variance; VI is biased but low variance.</li>
<li>Model fit: Gibbs is ideal when conditionals are easy; HMC when gradients are available.</li>
</ul>
</section>
<section id="tiny-code-48" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-48">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare MC vs VI-style approximation for E[X^2] with X~N(0,1)</span></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> np.random.normal(<span class="dv">0</span>,<span class="dv">1</span>,N)</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>mc_estimate <span class="op">=</span> np.mean(samples2)  <span class="co"># unbiased, noisy</span></span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a><span class="co"># VI-style approximation: assume q ~ N(0,0.8^2) instead of N(0,1)</span></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>q_sigma <span class="op">=</span> <span class="fl">0.8</span></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>vi_estimate <span class="op">=</span> q_sigma2  <span class="co"># biased, but deterministic</span></span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Monte Carlo estimate:"</span>, mc_estimate)</span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"VI-style estimate (biased):"</span>, vi_estimate)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-49" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-49">Why It Matters</h4>
<p>Choosing the right inference method is about aligning with application goals. If accuracy is paramount (e.g., physics simulations, safety-critical systems), sampling methods are preferable. If scalability and speed dominate (e.g., large-scale deep generative models), VI is the tool of choice. Hybrids often strike the best balance in modern AI.</p>
</section>
<section id="try-it-yourself-49" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-49">Try It Yourself</h4>
<ol type="1">
<li>Estimate the posterior mean of a Bayesian linear regression using MCMC, VI, and IWAE. Compare results and runtime.</li>
<li>Explore how minibatch training makes VI feasible on large datasets where MCMC stalls.</li>
<li>Reflect: when is it acceptable to sacrifice exactness for speed, and when is accuracy worth the computational cost?</li>
</ol>
</section>
</section>
</section>
<section id="chapter-56.-latent-variable-models-and-em" class="level2">
<h2 class="anchored" data-anchor-id="chapter-56.-latent-variable-models-and-em">Chapter 56. Latent Variable Models and EM</h2>
<section id="latent-vs.-observed-variables" class="level3">
<h3 class="anchored" data-anchor-id="latent-vs.-observed-variables">551. Latent vs.&nbsp;Observed Variables</h3>
<p>Probabilistic models often distinguish between observed variables (data we can measure) and latent variables (hidden structure or causes we cannot see directly). Latent variables explain observed data, simplify modeling, and enable richer representations.</p>
<section id="picture-in-your-head-50" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-50">Picture in Your Head</h4>
<p>Think of a classroom test. The observed variables are the students’ answers on the exam. The latent variable is each student’s true understanding of the material. We never see the understanding directly, but it shapes the answers.</p>
</section>
<section id="deep-dive-50" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-50">Deep Dive</h4>
<ul>
<li><p>Observed variables (<span class="math inline">\(x\)</span>): known data points (images, words, test scores).</p></li>
<li><p>Latent variables (<span class="math inline">\(z\)</span>): hidden variables that generate or structure the data.</p></li>
<li><p>Model factorization:</p>
<p><span class="math display">\[
p(x,z) = p(z) \, p(x \mid z)
\]</span></p>
<ul>
<li><span class="math inline">\(p(z)\)</span>: prior over latent variables.</li>
<li><span class="math inline">\(p(x \mid z)\)</span>: likelihood of observed data given latent structure.</li>
</ul></li>
</ul>
<p>Examples:</p>
<ul>
<li>Mixture of Gaussians: latent variable = cluster assignment.</li>
<li>Topic models (LDA): latent variable = topic proportions.</li>
<li>Hidden Markov Models (HMMs): latent variable = hidden state sequence.</li>
<li>VAEs: latent variable = compressed representation of data.</li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Model</th>
<th>Observed</th>
<th>Latent</th>
<th>Role of Latent</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Gaussian Mixture</td>
<td>Data points</td>
<td>Cluster IDs</td>
<td>Explain clusters</td>
</tr>
<tr class="even">
<td>HMM</td>
<td>Emissions</td>
<td>Hidden states</td>
<td>Explain sequences</td>
</tr>
<tr class="odd">
<td>LDA</td>
<td>Words</td>
<td>Topics</td>
<td>Explain documents</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-49" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-49">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple latent-variable model: mixture of Gaussians</span></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> np.random.choice([<span class="dv">0</span>,<span class="dv">1</span>], size<span class="op">=</span><span class="dv">10</span>, p<span class="op">=</span>[<span class="fl">0.4</span>,<span class="fl">0.6</span>])  <span class="co"># latent cluster labels</span></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>means <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">5</span>]</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.array([np.random.normal(means[zi], <span class="dv">1</span>) <span class="cf">for</span> zi <span class="kw">in</span> z])  <span class="co"># observed data</span></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Latent cluster assignments:"</span>, z)</span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Observed data:"</span>, x.<span class="bu">round</span>(<span class="dv">2</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-50" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-50">Why It Matters</h4>
<p>Latent variables allow us to capture structure, compress data, and reason about hidden causes. They are central to unsupervised learning and probabilistic AI, where the goal is often to uncover what’s not directly observable.</p>
</section>
<section id="try-it-yourself-50" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-50">Try It Yourself</h4>
<ol type="1">
<li>Write down the latent-variable structure of a Gaussian mixture model for 1D data.</li>
<li>Think of a real-world dataset (e.g., movie ratings). What could the latent variables be?</li>
<li>Reflect: why do latent variables make inference harder, but also make models more expressive?</li>
</ol>
</section>
</section>
<section id="mixture-models-as-latent-variable-models" class="level3">
<h3 class="anchored" data-anchor-id="mixture-models-as-latent-variable-models">552. Mixture Models as Latent Variable Models</h3>
<p>Mixture models describe data as coming from a combination of several underlying distributions. Each observation is assumed to be generated by first choosing a latent component (cluster), then sampling from that component’s distribution. This makes mixture models a classic example of latent variable models.</p>
<section id="picture-in-your-head-51" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-51">Picture in Your Head</h4>
<p>Imagine you walk into an ice cream shop and see a mix of chocolate, vanilla, and strawberry scoops in a bowl. Each scoop (data point) clearly belongs to one flavor (latent component), but you only observe the mixture as a whole. The “flavor identity” is the latent variable.</p>
</section>
<section id="deep-dive-51" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-51">Deep Dive</h4>
<ul>
<li><p>Model definition:</p>
<p><span class="math display">\[
p(x) = \sum_{k=1}^K \pi_k \, p(x \mid z=k, \theta_k)
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\pi_k\)</span>: mixture weights (<span class="math inline">\(\sum_k \pi_k = 1\)</span>)</li>
<li><span class="math inline">\(z\)</span>: latent variable indicating component assignment</li>
<li><span class="math inline">\(p(x \mid z=k, \theta_k)\)</span>: component distribution</li>
</ul></li>
<li><p>Latent structure:</p>
<ul>
<li><span class="math inline">\(z \sim \text{Categorical}(\pi)\)</span></li>
<li><span class="math inline">\(x \sim p(x \mid z, \theta_z)\)</span></li>
</ul></li>
</ul>
<p>Examples:</p>
<ul>
<li>Gaussian Mixture Models (GMMs): each component is a Gaussian.</li>
<li>Mixture of multinomials: topic models for documents.</li>
<li>Mixture of experts: gating network decides which expert model generates data.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 27%">
<col style="width: 35%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Component</th>
<th>Role</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Latent variable <span class="math inline">\(z\)</span></td>
<td>Selects component</td>
<td>Cluster ID</td>
</tr>
<tr class="even">
<td>Parameters <span class="math inline">\(\theta_k\)</span></td>
<td>Defines each component</td>
<td>Mean &amp; covariance of Gaussian</td>
</tr>
<tr class="odd">
<td>Mixing weights <span class="math inline">\(\pi\)</span></td>
<td>Probabilities of components</td>
<td>Cluster proportions</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-50" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-50">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Gaussian mixture with 2 components</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>pi <span class="op">=</span> [<span class="fl">0.3</span>, <span class="fl">0.7</span>]</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>means <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">5</span>]</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>sigmas <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample latent assignments</span></span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> np.random.choice([<span class="dv">0</span>,<span class="dv">1</span>], size<span class="op">=</span><span class="dv">10</span>, p<span class="op">=</span>pi)</span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.array([np.random.normal(means[zi], sigmas[zi]) <span class="cf">for</span> zi <span class="kw">in</span> z])</span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Latent assignments:"</span>, z)</span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Observed samples:"</span>, np.<span class="bu">round</span>(x,<span class="dv">2</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-51" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-51">Why It Matters</h4>
<p>Mixture models are a cornerstone of unsupervised learning. They formalize clustering probabilistically and provide interpretable latent structure. They also serve as building blocks for more advanced models like HMMs, topic models, and deep mixture models.</p>
</section>
<section id="try-it-yourself-51" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-51">Try It Yourself</h4>
<ol type="1">
<li>Write down the joint distribution <span class="math inline">\(p(x, z)\)</span> for a mixture of Gaussians.</li>
<li>Simulate 100 samples from a 3-component Gaussian mixture and plot the histogram.</li>
<li>Reflect: why do mixture models naturally capture multimodality in data distributions?</li>
</ol>
</section>
</section>
<section id="expectation-maximization-em-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="expectation-maximization-em-algorithm">553. Expectation-Maximization (EM) Algorithm</h3>
<p>The Expectation-Maximization (EM) algorithm is a general framework for learning parameters in models with latent variables. Since the latent structure makes direct maximum likelihood estimation hard, EM alternates between estimating the hidden variables (E-step) and optimizing the parameters (M-step).</p>
<section id="picture-in-your-head-52" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-52">Picture in Your Head</h4>
<p>Think of trying to organize a party guest list. Some guests didn’t RSVP, so you don’t know who’s coming (latent variables). First, you estimate who is likely to attend based on partial info (E-step). Then, you adjust the catering order accordingly (M-step). Repeat until the estimates stabilize.</p>
</section>
<section id="deep-dive-52" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-52">Deep Dive</h4>
<ul>
<li><p>Goal: maximize likelihood</p>
<p><span class="math display">\[
\ell(\theta) = \log p(x \mid \theta) = \log \sum_z p(x,z \mid \theta)
\]</span></p></li>
<li><p>Challenge: log of a sum prevents closed-form optimization.</p></li>
<li><p>EM procedure:</p>
<ol type="1">
<li><p>E-step: compute expected complete-data log-likelihood using current parameters:</p>
<p><span class="math display">\[
Q(\theta \mid \theta^{(t)}) = \mathbb{E}_{z \mid x, \theta^{(t)}}[\log p(x,z \mid \theta)]
\]</span></p></li>
<li><p>M-step: maximize this expectation w.r.t. <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[
\theta^{(t+1)} = \arg\max_\theta Q(\theta \mid \theta^{(t)})
\]</span></p></li>
</ol></li>
<li><p>Convergence: guaranteed to increase likelihood at each step, though only to a local optimum.</p></li>
</ul>
<p>Examples:</p>
<ul>
<li>Gaussian mixture models (GMMs).</li>
<li>Hidden Markov models (HMMs).</li>
<li>Factor analyzers, topic models.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 7%">
<col style="width: 25%">
<col style="width: 35%">
<col style="width: 31%">
</colgroup>
<thead>
<tr class="header">
<th>Step</th>
<th>Input</th>
<th>Output</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>E-step</td>
<td>Current parameters</td>
<td>Expected latent assignments</td>
<td>“Guess hidden structure”</td>
</tr>
<tr class="even">
<td>M-step</td>
<td>Expected assignments</td>
<td>Updated parameters</td>
<td>“Refit model”</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-51" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-51">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.mixture <span class="im">import</span> GaussianMixture</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a 2-component GMM with EM</span></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.concatenate([np.random.normal(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">100</span>), np.random.normal(<span class="dv">5</span>,<span class="dv">1</span>,<span class="dv">100</span>)]).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>gmm <span class="op">=</span> GaussianMixture(n_components<span class="op">=</span><span class="dv">2</span>).fit(X)</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated means:"</span>, gmm.means_.ravel())</span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated weights:"</span>, gmm.weights_)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-52" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-52">Why It Matters</h4>
<p>EM is one of the most widely used algorithms for models with latent structure. It provides a systematic way to handle missing or hidden data, and forms the basis of many classical AI systems before deep learning. Even today, EM underlies expectation-based updates in probabilistic models.</p>
</section>
<section id="try-it-yourself-52" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-52">Try It Yourself</h4>
<ol type="1">
<li>Derive the E-step and M-step updates for a Gaussian mixture model with known variances.</li>
<li>Implement EM for coin toss data with two biased coins (latent: which coin generated the toss).</li>
<li>Reflect: why does EM often converge to local optima, and how can initialization affect results?</li>
</ol>
</section>
</section>
<section id="e-step-posterior-expectations" class="level3">
<h3 class="anchored" data-anchor-id="e-step-posterior-expectations">554. E-Step: Posterior Expectations</h3>
<p>In the Expectation-Maximization (EM) algorithm, the E-step computes the expected value of the latent variables given the observed data and the current parameters. This transforms the incomplete-data likelihood into a form that can be optimized in the M-step.</p>
<section id="picture-in-your-head-53" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-53">Picture in Your Head</h4>
<p>Imagine a detective solving a mystery. With partial evidence (observed data) and a current theory (parameters), the detective estimates the likelihood of each suspect’s involvement (latent variables). These probabilities guide the next round of investigation.</p>
</section>
<section id="deep-dive-53" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-53">Deep Dive</h4>
<ul>
<li><p>General form: For latent variables <span class="math inline">\(z\)</span> and parameters <span class="math inline">\(\theta^{(t)}\)</span>:</p>
<p><span class="math display">\[
Q(\theta \mid \theta^{(t)}) = \mathbb{E}_{z \mid x, \theta^{(t)}} \big[ \log p(x,z \mid \theta) \big]
\]</span></p></li>
<li><p>Posterior responsibilities (soft assignments): In mixture models:</p>
<p><span class="math display">\[
\gamma_{nk} = P(z_n = k \mid x_n, \theta^{(t)}) = \frac{\pi_k^{(t)} \, p(x_n \mid \theta_k^{(t)})}{\sum_j \pi_j^{(t)} \, p(x_n \mid \theta_j^{(t)})}
\]</span></p></li>
<li><p>Interpretation:</p>
<ul>
<li><span class="math inline">\(\gamma_{nk}\)</span> = responsibility of component <span class="math inline">\(k\)</span> for data point <span class="math inline">\(x_n\)</span>.</li>
<li>These responsibilities act as weights for updating parameters in the M-step.</li>
</ul></li>
</ul>
<p>Example: Gaussian Mixture Model (GMM)</p>
<ul>
<li>E-step assigns each data point a fractional membership in clusters.</li>
<li>If a point lies midway between two Gaussians, both clusters get ~50% responsibility.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 30%">
<col style="width: 32%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="header">
<th>Term</th>
<th>Role in E-step</th>
<th>Example (GMM)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Posterior <span class="math inline">\(P(z \mid x)\)</span></td>
<td>Distribution over latent vars</td>
<td>Cluster probabilities</td>
</tr>
<tr class="even">
<td>Responsibilities <span class="math inline">\(\gamma_{nk}\)</span></td>
<td>Expected latent assignments</td>
<td>Weight of cluster <span class="math inline">\(k\)</span> for point <span class="math inline">\(n\)</span></td>
</tr>
<tr class="odd">
<td>Q-function</td>
<td>Expected complete log-likelihood</td>
<td>Guides parameter updates</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-52" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-52">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple 2-component Gaussian mixture E-step</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array([<span class="fl">0.2</span>, <span class="fl">1.8</span>, <span class="fl">5.0</span>])</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>pi <span class="op">=</span> [<span class="fl">0.5</span>, <span class="fl">0.5</span>]</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>means <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">5</span>]</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>stds <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>resp <span class="op">=</span> []</span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> X:</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>    num <span class="op">=</span> [pi[k]<span class="op">*</span>norm.pdf(x, means[k], stds[k]) <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>)]</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a>    gamma <span class="op">=</span> num <span class="op">/</span> np.<span class="bu">sum</span>(num)</span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a>    resp.append(gamma)</span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Responsibilities:"</span>, np.<span class="bu">round</span>(resp,<span class="dv">3</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-53" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-53">Why It Matters</h4>
<p>The E-step turns hard, unknown latent variables into soft probabilistic estimates. This allows models to handle uncertainty about hidden structure gracefully, avoiding brittle all-or-nothing assignments.</p>
</section>
<section id="try-it-yourself-53" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-53">Try It Yourself</h4>
<ol type="1">
<li>Derive the E-step responsibilities for a 3-component Gaussian mixture.</li>
<li>Run the E-step for a dataset of coin flips with two biased coins.</li>
<li>Reflect: why is the E-step often viewed as “filling in missing data with expectations”?</li>
</ol>
</section>
</section>
<section id="m-step-parameter-maximization" class="level3">
<h3 class="anchored" data-anchor-id="m-step-parameter-maximization">555. M-Step: Parameter Maximization</h3>
<p>In the EM algorithm, the M-step updates the model parameters by maximizing the expected complete-data log-likelihood, using the posterior expectations from the E-step. It’s where the algorithm refits the model to the “softly completed” data.</p>
<section id="picture-in-your-head-54" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-54">Picture in Your Head</h4>
<p>Think of updating a recipe. After tasting (E-step responsibilities), you adjust ingredient proportions (parameters) to better match the desired flavor. Each iteration refines the recipe until it stabilizes.</p>
</section>
<section id="deep-dive-54" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-54">Deep Dive</h4>
<ul>
<li><p>General update rule:</p>
<p><span class="math display">\[
\theta^{(t+1)} = \arg\max_\theta Q(\theta \mid \theta^{(t)})
\]</span></p>
<p>where:</p>
<p><span class="math display">\[
Q(\theta \mid \theta^{(t)}) = \mathbb{E}_{z \mid x, \theta^{(t)}}[\log p(x,z \mid \theta)]
\]</span></p></li>
<li><p>For mixture models (example: Gaussian Mixture Model):</p>
<ul>
<li><p>Mixing coefficients:</p>
<p><span class="math display">\[
\pi_k^{(t+1)} = \frac{1}{N} \sum_{n=1}^N \gamma_{nk}
\]</span></p></li>
<li><p>Means:</p>
<p><span class="math display">\[
\mu_k^{(t+1)} = \frac{\sum_{n=1}^N \gamma_{nk} x_n}{\sum_{n=1}^N \gamma_{nk}}
\]</span></p></li>
<li><p>Variances:</p>
<p><span class="math display">\[
\sigma_k^{2(t+1)} = \frac{\sum_{n=1}^N \gamma_{nk}(x_n - \mu_k^{(t+1)})^2}{\sum_{n=1}^N \gamma_{nk}}
\]</span></p></li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Parameter</th>
<th>Update Rule</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\pi_k\)</span></td>
<td>Average responsibility</td>
<td>Cluster weight</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mu_k\)</span></td>
<td>Weighted average of data</td>
<td>Cluster center</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\sigma_k^2\)</span></td>
<td>Weighted variance</td>
<td>Cluster spread</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-53" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-53">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Toy responsibilities from E-step (3 points, 2 clusters)</span></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>resp <span class="op">=</span> np.array([[<span class="fl">0.9</span>,<span class="fl">0.1</span>],[<span class="fl">0.2</span>,<span class="fl">0.8</span>],[<span class="fl">0.5</span>,<span class="fl">0.5</span>]])</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array([<span class="fl">0.2</span>, <span class="fl">1.8</span>, <span class="fl">5.0</span>])</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>Nk <span class="op">=</span> resp.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>)  <span class="co"># effective cluster sizes</span></span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>pi <span class="op">=</span> Nk <span class="op">/</span> <span class="bu">len</span>(X)</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> (resp.T <span class="op">@</span> X) <span class="op">/</span> Nk</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="op">=</span> (resp.T <span class="op">@</span> (X[:,<span class="va">None</span>] <span class="op">-</span> mu)<span class="dv">2</span>) <span class="op">/</span> Nk</span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Updated pi:"</span>, np.<span class="bu">round</span>(pi,<span class="dv">3</span>))</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Updated mu:"</span>, np.<span class="bu">round</span>(mu,<span class="dv">3</span>))</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Updated sigma^2:"</span>, np.<span class="bu">round</span>(sigma2,<span class="dv">3</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-54" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-54">Why It Matters</h4>
<p>The M-step makes EM a powerful iterative refinement algorithm. By re-estimating parameters based on soft assignments, it avoids overcommitting too early and steadily improves likelihood. Many classic models (mixture models, HMMs, factor analyzers) rely on these updates.</p>
</section>
<section id="try-it-yourself-54" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-54">Try It Yourself</h4>
<ol type="1">
<li>Derive M-step updates for a Bernoulli mixture model (latent = which coin generated each toss).</li>
<li>Implement one iteration of E-step + M-step for a 2D Gaussian mixture.</li>
<li>Reflect: why does the M-step often resemble weighted maximum likelihood estimation?</li>
</ol>
</section>
</section>
<section id="convergence-properties-of-em" class="level3">
<h3 class="anchored" data-anchor-id="convergence-properties-of-em">556. Convergence Properties of EM</h3>
<p>The EM algorithm guarantees that the data likelihood never decreases with each iteration. It climbs the likelihood surface step by step until it reaches a stationary point. However, EM does not guarantee finding the global maximum—it can get stuck in local optima.</p>
<section id="picture-in-your-head-55" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-55">Picture in Your Head</h4>
<p>Imagine climbing a foggy mountain trail. Each step (E-step + M-step) ensures you move uphill. But since the fog blocks your view, you might stop at a smaller hill (local optimum) instead of the tallest peak (global optimum).</p>
</section>
<section id="deep-dive-55" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-55">Deep Dive</h4>
<ul>
<li><p>Monotonic improvement: At each iteration, EM ensures:</p>
<p><span class="math display">\[
\ell(\theta^{(t+1)}) \geq \ell(\theta^{(t)})
\]</span></p>
<p>where <span class="math inline">\(\ell(\theta) = \log p(x \mid \theta)\)</span>.</p></li>
<li><p>Stationary points: Convergence occurs when updates no longer change parameters:</p>
<p><span class="math display">\[
\theta^{(t+1)} \approx \theta^{(t)}
\]</span></p>
<p>This can be a maximum, minimum, or saddle point (though typically a local maximum).</p></li>
<li><p>Speed:</p>
<ul>
<li>Converges linearly (can be slow near optimum).</li>
<li>Sensitive to initialization—bad starts → poor local optima.</li>
</ul></li>
<li><p>Diagnostics:</p>
<ul>
<li>Track log-likelihood increase per iteration.</li>
<li>Use multiple random initializations to avoid poor local maxima.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 27%">
<col style="width: 35%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Property</th>
<th>Behavior</th>
<th>Implication</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Likelihood monotonicity</td>
<td>Always increases</td>
<td>Stable optimization</td>
</tr>
<tr class="even">
<td>Global vs.&nbsp;local</td>
<td>No guarantee of global optimum</td>
<td>Multiple runs often needed</td>
</tr>
<tr class="odd">
<td>Speed</td>
<td>Linear, sometimes slow</td>
<td>May require acceleration methods</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-54" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-54">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.mixture <span class="im">import</span> GaussianMixture</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit GMM multiple times with different initializations</span></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.concatenate([np.random.normal(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">100</span>),</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>                    np.random.normal(<span class="dv">5</span>,<span class="dv">1</span>,<span class="dv">100</span>)]).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>    gmm <span class="op">=</span> GaussianMixture(n_components<span class="op">=</span><span class="dv">2</span>, n_init<span class="op">=</span><span class="dv">1</span>, init_params<span class="op">=</span><span class="st">"random"</span>).fit(X)</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Run </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">, Log-likelihood:"</span>, gmm.score(X)<span class="op">*</span><span class="bu">len</span>(X))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-55" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-55">Why It Matters</h4>
<p>Understanding convergence is crucial in practice. EM is reliable for monotonic improvement but not foolproof—initialization strategies, restarts, or smarter variants (like annealed EM or variational EM) are often required to reach good solutions.</p>
</section>
<section id="try-it-yourself-55" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-55">Try It Yourself</h4>
<ol type="1">
<li>Run EM on a simple Gaussian mixture with poor initialization. Does it converge to the wrong clusters?</li>
<li>Compare convergence speed with well-separated vs.&nbsp;overlapping clusters.</li>
<li>Reflect: why does EM’s guarantee of monotonic improvement make it attractive, despite its local optimum problem?</li>
</ol>
</section>
</section>
<section id="extensions-generalized-em-online-em" class="level3">
<h3 class="anchored" data-anchor-id="extensions-generalized-em-online-em">557. Extensions: Generalized EM, Online EM</h3>
<p>The classical EM algorithm alternates between a full E-step (posterior expectations) and a full M-step (maximize expected log-likelihood). Extensions like Generalized EM (GEM) and Online EM relax these requirements to make EM more flexible, faster, or suitable for streaming data.</p>
<section id="picture-in-your-head-56" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-56">Picture in Your Head</h4>
<p>Think of training for a marathon. Standard EM is like following a strict regimen—complete every drill fully before moving on. GEM allows you to do “good enough” workouts (not perfect but still improving). Online EM is like training in short bursts every day, continuously adapting as conditions change.</p>
</section>
<section id="deep-dive-56" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-56">Deep Dive</h4>
<ul>
<li><p>Generalized EM (GEM):</p>
<ul>
<li><p>M-step doesn’t need to fully maximize <span class="math inline">\(Q(\theta)\)</span>.</p></li>
<li><p>Only requires improvement:</p>
<p><span class="math display">\[
Q(\theta^{(t+1)} \mid \theta^{(t)}) \geq Q(\theta^{(t)} \mid \theta^{(t)})
\]</span></p></li>
<li><p>Useful when exact maximization is hard (e.g., large models, non-closed-form updates).</p></li>
</ul></li>
<li><p>Online EM:</p>
<ul>
<li><p>Updates parameters incrementally as data arrives.</p></li>
<li><p>Uses stochastic approximation:</p>
<p><span class="math display">\[
\theta^{(t+1)} = (1 - \eta_t) \theta^{(t)} + \eta_t \hat{\theta}(x_t)
\]</span></p>
<p>where <span class="math inline">\(\eta_t\)</span> is a learning rate.</p></li>
<li><p>Suitable for streaming or very large datasets.</p></li>
</ul></li>
<li><p>Variants:</p>
<ul>
<li>Stochastic EM: minibatch-based version.</li>
<li>Incremental EM: updates parameters per data point.</li>
<li>Variational EM: replaces E-step with variational inference.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 31%">
<col style="width: 24%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Variant</th>
<th>Key Idea</th>
<th>Benefit</th>
<th>Example Use</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>GEM</td>
<td>Approximate M-step</td>
<td>Faster iterations</td>
<td>Complex latent models</td>
</tr>
<tr class="even">
<td>Online EM</td>
<td>Update with streaming data</td>
<td>Scalability</td>
<td>Real-time recommendation</td>
</tr>
<tr class="odd">
<td>Stochastic EM</td>
<td>Use minibatches</td>
<td>Handles big datasets</td>
<td>Large-scale GMMs</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-55" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-55">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Online EM-style update for Gaussian mean</span></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>eta <span class="op">=</span> <span class="fl">0.1</span>  <span class="co"># learning rate</span></span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.random.normal(<span class="dv">5</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> data:</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> eta) <span class="op">*</span> mu <span class="op">+</span> eta <span class="op">*</span> x  <span class="co"># online update</span></span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated mean (online EM):"</span>, mu)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-56" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-56">Why It Matters</h4>
<p>These extensions make EM practical for real-world AI, where datasets are massive or streaming, and exact optimization is infeasible. GEM provides flexibility, while online EM scales EM’s principles to modern data-intensive settings.</p>
</section>
<section id="try-it-yourself-56" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-56">Try It Yourself</h4>
<ol type="1">
<li>Implement GEM by replacing the M-step in GMM EM with just one gradient ascent step. Does it still converge?</li>
<li>Run online EM on a data stream of Gaussian samples. Compare with batch EM.</li>
<li>Reflect: why is approximate but faster convergence sometimes better than exact but slow convergence?</li>
</ol>
</section>
</section>
<section id="em-in-gaussian-mixture-models" class="level3">
<h3 class="anchored" data-anchor-id="em-in-gaussian-mixture-models">558. EM in Gaussian Mixture Models</h3>
<p>Gaussian Mixture Models (GMMs) are the textbook application of the EM algorithm. Each data point is assumed to come from one of several Gaussian components, but the component assignments are latent. EM alternates between estimating soft assignments of points to clusters (E-step) and updating the Gaussian parameters (M-step).</p>
<section id="picture-in-your-head-57" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-57">Picture in Your Head</h4>
<p>Think of sorting marbles from a mixed jar. You can’t see labels, but you guess which marble belongs to which bag (E-step), then adjust the bag descriptions (mean and variance) based on these guesses (M-step). Repeat until the grouping makes sense.</p>
</section>
<section id="deep-dive-57" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-57">Deep Dive</h4>
<ul>
<li><p>Model:</p>
<p><span class="math display">\[
p(x) = \sum_{k=1}^K \pi_k \, \mathcal{N}(x \mid \mu_k, \Sigma_k)
\]</span></p>
<ul>
<li>Latent variable <span class="math inline">\(z_n\)</span>: component assignment for data point <span class="math inline">\(x_n\)</span>.</li>
</ul></li>
<li><p>E-step: compute responsibilities:</p>
<p><span class="math display">\[
\gamma_{nk} = \frac{\pi_k \, \mathcal{N}(x_n \mid \mu_k, \Sigma_k)}{\sum_j \pi_j \, \mathcal{N}(x_n \mid \mu_j, \Sigma_j)}
\]</span></p></li>
<li><p>M-step: update parameters using responsibilities:</p>
<p><span class="math display">\[
N_k = \sum_{n=1}^N \gamma_{nk}
\]</span></p>
<p><span class="math display">\[
\pi_k^{\text{new}} = \frac{N_k}{N}, \quad
\mu_k^{\text{new}} = \frac{1}{N_k} \sum_{n=1}^N \gamma_{nk} x_n, \quad
\Sigma_k^{\text{new}} = \frac{1}{N_k} \sum_{n=1}^N \gamma_{nk} (x_n - \mu_k)(x_n - \mu_k)^T
\]</span></p></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 9%">
<col style="width: 48%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Step</th>
<th>Update</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>E-step</td>
<td>Compute <span class="math inline">\(\gamma_{nk}\)</span></td>
<td>Soft cluster memberships</td>
</tr>
<tr class="even">
<td>M-step</td>
<td>Update <span class="math inline">\(\pi_k, \mu_k, \Sigma_k\)</span></td>
<td>Weighted maximum likelihood</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-56" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-56">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.mixture <span class="im">import</span> GaussianMixture</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate synthetic data</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.concatenate([</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>    np.random.normal(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">100</span>),</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>    np.random.normal(<span class="dv">5</span>,<span class="dv">1</span>,<span class="dv">100</span>)</span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>]).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit GMM using EM</span></span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a>gmm <span class="op">=</span> GaussianMixture(n_components<span class="op">=</span><span class="dv">2</span>).fit(X)</span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Means:"</span>, gmm.means_.ravel())</span>
<span id="cb59-14"><a href="#cb59-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Weights:"</span>, gmm.weights_)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-57" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-57">Why It Matters</h4>
<p>EM for GMMs illustrates how latent-variable models can be learned efficiently. The GMM remains a standard clustering technique in statistics and machine learning, and EM’s derivation for it is a core example taught in most AI curricula.</p>
</section>
<section id="try-it-yourself-57" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-57">Try It Yourself</h4>
<ol type="1">
<li>Derive the E-step and M-step updates for a 1D GMM with two components.</li>
<li>Run EM on overlapping Gaussians and observe convergence behavior.</li>
<li>Reflect: why do responsibilities allow EM to handle uncertainty in cluster assignments better than hard k-means clustering?</li>
</ol>
</section>
</section>
<section id="em-in-hidden-markov-models" class="level3">
<h3 class="anchored" data-anchor-id="em-in-hidden-markov-models">559. EM in Hidden Markov Models</h3>
<p>The Expectation-Maximization algorithm is the foundation of Baum–Welch, the standard method for training Hidden Markov Models (HMMs). Here, the latent variables are the hidden states, and the observed variables are the emissions. EM alternates between estimating state sequence probabilities (E-step) and re-estimating transition/emission parameters (M-step).</p>
<section id="picture-in-your-head-58" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-58">Picture in Your Head</h4>
<p>Imagine trying to learn the rules of a language by listening to speech. The actual grammar rules (hidden states) are invisible—you only hear words (observations). EM helps you infer the likely sequence of grammatical categories and refine your guesses about the rules over time.</p>
</section>
<section id="deep-dive-58" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-58">Deep Dive</h4>
<ul>
<li><p>Model:</p>
<ul>
<li>Latent sequence: <span class="math inline">\(z_1, z_2, \dots, z_T\)</span> (hidden states).</li>
<li>Observations: <span class="math inline">\(x_1, x_2, \dots, x_T\)</span>.</li>
<li>Parameters: transition probabilities <span class="math inline">\(A\)</span>, emission probabilities <span class="math inline">\(B\)</span>, initial state distribution <span class="math inline">\(\pi\)</span>.</li>
</ul></li>
<li><p>E-step (Forward–Backward algorithm):</p>
<ul>
<li><p>Compute posterior probabilities of states given data and current parameters:</p>
<p><span class="math display">\[
\gamma_t(i) = P(z_t = i \mid x_{1:T}, \theta)
\]</span></p></li>
<li><p>And joint probabilities of transitions:</p>
<p><span class="math display">\[
\xi_t(i,j) = P(z_t=i, z_{t+1}=j \mid x_{1:T}, \theta)
\]</span></p></li>
</ul></li>
<li><p>M-step: re-estimate parameters:</p>
<ul>
<li><p>Initial distribution:</p>
<p><span class="math display">\[
\pi_i^{\text{new}} = \gamma_1(i)
\]</span></p></li>
<li><p>Transition probabilities:</p>
<p><span class="math display">\[
A_{ij}^{\text{new}} = \frac{\sum_{t=1}^{T-1} \xi_t(i,j)}{\sum_{t=1}^{T-1} \gamma_t(i)}
\]</span></p></li>
<li><p>Emission probabilities:</p>
<p><span class="math display">\[
B_{i}(o)^{\text{new}} = \frac{\sum_{t=1}^T \gamma_t(i)\,\mathbb{1}[x_t=o]}{\sum_{t=1}^T \gamma_t(i)}
\]</span></p></li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 9%">
<col style="width: 28%">
<col style="width: 62%">
</colgroup>
<thead>
<tr class="header">
<th>Step</th>
<th>Computation</th>
<th>Role</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>E-step</td>
<td>Forward–Backward</td>
<td>Posterior state/transition probabilities</td>
</tr>
<tr class="even">
<td>M-step</td>
<td>Update <span class="math inline">\(A, B, \pi\)</span></td>
<td>Maximize expected log-likelihood</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-57" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-57">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> hmmlearn <span class="im">import</span> hmm</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate synthetic HMM data</span></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> hmm.MultinomialHMM(n_components<span class="op">=</span><span class="dv">2</span>, n_iter<span class="op">=</span><span class="dv">10</span>, init_params<span class="op">=</span><span class="st">"ste"</span>)</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>model.startprob_ <span class="op">=</span> np.array([<span class="fl">0.6</span>, <span class="fl">0.4</span>])</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>model.transmat_ <span class="op">=</span> np.array([[<span class="fl">0.7</span>, <span class="fl">0.3</span>],[<span class="fl">0.4</span>, <span class="fl">0.6</span>]])</span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>model.emissionprob_ <span class="op">=</span> np.array([[<span class="fl">0.5</span>, <span class="fl">0.5</span>],[<span class="fl">0.1</span>, <span class="fl">0.9</span>]])</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a>X, Z <span class="op">=</span> model.sample(<span class="dv">100</span>)</span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Refit HMM with Baum-Welch (EM)</span></span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> hmm.MultinomialHMM(n_components<span class="op">=</span><span class="dv">2</span>, n_iter<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a>model2.fit(X)</span>
<span id="cb60-15"><a href="#cb60-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-16"><a href="#cb60-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Learned transition matrix:</span><span class="ch">\n</span><span class="st">"</span>, model2.transmat_)</span>
<span id="cb60-17"><a href="#cb60-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Learned emission matrix:</span><span class="ch">\n</span><span class="st">"</span>, model2.emissionprob_)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-58" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-58">Why It Matters</h4>
<p>Baum–Welch made HMMs practical for speech recognition, bioinformatics, and sequence modeling. It’s a canonical example of EM applied to temporal models, where the hidden structure is sequential rather than independent.</p>
</section>
<section id="try-it-yourself-58" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-58">Try It Yourself</h4>
<ol type="1">
<li>Derive the forward–backward recursions for <span class="math inline">\(\gamma_t(i)\)</span>.</li>
<li>Train an HMM on synthetic data using EM and compare learned vs.&nbsp;true parameters.</li>
<li>Reflect: why does EM for HMMs avoid enumerating all possible state sequences, which would be exponentially many?</li>
</ol>
</section>
</section>
<section id="variants-and-alternatives-to-em" class="level3">
<h3 class="anchored" data-anchor-id="variants-and-alternatives-to-em">560. Variants and Alternatives to EM</h3>
<p>While EM is a powerful algorithm for latent-variable models, it has limitations: slow convergence near optima, sensitivity to initialization, and a tendency to get stuck in local maxima. Over time, researchers have developed variants of EM to improve convergence, and alternatives that replace or generalize EM for greater robustness.</p>
<section id="picture-in-your-head-59" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-59">Picture in Your Head</h4>
<p>Think of EM as climbing a hill by alternating between two steady steps: estimating hidden variables, then updating parameters. Sometimes you end up circling a small hill instead of reaching the mountain peak. Variants give you better boots, shortcuts, or different climbing styles.</p>
</section>
<section id="deep-dive-59" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-59">Deep Dive</h4>
<p>Variants of EM:</p>
<ul>
<li>Accelerated EM: uses quasi-Newton or conjugate gradient methods in the M-step to speed up convergence.</li>
<li>Deterministic Annealing EM (DAEM): adds a “temperature” parameter to smooth the likelihood surface and avoid poor local optima.</li>
<li>Sparse EM: encourages sparsity in responsibilities for efficiency.</li>
<li>Stochastic EM: processes minibatches of data instead of full datasets.</li>
</ul>
<p>Alternatives to EM:</p>
<ul>
<li>Gradient-based optimization: directly maximize log-likelihood using automatic differentiation and SGD.</li>
<li>Variational Inference (VI): replaces E-step with variational optimization, scalable to large datasets.</li>
<li>Sampling-based methods (MCMC): replace expectation with Monte Carlo approximations.</li>
<li>Variational Autoencoders (VAEs): amortize inference with neural networks.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 34%">
<col style="width: 25%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Idea</th>
<th>Strength</th>
<th>Weakness</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Accelerated EM</td>
<td>Faster updates</td>
<td>Quicker convergence</td>
<td>More complex</td>
</tr>
<tr class="even">
<td>DAEM</td>
<td>Annealed likelihood</td>
<td>Avoids bad local optima</td>
<td>Extra tuning</td>
</tr>
<tr class="odd">
<td>Gradient-based</td>
<td>Direct optimization</td>
<td>Scales with autodiff</td>
<td>No closed-form updates</td>
</tr>
<tr class="even">
<td>VI</td>
<td>Approximate posterior</td>
<td>Scalable, flexible</td>
<td>Biased solutions</td>
</tr>
<tr class="odd">
<td>MCMC</td>
<td>Sampling instead of expectation</td>
<td>Asymptotically exact</td>
<td>Slow for large data</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-58" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-58">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.mixture <span class="im">import</span> GaussianMixture</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare standard EM (GMM) vs. stochastic EM (minibatch)</span></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.concatenate([np.random.normal(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">500</span>),</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>                    np.random.normal(<span class="dv">5</span>,<span class="dv">1</span>,<span class="dv">500</span>)]).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Standard EM</span></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>gmm_full <span class="op">=</span> GaussianMixture(n_components<span class="op">=</span><span class="dv">2</span>, max_iter<span class="op">=</span><span class="dv">100</span>).fit(X)</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a><span class="co"># "Stochastic EM" via subsampling</span></span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a>subset <span class="op">=</span> X[np.random.choice(<span class="bu">len</span>(X), <span class="dv">200</span>, replace<span class="op">=</span><span class="va">False</span>)]</span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a>gmm_subset <span class="op">=</span> GaussianMixture(n_components<span class="op">=</span><span class="dv">2</span>, max_iter<span class="op">=</span><span class="dv">100</span>).fit(subset)</span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Full data means:"</span>, gmm_full.means_.ravel())</span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Subset (stochastic) means:"</span>, gmm_subset.means_.ravel())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-59" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-59">Why It Matters</h4>
<p>EM is elegant but not always the best choice. Modern AI systems often need scalability, robustness, and flexibility that EM lacks. Its variants and alternatives extend the idea of alternating optimization into forms better suited for today’s data-rich environments.</p>
</section>
<section id="try-it-yourself-59" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-59">Try It Yourself</h4>
<ol type="1">
<li>Implement DAEM for a Gaussian mixture and see if it avoids poor local optima.</li>
<li>Compare EM vs.&nbsp;gradient ascent on the same latent-variable model.</li>
<li>Reflect: when is EM’s closed-form structure preferable, and when is flexibility more important?</li>
</ol>
</section>
</section>
</section>
<section id="chapter-57.-sequential-models-hmms-kalman-particle-filters" class="level2">
<h2 class="anchored" data-anchor-id="chapter-57.-sequential-models-hmms-kalman-particle-filters">Chapter 57. Sequential Models (HMMs, Kalman, Particle Filters)</h2>
<section id="temporal-structure-in-probabilistic-models" class="level3">
<h3 class="anchored" data-anchor-id="temporal-structure-in-probabilistic-models">561. Temporal Structure in Probabilistic Models</h3>
<p>Sequential probabilistic models capture the idea that data unfolds over time. Instead of treating observations as independent, these models encode temporal dependencies—the present depends on the past, and possibly influences the future. This structure is the backbone of Hidden Markov Models, Kalman filters, and particle filters.</p>
<section id="picture-in-your-head-60" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-60">Picture in Your Head</h4>
<p>Think of watching a movie frame by frame. Each frame isn’t random—it depends on the previous one. If you see storm clouds in one frame, the next likely shows rain. Temporal models formalize this intuition: the past informs the present, which in turn shapes the future.</p>
</section>
<section id="deep-dive-60" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-60">Deep Dive</h4>
<ul>
<li><p>Markov assumption:</p>
<p><span class="math display">\[
P(z_t \mid z_{1:t-1}) \approx P(z_t \mid z_{t-1})
\]</span></p>
<p>The future depends only on the most recent past, not the full history.</p></li>
<li><p>Generative process:</p>
<ul>
<li><p>Hidden states: <span class="math inline">\(z_1, z_2, \dots, z_T\)</span>.</p></li>
<li><p>Observations: <span class="math inline">\(x_1, x_2, \dots, x_T\)</span>.</p></li>
<li><p>Joint distribution:</p>
<p><span class="math display">\[
P(z_{1:T}, x_{1:T}) = P(z_1) \prod_{t=2}^T P(z_t \mid z_{t-1}) \prod_{t=1}^T P(x_t \mid z_t)
\]</span></p></li>
</ul></li>
<li><p>Examples of temporal structure:</p>
<ul>
<li>HMMs: discrete hidden states, categorical transitions.</li>
<li>Kalman filters: continuous states, linear-Gaussian transitions.</li>
<li>Particle filters: nonlinear, non-Gaussian transitions.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 17%">
<col style="width: 23%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>State Space</th>
<th>Transition</th>
<th>Observation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>HMM</td>
<td>Discrete</td>
<td>Categorical</td>
<td>Categorical / Gaussian</td>
</tr>
<tr class="even">
<td>Kalman Filter</td>
<td>Continuous</td>
<td>Linear Gaussian</td>
<td>Linear Gaussian</td>
</tr>
<tr class="odd">
<td>Particle Filter</td>
<td>Continuous</td>
<td>Arbitrary</td>
<td>Arbitrary</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-59" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-59">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple Markov chain simulation</span></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>states <span class="op">=</span> [<span class="st">"Sunny"</span>, <span class="st">"Rainy"</span>]</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>transition <span class="op">=</span> np.array([[<span class="fl">0.8</span>, <span class="fl">0.2</span>],</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>                       [<span class="fl">0.4</span>, <span class="fl">0.6</span>]])</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> [<span class="dv">0</span>]  <span class="co"># start in "Sunny"</span></span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">9</span>):</span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a>    z.append(np.random.choice([<span class="dv">0</span>,<span class="dv">1</span>], p<span class="op">=</span>transition[z[<span class="op">-</span><span class="dv">1</span>]]))</span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Weather sequence:"</span>, [states[i] <span class="cf">for</span> i <span class="kw">in</span> z])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-60" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-60">Why It Matters</h4>
<p>Temporal models allow AI systems to handle speech, video, sensor data, financial time series, and any process where time matters. Ignoring sequential structure leads to poor predictions because past dependencies are essential for understanding and forecasting.</p>
</section>
<section id="try-it-yourself-60" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-60">Try It Yourself</h4>
<ol type="1">
<li>Write down the joint probability factorization for a 3-step HMM.</li>
<li>Simulate a sequence of states and emissions from a 2-state HMM.</li>
<li>Reflect: why does the Markov assumption both simplify computation and limit expressivity?</li>
</ol>
</section>
</section>
<section id="hidden-markov-models-hmms-overview" class="level3">
<h3 class="anchored" data-anchor-id="hidden-markov-models-hmms-overview">562. Hidden Markov Models (HMMs) Overview</h3>
<p>A Hidden Markov Model (HMM) is a sequential probabilistic model where the system evolves through hidden states that follow a Markov process, and each hidden state generates an observation. The hidden states capture structure we cannot observe directly, while the observations are the noisy signals we measure.</p>
<section id="picture-in-your-head-61" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-61">Picture in Your Head</h4>
<p>Imagine listening to someone speaking in another language. You hear sounds (observations), but behind them lies an invisible grammar (hidden states). HMMs let us model how the grammar (state transitions) produces the sounds we actually hear.</p>
</section>
<section id="deep-dive-61" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-61">Deep Dive</h4>
<ul>
<li><p>Components of an HMM:</p>
<ol type="1">
<li>Hidden states <span class="math inline">\(z_t\)</span>: evolve according to a transition matrix <span class="math inline">\(A\)</span>.</li>
<li>Observations <span class="math inline">\(x_t\)</span>: generated from state-dependent emission distribution <span class="math inline">\(B\)</span>.</li>
<li>Initial distribution <span class="math inline">\(\pi\)</span>: probability of the first state.</li>
</ol></li>
<li><p>Joint distribution:</p>
<p><span class="math display">\[
P(z_{1:T}, x_{1:T}) = \pi_{z_1} \, \prod_{t=2}^T A_{z_{t-1},z_t} \, \prod_{t=1}^T B_{z_t}(x_t)
\]</span></p></li>
<li><p>Key problems HMMs solve:</p>
<ol type="1">
<li>Likelihood: compute <span class="math inline">\(P(x_{1:T})\)</span>.</li>
<li>Decoding: infer the most likely state sequence <span class="math inline">\(z_{1:T}\)</span>.</li>
<li>Learning: estimate parameters <span class="math inline">\((A, B, \pi)\)</span> from data.</li>
</ol></li>
<li><p>Common observation models:</p>
<ul>
<li>Discrete HMM: emissions are categorical.</li>
<li>Gaussian HMM: emissions are continuous.</li>
<li>Mixture HMM: emissions are mixtures of Gaussians.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Element</th>
<th>Symbol</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Hidden states</td>
<td><span class="math inline">\(z_t\)</span></td>
<td>“Weather” (Sunny, Rainy)</td>
</tr>
<tr class="even">
<td>Observations</td>
<td><span class="math inline">\(x_t\)</span></td>
<td>“Activity” (Picnic, Umbrella)</td>
</tr>
<tr class="odd">
<td>Transition matrix</td>
<td><span class="math inline">\(A\)</span></td>
<td><span class="math inline">\(P(z_{t+1} \mid z_t)\)</span></td>
</tr>
<tr class="even">
<td>Emission model</td>
<td><span class="math inline">\(B\)</span></td>
<td><span class="math inline">\(P(x_t \mid z_t)\)</span></td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-60" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-60">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple 2-state HMM parameters</span></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>pi <span class="op">=</span> np.array([<span class="fl">0.6</span>, <span class="fl">0.4</span>])</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="fl">0.7</span>, <span class="fl">0.3</span>],</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>              [<span class="fl">0.4</span>, <span class="fl">0.6</span>]])</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> np.array([[<span class="fl">0.9</span>, <span class="fl">0.1</span>],  <span class="co"># P(obs | Sunny)</span></span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>              [<span class="fl">0.2</span>, <span class="fl">0.8</span>]]) <span class="co"># P(obs | Rainy)</span></span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a>states <span class="op">=</span> [<span class="st">"Sunny"</span>, <span class="st">"Rainy"</span>]</span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a>obs <span class="op">=</span> [<span class="st">"Picnic"</span>, <span class="st">"Umbrella"</span>]</span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> [np.random.choice([<span class="dv">0</span>,<span class="dv">1</span>], p<span class="op">=</span>pi)]</span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> [np.random.choice([<span class="dv">0</span>,<span class="dv">1</span>], p<span class="op">=</span>B[z[<span class="op">-</span><span class="dv">1</span>]])]</span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">9</span>):</span>
<span id="cb63-18"><a href="#cb63-18" aria-hidden="true" tabindex="-1"></a>    z.append(np.random.choice([<span class="dv">0</span>,<span class="dv">1</span>], p<span class="op">=</span>A[z[<span class="op">-</span><span class="dv">1</span>]]))</span>
<span id="cb63-19"><a href="#cb63-19" aria-hidden="true" tabindex="-1"></a>    x.append(np.random.choice([<span class="dv">0</span>,<span class="dv">1</span>], p<span class="op">=</span>B[z[<span class="op">-</span><span class="dv">1</span>]]))</span>
<span id="cb63-20"><a href="#cb63-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-21"><a href="#cb63-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"States:"</span>, [states[i] <span class="cf">for</span> i <span class="kw">in</span> z])</span>
<span id="cb63-22"><a href="#cb63-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Observations:"</span>, [obs[i] <span class="cf">for</span> i <span class="kw">in</span> x])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-61" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-61">Why It Matters</h4>
<p>HMMs were the workhorse of speech recognition, NLP, and bioinformatics for decades before deep learning. They remain important for interpretable modeling of sequences, especially when hidden structure is meaningful (e.g., DNA motifs, phonemes, weather states).</p>
</section>
<section id="try-it-yourself-61" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-61">Try It Yourself</h4>
<ol type="1">
<li>Define a 3-state HMM with discrete emissions and simulate a sequence of length 20.</li>
<li>Write down the joint probability factorization for that sequence.</li>
<li>Reflect: why are HMMs more interpretable than deep sequence models like RNNs or Transformers?</li>
</ol>
</section>
</section>
<section id="forward-backward-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="forward-backward-algorithm">563. Forward-Backward Algorithm</h3>
<p>The Forward-Backward algorithm is the standard dynamic programming method for computing posterior probabilities of hidden states in an HMM. Instead of enumerating all possible state sequences (exponential in length), it efficiently combines probabilities forward in time and backward in time.</p>
<section id="picture-in-your-head-62" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-62">Picture in Your Head</h4>
<p>Imagine trying to guess the weather yesterday given today’s and tomorrow’s activities. You reason forward from the start of the week (past evidence) and backward from the weekend (future evidence). By combining both, you get the most informed estimate of yesterday’s weather.</p>
</section>
<section id="deep-dive-62" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-62">Deep Dive</h4>
<ul>
<li><p>Forward pass (<span class="math inline">\(\alpha\)</span>): probability of partial sequence up to <span class="math inline">\(t\)</span>:</p>
<p><span class="math display">\[
\alpha_t(i) = P(x_{1:t}, z_t = i)
\]</span></p>
<p>Recurrence:</p>
<p><span class="math display">\[
\alpha_t(i) = \Big( \sum_j \alpha_{t-1}(j) A_{ji} \Big) B_i(x_t)
\]</span></p></li>
<li><p>Backward pass (<span class="math inline">\(\beta\)</span>): probability of future sequence given state at <span class="math inline">\(t\)</span>:</p>
<p><span class="math display">\[
\beta_t(i) = P(x_{t+1:T} \mid z_t = i)
\]</span></p>
<p>Recurrence:</p>
<p><span class="math display">\[
\beta_t(i) = \sum_j A_{ij} B_j(x_{t+1}) \beta_{t+1}(j)
\]</span></p></li>
<li><p>Posterior (state marginals):</p>
<p><span class="math display">\[
\gamma_t(i) = P(z_t = i \mid x_{1:T}) \propto \alpha_t(i) \beta_t(i)
\]</span></p></li>
<li><p>Likelihood of sequence:</p>
<p><span class="math display">\[
P(x_{1:T}) = \sum_i \alpha_T(i) = \sum_i \pi_i B_i(x_1)\beta_1(i)
\]</span></p></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 16%">
<col style="width: 69%">
</colgroup>
<thead>
<tr class="header">
<th>Step</th>
<th>Variable</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Forward</td>
<td><span class="math inline">\(\alpha_t(i)\)</span></td>
<td>Prob. of partial sequence up to <span class="math inline">\(t\)</span> ending in state <span class="math inline">\(i\)</span></td>
</tr>
<tr class="even">
<td>Backward</td>
<td><span class="math inline">\(\beta_t(i)\)</span></td>
<td>Prob. of remaining sequence given state <span class="math inline">\(i\)</span> at <span class="math inline">\(t\)</span></td>
</tr>
<tr class="odd">
<td>Combination</td>
<td><span class="math inline">\(\gamma_t(i)\)</span></td>
<td>Posterior state probability at time <span class="math inline">\(t\)</span></td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-61" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-61">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple HMM: 2 states, 2 observations</span></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>pi <span class="op">=</span> np.array([<span class="fl">0.6</span>, <span class="fl">0.4</span>])</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="fl">0.7</span>, <span class="fl">0.3</span>],</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>              [<span class="fl">0.4</span>, <span class="fl">0.6</span>]])</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> np.array([[<span class="fl">0.9</span>, <span class="fl">0.1</span>],</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>              [<span class="fl">0.2</span>, <span class="fl">0.8</span>]])  <span class="co"># rows=states, cols=obs</span></span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> [<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>]  <span class="co"># observation sequence</span></span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Forward</span></span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> np.zeros((<span class="bu">len</span>(X),<span class="dv">2</span>))</span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a>alpha[<span class="dv">0</span>] <span class="op">=</span> pi <span class="op">*</span> B[:,X[<span class="dv">0</span>]]</span>
<span id="cb64-15"><a href="#cb64-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,<span class="bu">len</span>(X)):</span>
<span id="cb64-16"><a href="#cb64-16" aria-hidden="true" tabindex="-1"></a>    alpha[t] <span class="op">=</span> (alpha[t<span class="op">-</span><span class="dv">1</span>] <span class="op">@</span> A) <span class="op">*</span> B[:,X[t]]</span>
<span id="cb64-17"><a href="#cb64-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-18"><a href="#cb64-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Backward</span></span>
<span id="cb64-19"><a href="#cb64-19" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> np.zeros((<span class="bu">len</span>(X),<span class="dv">2</span>))</span>
<span id="cb64-20"><a href="#cb64-20" aria-hidden="true" tabindex="-1"></a>beta[<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb64-21"><a href="#cb64-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">reversed</span>(<span class="bu">range</span>(<span class="bu">len</span>(X)<span class="op">-</span><span class="dv">1</span>)):</span>
<span id="cb64-22"><a href="#cb64-22" aria-hidden="true" tabindex="-1"></a>    beta[t] <span class="op">=</span> (A <span class="op">@</span> (B[:,X[t<span class="op">+</span><span class="dv">1</span>]] <span class="op">*</span> beta[t<span class="op">+</span><span class="dv">1</span>]))</span>
<span id="cb64-23"><a href="#cb64-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-24"><a href="#cb64-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior</span></span>
<span id="cb64-25"><a href="#cb64-25" aria-hidden="true" tabindex="-1"></a>gamma <span class="op">=</span> (alpha<span class="op">*</span>beta) <span class="op">/</span> (alpha<span class="op">*</span>beta).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>,keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb64-26"><a href="#cb64-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-27"><a href="#cb64-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Posterior state probabilities:</span><span class="ch">\n</span><span class="st">"</span>, np.<span class="bu">round</span>(gamma,<span class="dv">3</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-62" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-62">Why It Matters</h4>
<p>The Forward-Backward algorithm is the engine of HMM inference. It allows efficient computation of posterior state distributions, which are critical for:</p>
<ul>
<li>Smoothing (estimating hidden states given all data).</li>
<li>Training (E-step of Baum–Welch).</li>
<li>Computing sequence likelihoods.</li>
</ul>
</section>
<section id="try-it-yourself-62" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-62">Try It Yourself</h4>
<ol type="1">
<li>Apply the forward-backward algorithm on a 2-state HMM for a sequence of length 5.</li>
<li>Compare the posterior distribution <span class="math inline">\(\gamma_t\)</span> with the most likely state sequence from Viterbi.</li>
<li>Reflect: why does forward-backward give probabilities while Viterbi gives a single best path?</li>
</ol>
</section>
</section>
<section id="viterbi-decoding-for-sequences" class="level3">
<h3 class="anchored" data-anchor-id="viterbi-decoding-for-sequences">564. Viterbi Decoding for Sequences</h3>
<p>The Viterbi algorithm finds the most likely sequence of hidden states in a Hidden Markov Model given an observation sequence. Unlike Forward-Backward, which computes probabilities of all possible states, Viterbi outputs a single best path (maximum a posteriori sequence).</p>
<section id="picture-in-your-head-63" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-63">Picture in Your Head</h4>
<p>Think of tracking an animal’s footprints in the snow. Many possible paths exist, but you want to reconstruct the single most likely trail it took, step by step. Viterbi decoding does exactly this for hidden states.</p>
</section>
<section id="deep-dive-63" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-63">Deep Dive</h4>
<ul>
<li><p>Goal:</p>
<p><span class="math display">\[
z_{1:T}^* = \arg\max_{z_{1:T}} P(z_{1:T} \mid x_{1:T})
\]</span></p></li>
<li><p>Recurrence (dynamic programming): Define <span class="math inline">\(\delta_t(i)\)</span> = probability of the most likely path ending in state <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span>.</p>
<p><span class="math display">\[
\delta_t(i) = \max_j \big[ \delta_{t-1}(j) A_{ji} \big] \, B_i(x_t)
\]</span></p>
<p>Keep backpointers <span class="math inline">\(\psi_t(i)\)</span> to reconstruct the path.</p></li>
<li><p>Initialization:</p>
<p><span class="math display">\[
\delta_1(i) = \pi_i B_i(x_1)
\]</span></p></li>
<li><p>Termination:</p>
<p><span class="math display">\[
P^* = \max_i \delta_T(i), \quad z_T^* = \arg\max_i \delta_T(i)
\]</span></p></li>
<li><p>Backtracking: follow backpointers from <span class="math inline">\(T\)</span> to 1 to recover full state sequence.</p></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Step</th>
<th>Variable</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Initialization</td>
<td><span class="math inline">\(\delta_1(i)\)</span></td>
<td>Best path to state <span class="math inline">\(i\)</span> at <span class="math inline">\(t=1\)</span></td>
</tr>
<tr class="even">
<td>Recurrence</td>
<td><span class="math inline">\(\delta_t(i)\)</span></td>
<td>Best path to state <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span></td>
</tr>
<tr class="odd">
<td>Backpointers</td>
<td><span class="math inline">\(\psi_t(i)\)</span></td>
<td>Previous best state leading to <span class="math inline">\(i\)</span></td>
</tr>
<tr class="even">
<td>Backtrack</td>
<td><span class="math inline">\(z_{1:T}^*\)</span></td>
<td>Most likely hidden state sequence</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-62" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-62">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a><span class="co"># HMM parameters</span></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>pi <span class="op">=</span> np.array([<span class="fl">0.6</span>, <span class="fl">0.4</span>])</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="fl">0.7</span>, <span class="fl">0.3</span>],</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>              [<span class="fl">0.4</span>, <span class="fl">0.6</span>]])</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> np.array([[<span class="fl">0.9</span>, <span class="fl">0.1</span>],</span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>              [<span class="fl">0.2</span>, <span class="fl">0.8</span>]])  <span class="co"># rows=states, cols=obs</span></span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> [<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>]  <span class="co"># observation sequence</span></span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>T, N <span class="op">=</span> <span class="bu">len</span>(X), <span class="bu">len</span>(pi)</span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>delta <span class="op">=</span> np.zeros((T,N))</span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>psi <span class="op">=</span> np.zeros((T,N), dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialization</span></span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a>delta[<span class="dv">0</span>] <span class="op">=</span> pi <span class="op">*</span> B[:,X[<span class="dv">0</span>]]</span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-19"><a href="#cb65-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Recursion</span></span>
<span id="cb65-20"><a href="#cb65-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,T):</span>
<span id="cb65-21"><a href="#cb65-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb65-22"><a href="#cb65-22" aria-hidden="true" tabindex="-1"></a>        seq_probs <span class="op">=</span> delta[t<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> A[:,i]</span>
<span id="cb65-23"><a href="#cb65-23" aria-hidden="true" tabindex="-1"></a>        psi[t,i] <span class="op">=</span> np.argmax(seq_probs)</span>
<span id="cb65-24"><a href="#cb65-24" aria-hidden="true" tabindex="-1"></a>        delta[t,i] <span class="op">=</span> np.<span class="bu">max</span>(seq_probs) <span class="op">*</span> B[i,X[t]]</span>
<span id="cb65-25"><a href="#cb65-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-26"><a href="#cb65-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Backtracking</span></span>
<span id="cb65-27"><a href="#cb65-27" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> np.zeros(T, dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb65-28"><a href="#cb65-28" aria-hidden="true" tabindex="-1"></a>path[<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> np.argmax(delta[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb65-29"><a href="#cb65-29" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">reversed</span>(<span class="bu">range</span>(<span class="dv">1</span>,T)):</span>
<span id="cb65-30"><a href="#cb65-30" aria-hidden="true" tabindex="-1"></a>    path[t<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> psi[t, path[t]]</span>
<span id="cb65-31"><a href="#cb65-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-32"><a href="#cb65-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Most likely state sequence:"</span>, path)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-63" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-63">Why It Matters</h4>
<p>The Viterbi algorithm is the decoding workhorse of HMMs. It has been foundational in:</p>
<ul>
<li>Speech recognition (phoneme decoding).</li>
<li>Bioinformatics (gene prediction).</li>
<li>NLP (part-of-speech tagging, information extraction).</li>
</ul>
</section>
<section id="try-it-yourself-63" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-63">Try It Yourself</h4>
<ol type="1">
<li>Run Viterbi and Forward-Backward on the same sequence. Compare the single best path vs.&nbsp;posterior marginals.</li>
<li>Test Viterbi on a 3-state HMM with overlapping emissions—does it make sharp or uncertain choices?</li>
<li>Reflect: when is the single “best path” more useful than a full distribution over possibilities?</li>
</ol>
</section>
</section>
<section id="kalman-filters-for-linear-gaussian-systems" class="level3">
<h3 class="anchored" data-anchor-id="kalman-filters-for-linear-gaussian-systems">565. Kalman Filters for Linear Gaussian Systems</h3>
<p>The Kalman filter is a recursive algorithm for estimating the hidden state of a linear dynamical system with Gaussian noise. It maintains a belief about the current state as a Gaussian distribution, updated in two phases: prediction (using system dynamics) and correction (using new observations).</p>
<section id="picture-in-your-head-64" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-64">Picture in Your Head</h4>
<p>Imagine tracking an airplane on radar. The radar gives noisy position signals. The plane also follows predictable physics (momentum, velocity). The Kalman filter combines these two sources—prediction from physics and correction from radar—to produce the best possible estimate.</p>
</section>
<section id="deep-dive-64" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-64">Deep Dive</h4>
<ul>
<li><p>State-space model:</p>
<ul>
<li><p>State evolution:</p>
<p><span class="math display">\[
z_t = A z_{t-1} + w_t, \quad w_t \sim \mathcal{N}(0,Q)
\]</span></p></li>
<li><p>Observation:</p>
<p><span class="math display">\[
x_t = H z_t + v_t, \quad v_t \sim \mathcal{N}(0,R)
\]</span></p></li>
</ul></li>
<li><p>Recursive updates:</p>
<ol type="1">
<li><p>Prediction:</p>
<p><span class="math display">\[
\hat{z}_t^- = A \hat{z}_{t-1}, \quad P_t^- = A P_{t-1} A^T + Q
\]</span></p></li>
<li><p>Correction:</p>
<p><span class="math display">\[
K_t = P_t^- H^T (H P_t^- H^T + R)^{-1}
\]</span></p>
<p><span class="math display">\[
\hat{z}_t = \hat{z}_t^- + K_t (x_t - H \hat{z}_t^-)
\]</span></p>
<p><span class="math display">\[
P_t = (I - K_t H) P_t^-
\]</span></p></li>
</ol></li>
<li><p>Assumptions:</p>
<ul>
<li>Linear dynamics, Gaussian noise.</li>
<li>Belief remains Gaussian at each step.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 26%">
<col style="width: 58%">
</colgroup>
<thead>
<tr class="header">
<th>Step</th>
<th>Formula</th>
<th>Role</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Prediction</td>
<td><span class="math inline">\(\hat{z}_t^-, P_t^-\)</span></td>
<td>Estimate before seeing data</td>
</tr>
<tr class="even">
<td>Kalman gain</td>
<td><span class="math inline">\(K_t\)</span></td>
<td>Balances trust between model vs.&nbsp;observation</td>
</tr>
<tr class="odd">
<td>Update</td>
<td><span class="math inline">\(\hat{z}_t, P_t\)</span></td>
<td>Refined estimate after observation</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-63" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-63">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple 1D Kalman filter</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>A, H <span class="op">=</span> <span class="dv">1</span>, <span class="dv">1</span></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>Q, R <span class="op">=</span> <span class="fl">0.01</span>, <span class="fl">0.1</span>  <span class="co"># process noise, observation noise</span></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>z_est, P <span class="op">=</span> <span class="fl">0.0</span>, <span class="fl">1.0</span>  <span class="co"># initial estimate and covariance</span></span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>observations <span class="op">=</span> [<span class="fl">1.0</span>, <span class="fl">0.9</span>, <span class="fl">1.2</span>, <span class="fl">1.1</span>, <span class="fl">0.95</span>]</span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> observations:</span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prediction</span></span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a>    z_pred <span class="op">=</span> A <span class="op">*</span> z_est</span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a>    P_pred <span class="op">=</span> A <span class="op">*</span> P <span class="op">*</span> A <span class="op">+</span> Q</span>
<span id="cb66-14"><a href="#cb66-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb66-15"><a href="#cb66-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Kalman gain</span></span>
<span id="cb66-16"><a href="#cb66-16" aria-hidden="true" tabindex="-1"></a>    K <span class="op">=</span> P_pred <span class="op">*</span> H <span class="op">/</span> (H <span class="op">*</span> P_pred <span class="op">*</span> H <span class="op">+</span> R)</span>
<span id="cb66-17"><a href="#cb66-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb66-18"><a href="#cb66-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Correction</span></span>
<span id="cb66-19"><a href="#cb66-19" aria-hidden="true" tabindex="-1"></a>    z_est <span class="op">=</span> z_pred <span class="op">+</span> K <span class="op">*</span> (x <span class="op">-</span> H <span class="op">*</span> z_pred)</span>
<span id="cb66-20"><a href="#cb66-20" aria-hidden="true" tabindex="-1"></a>    P <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> K <span class="op">*</span> H) <span class="op">*</span> P_pred</span>
<span id="cb66-21"><a href="#cb66-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb66-22"><a href="#cb66-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Observation: </span><span class="sc">{</span>x<span class="sc">:.2f}</span><span class="ss">, Estimate: </span><span class="sc">{</span>z_est<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-64" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-64">Why It Matters</h4>
<p>The Kalman filter is a cornerstone of control, robotics, and signal processing. It provides optimal state estimation under Gaussian noise and remains widely used in navigation (GPS, self-driving cars), finance, and tracking systems.</p>
</section>
<section id="try-it-yourself-64" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-64">Try It Yourself</h4>
<ol type="1">
<li>Derive the Kalman update equations for a 2D system (position + velocity).</li>
<li>Implement a Kalman filter for tracking a moving object with noisy sensors.</li>
<li>Reflect: why is the Kalman filter both statistically optimal (under assumptions) and computationally efficient?</li>
</ol>
</section>
</section>
<section id="extended-and-unscented-kalman-filters" class="level3">
<h3 class="anchored" data-anchor-id="extended-and-unscented-kalman-filters">566. Extended and Unscented Kalman Filters</h3>
<p>The Kalman filter assumes linear dynamics and Gaussian noise, but many real-world systems (robots, weather, finance) are nonlinear. The Extended Kalman Filter (EKF) and Unscented Kalman Filter (UKF) generalize the method to handle nonlinear transitions and observations while still maintaining Gaussian approximations of belief.</p>
<section id="picture-in-your-head-65" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-65">Picture in Your Head</h4>
<p>Tracking a drone: its flight path follows nonlinear physics (angles, rotations). A standard Kalman filter can’t capture this. The EKF linearizes the curves (like drawing tangents), while the UKF samples representative points (like scattering a net of beads) to follow the nonlinear shape more faithfully.</p>
</section>
<section id="deep-dive-65" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-65">Deep Dive</h4>
<ul>
<li><p>Extended Kalman Filter (EKF):</p>
<ul>
<li><p>Assumes nonlinear functions:</p>
<p><span class="math display">\[
z_t = f(z_{t-1}) + w_t, \quad x_t = h(z_t) + v_t
\]</span></p></li>
<li><p>Linearizes via Jacobians:</p>
<p><span class="math display">\[
F_t = \frac{\partial f}{\partial z}, \quad H_t = \frac{\partial h}{\partial z}
\]</span></p></li>
<li><p>Then applies standard Kalman updates with these approximations.</p></li>
<li><p>Works if system is “locally linear.”</p></li>
</ul></li>
<li><p>Unscented Kalman Filter (UKF):</p>
<ul>
<li>Avoids explicit linearization.</li>
<li>Uses sigma points: carefully chosen samples around the mean.</li>
<li>Propagates sigma points through nonlinear functions <span class="math inline">\(f, h\)</span>.</li>
<li>Reconstructs mean and covariance from transformed sigma points.</li>
<li>More accurate for strongly nonlinear systems.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 6%">
<col style="width: 24%">
<col style="width: 32%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="header">
<th>Filter</th>
<th>Technique</th>
<th>Strength</th>
<th>Weakness</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>EKF</td>
<td>Linearize via Jacobians</td>
<td>Simple, widely used</td>
<td>Breaks for highly nonlinear systems</td>
</tr>
<tr class="even">
<td>UKF</td>
<td>Sigma-point sampling</td>
<td>Better accuracy, no derivatives</td>
<td>More computation, tuning needed</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-64" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-64">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example nonlinear system: z_t = z_{t-1}^2/2 + noise</span></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(z): <span class="cf">return</span> <span class="fl">0.5</span> <span class="op">*</span> z2</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> h(z): <span class="cf">return</span> np.sin(z)</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a><span class="co"># EKF linearization (Jacobian approx at mean)</span></span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> jacobian_f(z): <span class="cf">return</span> z</span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> jacobian_h(z): <span class="cf">return</span> np.cos(z)</span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a>z_est, P <span class="op">=</span> <span class="fl">0.5</span>, <span class="fl">1.0</span></span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a>Q, R <span class="op">=</span> <span class="fl">0.01</span>, <span class="fl">0.1</span></span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a>obs <span class="op">=</span> [<span class="fl">0.2</span>, <span class="fl">0.4</span>, <span class="fl">0.1</span>]</span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> obs:</span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prediction (EKF)</span></span>
<span id="cb67-17"><a href="#cb67-17" aria-hidden="true" tabindex="-1"></a>    z_pred <span class="op">=</span> f(z_est)</span>
<span id="cb67-18"><a href="#cb67-18" aria-hidden="true" tabindex="-1"></a>    F <span class="op">=</span> jacobian_f(z_est)</span>
<span id="cb67-19"><a href="#cb67-19" aria-hidden="true" tabindex="-1"></a>    P_pred <span class="op">=</span> F <span class="op">*</span> P <span class="op">*</span> F <span class="op">+</span> Q</span>
<span id="cb67-20"><a href="#cb67-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-21"><a href="#cb67-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Update (EKF)</span></span>
<span id="cb67-22"><a href="#cb67-22" aria-hidden="true" tabindex="-1"></a>    H <span class="op">=</span> jacobian_h(z_pred)</span>
<span id="cb67-23"><a href="#cb67-23" aria-hidden="true" tabindex="-1"></a>    K <span class="op">=</span> P_pred <span class="op">*</span> H <span class="op">/</span> (H<span class="op">*</span>P_pred<span class="op">*</span>H <span class="op">+</span> R)</span>
<span id="cb67-24"><a href="#cb67-24" aria-hidden="true" tabindex="-1"></a>    z_est <span class="op">=</span> z_pred <span class="op">+</span> K <span class="op">*</span> (x <span class="op">-</span> h(z_pred))</span>
<span id="cb67-25"><a href="#cb67-25" aria-hidden="true" tabindex="-1"></a>    P <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> K<span class="op">*</span>H) <span class="op">*</span> P_pred</span>
<span id="cb67-26"><a href="#cb67-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-27"><a href="#cb67-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Obs=</span><span class="sc">{</span>x<span class="sc">:.2f}</span><span class="ss">, EKF estimate=</span><span class="sc">{</span>z_est<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-65" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-65">Why It Matters</h4>
<p>EKF and UKF are vital for robotics, navigation, aerospace, and sensor fusion. They extend Kalman filtering to nonlinear systems, from spacecraft guidance to smartphone motion tracking.</p>
</section>
<section id="try-it-yourself-65" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-65">Try It Yourself</h4>
<ol type="1">
<li>Derive Jacobians for a 2D robot motion model (position + angle).</li>
<li>Compare EKF vs.&nbsp;UKF performance on a nonlinear pendulum system.</li>
<li>Reflect: why does UKF avoid the pitfalls of linearization, and when is its extra cost justified?</li>
</ol>
</section>
</section>
<section id="particle-filtering-for-nonlinear-systems" class="level3">
<h3 class="anchored" data-anchor-id="particle-filtering-for-nonlinear-systems">567. Particle Filtering for Nonlinear Systems</h3>
<p>Particle filtering, or Sequential Monte Carlo (SMC), is a method for state estimation in nonlinear, non-Gaussian systems. Instead of assuming Gaussian beliefs (like Kalman filters), it represents the posterior distribution with a set of particles (samples), which evolve and reweight over time.</p>
<section id="picture-in-your-head-66" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-66">Picture in Your Head</h4>
<p>Imagine trying to track a fish in a murky pond. Instead of keeping a single blurry estimate (like a Gaussian), you release many small buoys (particles). Each buoy drifts according to dynamics and is weighted by how well it matches new sonar readings. Over time, the cloud of buoys converges around the fish.</p>
</section>
<section id="deep-dive-66" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-66">Deep Dive</h4>
<ul>
<li><p>State-space model:</p>
<ul>
<li>Transition: <span class="math inline">\(z_t \sim p(z_t \mid z_{t-1})\)</span></li>
<li>Observation: <span class="math inline">\(x_t \sim p(x_t \mid z_t)\)</span></li>
</ul></li>
<li><p>Particle filter algorithm:</p>
<ol type="1">
<li>Initialization: sample particles from prior <span class="math inline">\(p(z_0)\)</span>.</li>
<li>Prediction: propagate each particle through dynamics <span class="math inline">\(p(z_t \mid z_{t-1})\)</span>.</li>
<li>Weighting: assign weights <span class="math inline">\(w_t^{(i)} \propto p(x_t \mid z_t^{(i)})\)</span>.</li>
<li>Resampling: resample particles according to weights to avoid degeneracy.</li>
<li>Repeat for each time step.</li>
</ol></li>
<li><p>Approximate posterior:</p>
<p><span class="math display">\[
p(z_t \mid x_{1:t}) \approx \sum_{i=1}^N w_t^{(i)} \, \delta(z_t - z_t^{(i)})
\]</span></p></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Step</th>
<th>Purpose</th>
<th>Analogy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Prediction</td>
<td>Move particles forward</td>
<td>Drift buoys with current</td>
</tr>
<tr class="even">
<td>Weighting</td>
<td>Score against observations</td>
<td>Match buoys to sonar pings</td>
</tr>
<tr class="odd">
<td>Resampling</td>
<td>Focus on good hypotheses</td>
<td>Drop buoys far from fish</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-65" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-65">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Toy 1D particle filter</span></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100</span>  <span class="co"># number of particles</span></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>particles <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, N)</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> np.ones(N) <span class="op">/</span> N</span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> transition(z): <span class="cf">return</span> z <span class="op">+</span> np.random.normal(<span class="dv">0</span>, <span class="fl">0.5</span>)</span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> likelihood(x, z): <span class="cf">return</span> np.exp(<span class="op">-</span>(x <span class="op">-</span> z)<span class="dv">2</span> <span class="op">/</span> <span class="fl">0.5</span>)</span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a>observations <span class="op">=</span> [<span class="fl">0.2</span>, <span class="fl">0.0</span>, <span class="fl">1.0</span>, <span class="fl">0.5</span>]</span>
<span id="cb68-13"><a href="#cb68-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-14"><a href="#cb68-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> observations:</span>
<span id="cb68-15"><a href="#cb68-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict</span></span>
<span id="cb68-16"><a href="#cb68-16" aria-hidden="true" tabindex="-1"></a>    particles <span class="op">=</span> transition(particles)</span>
<span id="cb68-17"><a href="#cb68-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Weight</span></span>
<span id="cb68-18"><a href="#cb68-18" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">=</span> likelihood(x, particles)</span>
<span id="cb68-19"><a href="#cb68-19" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">/=</span> np.<span class="bu">sum</span>(weights)</span>
<span id="cb68-20"><a href="#cb68-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Resample</span></span>
<span id="cb68-21"><a href="#cb68-21" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> np.random.choice(<span class="bu">range</span>(N), size<span class="op">=</span>N, p<span class="op">=</span>weights)</span>
<span id="cb68-22"><a href="#cb68-22" aria-hidden="true" tabindex="-1"></a>    particles <span class="op">=</span> particles[indices]</span>
<span id="cb68-23"><a href="#cb68-23" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">=</span> np.ones(N) <span class="op">/</span> N</span>
<span id="cb68-24"><a href="#cb68-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Observation=</span><span class="sc">{</span>x<span class="sc">:.2f}</span><span class="ss">, Estimate=</span><span class="sc">{</span>np<span class="sc">.</span>mean(particles)<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-66" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-66">Why It Matters</h4>
<p>Particle filters can approximate arbitrary distributions, making them powerful for robot localization, object tracking, and nonlinear control. Unlike Kalman filters, they handle multimodality (e.g., multiple possible hypotheses about where a robot might be).</p>
</section>
<section id="try-it-yourself-66" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-66">Try It Yourself</h4>
<ol type="1">
<li>Implement a particle filter for a robot moving in 1D with noisy distance sensors.</li>
<li>Compare particle filtering vs.&nbsp;Kalman filtering on nonlinear dynamics (e.g., pendulum).</li>
<li>Reflect: why is resampling necessary, and what happens if you skip it?</li>
</ol>
</section>
</section>
<section id="sequential-monte-carlo-methods" class="level3">
<h3 class="anchored" data-anchor-id="sequential-monte-carlo-methods">568. Sequential Monte Carlo Methods</h3>
<p>Sequential Monte Carlo (SMC) methods generalize particle filtering to a broader class of problems. They use importance sampling, resampling, and propagation to approximate evolving probability distributions. Particle filtering is the canonical example, but SMC also covers smoothing, parameter estimation, and advanced resampling strategies.</p>
<section id="picture-in-your-head-67" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-67">Picture in Your Head</h4>
<p>Imagine following a river downstream. At each bend, you release colored dye (particles) to see where the current flows. Some dye particles spread thin and fade (low weight), while others cluster in strong currents (high weight). By repeatedly releasing and redistributing dye, you map the whole river path.</p>
</section>
<section id="deep-dive-67" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-67">Deep Dive</h4>
<ul>
<li><p>Goal: approximate posterior over states as data arrives:</p>
<p><span class="math display">\[
p(z_{1:t} \mid x_{1:t})
\]</span></p>
<p>using weighted particles.</p></li>
<li><p>Key components:</p>
<ol type="1">
<li><p>Proposal distribution <span class="math inline">\(q(z_t \mid z_{t-1}, x_t)\)</span>: how to sample new particles.</p></li>
<li><p>Importance weights:</p>
<p><span class="math display">\[
w_t^{(i)} \propto w_{t-1}^{(i)} \cdot \frac{p(x_t \mid z_t^{(i)}) \, p(z_t^{(i)} \mid z_{t-1}^{(i)})}{q(z_t^{(i)} \mid z_{t-1}^{(i)}, x_t)}
\]</span></p></li>
<li><p>Resampling: combats weight degeneracy.</p></li>
</ol></li>
<li><p>Variants:</p>
<ul>
<li>Particle filtering: online estimation of current state.</li>
<li>Particle smoothing: estimate full trajectories <span class="math inline">\(z_{1:T}\)</span>.</li>
<li>Particle MCMC (PMCMC): combine SMC with MCMC for parameter inference.</li>
<li>Adaptive resampling: only resample when effective sample size (ESS) is too low.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Variant</th>
<th>Purpose</th>
<th>Application</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Particle filter</td>
<td>Online state estimation</td>
<td>Robot tracking</td>
</tr>
<tr class="even">
<td>Particle smoother</td>
<td>Whole-sequence inference</td>
<td>Speech processing</td>
</tr>
<tr class="odd">
<td>PMCMC</td>
<td>Parameter learning</td>
<td>Bayesian econometrics</td>
</tr>
<tr class="even">
<td>Adaptive SMC</td>
<td>Efficiency</td>
<td>Weather forecasting</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-66" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-66">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>particles <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, N)</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> np.ones(N) <span class="op">/</span> N</span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> transition(z): <span class="cf">return</span> z <span class="op">+</span> np.random.normal(<span class="dv">0</span>, <span class="fl">0.5</span>)</span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> obs_likelihood(x, z): <span class="cf">return</span> np.exp(<span class="op">-</span>(x <span class="op">-</span> z)<span class="dv">2</span> <span class="op">/</span> <span class="fl">0.5</span>)</span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> effective_sample_size(w):</span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="fl">1.0</span> <span class="op">/</span> np.<span class="bu">sum</span>(w2)</span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-13"><a href="#cb69-13" aria-hidden="true" tabindex="-1"></a>observations <span class="op">=</span> [<span class="fl">0.2</span>, <span class="fl">0.0</span>, <span class="fl">1.0</span>, <span class="fl">0.5</span>]</span>
<span id="cb69-14"><a href="#cb69-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-15"><a href="#cb69-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> observations:</span>
<span id="cb69-16"><a href="#cb69-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Proposal = transition prior</span></span>
<span id="cb69-17"><a href="#cb69-17" aria-hidden="true" tabindex="-1"></a>    particles <span class="op">=</span> transition(particles)</span>
<span id="cb69-18"><a href="#cb69-18" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">*=</span> obs_likelihood(x, particles)</span>
<span id="cb69-19"><a href="#cb69-19" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">/=</span> np.<span class="bu">sum</span>(weights)</span>
<span id="cb69-20"><a href="#cb69-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-21"><a href="#cb69-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Resample if degeneracy</span></span>
<span id="cb69-22"><a href="#cb69-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> effective_sample_size(weights) <span class="op">&lt;</span> N<span class="op">/</span><span class="dv">2</span>:</span>
<span id="cb69-23"><a href="#cb69-23" aria-hidden="true" tabindex="-1"></a>        idx <span class="op">=</span> np.random.choice(N, N, p<span class="op">=</span>weights)</span>
<span id="cb69-24"><a href="#cb69-24" aria-hidden="true" tabindex="-1"></a>        particles, weights <span class="op">=</span> particles[idx], np.ones(N)<span class="op">/</span>N</span>
<span id="cb69-25"><a href="#cb69-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-26"><a href="#cb69-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Obs=</span><span class="sc">{</span>x<span class="sc">:.2f}</span><span class="ss">, Estimate=</span><span class="sc">{</span>np<span class="sc">.</span>mean(particles)<span class="sc">:.2f}</span><span class="ss">, ESS=</span><span class="sc">{</span>effective_sample_size(weights)<span class="sc">:.1f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-67" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-67">Why It Matters</h4>
<p>SMC is a flexible toolbox for Bayesian inference in sequential settings, beyond what Kalman or particle filters alone can do. It enables parameter learning, trajectory smoothing, and high-dimensional inference in models where exact solutions are impossible.</p>
</section>
<section id="try-it-yourself-67" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-67">Try It Yourself</h4>
<ol type="1">
<li>Implement adaptive resampling based on ESS threshold.</li>
<li>Compare particle filtering (online) vs.&nbsp;particle smoothing (offline) on the same dataset.</li>
<li>Reflect: how does the choice of proposal distribution <span class="math inline">\(q\)</span> affect the efficiency of SMC?</li>
</ol>
</section>
</section>
<section id="hybrid-models-neural-probabilistic" class="level3">
<h3 class="anchored" data-anchor-id="hybrid-models-neural-probabilistic">569. Hybrid Models: Neural + Probabilistic</h3>
<p>Hybrid sequential models combine probabilistic structure (like HMMs or state-space models) with neural networks for flexible function approximation. This pairing keeps the strengths of probabilistic reasoning—uncertainty handling, temporal structure—while leveraging neural networks’ ability to learn rich, nonlinear representations.</p>
<section id="picture-in-your-head-68" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-68">Picture in Your Head</h4>
<p>Imagine predicting traffic. A probabilistic model gives structure: cars move forward with inertia, streets have constraints. But traffic is also messy and nonlinear—affected by weather, accidents, or holidays. A neural network can capture these irregular patterns, while the probabilistic backbone ensures consistent predictions.</p>
</section>
<section id="deep-dive-68" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-68">Deep Dive</h4>
<ul>
<li><p>Neural extensions of HMMs / state-space models:</p>
<ul>
<li>Neural HMMs: emissions or transitions parameterized by neural nets.</li>
<li>Deep Kalman Filters (DKF): nonlinear transition and observation functions learned by deep nets.</li>
<li>Variational Recurrent Neural Networks (VRNN): combine RNNs with latent-variable probabilistic inference.</li>
<li>Neural SMC: use neural networks to learn proposal distributions in particle filters.</li>
</ul></li>
<li><p>Formulation example (Deep Kalman Filter):</p>
<ul>
<li><p>Latent state dynamics:</p>
<p><span class="math display">\[
z_t = f_\theta(z_{t-1}, \epsilon_t)
\]</span></p></li>
<li><p>Observations:</p>
<p><span class="math display">\[
x_t = g_\phi(z_t, v_t)
\]</span></p></li>
</ul>
<p>where <span class="math inline">\(f_\theta, g_\phi\)</span> are neural networks.</p></li>
<li><p>Advantages:</p>
<ul>
<li>Flexible modeling of nonlinearities.</li>
<li>Scales with deep learning infrastructure.</li>
<li>Captures both interpretable structure and rich patterns.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 43%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>Probabilistic Backbone</th>
<th>Neural Enhancement</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Neural HMM</td>
<td>State transitions + emissions</td>
<td>NN for emissions</td>
</tr>
<tr class="even">
<td>DKF</td>
<td>Linear-Gaussian SSM</td>
<td>NN for dynamics/observations</td>
</tr>
<tr class="odd">
<td>VRNN</td>
<td>RNN + latent vars</td>
<td>Variational inference + NN</td>
</tr>
<tr class="even">
<td>Neural SMC</td>
<td>Particle filter</td>
<td>NN-learned proposals</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (PyTorch-like)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DeepKalmanFilter(nn.Module):</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, latent_dim, obs_dim):</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transition <span class="op">=</span> nn.GRUCell(latent_dim, latent_dim)</span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.emission <span class="op">=</span> nn.Linear(latent_dim, obs_dim)</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> step(<span class="va">self</span>, z_prev):</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a>        z_next <span class="op">=</span> <span class="va">self</span>.transition(z_prev, z_prev)  <span class="co"># nonlinear dynamics</span></span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a>        x_mean <span class="op">=</span> <span class="va">self</span>.emission(z_next)            <span class="co"># emission model</span></span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> z_next, x_mean</span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb70-16"><a href="#cb70-16" aria-hidden="true" tabindex="-1"></a>latent_dim, obs_dim <span class="op">=</span> <span class="dv">4</span>, <span class="dv">2</span></span>
<span id="cb70-17"><a href="#cb70-17" aria-hidden="true" tabindex="-1"></a>dkf <span class="op">=</span> DeepKalmanFilter(latent_dim, obs_dim)</span>
<span id="cb70-18"><a href="#cb70-18" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> torch.zeros(latent_dim)</span>
<span id="cb70-19"><a href="#cb70-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb70-20"><a href="#cb70-20" aria-hidden="true" tabindex="-1"></a>    z, x <span class="op">=</span> dkf.step(z)</span>
<span id="cb70-21"><a href="#cb70-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Step </span><span class="sc">{</span>t<span class="sc">}</span><span class="ss">: latent=</span><span class="sc">{</span>z<span class="sc">.</span>detach()<span class="sc">.</span>numpy()<span class="sc">}</span><span class="ss">, obs=</span><span class="sc">{</span>x<span class="sc">.</span>detach()<span class="sc">.</span>numpy()<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-68" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-68">Why It Matters</h4>
<p>Hybrid models are central to modern AI: they combine the rigor of probabilistic reasoning with the flexibility of deep learning. Applications include speech recognition, time-series forecasting, robotics, and reinforcement learning.</p>
</section>
<section id="try-it-yourself-68" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-68">Try It Yourself</h4>
<ol type="1">
<li>Replace the Gaussian emission in an HMM with a neural network that outputs a distribution.</li>
<li>Implement a Deep Kalman Filter and compare it with a standard Kalman Filter on nonlinear data.</li>
<li>Reflect: when should you prefer a pure neural model vs.&nbsp;a neural+probabilistic hybrid?</li>
</ol>
</section>
</section>
<section id="applications-speech-tracking-finance" class="level3">
<h3 class="anchored" data-anchor-id="applications-speech-tracking-finance">570. Applications: Speech, Tracking, Finance</h3>
<p>Sequential probabilistic models—HMMs, Kalman filters, particle filters, and their neural hybrids—are widely applied in domains where time, uncertainty, and dynamics matter. Speech recognition, target tracking, and financial forecasting are three classic areas where these models excel.</p>
<section id="picture-in-your-head-69" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-69">Picture in Your Head</h4>
<p>Think of three scenarios: a voice assistant transcribing speech (speech → text), a radar system following an aircraft (tracking), and an investor modeling stock prices (finance). In all three, signals are noisy, evolve over time, and require probabilistic reasoning to separate meaningful structure from randomness.</p>
</section>
<section id="deep-dive-69" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-69">Deep Dive</h4>
<ol type="1">
<li><p>Speech Recognition (HMMs, Hybrid Models):</p>
<ul>
<li>HMMs model phonemes as hidden states and acoustic features as observations.</li>
<li>Viterbi decoding finds the most likely phoneme sequence.</li>
<li>Modern systems combine HMMs or CTC with deep neural networks.</li>
</ul></li>
<li><p>Tracking and Navigation (Kalman, Particle Filters):</p>
<ul>
<li>Kalman filters estimate position/velocity of moving objects (aircraft, cars).</li>
<li>Particle filters handle nonlinear dynamics (e.g., robot localization).</li>
<li>Used in GPS, radar, and autonomous vehicle navigation.</li>
</ul></li>
<li><p>Finance and Economics (State-Space Models):</p>
<ul>
<li>Kalman filters model latent market factors (e.g., trends, volatility).</li>
<li>Particle filters capture nonlinear dynamics in asset pricing.</li>
<li>HMMs detect market regimes (bull/bear states).</li>
</ul></li>
</ol>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 20%">
<col style="width: 38%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th>Domain</th>
<th>Model</th>
<th>Role</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Speech</td>
<td>HMM + DNN</td>
<td>Map audio to phonemes</td>
<td>Siri, Google Assistant</td>
</tr>
<tr class="even">
<td>Tracking</td>
<td>Kalman/Particle</td>
<td>State estimation under noise</td>
<td>Radar, GPS, robotics</td>
</tr>
<tr class="odd">
<td>Finance</td>
<td>HMM, Kalman</td>
<td>Latent market structure</td>
<td>Bull/bear detection</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-67" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-67">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Toy financial regime-switching model (HMM)</span></span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="fl">0.9</span>, <span class="fl">0.1</span>],</span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>              [<span class="fl">0.2</span>, <span class="fl">0.8</span>]])  <span class="co"># transition matrix (bull/bear)</span></span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>means <span class="op">=</span> [<span class="fl">0.01</span>, <span class="op">-</span><span class="fl">0.01</span>]       <span class="co"># returns: bull=+1%, bear=-1%</span></span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>state <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a>returns <span class="op">=</span> []</span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a>    state <span class="op">=</span> np.random.choice([<span class="dv">0</span>,<span class="dv">1</span>], p<span class="op">=</span>A[state])</span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a>    r <span class="op">=</span> np.random.normal(means[state], <span class="fl">0.02</span>)</span>
<span id="cb71-14"><a href="#cb71-14" aria-hidden="true" tabindex="-1"></a>    returns.append(r)</span>
<span id="cb71-15"><a href="#cb71-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-16"><a href="#cb71-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Simulated returns:"</span>, np.<span class="bu">round</span>(returns,<span class="dv">3</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-69" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-69">Why It Matters</h4>
<p>These applications show why sequential probabilistic models remain core AI tools: they balance uncertainty, structure, and prediction. Even as deep learning dominates, these models form the foundation of robust, interpretable AI in real-world temporal domains.</p>
</section>
<section id="try-it-yourself-69" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-69">Try It Yourself</h4>
<ol type="1">
<li>Build an HMM to distinguish between two speakers’ speech patterns.</li>
<li>Implement a Kalman filter to track a moving object with noisy position data.</li>
<li>Reflect: how do assumptions (linearity, Gaussianity, Markov property) affect reliability in each domain?</li>
</ol>
</section>
</section>
</section>
<section id="chapter-58.-decision-theory-and-influence-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="chapter-58.-decision-theory-and-influence-diagrams">Chapter 58. Decision Theory and Influence Diagrams</h2>
<section id="utility-and-preferences" class="level3">
<h3 class="anchored" data-anchor-id="utility-and-preferences">571. Utility and Preferences</h3>
<p>Decision theory extends probabilistic modeling by introducing utilities, numerical values that represent preferences over outcomes. While probabilities capture what is likely, utilities capture what is desirable. Together, they provide a framework for making rational choices under uncertainty.</p>
<section id="picture-in-your-head-70" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-70">Picture in Your Head</h4>
<p>Imagine choosing between taking an umbrella or not. Probabilities tell you there’s a 40% chance of rain. Utilities tell you how much you dislike getting wet versus the inconvenience of carrying an umbrella. The combination guides the rational choice.</p>
</section>
<section id="deep-dive-70" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-70">Deep Dive</h4>
<ul>
<li><p>Utility function: assigns real numbers to outcomes.</p>
<p><span class="math display">\[
U: \Omega \to \mathbb{R}
\]</span></p>
<p>Higher values = more preferred outcomes.</p></li>
<li><p>Preferences:</p>
<ul>
<li>If <span class="math inline">\(U(a) &gt; U(b)\)</span>, outcome <span class="math inline">\(a\)</span> is preferred over <span class="math inline">\(b\)</span>.</li>
<li>Utilities are unique up to positive affine transformations.</li>
</ul></li>
<li><p>Expected utility: Rational decision-making under uncertainty chooses the action <span class="math inline">\(a\)</span> maximizing:</p>
<p><span class="math display">\[
EU(a) = \sum_{s} P(s \mid a) \, U(s)
\]</span></p></li>
<li><p>Types of preferences:</p>
<ul>
<li>Risk-neutral: cares only about expected value.</li>
<li>Risk-averse: prefers safer outcomes, concave utility curve.</li>
<li>Risk-seeking: prefers risky outcomes, convex utility curve.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Preference Type</th>
<th>Utility Curve</th>
<th>Behavior</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Risk-neutral</td>
<td>Linear</td>
<td>Indifferent to variance</td>
</tr>
<tr class="even">
<td>Risk-averse</td>
<td>Concave</td>
<td>Avoids uncertainty</td>
</tr>
<tr class="odd">
<td>Risk-seeking</td>
<td>Convex</td>
<td>Favors gambles</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-68" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-68">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: umbrella decision</span></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>p_rain <span class="op">=</span> <span class="fl">0.4</span></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> {<span class="st">"umbrella_rain"</span>: <span class="dv">8</span>, <span class="st">"umbrella_sun"</span>: <span class="dv">5</span>,</span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>     <span class="st">"no_umbrella_rain"</span>: <span class="dv">0</span>, <span class="st">"no_umbrella_sun"</span>: <span class="dv">10</span>}</span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a>EU_umbrella <span class="op">=</span> p_rain<span class="op">*</span>U[<span class="st">"umbrella_rain"</span>] <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>p_rain)<span class="op">*</span>U[<span class="st">"umbrella_sun"</span>]</span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a>EU_no_umbrella <span class="op">=</span> p_rain<span class="op">*</span>U[<span class="st">"no_umbrella_rain"</span>] <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>p_rain)<span class="op">*</span>U[<span class="st">"no_umbrella_sun"</span>]</span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Expected Utility (umbrella):"</span>, EU_umbrella)</span>
<span id="cb72-12"><a href="#cb72-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Expected Utility (no umbrella):"</span>, EU_no_umbrella)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-70" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-70">Why It Matters</h4>
<p>Utility functions turn probabilistic predictions into actionable decisions. They make AI systems not just models of the world, but agents capable of acting in it. From game-playing to self-driving cars, expected utility maximization is the backbone of rational decision-making.</p>
</section>
<section id="try-it-yourself-70" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-70">Try It Yourself</h4>
<ol type="1">
<li>Define a utility function for a robot choosing between charging its battery or continuing exploration.</li>
<li>Model a gamble with 50% chance of winning $100 and 50% chance of losing $50. Compare risk-neutral vs.&nbsp;risk-averse utilities.</li>
<li>Reflect: why are probabilities alone insufficient for guiding decisions?</li>
</ol>
</section>
</section>
<section id="rational-decision-making-under-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="rational-decision-making-under-uncertainty">572. Rational Decision-Making under Uncertainty</h3>
<p>Rational decision-making combines probabilities (what might happen) with utilities (how good or bad those outcomes are). Under uncertainty, a rational agent selects the action that maximizes expected utility, balancing risks and rewards systematically.</p>
<section id="picture-in-your-head-71" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-71">Picture in Your Head</h4>
<p>Imagine you’re planning whether to invest in a startup. There’s a 30% chance it becomes hugely profitable and a 70% chance it fails. The rational choice isn’t just about the probabilities—it’s about weighing the potential payoff against the potential loss.</p>
</section>
<section id="deep-dive-71" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-71">Deep Dive</h4>
<ul>
<li><p>Expected utility principle: An action <span class="math inline">\(a\)</span> is rational if:</p>
<p><span class="math display">\[
a^* = \arg\max_a \; \mathbb{E}[U \mid a] = \arg\max_a \sum_s P(s \mid a) \, U(s)
\]</span></p></li>
<li><p>Decision-making pipeline:</p>
<ol type="1">
<li>Model uncertainty: estimate probabilities <span class="math inline">\(P(s \mid a)\)</span>.</li>
<li>Assign utilities: quantify preferences over outcomes.</li>
<li>Compute expected utility: combine the two.</li>
<li>Choose action: pick <span class="math inline">\(a^*\)</span>.</li>
</ol></li>
<li><p>Key properties of rationality (Savage axioms, von Neumann–Morgenstern):</p>
<ul>
<li>Completeness: preferences are always defined.</li>
<li>Transitivity: if <span class="math inline">\(a &gt; b\)</span> and <span class="math inline">\(b &gt; c\)</span>, then <span class="math inline">\(a &gt; c\)</span>.</li>
<li>Independence: irrelevant alternatives don’t affect preferences.</li>
<li>Continuity: small changes in probabilities don’t flip preferences abruptly.</li>
</ul></li>
<li><p>Limitations in practice:</p>
<ul>
<li>Humans often violate rational axioms (prospect theory).</li>
<li>Utilities are hard to elicit.</li>
<li>Probabilities may be subjective or uncertain themselves.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 28%">
<col style="width: 35%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="header">
<th>Step</th>
<th>Question Answered</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Model uncertainty</td>
<td>What might happen?</td>
<td>30% startup succeeds</td>
</tr>
<tr class="even">
<td>Assign utilities</td>
<td>How do I feel about outcomes?</td>
<td>$1M if succeed, -$50K if fail</td>
</tr>
<tr class="odd">
<td>Compute expected utility</td>
<td>What’s the weighted payoff?</td>
<td><span class="math inline">\(0.3 \cdot 1M + 0.7 \cdot -50K\)</span></td>
</tr>
<tr class="even">
<td>Choose action</td>
<td>Which action maximizes payoff?</td>
<td>Invest or not invest</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-69" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-69">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Startup investment decision</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>p_success <span class="op">=</span> <span class="fl">0.3</span></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> {<span class="st">"success"</span>: <span class="dv">1_000_000</span>, <span class="st">"failure"</span>: <span class="op">-</span><span class="dv">50_000</span>, <span class="st">"no_invest"</span>: <span class="dv">0</span>}</span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>EU_invest <span class="op">=</span> p_success<span class="op">*</span>U[<span class="st">"success"</span>] <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>p_success)<span class="op">*</span>U[<span class="st">"failure"</span>]</span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a>EU_no_invest <span class="op">=</span> U[<span class="st">"no_invest"</span>]</span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Expected Utility (invest):"</span>, EU_invest)</span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Expected Utility (no invest):"</span>, EU_no_invest)</span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Decision:"</span>, <span class="st">"Invest"</span> <span class="cf">if</span> EU_invest <span class="op">&gt;</span> EU_no_invest <span class="cf">else</span> <span class="st">"No Invest"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-71" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-71">Why It Matters</h4>
<p>This principle transforms AI from passive prediction into active decision-making. From medical diagnosis to autonomous vehicles, rational agents must weigh uncertainty against goals, ensuring choices align with long-term preferences.</p>
</section>
<section id="try-it-yourself-71" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-71">Try It Yourself</h4>
<ol type="1">
<li>Define a decision problem with three actions and uncertain outcomes—compute expected utilities.</li>
<li>Modify the utility function to reflect risk aversion. Does the rational choice change?</li>
<li>Reflect: why might bounded rationality (limited computation or imperfect models) alter real-world decisions?</li>
</ol>
</section>
</section>
<section id="expected-utility-theory" class="level3">
<h3 class="anchored" data-anchor-id="expected-utility-theory">573. Expected Utility Theory</h3>
<p>Expected Utility Theory (EUT) formalizes how rational agents should make decisions under uncertainty. It states that if an agent’s preferences satisfy certain rationality axioms, then there exists a utility function such that the agent always chooses the action maximizing its expected utility.</p>
<section id="picture-in-your-head-72" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-72">Picture in Your Head</h4>
<p>Think of playing a lottery: a 50% chance to win $100 or a 50% chance to win nothing. A rational agent evaluates the gamble not by the possible outcomes alone, but by the average utility weighted by probabilities, and decides whether to play.</p>
</section>
<section id="deep-dive-72" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-72">Deep Dive</h4>
<ul>
<li><p>Core principle: For actions <span class="math inline">\(a\)</span>, outcomes <span class="math inline">\(s\)</span>, and utility function <span class="math inline">\(U\)</span>:</p>
<p><span class="math display">\[
EU(a) = \sum_{s} P(s \mid a) \, U(s)
\]</span></p>
<p>The rational choice is:</p>
<p><span class="math display">\[
a^* = \arg\max_a EU(a)
\]</span></p></li>
<li><p>Von Neumann–Morgenstern utility theorem: If preferences satisfy completeness, transitivity, independence, continuity, then they can be represented by a utility function, and maximizing expected utility is rational.</p></li>
<li><p>Risk attitudes in EUT:</p>
<ul>
<li>Risk-neutral: linear utility in money.</li>
<li>Risk-averse: concave utility (prefers sure gains).</li>
<li>Risk-seeking: convex utility (prefers risky gambles).</li>
</ul></li>
<li><p>Applications in AI:</p>
<ul>
<li>Planning under uncertainty.</li>
<li>Game theory and multi-agent systems.</li>
<li>Reinforcement learning reward maximization.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 24%">
<col style="width: 21%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th>Risk Attitude</th>
<th>Utility Function Shape</th>
<th>Behavior</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Neutral</td>
<td>Linear</td>
<td>Indifferent to risk</td>
<td>Prefers $50 for sure = 50% of $100</td>
</tr>
<tr class="even">
<td>Averse</td>
<td>Concave</td>
<td>Avoids risky bets</td>
<td>Prefers $50 for sure &gt; 50% of $100</td>
</tr>
<tr class="odd">
<td>Seeking</td>
<td>Convex</td>
<td>Loves risky bets</td>
<td>Prefers 50% of $100 &gt; $50 for sure</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-70" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-70">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Lottery: 50% chance win $100, 50% chance $0</span></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>p_win <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>payoffs <span class="op">=</span> [<span class="dv">100</span>, <span class="dv">0</span>]</span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Different utility functions</span></span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>U_linear <span class="op">=</span> <span class="kw">lambda</span> x: x</span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a>U_concave <span class="op">=</span> <span class="kw">lambda</span> x: np.sqrt(x)   <span class="co"># risk-averse</span></span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>U_convex <span class="op">=</span> <span class="kw">lambda</span> x: x2          <span class="co"># risk-seeking</span></span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, U <span class="kw">in</span> [(<span class="st">"Neutral"</span>, U_linear), (<span class="st">"Averse"</span>, U_concave), (<span class="st">"Seeking"</span>, U_convex)]:</span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a>    EU <span class="op">=</span> p_win<span class="op">*</span>U(payoffs[<span class="dv">0</span>]) <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>p_win)<span class="op">*</span>U(payoffs[<span class="dv">1</span>])</span>
<span id="cb74-14"><a href="#cb74-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> expected utility:"</span>, EU)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-72" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-72">Why It Matters</h4>
<p>Expected Utility Theory is the mathematical backbone of rational decision-making. It connects uncertainty (probabilities) and preferences (utilities) into a single decision criterion, enabling AI systems to act coherently in uncertain environments.</p>
</section>
<section id="try-it-yourself-72" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-72">Try It Yourself</h4>
<ol type="1">
<li>Write a utility function for a person who strongly dislikes losses more than they value gains.</li>
<li>Compare expected utilities of two lotteries: (a) 40% chance of $200, (b) 100% chance of $70.</li>
<li>Reflect: why do real humans often violate EUT, and what alternative models (e.g., prospect theory) address this?</li>
</ol>
</section>
</section>
<section id="risk-aversion-and-utility-curves" class="level3">
<h3 class="anchored" data-anchor-id="risk-aversion-and-utility-curves">574. Risk Aversion and Utility Curves</h3>
<p>Risk aversion reflects how decision-makers value certainty versus uncertainty. Even when two options have the same expected monetary value, a risk-averse agent prefers the safer option. This behavior is captured by the shape of the utility curve: concave for risk-averse, convex for risk-seeking, and linear for risk-neutral.</p>
<section id="picture-in-your-head-73" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-73">Picture in Your Head</h4>
<p>Imagine choosing between:</p>
<ul>
<li><ol type="A">
<li>Guaranteed $50.</li>
</ol></li>
<li><ol start="2" type="A">
<li>A coin flip: 50% chance of $100, 50% chance of $0. Both have the same expected value ($50). A risk-averse person prefers (A), while a risk-seeker prefers (B).</li>
</ol></li>
</ul>
</section>
<section id="deep-dive-73" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-73">Deep Dive</h4>
<ul>
<li><p>Utility function shapes:</p>
<ul>
<li>Risk-neutral: <span class="math inline">\(U(x) = x\)</span> (linear).</li>
<li>Risk-averse: <span class="math inline">\(U(x) = \sqrt{x}\)</span> or <span class="math inline">\(\log(x)\)</span> (concave).</li>
<li>Risk-seeking: <span class="math inline">\(U(x) = x^2\)</span> (convex).</li>
</ul></li>
<li><p>Certainty equivalent (CE): the guaranteed value the agent finds equally desirable as the gamble.</p>
<ul>
<li>For risk-averse agents, <span class="math inline">\(CE &lt; \mathbb{E}[X]\)</span>.</li>
<li>For risk-seeking agents, <span class="math inline">\(CE &gt; \mathbb{E}[X]\)</span>.</li>
</ul></li>
<li><p>Risk premium: difference between expected value and certainty equivalent:</p>
<p><span class="math display">\[
\text{Risk Premium} = \mathbb{E}[X] - CE
\]</span></p>
<p>A measure of how much someone is willing to pay to avoid risk.</p></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Attitude</th>
<th>Utility Curve</th>
<th>CE vs EV</th>
<th>Example Behavior</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Neutral</td>
<td>Linear</td>
<td>CE = EV</td>
<td>Indifferent to risk</td>
</tr>
<tr class="even">
<td>Averse</td>
<td>Concave</td>
<td>CE &lt; EV</td>
<td>Prefers safe bet</td>
</tr>
<tr class="odd">
<td>Seeking</td>
<td>Convex</td>
<td>CE &gt; EV</td>
<td>Prefers gamble</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-71" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-71">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>lottery <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">100</span>]  <span class="co"># coin flip outcomes</span></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>EV <span class="op">=</span> np.mean(lottery)</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>U_linear <span class="op">=</span> <span class="kw">lambda</span> x: x</span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a>U_concave <span class="op">=</span> <span class="kw">lambda</span> x: np.sqrt(x)</span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a>U_convex <span class="op">=</span> <span class="kw">lambda</span> x: x2</span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, U <span class="kw">in</span> [(<span class="st">"Neutral"</span>, U_linear), (<span class="st">"Averse"</span>, U_concave), (<span class="st">"Seeking"</span>, U_convex)]:</span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a>    EU <span class="op">=</span> p<span class="op">*</span>U(lottery[<span class="dv">0</span>]) <span class="op">+</span> p<span class="op">*</span>U(lottery[<span class="dv">1</span>])</span>
<span id="cb75-13"><a href="#cb75-13" aria-hidden="true" tabindex="-1"></a>    CE <span class="op">=</span> (EU2 <span class="cf">if</span> name<span class="op">==</span><span class="st">"Averse"</span> <span class="cf">else</span> (np.sqrt(EU) <span class="cf">if</span> name<span class="op">==</span><span class="st">"Seeking"</span> <span class="cf">else</span> EU))</span>
<span id="cb75-14"><a href="#cb75-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">: EV=</span><span class="sc">{</span>EV<span class="sc">}</span><span class="ss">, EU=</span><span class="sc">{</span>EU<span class="sc">:.2f}</span><span class="ss">, CE≈</span><span class="sc">{</span>CE<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-73" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-73">Why It Matters</h4>
<p>Modeling risk preferences is essential in finance, healthcare, and autonomous systems. An AI trading system, a self-driving car, or a medical decision support tool must respect whether stakeholders prefer safer, more predictable outcomes or are willing to gamble for higher rewards.</p>
</section>
<section id="try-it-yourself-73" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-73">Try It Yourself</h4>
<ol type="1">
<li>Draw concave, linear, and convex utility curves for wealth values from 0–100.</li>
<li>Compute the certainty equivalent of a 50-50 lottery between $0 and $200 for risk-averse vs.&nbsp;risk-seeking agents.</li>
<li>Reflect: how does risk aversion explain why people buy insurance or avoid high-risk investments?</li>
</ol>
</section>
</section>
<section id="influence-diagrams-structure-and-semantics" class="level3">
<h3 class="anchored" data-anchor-id="influence-diagrams-structure-and-semantics">575. Influence Diagrams: Structure and Semantics</h3>
<p>An influence diagram is a graphical representation that extends Bayesian networks to include decisions and utilities alongside random variables. It compactly encodes decision problems under uncertainty by showing how chance, choices, and preferences interact.</p>
<section id="picture-in-your-head-74" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-74">Picture in Your Head</h4>
<p>Think of planning a road trip. The weather (chance node) affects whether you take an umbrella (decision node), and that choice impacts your comfort (utility node). An influence diagram shows this causal chain in one coherent picture.</p>
</section>
<section id="deep-dive-74" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-74">Deep Dive</h4>
<ul>
<li><p>Node types:</p>
<ul>
<li>Chance nodes (ovals): uncertain variables with probability distributions.</li>
<li>Decision nodes (rectangles): actions under the agent’s control.</li>
<li>Utility nodes (diamonds): represent payoffs or preferences.</li>
</ul></li>
<li><p>Arcs:</p>
<ul>
<li>Into chance nodes = probabilistic dependence.</li>
<li>Into decision nodes = information available at decision time.</li>
<li>Into utility nodes = variables that affect utility.</li>
</ul></li>
<li><p>Semantics:</p>
<ul>
<li>Defines a joint distribution over chance variables.</li>
<li>Defines a policy mapping from information → decisions.</li>
<li>Expected utility is computed to identify optimal decisions.</li>
</ul></li>
<li><p>Compactness advantage: Compared to decision trees, influence diagrams avoid combinatorial explosion by factorizing probabilities and utilities.</p></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Node Type</th>
<th>Shape</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Chance</td>
<td>Oval</td>
<td>Weather (Sunny/Rainy)</td>
</tr>
<tr class="even">
<td>Decision</td>
<td>Rectangle</td>
<td>Bring umbrella?</td>
</tr>
<tr class="odd">
<td>Utility</td>
<td>Diamond</td>
<td>Comfort level</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, using networkx for structure)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Build simple influence diagram</span></span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.DiGraph()</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>G.add_nodes_from([</span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Weather"</span>, {<span class="st">"type"</span>:<span class="st">"chance"</span>}),</span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Umbrella"</span>, {<span class="st">"type"</span>:<span class="st">"decision"</span>}),</span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Comfort"</span>, {<span class="st">"type"</span>:<span class="st">"utility"</span>})</span>
<span id="cb76-9"><a href="#cb76-9" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb76-10"><a href="#cb76-10" aria-hidden="true" tabindex="-1"></a>G.add_edges_from([</span>
<span id="cb76-11"><a href="#cb76-11" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Weather"</span>,<span class="st">"Umbrella"</span>),  <span class="co"># info arc</span></span>
<span id="cb76-12"><a href="#cb76-12" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Weather"</span>,<span class="st">"Comfort"</span>),</span>
<span id="cb76-13"><a href="#cb76-13" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Umbrella"</span>,<span class="st">"Comfort"</span>)</span>
<span id="cb76-14"><a href="#cb76-14" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb76-15"><a href="#cb76-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-16"><a href="#cb76-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Nodes with types:"</span>, G.nodes(data<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb76-17"><a href="#cb76-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Edges:"</span>, <span class="bu">list</span>(G.edges()))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-74" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-74">Why It Matters</h4>
<p>Influence diagrams are widely used in AI planning, medical decision support, and economics because they unify probability, decision, and utility in a single framework. They make reasoning about complex choices tractable and interpretable.</p>
</section>
<section id="try-it-yourself-74" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-74">Try It Yourself</h4>
<ol type="1">
<li>Draw an influence diagram for a robot deciding whether to recharge its battery or continue exploring.</li>
<li>Translate the diagram into probabilities, utilities, and a decision policy.</li>
<li>Reflect: how does an influence diagram simplify large decision problems compared to a raw decision tree?</li>
</ol>
</section>
</section>
<section id="combining-probabilistic-and-utility-models" class="level3">
<h3 class="anchored" data-anchor-id="combining-probabilistic-and-utility-models">576. Combining Probabilistic and Utility Models</h3>
<p>Decision theory fuses probabilistic models (describing uncertainty) with utility models (capturing preferences) to guide rational action. Probabilities alone can predict what might happen, but only when combined with utilities can an agent decide what it ought to do.</p>
<section id="picture-in-your-head-75" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-75">Picture in Your Head</h4>
<p>Suppose a doctor is deciding whether to prescribe a treatment. Probabilities estimate outcomes: recovery, side effects, or no change. Utilities quantify how desirable each outcome is (longer life, discomfort, costs). Combining both gives the best course of action.</p>
</section>
<section id="deep-dive-75" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-75">Deep Dive</h4>
<ul>
<li><p>Two ingredients:</p>
<ol type="1">
<li><p>Probabilistic model:</p>
<p><span class="math display">\[
P(s \mid a)
\]</span></p>
<p>Likelihood of outcomes <span class="math inline">\(s\)</span> given action <span class="math inline">\(a\)</span>.</p></li>
<li><p>Utility model:</p>
<p><span class="math display">\[
U(s)
\]</span></p>
<p>Value assigned to outcome <span class="math inline">\(s\)</span>.</p></li>
</ol></li>
<li><p>Expected utility principle:</p>
<p><span class="math display">\[
a^* = \arg\max_a \sum_s P(s \mid a) U(s)
\]</span></p>
<p>Action chosen is the one maximizing expected utility.</p></li>
<li><p>Influence diagram integration:</p>
<ul>
<li>Chance nodes: probabilities.</li>
<li>Decision nodes: available actions.</li>
<li>Utility nodes: preferences.</li>
<li>Together, they form a compact representation of a decision problem.</li>
</ul></li>
<li><p>Applications:</p>
<ul>
<li>Medical diagnosis: choose treatment under uncertain prognosis.</li>
<li>Autonomous driving: balance safety (utilities) with speed and efficiency.</li>
<li>Economics &amp; policy: weigh uncertain benefits vs.&nbsp;costs.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 27%">
<col style="width: 27%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th>Component</th>
<th>Role</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Probabilistic model</td>
<td>Predicts outcomes</td>
<td>Weather forecast: 60% rain</td>
</tr>
<tr class="even">
<td>Utility model</td>
<td>Values outcomes</td>
<td>Dislike being wet: -10 utility</td>
</tr>
<tr class="odd">
<td>Decision rule</td>
<td>Chooses best action</td>
<td>Carry umbrella if EU higher</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-72" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-72">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Treatment decision: treat or not treat</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>p_success <span class="op">=</span> <span class="fl">0.7</span></span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>p_side_effects <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>p_no_change <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> {<span class="st">"success"</span>: <span class="dv">100</span>, <span class="st">"side_effects"</span>: <span class="dv">20</span>, <span class="st">"no_change"</span>: <span class="dv">50</span>, <span class="st">"no_treatment"</span>: <span class="dv">60</span>}</span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a>EU_treat <span class="op">=</span> (p_success<span class="op">*</span>U[<span class="st">"success"</span>] <span class="op">+</span></span>
<span id="cb77-9"><a href="#cb77-9" aria-hidden="true" tabindex="-1"></a>            p_side_effects<span class="op">*</span>U[<span class="st">"side_effects"</span>] <span class="op">+</span></span>
<span id="cb77-10"><a href="#cb77-10" aria-hidden="true" tabindex="-1"></a>            p_no_change<span class="op">*</span>U[<span class="st">"no_change"</span>])</span>
<span id="cb77-11"><a href="#cb77-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-12"><a href="#cb77-12" aria-hidden="true" tabindex="-1"></a>EU_no_treat <span class="op">=</span> U[<span class="st">"no_treatment"</span>]</span>
<span id="cb77-13"><a href="#cb77-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-14"><a href="#cb77-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Expected Utility (treat):"</span>, EU_treat)</span>
<span id="cb77-15"><a href="#cb77-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Expected Utility (no treat):"</span>, EU_no_treat)</span>
<span id="cb77-16"><a href="#cb77-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best choice:"</span>, <span class="st">"Treat"</span> <span class="cf">if</span> EU_treat <span class="op">&gt;</span> EU_no_treat <span class="cf">else</span> <span class="st">"No treat"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-75" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-75">Why It Matters</h4>
<p>This combination is what turns AI systems into agents: they don’t just model the world, they act purposefully in it. By balancing uncertain predictions with preferences, agents can make principled, rational choices aligned with goals.</p>
</section>
<section id="try-it-yourself-75" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-75">Try It Yourself</h4>
<ol type="1">
<li>Model a robot deciding whether to take a short but risky path vs.&nbsp;a long safe path.</li>
<li>Assign probabilities to possible hazards and utilities to outcomes.</li>
<li>Reflect: why does ignoring utilities make an agent incomplete, even with perfect probability estimates?</li>
</ol>
</section>
</section>
<section id="multi-stage-decision-problems" class="level3">
<h3 class="anchored" data-anchor-id="multi-stage-decision-problems">577. Multi-Stage Decision Problems</h3>
<p>Many real-world decisions aren’t one-shot—they unfold over time. Multi-stage decision problems involve sequences of choices where each decision affects both immediate outcomes and future options. Solving them requires combining probabilistic modeling, utilities, and planning over multiple steps.</p>
<section id="picture-in-your-head-76" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-76">Picture in Your Head</h4>
<p>Imagine a chess game. Each move (decision) influences the opponent’s response (chance) and the long-term outcome (utility: win, lose, draw). Thinking only about the next move isn’t enough—you must evaluate sequences of moves and counter-moves.</p>
</section>
<section id="deep-dive-76" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-76">Deep Dive</h4>
<ul>
<li><p>Sequential structure:</p>
<ul>
<li>State <span class="math inline">\(s_t\)</span>: information available at time <span class="math inline">\(t\)</span>.</li>
<li>Action <span class="math inline">\(a_t\)</span>: decision made at time <span class="math inline">\(t\)</span>.</li>
<li>Transition model: <span class="math inline">\(P(s_{t+1} \mid s_t, a_t)\)</span>.</li>
<li>Reward/utility: <span class="math inline">\(U(s_t, a_t)\)</span>.</li>
</ul></li>
<li><p>Objective: maximize total expected utility over horizon <span class="math inline">\(T\)</span>:</p>
<p><span class="math display">\[
a^*_{1:T} = \arg\max_{a_{1:T}} \mathbb{E}\Big[\sum_{t=1}^T U(s_t, a_t)\Big]
\]</span></p></li>
<li><p>Dynamic programming principle:</p>
<ul>
<li><p>Breaks down the problem into smaller subproblems.</p></li>
<li><p>Bellman recursion:</p>
<p><span class="math display">\[
V(s_t) = \max_{a_t} \Big[ U(s_t, a_t) + \sum_{s_{t+1}} P(s_{t+1} \mid s_t, a_t) V(s_{t+1}) \Big]
\]</span></p></li>
</ul></li>
<li><p>Special cases:</p>
<ul>
<li>Finite-horizon problems: limited number of stages.</li>
<li>Infinite-horizon problems: long-term optimization with discount factor <span class="math inline">\(\gamma\)</span>.</li>
<li>Leads directly into Markov Decision Processes (MDPs) and Reinforcement Learning.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 34%">
<col style="width: 48%">
</colgroup>
<thead>
<tr class="header">
<th>Aspect</th>
<th>One-shot</th>
<th>Multi-stage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Decision scope</td>
<td>Single action</td>
<td>Sequence of actions</td>
</tr>
<tr class="even">
<td>Evaluation</td>
<td>Expected utility of outcomes</td>
<td>Expected utility of cumulative outcomes</td>
</tr>
<tr class="odd">
<td>Methods</td>
<td>Influence diagrams</td>
<td>Dynamic programming, MDPs</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-73" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-73">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple 2-step decision problem</span></span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a><span class="co"># State: battery level {low, high}</span></span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Actions: {charge, explore}</span></span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a>states <span class="op">=</span> [<span class="st">"low"</span>, <span class="st">"high"</span>]</span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> {(<span class="st">"low"</span>,<span class="st">"charge"</span>):<span class="dv">5</span>, (<span class="st">"low"</span>,<span class="st">"explore"</span>):<span class="dv">0</span>,</span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a>     (<span class="st">"high"</span>,<span class="st">"charge"</span>):<span class="dv">2</span>, (<span class="st">"high"</span>,<span class="st">"explore"</span>):<span class="dv">10</span>}</span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a>P <span class="op">=</span> {(<span class="st">"low"</span>,<span class="st">"charge"</span>):<span class="st">"high"</span>, (<span class="st">"low"</span>,<span class="st">"explore"</span>):<span class="st">"low"</span>,</span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a>     (<span class="st">"high"</span>,<span class="st">"charge"</span>):<span class="st">"high"</span>, (<span class="st">"high"</span>,<span class="st">"explore"</span>):<span class="st">"low"</span>}</span>
<span id="cb78-13"><a href="#cb78-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-14"><a href="#cb78-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plan(state, steps<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb78-15"><a href="#cb78-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> steps <span class="op">==</span> <span class="dv">0</span>: <span class="cf">return</span> <span class="dv">0</span></span>
<span id="cb78-16"><a href="#cb78-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">max</span>(</span>
<span id="cb78-17"><a href="#cb78-17" aria-hidden="true" tabindex="-1"></a>        U[(state,a)] <span class="op">+</span> plan(P[(state,a)], steps<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb78-18"><a href="#cb78-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> a <span class="kw">in</span> [<span class="st">"charge"</span>,<span class="st">"explore"</span>]</span>
<span id="cb78-19"><a href="#cb78-19" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb78-20"><a href="#cb78-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-21"><a href="#cb78-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best value starting from low battery:"</span>, plan(<span class="st">"low"</span>,<span class="dv">2</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-76" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-76">Why It Matters</h4>
<p>Multi-stage problems capture the essence of intelligent behavior: planning, foresight, and sequential reasoning. They’re at the heart of robotics, reinforcement learning, operations research, and any system that must act over time.</p>
</section>
<section id="try-it-yourself-76" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-76">Try It Yourself</h4>
<ol type="1">
<li>Define a 3-step decision problem for a self-driving car (states = traffic, actions = accelerate/brake).</li>
<li>Write down its Bellman recursion.</li>
<li>Reflect: why does myopic (single-step) decision-making often fail in sequential settings?</li>
</ol>
</section>
</section>
<section id="decision-theoretic-inference-algorithms" class="level3">
<h3 class="anchored" data-anchor-id="decision-theoretic-inference-algorithms">578. Decision-Theoretic Inference Algorithms</h3>
<p>Decision-theoretic inference algorithms extend probabilistic inference by integrating utilities and decisions. Instead of just asking <em>“what is the probability of X?”</em>, they answer <em>“what is the best action to take?”</em> given both uncertainty and preferences.</p>
<section id="picture-in-your-head-77" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-77">Picture in Your Head</h4>
<p>Think of medical diagnosis: probabilistic inference estimates the likelihood of diseases, but decision-theoretic inference goes further—it chooses the treatment that maximizes expected patient outcomes.</p>
</section>
<section id="deep-dive-77" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-77">Deep Dive</h4>
<ul>
<li><p>Inputs:</p>
<ol type="1">
<li>Probabilistic model: <span class="math inline">\(P(s \mid a)\)</span> for states and actions.</li>
<li>Utility function: <span class="math inline">\(U(s, a)\)</span>.</li>
<li>Decision variables: available actions.</li>
</ol></li>
<li><p>Goal: compute optimal action(s) by maximizing expected utility:</p>
<p><span class="math display">\[
a^* = \arg\max_a \sum_s P(s \mid a) \, U(s, a)
\]</span></p></li>
<li><p>Algorithms:</p>
<ul>
<li>Variable elimination with decisions: extend standard probabilistic elimination to include decision and utility nodes.</li>
<li>Dynamic programming / Bellman equations: for sequential settings.</li>
<li>Value of information (VOI) computations: estimate benefit of gathering more evidence before acting.</li>
<li>Monte Carlo methods: approximate expected utilities when state/action spaces are large.</li>
</ul></li>
<li><p>Value of information example:</p>
<ul>
<li>Sometimes gathering more data changes the optimal decision.</li>
<li>VOI quantifies whether it’s worth paying the cost of getting that data.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 38%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Algorithm</th>
<th>Core Idea</th>
<th>Application</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Variable elimination</td>
<td>Combine probabilities + utilities</td>
<td>One-shot decisions</td>
</tr>
<tr class="even">
<td>Dynamic programming</td>
<td>Recursive optimality</td>
<td>Sequential MDPs</td>
</tr>
<tr class="odd">
<td>VOI analysis</td>
<td>Quantify benefit of info</td>
<td>Medical tests, diagnostics</td>
</tr>
<tr class="even">
<td>Monte Carlo</td>
<td>Sampling-based EU</td>
<td>Complex, high-dimensional spaces</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-74" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-74">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple VOI example: medical test</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>p_disease <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> {<span class="st">"treat"</span>: <span class="dv">50</span>, <span class="st">"no_treat"</span>: <span class="dv">0</span>, <span class="st">"side_effect"</span>: <span class="op">-</span><span class="dv">20</span>}</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Expected utility without test</span></span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a>EU_treat <span class="op">=</span> p_disease<span class="op">*</span>U[<span class="st">"treat"</span>] <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>p_disease)<span class="op">*</span>U[<span class="st">"side_effect"</span>]</span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>EU_no_treat <span class="op">=</span> U[<span class="st">"no_treat"</span>]</span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"EU treat:"</span>, EU_treat, <span class="st">"EU no_treat:"</span>, EU_no_treat)</span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-11"><a href="#cb79-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Suppose a test reveals disease with 90% accuracy</span></span>
<span id="cb79-12"><a href="#cb79-12" aria-hidden="true" tabindex="-1"></a>p_test_pos <span class="op">=</span> p_disease<span class="op">*</span><span class="fl">0.9</span> <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>p_disease)<span class="op">*</span><span class="fl">0.1</span></span>
<span id="cb79-13"><a href="#cb79-13" aria-hidden="true" tabindex="-1"></a>EU_test <span class="op">=</span> p_test_pos<span class="op">*</span><span class="bu">max</span>(<span class="fl">0.9</span><span class="op">*</span>U[<span class="st">"treat"</span>] <span class="op">+</span> <span class="fl">0.1</span><span class="op">*</span>U[<span class="st">"side_effect"</span>], U[<span class="st">"no_treat"</span>]) <span class="op">\</span></span>
<span id="cb79-14"><a href="#cb79-14" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>p_test_pos)<span class="op">*</span><span class="bu">max</span>(<span class="fl">0.1</span><span class="op">*</span>U[<span class="st">"treat"</span>] <span class="op">+</span> <span class="fl">0.9</span><span class="op">*</span>U[<span class="st">"side_effect"</span>], U[<span class="st">"no_treat"</span>])</span>
<span id="cb79-15"><a href="#cb79-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-16"><a href="#cb79-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"EU with test:"</span>, EU_test)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-77" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-77">Why It Matters</h4>
<p>These algorithms bridge the gap between inference (what we know) and decision-making (what we should do). They’re crucial in AI systems for healthcare, finance, robotics, and policy-making, where acting optimally matters as much as knowing.</p>
</section>
<section id="try-it-yourself-77" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-77">Try It Yourself</h4>
<ol type="1">
<li>Implement variable elimination with utilities for a 2-action decision problem.</li>
<li>Compare optimal actions before and after collecting extra evidence.</li>
<li>Reflect: why is computing the <em>value of information</em> essential for resource-limited agents?</li>
</ol>
</section>
</section>
<section id="ai-applications-diagnosis-planning-games" class="level3">
<h3 class="anchored" data-anchor-id="ai-applications-diagnosis-planning-games">579. AI Applications: Diagnosis, Planning, Games</h3>
<p>Decision-theoretic methods are not just abstract—they power real-world AI systems. In diagnosis, they help choose treatments; in planning, they optimize actions under uncertainty; in games, they balance strategies with risks and rewards. All rely on combining probabilities and utilities to act rationally.</p>
<section id="picture-in-your-head-78" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-78">Picture in Your Head</h4>
<p>Think of three AI agents:</p>
<ul>
<li>A doctor AI weighing test results to decide treatment.</li>
<li>A robot planner navigating a warehouse with uncertain obstacles.</li>
<li>A game AI balancing offensive and defensive moves. Each must evaluate uncertainty and choose actions that maximize long-term value.</li>
</ul>
</section>
<section id="deep-dive-78" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-78">Deep Dive</h4>
<ol type="1">
<li><p>Diagnosis (Medical Decision Support):</p>
<ul>
<li>Probabilities: likelihood of diseases given symptoms.</li>
<li>Utilities: outcomes like recovery, side effects, cost.</li>
<li>Decision rule: maximize expected patient benefit.</li>
<li>Example: influence diagrams in cancer treatment planning.</li>
</ul></li>
<li><p>Planning (Robotics, Logistics):</p>
<ul>
<li>Probabilities: success rates of actions, uncertainty in sensors.</li>
<li>Utilities: efficiency, safety, resource use.</li>
<li>Decision-theoretic planners use MDPs and POMDPs.</li>
<li>Example: robot choosing whether to recharge now or risk exploring longer.</li>
</ul></li>
<li><p>Games (Strategic Decision-Making):</p>
<ul>
<li>Probabilities: opponent actions, stochastic game elements.</li>
<li>Utilities: win, lose, draw, or intermediate payoffs.</li>
<li>Decision rules align with game theory and expected utility.</li>
<li>Example: poker bots blending bluffing (risk) and value play.</li>
</ul></li>
</ol>
<table class="caption-top table">
<colgroup>
<col style="width: 9%">
<col style="width: 39%">
<col style="width: 23%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th>Domain</th>
<th>Probabilistic Model</th>
<th>Utility Model</th>
<th>Example System</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Diagnosis</td>
<td>Bayesian network of symptoms → diseases</td>
<td>Patient health outcomes</td>
<td>MYCIN (early expert system)</td>
</tr>
<tr class="even">
<td>Planning</td>
<td>Transition probabilities in MDP</td>
<td>Energy, time, safety</td>
<td>Autonomous robots</td>
</tr>
<tr class="odd">
<td>Games</td>
<td>Opponent modeling</td>
<td>Win/loss payoff</td>
<td>AlphaZero, poker AIs</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-75" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-75">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Diagnosis example: treat or not treat given test</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>p_disease <span class="op">=</span> <span class="fl">0.3</span></span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> {<span class="st">"treat_recover"</span>: <span class="dv">100</span>, <span class="st">"treat_side_effects"</span>: <span class="op">-</span><span class="dv">20</span>,</span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a>     <span class="st">"no_treat_sick"</span>: <span class="op">-</span><span class="dv">50</span>, <span class="st">"no_treat_healthy"</span>: <span class="dv">0</span>}</span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a>EU_treat <span class="op">=</span> p_disease<span class="op">*</span>U[<span class="st">"treat_recover"</span>] <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>p_disease)<span class="op">*</span>U[<span class="st">"treat_side_effects"</span>]</span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a>EU_no_treat <span class="op">=</span> p_disease<span class="op">*</span>U[<span class="st">"no_treat_sick"</span>] <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>p_disease)<span class="op">*</span>U[<span class="st">"no_treat_healthy"</span>]</span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-9"><a href="#cb80-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Expected utility (treat):"</span>, EU_treat)</span>
<span id="cb80-10"><a href="#cb80-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Expected utility (no treat):"</span>, EU_no_treat)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-78" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-78">Why It Matters</h4>
<p>Decision-theoretic AI is the foundation of rational action in uncertain domains. It allows systems to go beyond prediction to choosing optimal actions, making it central to healthcare, robotics, economics, and competitive games.</p>
</section>
<section id="try-it-yourself-78" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-78">Try It Yourself</h4>
<ol type="1">
<li>Model a decision problem for a warehouse robot: continue working vs.&nbsp;recharge battery.</li>
<li>Extend it to a two-player game where one player’s move introduces uncertainty.</li>
<li>Reflect: why does AI in safety-critical applications (medicine, driving) demand explicit modeling of utilities, not just probabilities?</li>
</ol>
</section>
</section>
<section id="limitations-of-classical-decision-theory" class="level3">
<h3 class="anchored" data-anchor-id="limitations-of-classical-decision-theory">580. Limitations of Classical Decision Theory</h3>
<p>Classical decision theory assumes perfectly rational agents who know probabilities, have well-defined utilities, and can compute optimal actions. In practice, these assumptions break down: people and AI systems often face incomplete knowledge, limited computation, and inconsistent preferences.</p>
<section id="picture-in-your-head-79" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-79">Picture in Your Head</h4>
<p>Think of a person deciding whether to invest in stocks. They don’t know the true probabilities of market outcomes, their preferences shift over time, and they can’t compute all possible scenarios. Classical theory says “maximize expected utility,” but real-world agents can’t always follow that ideal.</p>
</section>
<section id="deep-dive-79" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-79">Deep Dive</h4>
<ul>
<li><p>Challenges with probabilities:</p>
<ul>
<li>Probabilities may be unknown, subjective, or hard to estimate.</li>
<li>Real-world events may not be well captured by simple distributions.</li>
</ul></li>
<li><p>Challenges with utilities:</p>
<ul>
<li>Assigning precise numerical values to outcomes is often unrealistic.</li>
<li>People exhibit context-dependent preferences (framing effects, loss aversion).</li>
</ul></li>
<li><p>Computational limits:</p>
<ul>
<li>Optimal decision-making may require solving intractable problems (e.g., POMDPs).</li>
<li>Approximation and heuristics are often necessary.</li>
</ul></li>
<li><p>Behavioral deviations:</p>
<ul>
<li>Humans systematically violate axioms (Prospect Theory, bounded rationality).</li>
<li>AI systems also rely on approximations, leading to suboptimal but practical solutions.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 19%">
<col style="width: 30%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Limitation</th>
<th>Classical Assumption</th>
<th>Real-World Issue</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Probabilities</td>
<td>Known and accurate</td>
<td>Often uncertain or subjective</td>
</tr>
<tr class="even">
<td>Utilities</td>
<td>Stable, numeric</td>
<td>Context-dependent, hard to elicit</td>
</tr>
<tr class="odd">
<td>Computation</td>
<td>Unlimited</td>
<td>Bounded resources, heuristics</td>
</tr>
<tr class="even">
<td>Behavior</td>
<td>Rational, consistent</td>
<td>Human biases, bounded rationality</td>
</tr>
</tbody>
</table>
</section>
<section id="tiny-code-76" class="level4">
<h4 class="anchored" data-anchor-id="tiny-code-76">Tiny Code</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Classical vs. behavioral decision</span></span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>lottery <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">100</span>]</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Classical: risk-neutral EU</span></span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a>EU_classical <span class="op">=</span> np.mean(lottery)</span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-10"><a href="#cb81-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Behavioral: overweight small probabilities (Prospect Theory-like)</span></span>
<span id="cb81-11"><a href="#cb81-11" aria-hidden="true" tabindex="-1"></a>weight <span class="op">=</span> <span class="kw">lambda</span> p: p0<span class="fl">.7</span> <span class="op">/</span> (p0<span class="fl">.7</span> <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>p)<span class="fl">0.7</span>)(<span class="dv">1</span><span class="op">/</span><span class="fl">0.7</span>)</span>
<span id="cb81-12"><a href="#cb81-12" aria-hidden="true" tabindex="-1"></a>EU_behavioral <span class="op">=</span> weight(p)<span class="op">*</span><span class="dv">100</span> <span class="op">+</span> weight(<span class="dv">1</span><span class="op">-</span>p)<span class="op">*</span><span class="dv">0</span></span>
<span id="cb81-13"><a href="#cb81-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-14"><a href="#cb81-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classical EU:"</span>, EU_classical)</span>
<span id="cb81-15"><a href="#cb81-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Behavioral EU (distorted):"</span>, EU_behavioral)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-79" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-79">Why It Matters</h4>
<p>Understanding limitations prevents over-reliance on idealized models. Modern AI integrates approximate inference, heuristic planning, and human-centered models of utility to handle uncertainty, complexity, and human-like decision behavior.</p>
</section>
<section id="try-it-yourself-79" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-79">Try It Yourself</h4>
<ol type="1">
<li>Define a decision problem where probabilities are unknown—how would you act with limited knowledge?</li>
<li>Compare choices under classical expected utility vs.&nbsp;prospect theory.</li>
<li>Reflect: why is it dangerous for AI in finance or healthcare to assume perfect rationality?</li>
</ol>
</section>
</section>
</section>
<section id="chapter-59.-probabilistic-programming-languages" class="level2">
<h2 class="anchored" data-anchor-id="chapter-59.-probabilistic-programming-languages">Chapter 59. Probabilistic Programming Languages</h2>
<section id="motivation-for-probabilistic-programming" class="level3">
<h3 class="anchored" data-anchor-id="motivation-for-probabilistic-programming">581. Motivation for Probabilistic Programming</h3>
<p>Probabilistic Programming Languages (PPLs) aim to make probabilistic modeling and inference as accessible as traditional programming. Instead of handcrafting inference algorithms for every model, a PPL lets you <em>write down the generative model</em> and automatically handles inference under the hood.</p>
<section id="picture-in-your-head-80" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-80">Picture in Your Head</h4>
<p>Think of a cooking recipe: you specify ingredients and steps, but you don’t need to reinvent ovens or stoves each time. Similarly, in a PPL you describe random variables, dependencies, and observations; the system “cooks” by running inference automatically.</p>
</section>
<section id="deep-dive-80" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-80">Deep Dive</h4>
<ul>
<li><p>Traditional approach (before PPLs):</p>
<ul>
<li>Define model (priors, likelihoods).</li>
<li>Derive inference algorithm (e.g., Gibbs sampling, variational inference).</li>
<li>Implement inference code by hand.</li>
<li>Very time-consuming and error-prone.</li>
</ul></li>
<li><p>Probabilistic programming approach:</p>
<ul>
<li>Write model as a program with random variables.</li>
<li>Condition on observed data.</li>
<li>Let the runtime system choose or optimize inference strategy.</li>
</ul></li>
<li><p>Benefits:</p>
<ul>
<li>Abstraction: separate model specification from inference.</li>
<li>Reusability: same inference engine works across many models.</li>
<li>Accessibility: practitioners can focus on modeling, not algorithms.</li>
<li>Flexibility: supports Bayesian methods, deep generative models, causal inference.</li>
</ul></li>
<li><p>Core workflow:</p>
<ol type="1">
<li>Define prior distributions over unknowns.</li>
<li>Define likelihood of observed data.</li>
<li>Run inference engine (MCMC, SVI, etc.).</li>
<li>Inspect posterior distributions.</li>
</ol></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 49%">
</colgroup>
<thead>
<tr class="header">
<th>Traditional Bayesian Workflow</th>
<th>Probabilistic Programming Workflow</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Manually derive inference equations</td>
<td>Write model as a program</td>
</tr>
<tr class="even">
<td>Hand-code sampling or optimization</td>
<td>Use built-in inference engine</td>
</tr>
<tr class="odd">
<td>Error-prone, model-specific</td>
<td>General, reusable, automatic</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Pyro - Python PPL)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro.distributions <span class="im">as</span> dist</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyro.infer <span class="im">import</span> MCMC, NUTS</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> coin_model(data):</span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> pyro.sample(<span class="st">"p"</span>, dist.Beta(<span class="dv">1</span>,<span class="dv">1</span>))  <span class="co"># prior on bias</span></span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, obs <span class="kw">in</span> <span class="bu">enumerate</span>(data):</span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a>        pyro.sample(<span class="ss">f"obs_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span>, dist.Bernoulli(p), obs<span class="op">=</span>obs)</span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-10"><a href="#cb82-10" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [<span class="fl">1.</span>, <span class="fl">0.</span>, <span class="fl">1.</span>, <span class="fl">1.</span>, <span class="fl">0.</span>, <span class="fl">1.</span>]  <span class="co"># coin flips</span></span>
<span id="cb82-11"><a href="#cb82-11" aria-hidden="true" tabindex="-1"></a>nuts_kernel <span class="op">=</span> NUTS(coin_model)</span>
<span id="cb82-12"><a href="#cb82-12" aria-hidden="true" tabindex="-1"></a>mcmc <span class="op">=</span> MCMC(nuts_kernel, num_samples<span class="op">=</span><span class="dv">500</span>, warmup_steps<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb82-13"><a href="#cb82-13" aria-hidden="true" tabindex="-1"></a>mcmc.run(data)</span>
<span id="cb82-14"><a href="#cb82-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mcmc.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-80" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-80">Why It Matters</h4>
<p>PPLs democratize Bayesian modeling, letting researchers, data scientists, and engineers rapidly build and test probabilistic models without needing expertise in custom inference algorithms. This accelerates progress in AI, statistics, and applied sciences.</p>
</section>
<section id="try-it-yourself-80" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-80">Try It Yourself</h4>
<ol type="1">
<li>Write a probabilistic program for estimating the probability of rain given umbrella sightings.</li>
<li>Compare the same model implemented in two PPLs (e.g., PyMC vs.&nbsp;Stan).</li>
<li>Reflect: how does separating model specification from inference change the way we approach AI modeling?</li>
</ol>
</section>
</section>
<section id="declarative-vs.-generative-models" class="level3">
<h3 class="anchored" data-anchor-id="declarative-vs.-generative-models">582. Declarative vs.&nbsp;Generative Models</h3>
<p>Probabilistic programs can be written in two complementary styles: declarative models, which describe the <em>statistical structure</em> of a problem, and generative models, which describe how data is produced step by step. Both capture uncertainty, but they differ in perspective and practical use.</p>
<section id="picture-in-your-head-81" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-81">Picture in Your Head</h4>
<p>Imagine you’re explaining a murder mystery:</p>
<ul>
<li>Generative style: “First, the butler chooses a weapon at random, then decides whether to act, and finally we observe the crime scene.”</li>
<li>Declarative style: “The probability of a crime scene depends on who the culprit is, what weapon is used, and whether they acted.” Both tell the same story, but from different directions.</li>
</ul>
</section>
<section id="deep-dive-81" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-81">Deep Dive</h4>
<ul>
<li><p>Generative models:</p>
<ul>
<li>Define a stochastic process for producing data.</li>
<li>Explicit sampling steps describe the world’s dynamics.</li>
<li>Example: latent variable models (HMMs, VAEs).</li>
<li>Code often looks like: <em>sample latent → sample observation</em>.</li>
</ul></li>
<li><p>Declarative models:</p>
<ul>
<li>Define a joint distribution over all variables.</li>
<li>Specify relationships via factorization or constraints.</li>
<li>Inference is about computing conditional probabilities.</li>
<li>Example: graphical models, factor graphs, Markov logic.</li>
</ul></li>
<li><p>In practice:</p>
<ul>
<li>PPLs often support both—write a generative process, and inference engines handle declarative conditioning.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 9%">
<col style="width: 30%">
<col style="width: 30%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th>Style</th>
<th>Strength</th>
<th>Weakness</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Generative</td>
<td>Natural, intuitive, easy to simulate</td>
<td>Harder to specify global constraints</td>
<td>HMM, VAE</td>
</tr>
<tr class="even">
<td>Declarative</td>
<td>Compact, emphasizes dependencies</td>
<td>Less intuitive for sampling</td>
<td>Factor graphs, Markov logic networks</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (PyMC - Declarative)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> pm.Beta(<span class="st">"p"</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>    obs <span class="op">=</span> pm.Bernoulli(<span class="st">"obs"</span>, p, observed<span class="op">=</span>[<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>    trace <span class="op">=</span> pm.sample(<span class="dv">1000</span>, tune<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pm.summary(trace))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Tiny Code Recipe (Pyro - Generative)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro, pyro.distributions <span class="im">as</span> dist</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> coin_model(data):</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> pyro.sample(<span class="st">"p"</span>, dist.Beta(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, obs <span class="kw">in</span> <span class="bu">enumerate</span>(data):</span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>        pyro.sample(<span class="ss">f"obs_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span>, dist.Bernoulli(p), obs<span class="op">=</span>obs)</span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [<span class="fl">1.</span>,<span class="fl">0.</span>,<span class="fl">1.</span>,<span class="fl">1.</span>,<span class="fl">0.</span>,<span class="fl">1.</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-81" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-81">Why It Matters</h4>
<p>The declarative vs.&nbsp;generative distinction affects how we think about models: declarative for clean probabilistic relationships, generative for simulation and data synthesis. Modern AI blends both styles, as in deep generative models with declarative inference.</p>
</section>
<section id="try-it-yourself-81" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-81">Try It Yourself</h4>
<ol type="1">
<li>Write a generative program for rolling a biased die.</li>
<li>Write the same die model declaratively as a probability table.</li>
<li>Reflect: which style feels more natural for you, and why might one be better for inference vs.&nbsp;simulation?</li>
</ol>
</section>
</section>
<section id="key-languages-and-frameworks-overview" class="level3">
<h3 class="anchored" data-anchor-id="key-languages-and-frameworks-overview">583. Key Languages and Frameworks (overview)</h3>
<p>Over the past two decades, several probabilistic programming languages (PPLs) and frameworks have emerged, each balancing expressivity, efficiency, and ease of use. They differ in whether they emphasize general-purpose programming with probability as an extension, or domain-specific modeling with strong inference support.</p>
<section id="picture-in-your-head-82" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-82">Picture in Your Head</h4>
<p>Think of PPLs as different kinds of kitchens:</p>
<ul>
<li>Some give you a fully equipped chef’s kitchen (flexible, but complex).</li>
<li>Others give you a specialized bakery setup (less flexible, but optimized for certain tasks). Both let you “cook with uncertainty,” but in different ways.</li>
</ul>
</section>
<section id="deep-dive-82" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-82">Deep Dive</h4>
<ul>
<li><p>Stan</p>
<ul>
<li>Domain-specific language for statistical modeling.</li>
<li>Declarative style: you specify priors, likelihoods, parameters.</li>
<li>Powerful inference: Hamiltonian Monte Carlo (NUTS).</li>
<li>Widely used in statistics and applied sciences.</li>
</ul></li>
<li><p>PyMC (PyMC3, PyMC v4)</p>
<ul>
<li>Python-based, declarative PPL.</li>
<li>Integrates well with NumPy, pandas, ArviZ.</li>
<li>Strong community and focus on Bayesian data analysis.</li>
</ul></li>
<li><p>Edward (now TensorFlow Probability)</p>
<ul>
<li>Embedded in TensorFlow.</li>
<li>Combines declarative probabilistic modeling with deep learning.</li>
<li>Useful for hybrid neural + probabilistic systems.</li>
</ul></li>
<li><p>Pyro (Uber AI)</p>
<ul>
<li>Built on PyTorch.</li>
<li>Emphasizes generative modeling and variational inference.</li>
<li>Deep PPL for combining probabilistic reasoning with modern deep nets.</li>
</ul></li>
<li><p>NumPyro</p>
<ul>
<li>Pyro reimplemented on JAX.</li>
<li>Much faster inference (via XLA compilation).</li>
<li>Lighter weight, but less feature-rich than Pyro.</li>
</ul></li>
<li><p>Turing.jl (Julia)</p>
<ul>
<li>General-purpose PPL embedded in Julia.</li>
<li>Flexible inference: MCMC, variational, SMC.</li>
<li>Benefits from Julia’s performance and composability.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 21%">
<col style="width: 26%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Framework</th>
<th>Language Base</th>
<th>Style</th>
<th>Strengths</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Stan</td>
<td>Custom DSL</td>
<td>Declarative</td>
<td>Gold standard for Bayesian inference</td>
</tr>
<tr class="even">
<td>PyMC</td>
<td>Python</td>
<td>Declarative</td>
<td>Easy for statisticians, rich ecosystem</td>
</tr>
<tr class="odd">
<td>Pyro</td>
<td>Python (PyTorch)</td>
<td>Generative</td>
<td>Deep learning + probabilistic</td>
</tr>
<tr class="even">
<td>NumPyro</td>
<td>Python (JAX)</td>
<td>Generative</td>
<td>High speed, scalability</td>
</tr>
<tr class="odd">
<td>Turing.jl</td>
<td>Julia</td>
<td>Mixed</td>
<td>Performance + flexibility</td>
</tr>
<tr class="even">
<td>TFP</td>
<td>Python (TensorFlow)</td>
<td>Declarative + Generative</td>
<td>Neural/probabilistic hybrids</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Stan)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb85"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N;</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>,<span class="kw">upper</span>=<span class="dv">1</span>&gt; y[N];</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>,<span class="kw">upper</span>=<span class="dv">1</span>&gt; theta;</span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a>  theta ~ beta(<span class="dv">1</span>,<span class="dv">1</span>);</span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a>  y ~ bernoulli(theta);</span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-82" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-82">Why It Matters</h4>
<p>Knowing the PPL landscape helps researchers and practitioners choose the right tool: statisticians might favor Stan/PyMC, while AI/ML practitioners prefer Pyro/NumPyro/TFP for integration with neural nets.</p>
</section>
<section id="try-it-yourself-82" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-82">Try It Yourself</h4>
<ol type="1">
<li>Write the same coin-flip model in Stan, PyMC, and Pyro. Compare readability.</li>
<li>Benchmark inference speed between Pyro and NumPyro.</li>
<li>Reflect: when would you choose a DSL like Stan vs.&nbsp;a flexible embedded PPL like Pyro?</li>
</ol>
</section>
</section>
<section id="sampling-semantics-of-probabilistic-programs" class="level3">
<h3 class="anchored" data-anchor-id="sampling-semantics-of-probabilistic-programs">584. Sampling Semantics of Probabilistic Programs</h3>
<p>At the core of probabilistic programming is the idea that a program defines a probability distribution. Running the program corresponds to sampling from that distribution. Conditioning on observed data transforms the program from a generator of samples into a machine for inference.</p>
<section id="picture-in-your-head-83" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-83">Picture in Your Head</h4>
<p>Imagine a slot machine where each lever pull corresponds to running your probabilistic program. Each spin yields a different random outcome, and over many runs, you build up the distribution of possible results. Adding observations is like fixing some reels and asking: <em>what do the unseen reels look like, given what I know?</em></p>
</section>
<section id="deep-dive-83" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-83">Deep Dive</h4>
<ul>
<li><p>Generative view:</p>
<ul>
<li>Each call to <code>sample</code> introduces randomness.</li>
<li>The program execution defines a joint probability distribution over all random choices.</li>
</ul></li>
<li><p>Formal semantics:</p>
<ul>
<li>Program = stochastic function.</li>
<li>A run yields one trace (sequence of random draws).</li>
<li>The set of all traces defines the distribution.</li>
</ul></li>
<li><p>Conditioning (observations):</p>
<ul>
<li><p>Using <code>observe</code> or <code>factor</code> statements, you constrain execution paths.</p></li>
<li><p>Posterior distribution over latent variables:</p>
<p><span class="math display">\[
P(z \mid x) \propto P(z, x)
\]</span></p></li>
</ul></li>
<li><p>Inference engines:</p>
<ul>
<li>MCMC, SMC, Variational Inference approximate posterior.</li>
<li>Program semantics stay the same—only inference method changes.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 27%">
<col style="width: 52%">
</colgroup>
<thead>
<tr class="header">
<th>Operation</th>
<th>Semantics</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>sample</code></td>
<td>Draw random variable</td>
<td>Flip a coin</td>
</tr>
<tr class="even">
<td><code>observe</code></td>
<td>Condition on data</td>
<td>See that a coin landed heads</td>
</tr>
<tr class="odd">
<td>Execution trace</td>
<td>One run of program</td>
<td>Sequence: p ~ Beta, x ~ Bernoulli(p)</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Pyro)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro, pyro.distributions <span class="im">as</span> dist</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> coin_model():</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> pyro.sample(<span class="st">"p"</span>, dist.Beta(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>    flip1 <span class="op">=</span> pyro.sample(<span class="st">"flip1"</span>, dist.Bernoulli(p))</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>    flip2 <span class="op">=</span> pyro.sample(<span class="st">"flip2"</span>, dist.Bernoulli(p))</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> flip1, flip2</span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Run multiple traces (sampling semantics)</span></span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(coin_model())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Conditioning Example</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> coin_model_with_obs(data):</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> pyro.sample(<span class="st">"p"</span>, dist.Beta(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, obs <span class="kw">in</span> <span class="bu">enumerate</span>(data):</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>        pyro.sample(<span class="ss">f"obs_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span>, dist.Bernoulli(p), obs<span class="op">=</span>obs)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-83" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-83">Why It Matters</h4>
<p>Sampling semantics unify programming and probability theory. They allow us to treat probabilistic programs as compact specifications of distributions, enabling flexible modeling and automatic inference.</p>
</section>
<section id="try-it-yourself-83" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-83">Try It Yourself</h4>
<ol type="1">
<li>Write a probabilistic program that rolls two dice and conditions on their sum being 7.</li>
<li>Run it repeatedly and observe the posterior distribution of each die.</li>
<li>Reflect: how does the notion of an execution trace help explain why inference can be difficult?</li>
</ol>
</section>
</section>
<section id="automatic-inference-engines" class="level3">
<h3 class="anchored" data-anchor-id="automatic-inference-engines">585. Automatic Inference Engines</h3>
<p>One of the most powerful features of probabilistic programming is that you write the model, and the system figures out how to perform inference. Automatic inference engines separate model specification from inference algorithms, letting practitioners focus on describing uncertainty instead of hand-coding samplers.</p>
<section id="picture-in-your-head-84" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-84">Picture in Your Head</h4>
<p>Think of a calculator: you enter an equation, and it automatically runs the correct sequence of multiplications, divisions, and powers. Similarly, in a PPL, you describe your probabilistic model, and the inference engine decides whether to run MCMC, variational inference, or another method to compute posteriors.</p>
</section>
<section id="deep-dive-84" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-84">Deep Dive</h4>
<ul>
<li><p>Types of automatic inference:</p>
<ol type="1">
<li><p>Sampling-based (exact in the limit):</p>
<ul>
<li>MCMC: Gibbs sampling, Metropolis–Hastings, HMC, NUTS.</li>
<li>Pros: asymptotically correct, flexible.</li>
<li>Cons: slow, can have convergence issues.</li>
</ul></li>
<li><p>Optimization-based (approximate):</p>
<ul>
<li>Variational Inference (VI): optimize a simpler distribution <span class="math inline">\(q(z)\)</span> to approximate <span class="math inline">\(p(z \mid x)\)</span>.</li>
<li>Pros: faster, scalable.</li>
<li>Cons: biased approximation, quality depends on chosen family.</li>
</ul></li>
<li><p>Hybrid methods:</p>
<ul>
<li>Sequential Monte Carlo (SMC).</li>
<li>Stochastic Variational Inference (SVI).</li>
</ul></li>
</ol></li>
<li><p>Declarative power:</p>
<ul>
<li>The same model can be paired with different inference engines without rewriting it.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 35%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="header">
<th>Engine Type</th>
<th>Method</th>
<th>Example Use</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sampling</td>
<td>MCMC, HMC, NUTS</td>
<td>Small/medium models, need accuracy</td>
</tr>
<tr class="even">
<td>Optimization</td>
<td>Variational Inference, SVI</td>
<td>Large-scale, deep generative models</td>
</tr>
<tr class="odd">
<td>Hybrid</td>
<td>SMC, particle VI</td>
<td>Sequential models, time series</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (PyMC – automatic inference)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> pm.Beta(<span class="st">"p"</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a>    obs <span class="op">=</span> pm.Bernoulli(<span class="st">"obs"</span>, p, observed<span class="op">=</span>[<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a>    trace <span class="op">=</span> pm.sample(<span class="dv">1000</span>, tune<span class="op">=</span><span class="dv">500</span>)   <span class="co"># automatically selects NUTS</span></span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pm.summary(trace))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Tiny Code Recipe (Pyro – switching engines)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro, pyro.distributions <span class="im">as</span> dist</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyro.infer <span class="im">import</span> MCMC, NUTS, SVI, Trace_ELBO</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro.optim <span class="im">as</span> optim</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> coin_model(data):</span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> pyro.sample(<span class="st">"p"</span>, dist.Beta(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, obs <span class="kw">in</span> <span class="bu">enumerate</span>(data):</span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a>        pyro.sample(<span class="ss">f"obs_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span>, dist.Bernoulli(p), obs<span class="op">=</span>obs)</span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [<span class="fl">1.</span>,<span class="fl">0.</span>,<span class="fl">1.</span>,<span class="fl">1.</span>,<span class="fl">0.</span>,<span class="fl">1.</span>]</span>
<span id="cb89-11"><a href="#cb89-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-12"><a href="#cb89-12" aria-hidden="true" tabindex="-1"></a><span class="co"># MCMC (HMC/NUTS)</span></span>
<span id="cb89-13"><a href="#cb89-13" aria-hidden="true" tabindex="-1"></a>nuts <span class="op">=</span> NUTS(coin_model)</span>
<span id="cb89-14"><a href="#cb89-14" aria-hidden="true" tabindex="-1"></a>mcmc <span class="op">=</span> MCMC(nuts, num_samples<span class="op">=</span><span class="dv">500</span>, warmup_steps<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb89-15"><a href="#cb89-15" aria-hidden="true" tabindex="-1"></a>mcmc.run(data)</span>
<span id="cb89-16"><a href="#cb89-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-17"><a href="#cb89-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Variational Inference</span></span>
<span id="cb89-18"><a href="#cb89-18" aria-hidden="true" tabindex="-1"></a>guide <span class="op">=</span> <span class="kw">lambda</span> data: pyro.sample(<span class="st">"p"</span>, dist.Beta(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb89-19"><a href="#cb89-19" aria-hidden="true" tabindex="-1"></a>svi <span class="op">=</span> SVI(coin_model, guide, optim.Adam({<span class="st">"lr"</span>:<span class="fl">0.01</span>}), loss<span class="op">=</span>Trace_ELBO())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-84" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-84">Why It Matters</h4>
<p>Automatic inference engines are the democratizing force of PPLs. They let domain experts (biologists, economists, engineers) build Bayesian models without needing to master advanced sampling or optimization methods.</p>
</section>
<section id="try-it-yourself-84" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-84">Try It Yourself</h4>
<ol type="1">
<li>Write a simple coin-flip model and run it under both MCMC and VI. Compare results.</li>
<li>Experiment with scaling the model to 10,000 observations. Which inference method works better?</li>
<li>Reflect: how does abstraction of inference change the role of the modeler?</li>
</ol>
</section>
</section>
<section id="expressivity-vs.-tractability-tradeoffs" class="level3">
<h3 class="anchored" data-anchor-id="expressivity-vs.-tractability-tradeoffs">586. Expressivity vs.&nbsp;Tractability Tradeoffs</h3>
<p>Probabilistic programming languages aim to let us express rich, flexible models while still enabling tractable inference. However, there is an unavoidable tension: the more expressive the modeling language, the harder inference becomes. Balancing this tradeoff is a central challenge in PPL design.</p>
<section id="picture-in-your-head-85" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-85">Picture in Your Head</h4>
<p>Think of a Swiss Army knife: the more tools you add, the bulkier and harder to use it becomes. Similarly, as you allow arbitrary control flow, recursion, and continuous distributions in a probabilistic program, inference can become computationally intractable.</p>
</section>
<section id="deep-dive-85" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-85">Deep Dive</h4>
<ul>
<li><p>Expressivity dimensions:</p>
<ul>
<li>Support for arbitrary stochastic control flow.</li>
<li>Rich prior distributions (nonparametric models, stochastic processes).</li>
<li>Nested or recursive probabilistic programs.</li>
<li>Integration with deep learning for neural likelihoods.</li>
</ul></li>
<li><p>Inference bottlenecks:</p>
<ul>
<li>Exact inference becomes impossible in highly expressive models.</li>
<li>Sampling may converge too slowly.</li>
<li>Variational inference may fail if approximating family is too limited.</li>
</ul></li>
<li><p>Design strategies:</p>
<ul>
<li>Restrict expressivity: e.g., Stan disallows stochastic control flow for efficient inference.</li>
<li>Approximate inference: accept approximate answers (VI, MCMC truncations).</li>
<li>Compositional inference: tailor inference strategies to model structure.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 27%">
<col style="width: 23%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Approach</th>
<th>Expressivity</th>
<th>Inference Tractability</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Stan</td>
<td>Limited (no stochastic loops)</td>
<td>High (HMC/NUTS efficient)</td>
<td>Statistical models</td>
</tr>
<tr class="even">
<td>Pyro / Turing</td>
<td>High (arbitrary control flow)</td>
<td>Lower (need VI or SMC)</td>
<td>Deep generative models</td>
</tr>
<tr class="odd">
<td>TensorFlow Probability</td>
<td>Medium</td>
<td>Moderate</td>
<td>Neural + probabilistic hybrids</td>
</tr>
</tbody>
</table>
<p>Tiny Code Illustration</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pyro example: expressive but harder to infer</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro, pyro.distributions <span class="im">as</span> dist</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> branching_model():</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> pyro.sample(<span class="st">"p"</span>, dist.Beta(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> pyro.sample(<span class="st">"n"</span>, dist.Poisson(<span class="dv">3</span>))</span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">int</span>(n)):</span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a>        pyro.sample(<span class="ss">f"x_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span>, dist.Bernoulli(p))</span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a><span class="co"># This program allows stochastic loops -&gt; very expressive</span></span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a><span class="co"># But inference requires approximation (e.g., SVI or particle methods).</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-85" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-85">Why It Matters</h4>
<p>This tradeoff explains why no single PPL dominates all domains. Statisticians may prefer restricted but efficient frameworks (Stan), while AI researchers use expressive PPLs (Pyro, Turing) that support deep learning but require approximate inference.</p>
</section>
<section id="try-it-yourself-85" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-85">Try It Yourself</h4>
<ol type="1">
<li>Write the same Bayesian linear regression in Stan and Pyro. Compare ease of inference.</li>
<li>Create a probabilistic program with a random loop bound—observe why inference becomes harder.</li>
<li>Reflect: how much expressivity do you really need for your application, and what inference cost are you willing to pay?</li>
</ol>
</section>
</section>
<section id="applications-in-ai-research" class="level3">
<h3 class="anchored" data-anchor-id="applications-in-ai-research">587. Applications in AI Research</h3>
<p>Probabilistic programming has become a powerful tool for AI research, enabling rapid prototyping of models that combine uncertainty, structure, and learning. By abstracting away the inference details, researchers can focus on building novel probabilistic models for perception, reasoning, and decision-making.</p>
<section id="picture-in-your-head-86" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-86">Picture in Your Head</h4>
<p>Think of a research lab where scientists can sketch a new model on a whiteboard in the morning and test it in code by afternoon—without spending weeks writing custom inference algorithms. Probabilistic programming makes this workflow possible.</p>
</section>
<section id="deep-dive-86" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-86">Deep Dive</h4>
<ul>
<li><p>Generative modeling:</p>
<ul>
<li>Variational Autoencoders (VAEs) and deep generative models expressed naturally as probabilistic programs.</li>
<li>Hybrid neural–probabilistic systems (e.g., Deep Kalman Filters).</li>
</ul></li>
<li><p>Causal inference:</p>
<ul>
<li>Structural causal models (SCMs) and counterfactual reasoning implemented directly.</li>
<li>PPLs allow explicit modeling of interventions and causal graphs.</li>
</ul></li>
<li><p>Reasoning under uncertainty:</p>
<ul>
<li>Probabilistic logical models expressed via PPLs (e.g., Markov logic).</li>
<li>Combines symbolic structure with probabilistic semantics.</li>
</ul></li>
<li><p>Reinforcement learning:</p>
<ul>
<li>Model-based RL benefits from Bayesian modeling of dynamics.</li>
<li>PPLs let researchers express uncertainty over environments and policies.</li>
</ul></li>
<li><p>Meta-learning and program induction:</p>
<ul>
<li>Bayesian program learning (BPL): learning new concepts by composing probabilistic primitives.</li>
<li>PPLs enable models that learn like humans—few-shot, structured, compositional.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 50%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="header">
<th>Research Area</th>
<th>PPL Contribution</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Generative models</td>
<td>Automatic VI for deep probabilistic models</td>
<td>VAE, DKF</td>
</tr>
<tr class="even">
<td>Causality</td>
<td>Encode SCMs, do-calculus, interventions</td>
<td>Counterfactual queries</td>
</tr>
<tr class="odd">
<td>Symbolic AI</td>
<td>Probabilistic logic integration</td>
<td>Probabilistic Prolog</td>
</tr>
<tr class="even">
<td>RL</td>
<td>Bayesian world models</td>
<td>Model-based RL</td>
</tr>
<tr class="odd">
<td>Program induction</td>
<td>Learning from few examples</td>
<td>Bayesian Program Learning</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Pyro – VAE sketch)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro, pyro.distributions <span class="im">as</span> dist</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> VAE(nn.Module):</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, z_dim<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoder <span class="op">=</span> nn.Linear(<span class="dv">784</span>, z_dim<span class="op">*</span><span class="dv">2</span>)  <span class="co"># mean+logvar</span></span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.decoder <span class="op">=</span> nn.Linear(z_dim, <span class="dv">784</span>)</span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> model(<span class="va">self</span>, x):</span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> pyro.sample(<span class="st">"z"</span>, dist.Normal(<span class="dv">0</span>,<span class="dv">1</span>).expand([<span class="dv">2</span>]).to_event(<span class="dv">1</span>))</span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a>        x_hat <span class="op">=</span> <span class="va">self</span>.decoder(z)</span>
<span id="cb91-13"><a href="#cb91-13" aria-hidden="true" tabindex="-1"></a>        pyro.sample(<span class="st">"obs"</span>, dist.Bernoulli(logits<span class="op">=</span>x_hat).to_event(<span class="dv">1</span>), obs<span class="op">=</span>x)</span>
<span id="cb91-14"><a href="#cb91-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-15"><a href="#cb91-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> guide(<span class="va">self</span>, x):</span>
<span id="cb91-16"><a href="#cb91-16" aria-hidden="true" tabindex="-1"></a>        stats <span class="op">=</span> <span class="va">self</span>.encoder(x)</span>
<span id="cb91-17"><a href="#cb91-17" aria-hidden="true" tabindex="-1"></a>        mu, logvar <span class="op">=</span> stats.chunk(<span class="dv">2</span>, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb91-18"><a href="#cb91-18" aria-hidden="true" tabindex="-1"></a>        pyro.sample(<span class="st">"z"</span>, dist.Normal(mu, (<span class="fl">0.5</span><span class="op">*</span>logvar).exp()).to_event(<span class="dv">1</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-86" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-86">Why It Matters</h4>
<p>PPLs accelerate research by letting scientists explore new probabilistic ideas quickly. They close the gap between theory and implementation, making it easier to test novel AI approaches in practice.</p>
</section>
<section id="try-it-yourself-86" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-86">Try It Yourself</h4>
<ol type="1">
<li>Implement a simple causal graph in a PPL and perform an intervention (<code>do(X=x)</code>).</li>
<li>Write a Bayesian linear regression in both PyMC and Pyro—compare flexibility vs.&nbsp;ease.</li>
<li>Reflect: why does separating inference from modeling accelerate innovation in AI research?</li>
</ol>
</section>
</section>
<section id="industrial-and-scientific-case-studies" class="level3">
<h3 class="anchored" data-anchor-id="industrial-and-scientific-case-studies">588. Industrial and Scientific Case Studies</h3>
<p>Probabilistic programming is not just for academia—it has proven valuable in industry and science, where uncertainty is pervasive. From drug discovery to fraud detection, PPLs enable practitioners to model complex systems, quantify uncertainty, and make better decisions.</p>
<section id="picture-in-your-head-87" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-87">Picture in Your Head</h4>
<p>Imagine three settings: a pharma company estimating drug efficacy from noisy clinical trials, a bank detecting fraud in massive transaction streams, and a climate lab modeling global temperature dynamics. Each problem has uncertainty, hidden variables, and limited data—perfect candidates for probabilistic programming.</p>
</section>
<section id="deep-dive-87" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-87">Deep Dive</h4>
<ul>
<li><p>Healthcare &amp; Biomedicine:</p>
<ul>
<li>Clinical trial analysis with hierarchical Bayesian models.</li>
<li>Genomic data modeling with hidden variables.</li>
<li>Drug response prediction under uncertainty.</li>
</ul></li>
<li><p>Finance &amp; Economics:</p>
<ul>
<li>Credit risk modeling with Bayesian networks.</li>
<li>Fraud detection via anomaly detection in probabilistic frameworks.</li>
<li>Economic forecasting using state-space models.</li>
</ul></li>
<li><p>Climate Science &amp; Physics:</p>
<ul>
<li>Bayesian calibration of climate models.</li>
<li>Probabilistic weather forecasting (ensembles, uncertainty quantification).</li>
<li>Astrophysics: modeling dark matter distribution from telescope data.</li>
</ul></li>
<li><p>Industrial Applications:</p>
<ul>
<li>Manufacturing: anomaly detection in production lines.</li>
<li>Recommendation systems: Bayesian matrix factorization.</li>
<li>Robotics: localization and mapping under uncertainty.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 25%">
<col style="width: 36%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Domain</th>
<th>Application</th>
<th>Probabilistic Programming Role</th>
<th>Example Framework</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Healthcare</td>
<td>Clinical trials</td>
<td>Hierarchical Bayesian modeling</td>
<td>Stan, PyMC</td>
</tr>
<tr class="even">
<td>Finance</td>
<td>Fraud detection</td>
<td>Probabilistic anomaly detection</td>
<td>Pyro, TFP</td>
</tr>
<tr class="odd">
<td>Climate science</td>
<td>Model calibration</td>
<td>Uncertainty quantification</td>
<td>Stan, Turing.jl</td>
</tr>
<tr class="even">
<td>Manufacturing</td>
<td>Predictive maintenance</td>
<td>Latent failure models</td>
<td>NumPyro</td>
</tr>
<tr class="odd">
<td>Robotics</td>
<td>SLAM</td>
<td>Sequential inference</td>
<td>Pyro, Turing</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Stan – Hierarchical Clinical Trial Model)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb92"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N;</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>,<span class="kw">upper</span>=<span class="dv">1</span>&gt; y[N];</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; group[N];</span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; G;</span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[G] alpha;</span>
<span id="cb92-9"><a href="#cb92-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> mu_alpha;</span>
<span id="cb92-10"><a href="#cb92-10" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma_alpha;</span>
<span id="cb92-11"><a href="#cb92-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb92-12"><a href="#cb92-12" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb92-13"><a href="#cb92-13" aria-hidden="true" tabindex="-1"></a>  alpha ~ normal(mu_alpha, sigma_alpha);</span>
<span id="cb92-14"><a href="#cb92-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N)</span>
<span id="cb92-15"><a href="#cb92-15" aria-hidden="true" tabindex="-1"></a>    y[n] ~ bernoulli_logit(alpha[group[n]]);</span>
<span id="cb92-16"><a href="#cb92-16" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-87" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-87">Why It Matters</h4>
<p>Probabilistic programming bridges the gap between domain expertise and advanced inference methods. It lets practitioners focus on modeling real-world processes while relying on robust inference engines to handle complexity.</p>
</section>
<section id="try-it-yourself-87" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-87">Try It Yourself</h4>
<ol type="1">
<li>Build a hierarchical Bayesian model for A/B testing in marketing.</li>
<li>Write a simple fraud detection model using Pyro with latent “fraudulent vs.&nbsp;normal” states.</li>
<li>Reflect: why do industries with high uncertainty and high stakes (healthcare, finance, climate) especially benefit from PPLs?</li>
</ol>
</section>
</section>
<section id="integration-with-deep-learning" class="level3">
<h3 class="anchored" data-anchor-id="integration-with-deep-learning">589. Integration with Deep Learning</h3>
<p>Probabilistic programming and deep learning complement each other. Deep learning excels at representation learning from large datasets, while probabilistic programming provides uncertainty quantification, interpretability, and principled reasoning under uncertainty. Integrating the two yields models that are both expressive and trustworthy.</p>
<section id="picture-in-your-head-88" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-88">Picture in Your Head</h4>
<p>Think of deep nets as powerful “feature extractors” (like microscopes for raw data) and probabilistic models as “reasoning engines” (weighing evidence, uncertainty, and structure). Together, they form systems that both <em>see</em> and <em>reason</em>.</p>
</section>
<section id="deep-dive-88" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-88">Deep Dive</h4>
<ul>
<li><p>Why integration matters:</p>
<ul>
<li>Deep nets: accurate but overconfident, data-hungry.</li>
<li>Probabilistic models: interpretable but limited in scale.</li>
<li>Fusion: scalable learning + uncertainty-aware reasoning.</li>
</ul></li>
<li><p>Integration patterns:</p>
<ol type="1">
<li>Deep priors: neural networks define priors or likelihood functions (e.g., Bayesian neural networks).</li>
<li>Amortized inference: neural networks approximate posterior distributions (e.g., VAEs).</li>
<li>Hybrid models: probabilistic state-space models with neural dynamics.</li>
<li>Deep probabilistic programming frameworks: Pyro, Edward2, NumPyro, TFP.</li>
</ol></li>
<li><p>Examples:</p>
<ul>
<li>Variational Autoencoders (VAE): deep encoder/decoder + latent variable probabilistic model.</li>
<li>Deep Kalman Filters (DKF): sequential probabilistic structure + deep neural transitions.</li>
<li>Bayesian Neural Networks (BNNs): weights treated as random variables, inference via VI/MCMC.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 49%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Integration Mode</th>
<th>Description</th>
<th>Example Framework</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Deep priors</td>
<td>NN defines distributions</td>
<td>Bayesian NN in Pyro</td>
</tr>
<tr class="even">
<td>Amortized inference</td>
<td>NN learns posterior mapping</td>
<td>VAE, CVAE</td>
</tr>
<tr class="odd">
<td>Hybrid models</td>
<td>Probabilistic backbone + NN dynamics</td>
<td>Deep Kalman Filter</td>
</tr>
<tr class="even">
<td>End-to-end</td>
<td>Unified probabilistic + neural engine</td>
<td>Pyro, TFP</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Pyro – Bayesian NN)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch, pyro, pyro.distributions <span class="im">as</span> dist</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> bayesian_nn(x):</span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> pyro.sample(<span class="st">"w"</span>, dist.Normal(torch.zeros(<span class="dv">1</span>, x.shape[<span class="dv">1</span>]), torch.ones(<span class="dv">1</span>, x.shape[<span class="dv">1</span>])))</span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> pyro.sample(<span class="st">"b"</span>, dist.Normal(<span class="fl">0.</span>, <span class="fl">1.</span>))</span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>    y_hat <span class="op">=</span> torch.matmul(x, w.T) <span class="op">+</span> b</span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>    pyro.sample(<span class="st">"obs"</span>, dist.Normal(y_hat, <span class="fl">1.0</span>), obs<span class="op">=</span>torch.randn(x.shape[<span class="dv">0</span>]))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-88" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-88">Why It Matters</h4>
<p>This integration addresses the trust gap in modern AI: deep learning provides accuracy, while probabilistic programming ensures uncertainty awareness and robustness. It underpins applications in healthcare, autonomous systems, and any high-stakes domain.</p>
</section>
<section id="try-it-yourself-88" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-88">Try It Yourself</h4>
<ol type="1">
<li>Implement a Bayesian linear regression with Pyro and compare it to a standard NN.</li>
<li>Train a small VAE in PyTorch and reinterpret it as a probabilistic program.</li>
<li>Reflect: how does uncertainty-aware deep learning change trust and deployment in real-world AI systems?</li>
</ol>
</section>
</section>
<section id="open-challenges-in-probabilistic-programming" class="level3">
<h3 class="anchored" data-anchor-id="open-challenges-in-probabilistic-programming">590. Open Challenges in Probabilistic Programming</h3>
<p>Despite rapid progress, probabilistic programming faces major open challenges in scalability, usability, and integration with modern AI. Solving these challenges is key to making PPLs as ubiquitous and reliable as deep learning frameworks.</p>
<section id="picture-in-your-head-89" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-89">Picture in Your Head</h4>
<p>Think of PPLs as powerful research labs: they contain incredible tools, but many are hard to use, slow to run, or limited to small projects. The challenge is to turn these labs into everyday toolkits—fast, user-friendly, and production-ready.</p>
</section>
<section id="deep-dive-89" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-89">Deep Dive</h4>
<ul>
<li><p>Scalability:</p>
<ul>
<li>Inference algorithms (MCMC, VI) often struggle with large datasets and high-dimensional models.</li>
<li>Need for distributed inference, GPU acceleration, and streaming data support.</li>
</ul></li>
<li><p>Expressivity vs.&nbsp;tractability:</p>
<ul>
<li>Allowing arbitrary stochastic control flow makes inference hard or intractable.</li>
<li>Research needed on compositional and modular inference strategies.</li>
</ul></li>
<li><p>Usability:</p>
<ul>
<li>Many PPLs require deep expertise in Bayesian stats and inference.</li>
<li>Better abstractions, visualization tools, and debugging aids are needed.</li>
</ul></li>
<li><p>Integration with deep learning:</p>
<ul>
<li>Hybrid models face optimization difficulties.</li>
<li>Bayesian deep learning still lags behind deterministic neural nets in performance.</li>
</ul></li>
<li><p>Evaluation and benchmarking:</p>
<ul>
<li>Lack of standard benchmarks for comparing models and inference engines.</li>
<li>Hard to measure tradeoffs between accuracy, scalability, and interpretability.</li>
</ul></li>
<li><p>Deployment and productionization:</p>
<ul>
<li>Few PPLs have mature deployment pipelines compared to TensorFlow or PyTorch.</li>
<li>Industry adoption slowed by inference cost and lack of tooling.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 27%">
<col style="width: 32%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th>Challenge</th>
<th>Current State</th>
<th>Future Direction</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Scalability</td>
<td>Struggles with large datasets</td>
<td>GPU/TPU acceleration, distributed VI</td>
</tr>
<tr class="even">
<td>Expressivity</td>
<td>Flexible but intractable</td>
<td>Modular, compositional inference</td>
</tr>
<tr class="odd">
<td>Usability</td>
<td>Steep learning curve</td>
<td>Higher-level APIs, visual debuggers</td>
</tr>
<tr class="even">
<td>Deep learning integration</td>
<td>Early-stage</td>
<td>Stable hybrid training methods</td>
</tr>
<tr class="odd">
<td>Deployment</td>
<td>Limited industry adoption</td>
<td>Production-grade toolchains</td>
</tr>
</tbody>
</table>
<p>Tiny Code Illustration (Pyro – scalability issue)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Bayesian logistic regression on large dataset</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro, pyro.distributions <span class="im">as</span> dist</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> logistic_model(x, y):</span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> pyro.sample(<span class="st">"w"</span>, dist.Normal(torch.zeros(x.shape[<span class="dv">1</span>]), torch.ones(x.shape[<span class="dv">1</span>])))</span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> pyro.sample(<span class="st">"b"</span>, dist.Normal(<span class="fl">0.</span>, <span class="fl">1.</span>))</span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a>    logits <span class="op">=</span> (x <span class="op">@</span> w) <span class="op">+</span> b</span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a>    pyro.sample(<span class="st">"obs"</span>, dist.Bernoulli(logits<span class="op">=</span>logits), obs<span class="op">=</span>y)</span>
<span id="cb94-10"><a href="#cb94-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-11"><a href="#cb94-11" aria-hidden="true" tabindex="-1"></a><span class="co"># For millions of rows, naive inference becomes prohibitively slow</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-89" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-89">Why It Matters</h4>
<p>These challenges define the next frontier for probabilistic programming. Overcoming them would make PPLs mainstream tools for machine learning, enabling AI systems that are interpretable, uncertainty-aware, and deployable at scale.</p>
</section>
<section id="try-it-yourself-89" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-89">Try It Yourself</h4>
<ol type="1">
<li>Attempt Bayesian inference on a dataset with 1M points—observe performance bottlenecks.</li>
<li>Compare inference results across Pyro, NumPyro, and Stan for the same model.</li>
<li>Reflect: what would it take for probabilistic programming to become as standard as PyTorch or TensorFlow in AI practice?</li>
</ol>
</section>
</section>
</section>
<section id="chapter-60.-calibration-uncertainty-quantification-reliability" class="level2">
<h2 class="anchored" data-anchor-id="chapter-60.-calibration-uncertainty-quantification-reliability">Chapter 60. Calibration, Uncertainty Quantification Reliability</h2>
<section id="what-is-calibration-reliability-diagrams" class="level3">
<h3 class="anchored" data-anchor-id="what-is-calibration-reliability-diagrams">591. What is Calibration? Reliability Diagrams</h3>
<p>Calibration measures how well a model’s predicted probabilities align with actual outcomes. A perfectly calibrated model’s 70% confidence predictions will be correct about 70% of the time. Reliability diagrams provide a visual way to evaluate calibration.</p>
<section id="picture-in-your-head-90" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-90">Picture in Your Head</h4>
<p>Imagine a weather forecaster: if they say “70% chance of rain” on 10 days, and it rains on exactly 7 of those days, their forecasts are well calibrated. If it rains on only 2 of those days, the forecaster is overconfident; if it rains on 9, they are underconfident.</p>
</section>
<section id="deep-dive-90" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-90">Deep Dive</h4>
<ul>
<li><p>Definition:</p>
<ul>
<li><p>A model is calibrated if predicted probability matches empirical frequency.</p></li>
<li><p>Formally:</p>
<p><span class="math display">\[
P(Y=1 \mid \hat{P}=p) = p
\]</span></p></li>
</ul></li>
<li><p>Reliability diagram:</p>
<ol type="1">
<li>Group predictions into probability bins (e.g., 0.0–0.1, 0.1–0.2, …).</li>
<li>For each bin, compute average predicted probability and observed frequency.</li>
<li>Plot predicted vs.&nbsp;actual accuracy.</li>
</ol></li>
<li><p>Interpretation:</p>
<ul>
<li>Perfect calibration → diagonal line.</li>
<li>Overconfidence → curve below diagonal.</li>
<li>Underconfidence → curve above diagonal.</li>
</ul></li>
<li><p>Metrics:</p>
<ul>
<li>Expected Calibration Error (ECE): average difference between confidence and accuracy.</li>
<li>Maximum Calibration Error (MCE): worst-case bin deviation.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Model</th>
<th>ECE (↓ better)</th>
<th>Calibration</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Logistic regression</td>
<td>0.02</td>
<td>Good</td>
</tr>
<tr class="even">
<td>Deep neural net (uncalibrated)</td>
<td>0.12</td>
<td>Overconfident</td>
</tr>
<tr class="odd">
<td>Deep net + temperature scaling</td>
<td>0.03</td>
<td>Improved</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, sklearn + matplotlib)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.calibration <span class="im">import</span> calibration_curve</span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a><span class="co"># True labels and predicted probabilities</span></span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> np.array([<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>])</span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a>y_prob <span class="op">=</span> np.array([<span class="fl">0.1</span>,<span class="fl">0.8</span>,<span class="fl">0.7</span>,<span class="fl">0.2</span>,<span class="fl">0.9</span>,<span class="fl">0.3</span>,<span class="fl">0.6</span>,<span class="fl">0.75</span>,<span class="fl">0.4</span>,<span class="fl">0.2</span>])</span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a>prob_true, prob_pred <span class="op">=</span> calibration_curve(y_true, y_prob, n_bins<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-11"><a href="#cb95-11" aria-hidden="true" tabindex="-1"></a>plt.plot(prob_pred, prob_true, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb95-12"><a href="#cb95-12" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>,<span class="dv">1</span>],[<span class="dv">0</span>,<span class="dv">1</span>],<span class="st">'--'</span>, color<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb95-13"><a href="#cb95-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Predicted probability"</span>)</span>
<span id="cb95-14"><a href="#cb95-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Observed frequency"</span>)</span>
<span id="cb95-15"><a href="#cb95-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Reliability Diagram"</span>)</span>
<span id="cb95-16"><a href="#cb95-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-90" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-90">Why It Matters</h4>
<p>Calibration is crucial for trustworthy AI. In applications like healthcare, finance, and autonomous driving, it’s not enough to predict accurately—the system must also know when it’s uncertain.</p>
</section>
<section id="try-it-yourself-90" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-90">Try It Yourself</h4>
<ol type="1">
<li>Train a classifier and plot its reliability diagram—does it over- or under-predict?</li>
<li>Apply temperature scaling to improve calibration and re-plot.</li>
<li>Reflect: why might an overconfident but accurate model still be dangerous in real-world settings?</li>
</ol>
</section>
</section>
<section id="confidence-intervals-and-credible-intervals" class="level3">
<h3 class="anchored" data-anchor-id="confidence-intervals-and-credible-intervals">592. Confidence Intervals and Credible Intervals</h3>
<p>Both confidence intervals (frequentist) and credible intervals (Bayesian) provide ranges of uncertainty, but they are interpreted differently. Confidence intervals are about long-run frequency properties of estimators, while credible intervals express direct probabilistic beliefs about parameters given data.</p>
<section id="picture-in-your-head-91" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-91">Picture in Your Head</h4>
<p>Imagine measuring the height of a plant species:</p>
<ul>
<li>A 95% confidence interval says: “If we repeated this experiment infinitely, 95% of such intervals would contain the true mean.”</li>
<li>A 95% credible interval says: “Given the data and prior, there’s a 95% probability the true mean lies in this interval.”</li>
</ul>
</section>
<section id="deep-dive-91" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-91">Deep Dive</h4>
<ul>
<li><p>Confidence intervals (CI):</p>
<ul>
<li><p>Constructed from sampling distributions.</p></li>
<li><p>Depend on repeated-sampling interpretation.</p></li>
<li><p>Example:</p>
<p><span class="math display">\[
\bar{x} \pm z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{n}}
\]</span></p></li>
</ul></li>
<li><p>Credible intervals (CrI):</p>
<ul>
<li>Derived from posterior distribution <span class="math inline">\(p(\theta \mid D)\)</span>.</li>
<li>Direct probability statement about parameter.</li>
<li>Example: central 95% interval of posterior samples.</li>
</ul></li>
<li><p>Comparison:</p>
<ul>
<li>CI: probability statement about procedure.</li>
<li>CrI: probability statement about parameter.</li>
<li>Often numerically similar, conceptually different.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 58%">
<col style="width: 8%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="header">
<th>Interval Type</th>
<th>Interpretation</th>
<th>Foundation</th>
<th>Example Tool</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Confidence Interval</td>
<td>95% of such intervals capture the true parameter (in repeated experiments)</td>
<td>Frequentist</td>
<td>t-test, bootstrapping</td>
</tr>
<tr class="even">
<td>Credible Interval</td>
<td>95% probability that parameter lies in this range (given data + prior)</td>
<td>Bayesian</td>
<td>MCMC posterior samples</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python, PyMC)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [<span class="fl">5.1</span>, <span class="fl">5.3</span>, <span class="fl">5.0</span>, <span class="fl">5.2</span>, <span class="fl">5.4</span>]</span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-5"><a href="#cb96-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb96-6"><a href="#cb96-6" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> pm.Normal(<span class="st">"mu"</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb96-7"><a href="#cb96-7" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> pm.HalfNormal(<span class="st">"sigma"</span>, sigma<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb96-8"><a href="#cb96-8" aria-hidden="true" tabindex="-1"></a>    obs <span class="op">=</span> pm.Normal(<span class="st">"obs"</span>, mu<span class="op">=</span>mu, sigma<span class="op">=</span>sigma, observed<span class="op">=</span>data)</span>
<span id="cb96-9"><a href="#cb96-9" aria-hidden="true" tabindex="-1"></a>    trace <span class="op">=</span> pm.sample(<span class="dv">1000</span>, tune<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb96-10"><a href="#cb96-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-11"><a href="#cb96-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Bayesian 95% credible interval</span></span>
<span id="cb96-12"><a href="#cb96-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pm.summary(trace, hdi_prob<span class="op">=</span><span class="fl">0.95</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-91" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-91">Why It Matters</h4>
<p>Understanding the distinction prevents misinterpretation of uncertainty. For practitioners, credible intervals often align more naturally with intuition, but confidence intervals remain the standard in many fields.</p>
</section>
<section id="try-it-yourself-91" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-91">Try It Yourself</h4>
<ol type="1">
<li>Compute a 95% confidence interval for the mean of a dataset using bootstrapping.</li>
<li>Compute a 95% credible interval for the same dataset using Bayesian inference.</li>
<li>Reflect: which interpretation feels more natural for decision-making, and why?</li>
</ol>
</section>
</section>
<section id="quantifying-aleatoric-vs.-epistemic-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="quantifying-aleatoric-vs.-epistemic-uncertainty">593. Quantifying Aleatoric vs.&nbsp;Epistemic Uncertainty</h3>
<p>Uncertainty in AI models comes in two main forms: aleatoric uncertainty (inherent randomness in data) and epistemic uncertainty (lack of knowledge about the model). Distinguishing the two helps in building systems that know whether errors come from noisy data or from insufficient learning.</p>
<section id="picture-in-your-head-92" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-92">Picture in Your Head</h4>
<p>Think of predicting house prices:</p>
<ul>
<li>Aleatoric uncertainty: Even with all features (location, size), prices vary due to unpredictable factors (negotiation, buyer mood).</li>
<li>Epistemic uncertainty: If your dataset has few houses in a rural town, your model may simply not know enough—uncertainty comes from missing information.</li>
</ul>
</section>
<section id="deep-dive-92" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-92">Deep Dive</h4>
<ul>
<li><p>Aleatoric uncertainty (data uncertainty):</p>
<ul>
<li>Irreducible even with infinite data.</li>
<li>Modeled via likelihood noise terms (e.g., Gaussian variance).</li>
<li>Example: image classification with noisy labels.</li>
</ul></li>
<li><p>Epistemic uncertainty (model uncertainty):</p>
<ul>
<li>Reducible with more data or better models.</li>
<li>High in regions with sparse training data.</li>
<li>Captured via Bayesian methods (distribution over parameters).</li>
</ul></li>
<li><p>Mathematical decomposition: Total predictive uncertainty can be decomposed into:</p>
<p><span class="math display">\[
\text{Var}[y \mid x, D] = \mathbb{E}_{\theta \sim p(\theta \mid D)}[\text{Var}(y \mid x, \theta)] + \text{Var}_{\theta \sim p(\theta \mid D)}[\mathbb{E}(y \mid x, \theta)]
\]</span></p>
<ul>
<li>First term = aleatoric.</li>
<li>Second term = epistemic.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Type</th>
<th>Source</th>
<th>Reducible?</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Aleatoric</td>
<td>Inherent data noise</td>
<td>No</td>
<td>Rain forecast, noisy sensors</td>
</tr>
<tr class="even">
<td>Epistemic</td>
<td>Model ignorance</td>
<td>Yes, with more data</td>
<td>Rare disease prediction</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Pyro – separating uncertainties)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro, pyro.distributions <span class="im">as</span> dist</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> regression_model(x):</span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> pyro.sample(<span class="st">"w"</span>, dist.Normal(<span class="fl">0.</span>, <span class="fl">1.</span>))   <span class="co"># epistemic</span></span>
<span id="cb97-6"><a href="#cb97-6" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> pyro.sample(<span class="st">"b"</span>, dist.Normal(<span class="fl">0.</span>, <span class="fl">1.</span>))</span>
<span id="cb97-7"><a href="#cb97-7" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> pyro.sample(<span class="st">"sigma"</span>, dist.HalfCauchy(<span class="fl">1.</span>))  <span class="co"># aleatoric</span></span>
<span id="cb97-8"><a href="#cb97-8" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> pyro.sample(<span class="st">"y"</span>, dist.Normal(w<span class="op">*</span>x <span class="op">+</span> b, sigma))</span>
<span id="cb97-9"><a href="#cb97-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-92" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-92">Why It Matters</h4>
<p>Safety-critical AI (healthcare, autonomous driving) requires knowing when uncertainty is from noise vs.&nbsp;ignorance. Aleatoric tells us when outcomes are inherently unpredictable; epistemic warns us when the model is clueless.</p>
</section>
<section id="try-it-yourself-92" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-92">Try It Yourself</h4>
<ol type="1">
<li>Train a Bayesian regression model and separate variance into aleatoric vs.&nbsp;epistemic parts.</li>
<li>Add more data and see epistemic uncertainty shrink, while aleatoric stays.</li>
<li>Reflect: why is epistemic uncertainty especially important for out-of-distribution detection?</li>
</ol>
</section>
</section>
<section id="bayesian-model-averaging" class="level3">
<h3 class="anchored" data-anchor-id="bayesian-model-averaging">594. Bayesian Model Averaging</h3>
<p>Instead of committing to a single model, Bayesian Model Averaging (BMA) combines predictions from multiple models, weighting them by their posterior probabilities. This reflects uncertainty about <em>which model is correct</em> and often improves predictive performance and robustness.</p>
<section id="picture-in-your-head-93" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-93">Picture in Your Head</h4>
<p>Imagine you’re forecasting tomorrow’s weather. One model says “70% rain,” another says “40%,” and a third says “90%.” Rather than picking just one, you weight their forecasts by how plausible each model is given past performance, producing a better-calibrated prediction.</p>
</section>
<section id="deep-dive-93" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-93">Deep Dive</h4>
<ul>
<li><p>Bayesian model posterior: For model <span class="math inline">\(M_i\)</span> with parameters <span class="math inline">\(\theta_i\)</span>:</p>
<p><span class="math display">\[
P(M_i \mid D) \propto P(D \mid M_i) P(M_i)
\]</span></p>
<p>where <span class="math inline">\(P(D \mid M_i)\)</span> is the marginal likelihood (evidence).</p></li>
<li><p>Prediction under BMA:</p>
<p><span class="math display">\[
P(y \mid x, D) = \sum_i P(y \mid x, M_i, D) P(M_i \mid D)
\]</span></p>
<ul>
<li>Weighted average across models.</li>
<li>Accounts for model uncertainty explicitly.</li>
</ul></li>
<li><p>Advantages:</p>
<ul>
<li>More robust predictions than any single model.</li>
<li>Naturally penalizes overfitting models (via marginal likelihood).</li>
<li>Provides uncertainty quantification at both parameter and model level.</li>
</ul></li>
<li><p>Limitations:</p>
<ul>
<li>Computing model evidence is expensive.</li>
<li>Not always feasible for large sets of complex models.</li>
<li>Approximations (e.g., variational methods, stacking) often needed.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 22%">
<col style="width: 39%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Approach</th>
<th>Benefit</th>
<th>Limitation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Full BMA</td>
<td>Best uncertainty treatment</td>
<td>Computationally heavy</td>
</tr>
<tr class="even">
<td>Approximate BMA</td>
<td>More scalable</td>
<td>Less exact</td>
</tr>
<tr class="odd">
<td>Model selection</td>
<td>Simpler</td>
<td>Ignores model uncertainty</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (PyMC – BMA over two models)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>]</span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 1: coin bias Beta(1,1)</span></span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> m1:</span>
<span id="cb98-8"><a href="#cb98-8" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> pm.Beta(<span class="st">"p"</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb98-9"><a href="#cb98-9" aria-hidden="true" tabindex="-1"></a>    obs <span class="op">=</span> pm.Bernoulli(<span class="st">"obs"</span>, p, observed<span class="op">=</span>data)</span>
<span id="cb98-10"><a href="#cb98-10" aria-hidden="true" tabindex="-1"></a>    trace1 <span class="op">=</span> pm.sample(<span class="dv">1000</span>, tune<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb98-11"><a href="#cb98-11" aria-hidden="true" tabindex="-1"></a>    logp1 <span class="op">=</span> m1.logp(trace1)</span>
<span id="cb98-12"><a href="#cb98-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-13"><a href="#cb98-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 2: coin bias Beta(2,2)</span></span>
<span id="cb98-14"><a href="#cb98-14" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> m2:</span>
<span id="cb98-15"><a href="#cb98-15" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> pm.Beta(<span class="st">"p"</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb98-16"><a href="#cb98-16" aria-hidden="true" tabindex="-1"></a>    obs <span class="op">=</span> pm.Bernoulli(<span class="st">"obs"</span>, p, observed<span class="op">=</span>data)</span>
<span id="cb98-17"><a href="#cb98-17" aria-hidden="true" tabindex="-1"></a>    trace2 <span class="op">=</span> pm.sample(<span class="dv">1000</span>, tune<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb98-18"><a href="#cb98-18" aria-hidden="true" tabindex="-1"></a>    logp2 <span class="op">=</span> m2.logp(trace2)</span>
<span id="cb98-19"><a href="#cb98-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-20"><a href="#cb98-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Approximate posterior model probabilities via WAIC</span></span>
<span id="cb98-21"><a href="#cb98-21" aria-hidden="true" tabindex="-1"></a>az.compare({<span class="st">"m1"</span>: trace1, <span class="st">"m2"</span>: trace2}, method<span class="op">=</span><span class="st">"BB-pseudo-BMA"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-93" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-93">Why It Matters</h4>
<p>BMA addresses model uncertainty, a critical but often ignored source of risk. In medicine, finance, or climate modeling, relying on one model may be dangerous—averaging across models gives more reliable, calibrated forecasts.</p>
</section>
<section id="try-it-yourself-93" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-93">Try It Yourself</h4>
<ol type="1">
<li>Compare logistic regression vs.&nbsp;decision tree using BMA on a classification dataset.</li>
<li>Inspect how posterior weights shift as more data is added.</li>
<li>Reflect: why is BMA more honest than picking a single “best” model?</li>
</ol>
</section>
</section>
<section id="conformal-prediction-methods" class="level3">
<h3 class="anchored" data-anchor-id="conformal-prediction-methods">595. Conformal Prediction Methods</h3>
<p>Conformal prediction provides valid prediction intervals for machine learning models without requiring Bayesian assumptions. It guarantees, under exchangeability, that the true outcome will fall within the predicted interval with a chosen probability (e.g., 95%), regardless of the underlying model.</p>
<section id="picture-in-your-head-94" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-94">Picture in Your Head</h4>
<p>Imagine a weather forecast app. Instead of saying “tomorrow’s temperature will be 25°C,” it says, “with 95% confidence, it will be between 23–28°C.” Conformal prediction ensures that this interval is statistically valid, no matter what predictive model generated it.</p>
</section>
<section id="deep-dive-94" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-94">Deep Dive</h4>
<ul>
<li><p>Key idea:</p>
<ul>
<li><p>Use past data to calibrate prediction intervals.</p></li>
<li><p>Guarantees coverage:</p>
<p><span class="math display">\[
P(y \in \hat{C}(x)) \geq 1 - \alpha
\]</span></p>
<p>where <span class="math inline">\(\hat{C}(x)\)</span> is the conformal prediction set.</p></li>
</ul></li>
<li><p>Types:</p>
<ul>
<li>Inductive Conformal Prediction (ICP): split data into training and calibration sets.</li>
<li>Full Conformal Prediction: recomputes residuals for all leave-one-out fits (slower).</li>
<li>Mondrian Conformal Prediction: stratifies calibration by class/feature groups.</li>
</ul></li>
<li><p>Advantages:</p>
<ul>
<li>Model-agnostic: works with any predictor.</li>
<li>Provides valid uncertainty estimates even for black-box models.</li>
</ul></li>
<li><p>Limitations:</p>
<ul>
<li>Intervals may be wide if the model is weak.</li>
<li>Requires i.i.d. or exchangeable data.</li>
</ul></li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Method</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Full CP</td>
<td>Strong guarantees</td>
<td>Computationally heavy</td>
</tr>
<tr class="even">
<td>ICP</td>
<td>Fast, practical</td>
<td>Requires calibration split</td>
</tr>
<tr class="odd">
<td>Mondrian CP</td>
<td>Handles heterogeneity</td>
<td>More complex</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python – sklearn + mapie)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mapie.regression <span class="im">import</span> MapieRegressor</span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated data</span></span>
<span id="cb99-6"><a href="#cb99-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.arange(<span class="dv">100</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb99-7"><a href="#cb99-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> <span class="dv">3</span><span class="op">*</span>X.squeeze() <span class="op">+</span> np.random.normal(<span class="dv">0</span>,<span class="dv">10</span>,<span class="dv">100</span>)</span>
<span id="cb99-8"><a href="#cb99-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-9"><a href="#cb99-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Model + conformal prediction</span></span>
<span id="cb99-10"><a href="#cb99-10" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb99-11"><a href="#cb99-11" aria-hidden="true" tabindex="-1"></a>mapie <span class="op">=</span> MapieRegressor(model, method<span class="op">=</span><span class="st">"plus"</span>)</span>
<span id="cb99-12"><a href="#cb99-12" aria-hidden="true" tabindex="-1"></a>mapie.fit(X, y)</span>
<span id="cb99-13"><a href="#cb99-13" aria-hidden="true" tabindex="-1"></a>preds, intervals <span class="op">=</span> mapie.predict(X, alpha<span class="op">=</span><span class="fl">0.1</span>)  <span class="co"># 90% intervals</span></span>
<span id="cb99-14"><a href="#cb99-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-15"><a href="#cb99-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(preds[:<span class="dv">5</span>])</span>
<span id="cb99-16"><a href="#cb99-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(intervals[:<span class="dv">5</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-94" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-94">Why It Matters</h4>
<p>Conformal prediction is becoming essential for trustworthy AI, especially in applications like healthcare diagnostics or financial forecasting, where calibrated uncertainty intervals are critical. Unlike Bayesian methods, it provides frequentist guarantees that are simple and robust.</p>
</section>
<section id="try-it-yourself-94" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-94">Try It Yourself</h4>
<ol type="1">
<li>Train a random forest regressor and wrap it with conformal prediction to produce intervals.</li>
<li>Compare interval widths when the model is strong vs.&nbsp;weak.</li>
<li>Reflect: how does conformal prediction differ in philosophy from Bayesian credible intervals?</li>
</ol>
</section>
</section>
<section id="ensembles-for-uncertainty-estimation" class="level3">
<h3 class="anchored" data-anchor-id="ensembles-for-uncertainty-estimation">596. Ensembles for Uncertainty Estimation</h3>
<p>Ensemble methods combine predictions from multiple models to improve accuracy and capture epistemic uncertainty. By training diverse models and aggregating their outputs, ensembles reveal disagreement that signals uncertainty—especially valuable when data is scarce or out-of-distribution.</p>
<section id="picture-in-your-head-95" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-95">Picture in Your Head</h4>
<p>Imagine asking five doctors for a diagnosis. If they all agree, you’re confident in the result. If their answers differ widely, you know the case is uncertain. Ensembles mimic this logic by consulting multiple models instead of relying on one.</p>
</section>
<section id="deep-dive-95" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-95">Deep Dive</h4>
<ul>
<li><p>Types of ensembles:</p>
<ul>
<li>Bagging (Bootstrap Aggregating): train models on bootstrap samples, average predictions.</li>
<li>Boosting: sequentially train models that correct predecessors’ errors.</li>
<li>Randomization ensembles: vary initialization, architectures, or subsets of features.</li>
<li>Deep ensembles: train multiple neural nets with different random seeds and aggregate.</li>
</ul></li>
<li><p>Uncertainty estimation:</p>
<ul>
<li>Aleatoric uncertainty comes from inherent noise (captured within each model).</li>
<li>Epistemic uncertainty arises when ensemble members disagree.</li>
</ul></li>
<li><p>Mathematical form: For ensemble of <span class="math inline">\(M\)</span> models with predictive distributions <span class="math inline">\(p_m(y \mid x)\)</span>:</p>
<p><span class="math display">\[
p(y \mid x) = \frac{1}{M} \sum_{m=1}^M p_m(y \mid x)
\]</span></p></li>
<li><p>Advantages:</p>
<ul>
<li>Simple, effective, often better calibrated than single models.</li>
<li>Robust to overfitting and local minima.</li>
</ul></li>
<li><p>Limitations:</p>
<ul>
<li>Computationally expensive (multiple models).</li>
<li>Memory-intensive for large neural nets.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 24%">
<col style="width: 31%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Ensemble Type</th>
<th>Core Idea</th>
<th>Strength</th>
<th>Weakness</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Bagging</td>
<td>Bootstrap resampling</td>
<td>Reduces variance</td>
<td>Many models needed</td>
</tr>
<tr class="even">
<td>Boosting</td>
<td>Sequential corrections</td>
<td>Strong accuracy</td>
<td>Less uncertainty-aware</td>
</tr>
<tr class="odd">
<td>Random forests</td>
<td>Randomized trees</td>
<td>Interpretability</td>
<td>Limited in high dimensions</td>
</tr>
<tr class="even">
<td>Deep ensembles</td>
<td>Multiple NNs</td>
<td>Strong uncertainty estimates</td>
<td>High compute cost</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (scikit-learn – Random Forest as Ensemble)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_classification(n_samples<span class="op">=</span><span class="dv">200</span>, n_features<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a>rf <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb100-7"><a href="#cb100-7" aria-hidden="true" tabindex="-1"></a>rf.fit(X, y)</span>
<span id="cb100-8"><a href="#cb100-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-9"><a href="#cb100-9" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> [tree.predict_proba(X) <span class="cf">for</span> tree <span class="kw">in</span> rf.estimators_]</span>
<span id="cb100-10"><a href="#cb100-10" aria-hidden="true" tabindex="-1"></a>avg_probs <span class="op">=</span> np.mean(probs, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb100-11"><a href="#cb100-11" aria-hidden="true" tabindex="-1"></a>uncertainty <span class="op">=</span> np.var(probs, axis<span class="op">=</span><span class="dv">0</span>)  <span class="co"># ensemble disagreement</span></span>
<span id="cb100-12"><a href="#cb100-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-13"><a href="#cb100-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted probs (first 5):"</span>, avg_probs[:<span class="dv">5</span>])</span>
<span id="cb100-14"><a href="#cb100-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Uncertainty estimates (first 5):"</span>, uncertainty[:<span class="dv">5</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-95" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-95">Why It Matters</h4>
<p>Ensembles provide a practical and powerful approach to uncertainty estimation in real-world AI, often outperforming Bayesian approximations in deep learning. They are widely used in safety-critical domains like medical imaging, fraud detection, and autonomous driving.</p>
</section>
<section id="try-it-yourself-95" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-95">Try It Yourself</h4>
<ol type="1">
<li>Train 5 independent neural nets with different seeds and compare their predictions on OOD data.</li>
<li>Compare uncertainty from ensembles vs.&nbsp;dropout-based Bayesian approximations.</li>
<li>Reflect: why do ensembles often work better in practice than theoretically elegant Bayesian neural networks?</li>
</ol>
</section>
</section>
<section id="robustness-in-deployed-systems" class="level3">
<h3 class="anchored" data-anchor-id="robustness-in-deployed-systems">597. Robustness in Deployed Systems</h3>
<p>When AI models move from lab settings to the real world, they face distribution shifts, noise, adversarial inputs, and hardware limitations. Robustness means maintaining reliable performance—and honest uncertainty estimates—under these unpredictable conditions.</p>
<section id="picture-in-your-head-96" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-96">Picture in Your Head</h4>
<p>Think of a self-driving car trained on sunny Californian roads. Once deployed in snowy Canada, it must handle unfamiliar conditions. A robust system won’t just make predictions—it will know when it’s uncertain and adapt accordingly.</p>
</section>
<section id="deep-dive-96" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-96">Deep Dive</h4>
<ul>
<li><p>Challenges in deployment:</p>
<ul>
<li>Distribution shift: test data differs from training distribution.</li>
<li>Noisy inputs: sensor errors, missing values.</li>
<li>Adversarial perturbations: small but harmful changes to inputs.</li>
<li>Resource limits: latency and memory constraints on edge devices.</li>
</ul></li>
<li><p>Robustness strategies:</p>
<ol type="1">
<li>Uncertainty-aware models: Bayesian methods, ensembles, conformal prediction.</li>
<li>Adversarial training: hardening against perturbations.</li>
<li>Data augmentation &amp; domain randomization: prepare for unseen conditions.</li>
<li>Monitoring and recalibration: detect drift, retrain when necessary.</li>
<li>Fail-safe mechanisms: abstaining from predictions when uncertainty is too high.</li>
</ol></li>
<li><p>Evaluation techniques:</p>
<ul>
<li>Stress testing with corrupted or shifted datasets.</li>
<li>Benchmarking on robustness suites (e.g., ImageNet-C, WILDS).</li>
<li>Reliability curves and uncertainty calibration checks.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 41%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Robustness Threat</th>
<th>Mitigation</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Distribution shift</td>
<td>Domain adaptation, retraining</td>
<td>Medical imaging across hospitals</td>
</tr>
<tr class="even">
<td>Noise</td>
<td>Data augmentation, robust likelihoods</td>
<td>Speech recognition in noisy rooms</td>
</tr>
<tr class="odd">
<td>Adversarial attacks</td>
<td>Adversarial training</td>
<td>Fraud detection</td>
</tr>
<tr class="even">
<td>Hardware limits</td>
<td>Model compression, distillation</td>
<td>On-device ML</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (PyTorch – abstaining classifier)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict_with_abstain(model, x, threshold<span class="op">=</span><span class="fl">0.7</span>):</span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>    logits <span class="op">=</span> model(x)</span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a>    probs <span class="op">=</span> F.softmax(logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a>    conf, pred <span class="op">=</span> torch.<span class="bu">max</span>(probs, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb101-8"><a href="#cb101-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [p.item() <span class="cf">if</span> c <span class="op">&gt;=</span> threshold <span class="cf">else</span> <span class="st">"abstain"</span></span>
<span id="cb101-9"><a href="#cb101-9" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> p, c <span class="kw">in</span> <span class="bu">zip</span>(pred, conf)]</span>
<span id="cb101-10"><a href="#cb101-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-11"><a href="#cb101-11" aria-hidden="true" tabindex="-1"></a><span class="co"># If confidence &lt; 0.7, system abstains</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-96" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-96">Why It Matters</h4>
<p>Robustness is a cornerstone of trustworthy AI. In safety-critical systems—healthcare, finance, autonomous driving—it’s not enough to be accurate on average; models must withstand uncertainty, adversaries, and unexpected environments.</p>
</section>
<section id="try-it-yourself-96" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-96">Try It Yourself</h4>
<ol type="1">
<li>Train a model on clean MNIST, then test it on MNIST with Gaussian noise—observe accuracy drop.</li>
<li>Add uncertainty-aware techniques (ensembles, dropout) to detect uncertain cases.</li>
<li>Reflect: why is “knowing when not to predict” as important as making predictions in real-world AI?</li>
</ol>
</section>
</section>
<section id="uncertainty-in-human-in-the-loop-systems" class="level3">
<h3 class="anchored" data-anchor-id="uncertainty-in-human-in-the-loop-systems">598. Uncertainty in Human-in-the-Loop Systems</h3>
<p>In many real-world applications, AI does not operate autonomously—humans remain in the decision loop. For these systems, uncertainty estimates guide when the AI should act on its own, when it should defer to a human, and how human feedback can improve the model.</p>
<section id="picture-in-your-head-97" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-97">Picture in Your Head</h4>
<p>Think of a medical AI that reviews X-rays. For clear cases, it confidently outputs “no fracture.” For ambiguous cases, it flags them for a radiologist. The human provides a judgment, and the system learns from it. This partnership hinges on trustworthy uncertainty estimates.</p>
</section>
<section id="deep-dive-97" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-97">Deep Dive</h4>
<ul>
<li><p>Roles of uncertainty in human-AI systems:</p>
<ol type="1">
<li>Deferral: AI abstains or flags cases when confidence is low.</li>
<li>Triaging: prioritize uncertain cases for expert review.</li>
<li>Active learning: uncertainty directs which data points to label.</li>
<li>Trust calibration: humans learn when to trust or override AI outputs.</li>
</ol></li>
<li><p>Modeling needs:</p>
<ul>
<li>Well-calibrated probabilities.</li>
<li>Interpretable uncertainty (why the model is unsure).</li>
<li>Mechanisms for combining AI predictions with human expertise.</li>
</ul></li>
<li><p>Challenges:</p>
<ul>
<li>Overconfident AI undermines trust.</li>
<li>Underconfident AI wastes human attention.</li>
<li>Aligning human mental models with statistical uncertainty.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 46%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="header">
<th>Application</th>
<th>Role of Uncertainty</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Healthcare</td>
<td>AI defers to doctors</td>
<td>Diagnostic support systems</td>
</tr>
<tr class="even">
<td>Finance</td>
<td>Flag high-risk trades</td>
<td>Fraud detection</td>
</tr>
<tr class="odd">
<td>Manufacturing</td>
<td>Triage borderline defects</td>
<td>Quality inspection</td>
</tr>
<tr class="even">
<td>Education</td>
<td>Tutor adapts to learner uncertainty</td>
<td>Intelligent tutoring systems</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Python – AI with deferral)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ai_with_deferral(pred_probs, threshold<span class="op">=</span><span class="fl">0.7</span>):</span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a>    decisions <span class="op">=</span> []</span>
<span id="cb102-5"><a href="#cb102-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> p <span class="kw">in</span> pred_probs:</span>
<span id="cb102-6"><a href="#cb102-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">max</span>(p) <span class="op">&lt;</span> threshold:</span>
<span id="cb102-7"><a href="#cb102-7" aria-hidden="true" tabindex="-1"></a>            decisions.append(<span class="st">"defer_to_human"</span>)</span>
<span id="cb102-8"><a href="#cb102-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb102-9"><a href="#cb102-9" aria-hidden="true" tabindex="-1"></a>            decisions.append(np.argmax(p))</span>
<span id="cb102-10"><a href="#cb102-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> decisions</span>
<span id="cb102-11"><a href="#cb102-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-12"><a href="#cb102-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb102-13"><a href="#cb102-13" aria-hidden="true" tabindex="-1"></a>pred_probs <span class="op">=</span> [[<span class="fl">0.6</span>, <span class="fl">0.4</span>], [<span class="fl">0.9</span>, <span class="fl">0.1</span>], [<span class="fl">0.55</span>, <span class="fl">0.45</span>]]</span>
<span id="cb102-14"><a href="#cb102-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ai_with_deferral(pred_probs))</span>
<span id="cb102-15"><a href="#cb102-15" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; ['defer_to_human', 0, 'defer_to_human']</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-97" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-97">Why It Matters</h4>
<p>Human-in-the-loop systems are essential for responsible AI deployment. By leveraging uncertainty, AI can complement human strengths instead of replacing them, ensuring safety, fairness, and accountability.</p>
</section>
<section id="try-it-yourself-97" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-97">Try It Yourself</h4>
<ol type="1">
<li>Build a simple classifier and add a deferral mechanism when confidence &lt; 0.8.</li>
<li>Simulate human correction of deferred cases—measure accuracy improvement.</li>
<li>Reflect: how does uncertainty sharing build trust between humans and AI systems?</li>
</ol>
</section>
</section>
<section id="safety-critical-reliability-requirements" class="level3">
<h3 class="anchored" data-anchor-id="safety-critical-reliability-requirements">599. Safety-Critical Reliability Requirements</h3>
<p>In domains like healthcare, aviation, finance, and autonomous driving, AI systems must meet safety-critical reliability requirements. This means not only being accurate but also being predictably reliable under uncertainty, distribution shift, and rare events.</p>
<section id="picture-in-your-head-98" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-98">Picture in Your Head</h4>
<p>Imagine an autopilot system: 99% accuracy is not enough if the 1% includes a catastrophic mid-air failure. In safety-critical contexts, reliability must be engineered to minimize the risk of rare but disastrous outcomes.</p>
</section>
<section id="deep-dive-98" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-98">Deep Dive</h4>
<ul>
<li><p>Key reliability requirements:</p>
<ol type="1">
<li>Fail-safe operation: system abstains or hands over control when uncertain.</li>
<li>Calibration: probability estimates must reflect real-world frequencies.</li>
<li>Robustness: performance must hold under noise, adversaries, or unexpected conditions.</li>
<li>Verification and validation: formal guarantees, stress testing, simulation.</li>
<li>Redundancy: multiple models/sensors for cross-checking.</li>
</ol></li>
<li><p>Approaches:</p>
<ul>
<li>Uncertainty quantification: Bayesian methods, ensembles, conformal prediction.</li>
<li>Out-of-distribution detection: flagging unfamiliar inputs.</li>
<li>Adversarial robustness: defenses against malicious perturbations.</li>
<li>Formal verification: proving safety properties of ML models.</li>
</ul></li>
<li><p>Industry practices:</p>
<ul>
<li>Aviation: DO-178C certification for software reliability.</li>
<li>Automotive: ISO 26262 for functional safety in vehicles.</li>
<li>Healthcare: FDA regulations for medical AI devices.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 40%">
<col style="width: 45%">
</colgroup>
<thead>
<tr class="header">
<th>Requirement</th>
<th>Method</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Fail-safe</td>
<td>Abstention thresholds</td>
<td>Medical AI defers to doctors</td>
</tr>
<tr class="even">
<td>Calibration</td>
<td>Reliability diagrams, scaling</td>
<td>Autonomous driving risk estimates</td>
</tr>
<tr class="odd">
<td>Robustness</td>
<td>Adversarial training, ensembles</td>
<td>Fraud detection under attacks</td>
</tr>
<tr class="even">
<td>Verification</td>
<td>Formal proofs, runtime monitoring</td>
<td>Certified neural networks in aviation</td>
</tr>
</tbody>
</table>
<p>Tiny Code Recipe (Fail-safe wrapper in PyTorch)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> safe_predict(model, x, threshold<span class="op">=</span><span class="fl">0.8</span>):</span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>    probs <span class="op">=</span> F.softmax(model(x), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a>    conf, pred <span class="op">=</span> torch.<span class="bu">max</span>(probs, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb103-6"><a href="#cb103-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [p.item() <span class="cf">if</span> c <span class="op">&gt;=</span> threshold <span class="cf">else</span> <span class="st">"safe_fail"</span></span>
<span id="cb103-7"><a href="#cb103-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> p, c <span class="kw">in</span> <span class="bu">zip</span>(pred, conf)]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-98" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-98">Why It Matters</h4>
<p>For safety-critical systems, uncertainty is not optional—it is a core requirement. Regulatory approval, public trust, and real-world deployment depend on demonstrable reliability under rare but high-stakes conditions.</p>
</section>
<section id="try-it-yourself-98" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-98">Try It Yourself</h4>
<ol type="1">
<li>Add an abstention rule to a classifier and measure its impact on false positives.</li>
<li>Test a model on out-of-distribution data—does it fail gracefully or catastrophically?</li>
<li>Reflect: why is “rare event reliability” more important than average-case accuracy in critical systems?</li>
</ol>
</section>
</section>
<section id="future-of-trustworthy-ai-with-uq" class="level3">
<h3 class="anchored" data-anchor-id="future-of-trustworthy-ai-with-uq">600. Future of Trustworthy AI with UQ</h3>
<p>The future of trustworthy AI depends on uncertainty quantification (UQ) becoming a first-class component of every model. Beyond accuracy, systems must be able to say <em>“I don’t know”</em> when faced with ambiguity, shift, or rare events—and communicate that uncertainty clearly to humans.</p>
<section id="picture-in-your-head-99" class="level4">
<h4 class="anchored" data-anchor-id="picture-in-your-head-99">Picture in Your Head</h4>
<p>Imagine an AI medical assistant. Instead of always giving a definitive diagnosis, it sometimes responds: <em>“I’m 55% confident it’s pneumonia, but I recommend a CT scan to be sure.”</em> This transparency transforms AI from a black box into a reliable collaborator.</p>
</section>
<section id="deep-dive-99" class="level4">
<h4 class="anchored" data-anchor-id="deep-dive-99">Deep Dive</h4>
<ul>
<li><p>Where UQ is heading:</p>
<ol type="1">
<li>Hybrid methods: combining Bayesian inference, ensembles, and conformal prediction.</li>
<li>Scalable UQ: uncertainty estimation for billion-parameter models and massive datasets.</li>
<li>Interactive UQ: communicating uncertainty in human-friendly ways (visualizations, explanations).</li>
<li>Regulatory standards: embedding UQ into certification processes (e.g., ISO, FDA).</li>
<li>Societal impact: enabling AI adoption in safety-critical and high-stakes domains.</li>
</ol></li>
<li><p>Grand challenges:</p>
<ul>
<li>Making UQ as easy to use as standard prediction pipelines.</li>
<li>Achieving real-time UQ in edge and embedded systems.</li>
<li>Balancing expressivity and computational efficiency.</li>
<li>Educating practitioners to interpret uncertainty correctly.</li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 34%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="header">
<th>Future Direction</th>
<th>Why It Matters</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Hybrid methods</td>
<td>Robustness across scenarios</td>
<td>Ensemble + Bayesian NN + conformal</td>
</tr>
<tr class="even">
<td>Real-time UQ</td>
<td>Safety in fast decisions</td>
<td>Autonomous driving</td>
</tr>
<tr class="odd">
<td>Human-centered UQ</td>
<td>Improves trust &amp; usability</td>
<td>Medical decision support</td>
</tr>
<tr class="even">
<td>Regulation</td>
<td>Ensures accountability</td>
<td>AI in aviation, healthcare</td>
</tr>
</tbody>
</table>
<p>Tiny Code Illustration (Uncertainty-Aware Pipeline)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> trustworthy_ai_pipeline(model, x, methods):</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Combine multiple UQ methods: ensemble, Bayesian dropout, conformal.</span></span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> {}</span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, method <span class="kw">in</span> methods.items():</span>
<span id="cb104-7"><a href="#cb104-7" aria-hidden="true" tabindex="-1"></a>        results[name] <span class="op">=</span> method(model, x)</span>
<span id="cb104-8"><a href="#cb104-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> results</span>
<span id="cb104-9"><a href="#cb104-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-10"><a href="#cb104-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Future systems will integrate multiple UQ layers by default</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="why-it-matters-99" class="level4">
<h4 class="anchored" data-anchor-id="why-it-matters-99">Why It Matters</h4>
<p>Uncertainty quantification is the bridge between powerful AI and responsible AI. It ensures that systems are not only accurate but also honest about their limitations—critical for human trust, regulatory approval, and safe deployment.</p>
</section>
<section id="try-it-yourself-99" class="level4">
<h4 class="anchored" data-anchor-id="try-it-yourself-99">Try It Yourself</h4>
<ol type="1">
<li>Take a model you’ve trained—add both ensemble-based and conformal prediction UQ.</li>
<li>Build a visualization of predictive distributions instead of single-point outputs.</li>
<li>Reflect: what would it take for every deployed AI system to have uncertainty as a feature, not an afterthought?</li>
</ol>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../books/en-US/volume_5.html" class="pagination-link" aria-label="Volume 5. Logic and Knowledge">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Volume 5. Logic and Knowledge</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../books/en-US/volume_7.html" class="pagination-link" aria-label="Volume 7. Machine Learning Theory and Practice">
        <span class="nav-page-text"><span class="chapter-title">Volume 7. Machine Learning Theory and Practice</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>