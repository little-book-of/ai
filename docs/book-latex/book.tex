% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother





\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={The Little Book of Artificial Intelligence},
  pdfauthor={Duc-Tam Nguyen},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{The Little Book of Artificial Intelligence}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Version 0.1.1}
\author{Duc-Tam Nguyen}
\date{2025-09-17}
\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter{Contents}\label{contents}

\subsubsection{Volume 1 --- First Principles of
AI}\label{volume-1-first-principles-of-ai}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Defining Intelligence, Agents, and Environments
\item
  Objectives, Utility, and Reward
\item
  Information, Uncertainty, and Entropy
\item
  Computation, Complexity, and Limits
\item
  Representation and Abstraction
\item
  Learning vs.~Reasoning: Two Paths to Intelligence
\item
  Search, Optimization, and Decision-Making
\item
  Data, Signals, and Measurement
\item
  Evaluation: Ground Truth, Metrics, and Benchmarks
\item
  Reproducibility, Tooling, and the Scientific Method
\end{enumerate}

\subsubsection{Volume 2 --- Mathematical
Foundations}\label{volume-2-mathematical-foundations}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{10}
\tightlist
\item
  Linear Algebra for Representations
\item
  Differential and Integral Calculus
\item
  Probability Theory Fundamentals
\item
  Statistics and Estimation
\item
  Optimization and Convex Analysis
\item
  Numerical Methods and Stability
\item
  Information Theory
\item
  Graphs, Matrices, and Spectral Methods
\item
  Logic, Sets, and Proof Techniques
\item
  Stochastic Processes and Markov Chains
\end{enumerate}

\subsubsection{Volume 3 --- Data \&
Representation}\label{volume-3-data-representation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{20}
\tightlist
\item
  Data Lifecycle and Governance
\item
  Data Models: Tensors, Tables, Graphs
\item
  Feature Engineering and Encodings
\item
  Labeling, Annotation, and Weak Supervision
\item
  Sampling, Splits, and Experimental Design
\item
  Augmentation, Synthesis, and Simulation
\item
  Data Quality, Integrity, and Bias
\item
  Privacy, Security, and Anonymization
\item
  Datasets, Benchmarks, and Data Cards
\item
  Data Versioning and Lineage
\end{enumerate}

\subsubsection{Volume 4 --- Search \&
Planning}\label{volume-4-search-planning}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{30}
\tightlist
\item
  State Spaces and Problem Formulation
\item
  Uninformed Search (BFS, DFS, Iterative Deepening)
\item
  Informed Search (Heuristics, A*)
\item
  Constraint Satisfaction Problems
\item
  Local Search and Metaheuristics
\item
  Game Search and Adversarial Planning
\item
  Planning in Deterministic Domains
\item
  Probabilistic Planning and POMDPs
\item
  Scheduling and Resource Allocation
\item
  Meta-Reasoning and Anytime Algorithms
\end{enumerate}

\subsubsection{Volume 5 --- Logic \&
Knowledge}\label{volume-5-logic-knowledge}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{40}
\tightlist
\item
  Propositional and First-Order Logic
\item
  Knowledge Representation Schemes
\item
  Inference Engines and Theorem Proving
\item
  Ontologies and Knowledge Graphs
\item
  Description Logics and the Semantic Web
\item
  Default, Non-Monotonic, and Probabilistic Logic
\item
  Temporal, Modal, and Spatial Reasoning
\item
  Commonsense and Qualitative Reasoning
\item
  Neuro-Symbolic AI: Bridging Learning and Logic
\item
  Knowledge Acquisition and Maintenance
\end{enumerate}

\subsubsection{Volume 6 --- Probabilistic Modeling \&
Inference}\label{volume-6-probabilistic-modeling-inference}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{50}
\tightlist
\item
  Bayesian Inference Basics
\item
  Directed Graphical Models (Bayesian Networks)
\item
  Undirected Graphical Models (MRFs/CRFs)
\item
  Exact Inference (Variable Elimination, Junction Tree)
\item
  Approximate Inference (Sampling, Variational)
\item
  Latent Variable Models and EM
\item
  Sequential Models (HMMs, Kalman, Particle Filters)
\item
  Decision Theory and Influence Diagrams
\item
  Probabilistic Programming Languages
\item
  Calibration, Uncertainty Quantification, Reliability
\end{enumerate}

\subsubsection{Volume 7 --- Machine Learning Theory \&
Practice}\label{volume-7-machine-learning-theory-practice}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{60}
\tightlist
\item
  Hypothesis Spaces, Bias, and Capacity
\item
  Generalization, VC, Rademacher, PAC
\item
  Losses, Regularization, and Optimization
\item
  Model Selection, Cross-Validation, Bootstrapping
\item
  Linear and Generalized Linear Models
\item
  Kernel Methods and SVMs
\item
  Trees, Random Forests, Gradient Boosting
\item
  Feature Selection and Dimensionality Reduction
\item
  Imbalanced Data and Cost-Sensitive Learning
\item
  Evaluation, Error Analysis, and Debugging
\end{enumerate}

\subsubsection{Volume 8 --- Supervised Learning
Systems}\label{volume-8-supervised-learning-systems}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{70}
\tightlist
\item
  Regression: From Linear to Nonlinear
\item
  Classification: Binary, Multiclass, Multilabel
\item
  Structured Prediction (CRFs, Seq2Seq Basics)
\item
  Time Series and Forecasting
\item
  Tabular Modeling and Feature Stores
\item
  Hyperparameter Optimization and AutoML
\item
  Interpretability and Explainability (XAI)
\item
  Robustness, Adversarial Examples, Hardening
\item
  Deployment Patterns for Supervised Models
\item
  Monitoring, Drift, and Lifecycle Management
\end{enumerate}

\subsubsection{Volume 9 --- Unsupervised, Self-Supervised \&
Representation}\label{volume-9-unsupervised-self-supervised-representation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{80}
\tightlist
\item
  Clustering (k-Means, Hierarchical, DBSCAN)
\item
  Density Estimation and Mixture Models
\item
  Matrix Factorization and NMF
\item
  Dimensionality Reduction (PCA, t-SNE, UMAP)
\item
  Manifold Learning and Topological Methods
\item
  Topic Models and Latent Dirichlet Allocation
\item
  Autoencoders and Representation Learning
\item
  Contrastive and Self-Supervised Learning
\item
  Anomaly and Novelty Detection
\item
  Graph Representation Learning
\end{enumerate}

\subsubsection{Volume 10 --- Deep Learning
Core}\label{volume-10-deep-learning-core}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{90}
\tightlist
\item
  Computational Graphs and Autodiff
\item
  Backpropagation and Initialization
\item
  Optimizers (SGD, Momentum, Adam, etc.)
\item
  Regularization (Dropout, Norms, Batch/Layer Norm)
\item
  Convolutional Networks and Inductive Biases
\item
  Recurrent Networks and Sequence Models
\item
  Attention Mechanisms and Transformers
\item
  Architecture Patterns and Design Spaces
\item
  Training at Scale (Parallelism, Mixed Precision)
\item
  Failure Modes, Debugging, Evaluation
\end{enumerate}

\subsubsection{Volume 11 --- Large Language
Models}\label{volume-11-large-language-models}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{100}
\tightlist
\item
  Tokenization, Subwords, and Embeddings
\item
  Transformer Architecture Deep Dive
\item
  Pretraining Objectives (MLM, CLM, SFT)
\item
  Scaling Laws and Data/Compute Tradeoffs
\item
  Instruction Tuning, RLHF, and RLAIF
\item
  Parameter-Efficient Tuning (Adapters, LoRA)
\item
  Retrieval-Augmented Generation (RAG) and Memory
\item
  Tool Use, Function Calling, and Agents
\item
  Evaluation, Safety, and Prompting Strategies
\item
  Production LLM Systems and Cost Optimization
\end{enumerate}

\subsubsection{Volume 12 --- Computer
Vision}\label{volume-12-computer-vision}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{110}
\tightlist
\item
  Image Formation and Preprocessing
\item
  ConvNets for Recognition
\item
  Object Detection and Tracking
\item
  Segmentation and Scene Understanding
\item
  3D Vision and Geometry
\item
  Self-Supervised and Foundation Models for Vision
\item
  Vision Transformers and Hybrid Models
\item
  Multimodal Vision-Language (VL) Models
\item
  Datasets, Metrics, and Benchmarks
\item
  Real-World Vision Systems and Edge Deployment
\end{enumerate}

\subsubsection{Volume 13 --- Natural Language
Processing}\label{volume-13-natural-language-processing}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{120}
\tightlist
\item
  Linguistic Foundations (Morphology, Syntax, Semantics)
\item
  Classical NLP (n-Grams, HMMs, CRFs)
\item
  Word and Sentence Embeddings
\item
  Sequence-to-Sequence and Attention
\item
  Machine Translation and Multilingual NLP
\item
  Question Answering and Information Retrieval
\item
  Summarization and Text Generation
\item
  Prompting, In-Context Learning, Program Induction
\item
  Evaluation, Bias, and Toxicity in NLP
\item
  Low-Resource, Code, and Domain-Specific NLP
\end{enumerate}

\subsubsection{Volume 14 --- Speech \& Audio
Intelligence}\label{volume-14-speech-audio-intelligence}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{130}
\tightlist
\item
  Signal Processing and Feature Extraction
\item
  Automatic Speech Recognition (CTC, Transducers)
\item
  Text-to-Speech and Voice Conversion
\item
  Speaker Identification and Diarization
\item
  Music Information Retrieval
\item
  Audio Event Detection and Scene Analysis
\item
  Prosody, Emotion, and Paralinguistics
\item
  Multimodal Audio-Visual Learning
\item
  Robustness to Noise, Accents, Reverberation
\item
  Real-Time and On-Device Audio AI
\end{enumerate}

\subsubsection{Volume 15 --- Reinforcement
Learning}\label{volume-15-reinforcement-learning}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{140}
\tightlist
\item
  Markov Decision Processes and Bellman Equations
\item
  Dynamic Programming and Planning
\item
  Monte Carlo and Temporal-Difference Learning
\item
  Value-Based Methods (DQN and Variants)
\item
  Policy Gradients and Actor-Critic
\item
  Exploration, Intrinsic Motivation, Bandits
\item
  Model-Based RL and World Models
\item
  Multi-Agent RL and Games
\item
  Offline RL, Safety, and Constraints
\item
  RL in the Wild: Sim2Real and Applications
\end{enumerate}

\subsubsection{Volume 16 --- Robotics \& Embodied
AI}\label{volume-16-robotics-embodied-ai}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{150}
\tightlist
\item
  Kinematics, Dynamics, and Control
\item
  Perception for Robotics
\item
  SLAM and Mapping
\item
  Motion Planning and Trajectory Optimization
\item
  Grasping and Manipulation
\item
  Locomotion and Balance
\item
  Human-Robot Interaction and Collaboration
\item
  Simulation, Digital Twins, Domain Randomization
\item
  Learning for Manipulation and Navigation
\item
  System Integration and Real-World Deployment
\end{enumerate}

\subsubsection{Volume 17 --- Causality, Reasoning \&
Science}\label{volume-17-causality-reasoning-science}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{160}
\tightlist
\item
  Causal Graphs, SCMs, and Do-Calculus
\item
  Identification, Estimation, and Transportability
\item
  Counterfactuals and Mediation
\item
  Causal Discovery from Observational Data
\item
  Experiment Design, A/B/n Testing, Uplift
\item
  Time Series Causality and Granger
\item
  Scientific ML and Differentiable Physics
\item
  Symbolic Regression and Program Synthesis
\item
  Automated Theorem Proving and Formal Methods
\item
  Limits, Fallacies, and Robust Scientific Practice
\end{enumerate}

\subsubsection{Volume 18 --- AI Systems, MLOps \&
Infrastructure}\label{volume-18-ai-systems-mlops-infrastructure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{170}
\tightlist
\item
  Data Engineering and Feature Stores
\item
  Experiment Tracking and Reproducibility
\item
  Training Orchestration and Scheduling
\item
  Distributed Training and Parallelism
\item
  Model Packaging, Serving, and APIs
\item
  Monitoring, Telemetry, and Observability
\item
  Drift, Feedback Loops, Continuous Learning
\item
  Privacy, Security, and Model Governance
\item
  Cost, Efficiency, and Green AI
\item
  Platform Architecture and Team Practices
\end{enumerate}

\subsubsection{Volume 19 --- Multimodality, Tools \&
Agents}\label{volume-19-multimodality-tools-agents}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{180}
\tightlist
\item
  Multimodal Pretraining and Alignment
\item
  Cross-Modal Retrieval and Fusion
\item
  Vision-Language-Action Models
\item
  Memory, Datastores, and RAG Systems
\item
  Tool Use, Function APIs, and Plugins
\item
  Planning, Decomposition, Toolformer-Style Agents
\item
  Multi-Agent Simulation and Coordination
\item
  Evaluation of Agents and Emergent Behavior
\item
  Human-in-the-Loop and Interactive Systems
\item
  Case Studies: Assistants, Copilots, Autonomy
\end{enumerate}

\subsubsection{Volume 20 --- Ethics, Safety, Governance \&
Futures}\label{volume-20-ethics-safety-governance-futures}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{190}
\tightlist
\item
  Ethical Frameworks and Principles
\item
  Fairness, Bias, and Inclusion
\item
  Privacy, Surveillance, and Consent
\item
  Robustness, Reliability, and Safety Engineering
\item
  Alignment, Preference Learning, and Control
\item
  Misuse, Abuse, and Red-Teaming
\item
  Law, Regulation, and International Policy
\item
  Economic Impacts, Labor, and Society
\item
  Education, Healthcare, and Public Goods
\item
  Roadmaps, Open Problems, and Future Scenarios
\end{enumerate}

\bookmarksetup{startatroot}

\chapter{Volume 1. First principles of Artificial
Intelligence}\label{volume-1.-first-principles-of-artificial-intelligence}

\section{Chapter 1. Defining Ingelligence, Agents, and
Environments}\label{chapter-1.-defining-ingelligence-agents-and-environments}

\subsection{1. What do we mean by
``intelligence''?}\label{what-do-we-mean-by-intelligence}

Intelligence is the capacity to achieve goals across a wide variety of
environments. In AI, it means designing systems that can perceive,
reason, and act effectively, even under uncertainty. Unlike narrow
programs built for one fixed task, intelligence implies adaptability and
generalization.

\subsubsection{Picture in Your Head}\label{picture-in-your-head}

Think of a skilled traveler arriving in a new city. They don't just
follow one rigid script---they observe the signs, ask questions, and
adjust plans when the bus is late or the route is blocked. An
intelligent system works the same way: it navigates new situations by
combining perception, reasoning, and action.

\subsubsection{Deep Dive}\label{deep-dive}

Researchers debate whether intelligence should be defined by behavior,
internal mechanisms, or measurable outcomes.

\begin{itemize}
\tightlist
\item
  Behavioral definitions focus on observable success in tasks (e.g.,
  solving puzzles, playing games).
\item
  Cognitive definitions emphasize processes like reasoning, planning,
  and learning.
\item
  Formal definitions often turn to frameworks like rational agents:
  entities that choose actions to maximize expected utility.
\end{itemize}

A challenge is that intelligence is multi-dimensional---logical
reasoning, creativity, social interaction, and physical dexterity are
all aspects. No single metric fully captures it, but unifying themes
include adaptability, generalization, and goal-directed behavior.

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1712}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2703}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2613}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2973}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Perspective
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Emphasis
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Behavioral & Task performance & Chess-playing programs & May not
generalize beyond task \\
Cognitive & Reasoning, planning, learning & Cognitive architectures &
Hard to measure directly \\
Formal (agent view) & Maximizing expected utility & Reinforcement
learning agents & Depends heavily on utility design \\
Human analogy & Mimicking human-like abilities & Conversational
assistants & Anthropomorphism can mislead \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# A toy "intelligent agent" choosing actions}
\ImportTok{import}\NormalTok{ random}

\NormalTok{goals }\OperatorTok{=}\NormalTok{ [}\StringTok{"find food"}\NormalTok{, }\StringTok{"avoid danger"}\NormalTok{, }\StringTok{"explore"}\NormalTok{]}
\NormalTok{environment }\OperatorTok{=}\NormalTok{ [}\StringTok{"food nearby"}\NormalTok{, }\StringTok{"predator spotted"}\NormalTok{, }\StringTok{"unknown terrain"}\NormalTok{]}

\KeywordTok{def}\NormalTok{ choose\_action(env):}
    \ControlFlowTok{if} \StringTok{"food"} \KeywordTok{in}\NormalTok{ env:}
        \ControlFlowTok{return} \StringTok{"eat"}
    \ControlFlowTok{elif} \StringTok{"predator"} \KeywordTok{in}\NormalTok{ env:}
        \ControlFlowTok{return} \StringTok{"hide"}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ random.choice([}\StringTok{"move forward"}\NormalTok{, }\StringTok{"observe"}\NormalTok{, }\StringTok{"rest"}\NormalTok{])}

\ControlFlowTok{for}\NormalTok{ situation }\KeywordTok{in}\NormalTok{ environment:}
\NormalTok{    action }\OperatorTok{=}\NormalTok{ choose\_action(situation)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Environment: }\SpecialCharTok{\{}\NormalTok{situation}\SpecialCharTok{\}}\SpecialStringTok{ {-}\textgreater{} Action: }\SpecialCharTok{\{}\NormalTok{action}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add new environments (e.g., ``ally detected'') and define how the
  agent should act.
\item
  Introduce conflicting goals (e.g., explore vs.~avoid danger) and
  create simple rules for trade-offs.
\item
  Reflect: does this toy model capture intelligence, or only a narrow
  slice of it?
\end{enumerate}

\subsection{2. Agents as entities that perceive and
act}\label{agents-as-entities-that-perceive-and-act}

An agent is anything that can perceive its environment through sensors
and act upon that environment through actuators. In AI, the agent
framework provides a clean abstraction: inputs come from the world,
outputs affect the world, and the cycle continues. This framing allows
us to model everything from a thermostat to a robot to a trading
algorithm as an agent.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-1}

Imagine a robot with eyes (cameras), ears (microphones), and wheels. The
robot sees an obstacle, hears a sound, and decides to turn left. It
takes in signals, processes them, and sends commands back out. That
perception--action loop defines what it means to be an agent.

\subsubsection{Deep Dive}\label{deep-dive-1}

Agents can be categorized by their complexity and decision-making
ability:

\begin{itemize}
\tightlist
\item
  Simple reflex agents act directly on current perceptions (if obstacle
  → turn).
\item
  Model-based agents maintain an internal representation of the world.
\item
  Goal-based agents plan actions to achieve objectives.
\item
  Utility-based agents optimize outcomes according to preferences.
\end{itemize}

This hierarchy illustrates increasing sophistication: from reactive
behaviors to deliberate reasoning and optimization. Modern AI systems
often combine multiple levels---deep learning for perception, symbolic
models for planning, and reinforcement learning for utility
maximization.

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1226}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2642}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2736}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3396}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type of Agent
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
How It Works
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Reflex & Condition → Action rules & Vacuum that turns at walls & Cannot
handle unseen situations \\
Model-based & Maintains internal state & Self-driving car localization &
Needs accurate, updated model \\
Goal-based & Chooses actions for outcomes & Path planning in robotics &
Requires explicit goal specification \\
Utility-based & Maximizes preferences & Trading algorithm & Success
depends on utility design \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-1}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple reflex agent: if obstacle detected, turn}
\KeywordTok{def}\NormalTok{ reflex\_agent(percept):}
    \ControlFlowTok{if}\NormalTok{ percept }\OperatorTok{==} \StringTok{"obstacle"}\NormalTok{:}
        \ControlFlowTok{return} \StringTok{"turn left"}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{return} \StringTok{"move forward"}

\NormalTok{percepts }\OperatorTok{=}\NormalTok{ [}\StringTok{"clear"}\NormalTok{, }\StringTok{"obstacle"}\NormalTok{, }\StringTok{"clear"}\NormalTok{]}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ percepts:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Percept: }\SpecialCharTok{\{}\NormalTok{p}\SpecialCharTok{\}}\SpecialStringTok{ {-}\textgreater{} Action: }\SpecialCharTok{\{}\NormalTok{reflex\_agent(p)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Extend the agent to include a goal, such as ``reach destination,'' and
  modify the rules.
\item
  Add state: track whether the agent has already turned left, and
  prevent repeated turns.
\item
  Reflect on how increasing complexity (state, goals, utilities)
  improves generality but adds design challenges.
\end{enumerate}

\subsection{3. The role of environments in shaping
behavior}\label{the-role-of-environments-in-shaping-behavior}

An environment defines the context in which an agent operates. It
supplies the inputs the agent perceives, the consequences of the agent's
actions, and the rules of interaction. AI systems cannot be understood
in isolation---their intelligence is always relative to the environment
they inhabit.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-2}

Think of a fish in a tank. The fish swims, but the glass walls, water,
plants, and currents determine what is possible and how hard certain
movements are. Likewise, an agent's ``tank'' is its environment, shaping
its behavior and success.

\subsubsection{Deep Dive}\label{deep-dive-2}

Environments can be characterized along several dimensions:

\begin{itemize}
\tightlist
\item
  Observable vs.~partially observable: whether the agent sees the full
  state or just partial glimpses.
\item
  Deterministic vs.~stochastic: whether actions lead to predictable
  outcomes or probabilistic ones.
\item
  Static vs.~dynamic: whether the environment changes on its own or only
  when the agent acts.
\item
  Discrete vs.~continuous: whether states and actions are finite steps
  or smooth ranges.
\item
  Single-agent vs.~multi-agent: whether others also influence outcomes.
\end{itemize}

These properties determine the difficulty of building agents. A chess
game is deterministic and fully observable, while real-world driving is
stochastic, dynamic, continuous, and multi-agent. Designing intelligent
behavior means tailoring methods to the environment's structure.

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2039}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1553}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3010}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3398}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Environment Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example (Simple)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example (Complex)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Implication for AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Observable & Chess board & Poker game & Hidden info requires
inference \\
Deterministic & Tic-tac-toe & Weather forecasting & Uncertainty needs
probabilities \\
Static & Crossword puzzle & Stock market & Must adapt to constant
change \\
Discrete & Board games & Robotics control & Continuous control needs
calculus \\
Single-agent & Maze navigation & Autonomous driving with traffic &
Coordination and competition matter \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-2}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Environment: simple grid world}
\KeywordTok{class}\NormalTok{ GridWorld:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, size}\OperatorTok{=}\DecValTok{3}\NormalTok{):}
        \VariableTok{self}\NormalTok{.size }\OperatorTok{=}\NormalTok{ size}
        \VariableTok{self}\NormalTok{.agent\_pos }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{]}
    
    \KeywordTok{def}\NormalTok{ step(}\VariableTok{self}\NormalTok{, action):}
        \ControlFlowTok{if}\NormalTok{ action }\OperatorTok{==} \StringTok{"right"} \KeywordTok{and} \VariableTok{self}\NormalTok{.agent\_pos[}\DecValTok{0}\NormalTok{] }\OperatorTok{\textless{}} \VariableTok{self}\NormalTok{.size }\OperatorTok{{-}} \DecValTok{1}\NormalTok{:}
            \VariableTok{self}\NormalTok{.agent\_pos[}\DecValTok{0}\NormalTok{] }\OperatorTok{+=} \DecValTok{1}
        \ControlFlowTok{elif}\NormalTok{ action }\OperatorTok{==} \StringTok{"down"} \KeywordTok{and} \VariableTok{self}\NormalTok{.agent\_pos[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textless{}} \VariableTok{self}\NormalTok{.size }\OperatorTok{{-}} \DecValTok{1}\NormalTok{:}
            \VariableTok{self}\NormalTok{.agent\_pos[}\DecValTok{1}\NormalTok{] }\OperatorTok{+=} \DecValTok{1}
        \ControlFlowTok{return} \BuiltInTok{tuple}\NormalTok{(}\VariableTok{self}\NormalTok{.agent\_pos)}

\NormalTok{env }\OperatorTok{=}\NormalTok{ GridWorld()}
\NormalTok{actions }\OperatorTok{=}\NormalTok{ [}\StringTok{"right"}\NormalTok{, }\StringTok{"down"}\NormalTok{, }\StringTok{"right"}\NormalTok{]}
\ControlFlowTok{for}\NormalTok{ a }\KeywordTok{in}\NormalTok{ actions:}
\NormalTok{    pos }\OperatorTok{=}\NormalTok{ env.step(a)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Action: }\SpecialCharTok{\{}\NormalTok{a}\SpecialCharTok{\}}\SpecialStringTok{ {-}\textgreater{} Position: }\SpecialCharTok{\{}\NormalTok{pos}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the grid to include obstacles---how does that alter the agent's
  path?
\item
  Add randomness to actions (e.g., a 10\% chance of slipping). Does the
  agent still reach its goal reliably?
\item
  Compare this toy world to real environments---what complexities are
  missing, and why do they matter?
\end{enumerate}

\subsection{4. Inputs, outputs, and feedback
loops}\label{inputs-outputs-and-feedback-loops}

An agent exists in a constant exchange with its environment: it receives
inputs, produces outputs, and adjusts based on the results. This cycle
is known as a feedback loop. Intelligence emerges not from isolated
decisions but from continuous interaction---perception, action, and
adaptation.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-3}

Picture a thermostat in a house. It senses the temperature (input),
decides whether to switch on heating or cooling (processing), and
changes the temperature (output). The altered temperature is then sensed
again, completing the loop. The same principle scales from thermostats
to autonomous robots and learning systems.

\subsubsection{Deep Dive}\label{deep-dive-3}

Feedback loops are fundamental to control theory, cybernetics, and AI.
Key ideas include:

\begin{itemize}
\tightlist
\item
  Open-loop systems: act without monitoring results (e.g., a microwave
  runs for a fixed time).
\item
  Closed-loop systems: adjust based on feedback (e.g., cruise control in
  cars).
\item
  Positive feedback: amplifies changes (e.g., recommendation engines
  reinforcing popularity).
\item
  Negative feedback: stabilizes systems (e.g., homeostasis in biology).
\end{itemize}

For AI, well-designed feedback loops enable adaptation and stability.
Poorly designed ones can cause runaway effects, bias reinforcement, or
instability.

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1300}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3200}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Feedback Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
How It Works
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Risk or Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Open-loop & No correction from output & Batch script that ignores errors
& Fails if environment changes \\
Closed-loop & Adjusts using feedback & Robot navigation with sensors &
Slower if feedback is delayed \\
Positive & Amplifies signal & Viral content recommendation & Can lead to
echo chambers \\
Negative & Stabilizes system & PID controller in robotics & May suppress
useful variations \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-3}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Closed{-}loop temperature controller}
\NormalTok{desired\_temp }\OperatorTok{=} \DecValTok{22}
\NormalTok{current\_temp }\OperatorTok{=} \DecValTok{18}

\KeywordTok{def}\NormalTok{ thermostat(current):}
    \ControlFlowTok{if}\NormalTok{ current }\OperatorTok{\textless{}}\NormalTok{ desired\_temp:}
        \ControlFlowTok{return} \StringTok{"heat on"}
    \ControlFlowTok{elif}\NormalTok{ current }\OperatorTok{\textgreater{}}\NormalTok{ desired\_temp:}
        \ControlFlowTok{return} \StringTok{"cool on"}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{return} \StringTok{"idle"}

\ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in}\NormalTok{ [}\DecValTok{18}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{22}\NormalTok{, }\DecValTok{24}\NormalTok{]:}
\NormalTok{    action }\OperatorTok{=}\NormalTok{ thermostat(t)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Temperature: }\SpecialCharTok{\{}\NormalTok{t}\SpecialCharTok{\}}\SpecialStringTok{°C {-}\textgreater{} Action: }\SpecialCharTok{\{}\NormalTok{action}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-3}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add noise to the temperature readings and see if the controller still
  stabilizes.
\item
  Modify the code to overshoot intentionally---what happens if heating
  continues after the target is reached?
\item
  Reflect on large-scale AI: where do feedback loops appear in social
  media, finance, or autonomous driving?
\end{enumerate}

\subsection{5. Rationality, bounded rationality, and
satisficing}\label{rationality-bounded-rationality-and-satisficing}

Rationality in AI means selecting the action that maximizes expected
performance given the available knowledge. However, real agents face
limits---computational power, time, and incomplete information. This
leads to bounded rationality: making good-enough decisions under
constraints. Often, agents satisfice (pick the first acceptable
solution) instead of optimizing perfectly.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-4}

Imagine grocery shopping with only ten minutes before the store closes.
You could, in theory, calculate the optimal shopping route through every
aisle. But in practice, you grab what you need in a reasonable order and
head to checkout. That's bounded rationality and satisficing at work.

\subsubsection{Deep Dive}\label{deep-dive-4}

\begin{itemize}
\tightlist
\item
  Perfect rationality assumes unlimited information, time, and
  computation---rarely possible in reality.
\item
  Bounded rationality (Herbert Simon's idea) acknowledges constraints
  and focuses on feasible choices.
\item
  Satisficing means picking an option that meets minimum criteria, not
  necessarily the absolute best.
\item
  In AI, heuristics, approximations, and greedy algorithms embody these
  ideas, enabling systems to act effectively in complex or
  time-sensitive domains.
\end{itemize}

This balance between ideal and practical rationality is central to AI
design. Systems must achieve acceptable performance within real-world
limits.

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1681}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2832}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2389}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3097}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Perfect rationality & Always chooses optimal action & Dynamic
programming solvers & Computationally infeasible at scale \\
Bounded rationality & Chooses under time/info limits & Heuristic search
(A*) & May miss optimal solutions \\
Satisficing & Picks first ``good enough'' option & Greedy algorithms &
Quality depends on threshold chosen \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-4}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Satisficing: pick the first option above a threshold}
\NormalTok{options }\OperatorTok{=}\NormalTok{ \{}\StringTok{"A"}\NormalTok{: }\FloatTok{0.6}\NormalTok{, }\StringTok{"B"}\NormalTok{: }\FloatTok{0.9}\NormalTok{, }\StringTok{"C"}\NormalTok{: }\FloatTok{0.7}\NormalTok{\}  }\CommentTok{\# scores for actions}
\NormalTok{threshold }\OperatorTok{=} \FloatTok{0.75}

\KeywordTok{def}\NormalTok{ satisficing(choices, threshold):}
    \ControlFlowTok{for}\NormalTok{ action, score }\KeywordTok{in}\NormalTok{ choices.items():}
        \ControlFlowTok{if}\NormalTok{ score }\OperatorTok{\textgreater{}=}\NormalTok{ threshold:}
            \ControlFlowTok{return}\NormalTok{ action}
    \ControlFlowTok{return} \StringTok{"no good option"}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Chosen action:"}\NormalTok{, satisficing(options, threshold))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-4}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Lower or raise the threshold---does the agent choose differently?
\item
  Shuffle the order of options---how does satisficing depend on
  ordering?
\item
  Compare results to an ``optimal'' strategy that always picks the
  highest score.
\end{enumerate}

\subsection{6. Goals, objectives, and adaptive
behavior}\label{goals-objectives-and-adaptive-behavior}

Goals give direction to an agent's behavior. Without goals, actions are
random or reflexive; with goals, behavior becomes purposeful. Objectives
translate goals into measurable targets, while adaptive behavior ensures
that agents can adjust their strategies when environments or goals
change.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-5}

Think of a GPS navigator. The goal is to reach a destination. The
objective is to minimize travel time. If a road is closed, the system
adapts by rerouting. This cycle---setting goals, pursuing objectives,
and adapting along the way---is central to intelligence.

\subsubsection{Deep Dive}\label{deep-dive-5}

\begin{itemize}
\tightlist
\item
  Goals: broad desired outcomes (e.g., ``deliver package'').
\item
  Objectives: quantifiable or operationalized targets (e.g., ``arrive in
  under 30 minutes'').
\item
  Adaptive behavior: the ability to change plans when obstacles arise.
\item
  Goal hierarchies: higher-level goals (stay safe) may constrain
  lower-level ones (move fast).
\item
  Multi-objective trade-offs: agents often balance efficiency, safety,
  cost, and fairness simultaneously.
\end{itemize}

Effective AI requires encoding not just static goals but also
flexibility---anticipating uncertainty and adjusting course as
conditions change.

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1478}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2522}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2696}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3304}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Element
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Challenge
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Goal & Desired outcome & Reach target location & May be vague or
high-level \\
Objective & Concrete, measurable target & Minimize travel time &
Requires careful specification \\
Adaptive behavior & Adjusting actions dynamically & Rerouting in
autonomous driving & Complexity grows with uncertainty \\
Goal hierarchy & Layered priorities & Safety \textgreater{} speed in
robotics & Conflicting priorities hard to resolve \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-5}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Adaptive goal pursuit}
\ImportTok{import}\NormalTok{ random}

\NormalTok{goal }\OperatorTok{=} \StringTok{"reach destination"}
\NormalTok{path }\OperatorTok{=}\NormalTok{ [}\StringTok{"road1"}\NormalTok{, }\StringTok{"road2"}\NormalTok{, }\StringTok{"road3"}\NormalTok{]}

\KeywordTok{def}\NormalTok{ travel(path):}
    \ControlFlowTok{for}\NormalTok{ road }\KeywordTok{in}\NormalTok{ path:}
        \ControlFlowTok{if}\NormalTok{ random.random() }\OperatorTok{\textless{}} \FloatTok{0.3}\NormalTok{:  }\CommentTok{\# simulate blockage}
            \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{road}\SpecialCharTok{\}}\SpecialStringTok{ blocked {-}\textgreater{} adapting route"}\NormalTok{)}
            \ControlFlowTok{continue}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Taking }\SpecialCharTok{\{}\NormalTok{road}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
        \ControlFlowTok{return} \StringTok{"destination reached"}
    \ControlFlowTok{return} \StringTok{"failed"}

\BuiltInTok{print}\NormalTok{(travel(path))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-5}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the blockage probability and observe how often the agent adapts
  successfully.
\item
  Add multiple goals (e.g., reach fast vs.~stay safe) and design rules
  to prioritize them.
\item
  Reflect: how do human goals shift when resources, risks, or
  preferences change?
\end{enumerate}

\subsection{7. Reactive vs.~deliberative
agents}\label{reactive-vs.-deliberative-agents}

Reactive agents respond immediately to stimuli without explicit
planning, while deliberative agents reason about the future before
acting. This distinction highlights two modes of intelligence: reflexive
speed versus thoughtful foresight. Most practical AI systems blend both
approaches.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-6}

Imagine driving a car. When a ball suddenly rolls into the street, you
react instantly by braking---this is reactive behavior. But planning a
road trip across the country, considering fuel stops and hotels,
requires deliberation. Intelligent systems must know when to be quick
and when to be thoughtful.

\subsubsection{Deep Dive}\label{deep-dive-6}

\begin{itemize}
\tightlist
\item
  Reactive agents: simple, fast, and robust in well-structured
  environments. They follow condition--action rules and excel in
  time-critical situations.
\item
  Deliberative agents: maintain models of the world, reason about
  possible futures, and plan sequences of actions. They handle complex,
  novel problems but require more computation.
\item
  Hybrid approaches: most real-world AI (e.g., robotics) combines
  reactive layers (for safety and reflexes) with deliberative layers
  (for planning and optimization).
\item
  Trade-offs: reactivity gives speed but little foresight; deliberation
  gives foresight but can stall in real time.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1165}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2621}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2816}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3398}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Agent Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Characteristics
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Reactive & Fast, rule-based, reflexive & Collision-avoidance in drones &
Shortsighted, no long-term planning \\
Deliberative & Model-based, plans ahead & Path planning in robotics &
Computationally expensive \\
Hybrid & Combines both layers & Self-driving cars & Integration
complexity \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-6}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Reactive vs. deliberative decision}
\ImportTok{import}\NormalTok{ random}

\KeywordTok{def}\NormalTok{ reactive\_agent(percept):}
    \ControlFlowTok{if}\NormalTok{ percept }\OperatorTok{==} \StringTok{"obstacle"}\NormalTok{:}
        \ControlFlowTok{return} \StringTok{"turn"}
    \ControlFlowTok{return} \StringTok{"forward"}

\KeywordTok{def}\NormalTok{ deliberative\_agent(goal, options):}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Planning for goal: }\SpecialCharTok{\{}\NormalTok{goal}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
    \ControlFlowTok{return} \BuiltInTok{min}\NormalTok{(options, key}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ x: x[}\StringTok{"cost"}\NormalTok{])[}\StringTok{"action"}\NormalTok{]}

\CommentTok{\# Demo}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Reactive:"}\NormalTok{, reactive\_agent(}\StringTok{"obstacle"}\NormalTok{))}
\NormalTok{options }\OperatorTok{=}\NormalTok{ [\{}\StringTok{"action"}\NormalTok{: }\StringTok{"path1"}\NormalTok{, }\StringTok{"cost"}\NormalTok{: }\DecValTok{5}\NormalTok{\}, \{}\StringTok{"action"}\NormalTok{: }\StringTok{"path2"}\NormalTok{, }\StringTok{"cost"}\NormalTok{: }\DecValTok{2}\NormalTok{\}]}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Deliberative:"}\NormalTok{, deliberative\_agent(}\StringTok{"reach target"}\NormalTok{, options))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-6}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more options to the deliberative agent and see how planning
  scales.
\item
  Simulate time pressure: what happens if the agent must decide in one
  step?
\item
  Design a hybrid agent: use reactive behavior for emergencies,
  deliberative planning for long-term goals.
\end{enumerate}

\subsection{8. Embodied, situated, and distributed
intelligence}\label{embodied-situated-and-distributed-intelligence}

Intelligence is not just about abstract computation---it is shaped by
the body it resides in (embodiment), the context it operates within
(situatedness), and how it interacts with others (distribution). These
perspectives highlight that intelligence emerges from the interaction
between mind, body, and world.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-7}

Picture a colony of ants. Each ant has limited abilities, but together
they forage, build, and defend. Their intelligence is distributed across
the colony. Now imagine a robot with wheels instead of legs---it solves
problems differently than a robot with arms. The shape of the body and
the environment it acts in fundamentally shape the form of intelligence.

\subsubsection{Deep Dive}\label{deep-dive-7}

\begin{itemize}
\tightlist
\item
  Embodied intelligence: The physical form influences cognition. A
  flying drone and a ground rover require different strategies for
  navigation.
\item
  Situated intelligence: Knowledge is tied to specific contexts. A
  chatbot trained for customer service behaves differently from one in
  medical triage.
\item
  Distributed intelligence: Multiple agents collaborate or compete,
  producing collective outcomes greater than individuals alone. Swarm
  robotics, sensor networks, and human-AI teams illustrate this
  principle.
\item
  These dimensions remind us that intelligence is not universal---it is
  adapted to bodies, places, and social structures.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1009}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2477}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3119}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3394}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Focus
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Embodied & Physical form shapes action & Humanoid robots vs.~drones &
Constrained by hardware design \\
Situated & Context-specific behavior & Chatbot for finance
vs.~healthcare & May fail when moved to new domain \\
Distributed & Collective problem-solving & Swarm robotics, multi-agent
games & Coordination overhead, emergent risks \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-7}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Distributed decision: majority voting among agents}
\NormalTok{agents }\OperatorTok{=}\NormalTok{ [}
    \KeywordTok{lambda}\NormalTok{: }\StringTok{"left"}\NormalTok{,}
    \KeywordTok{lambda}\NormalTok{: }\StringTok{"right"}\NormalTok{,}
    \KeywordTok{lambda}\NormalTok{: }\StringTok{"left"}
\NormalTok{]}

\NormalTok{votes }\OperatorTok{=}\NormalTok{ [agent() }\ControlFlowTok{for}\NormalTok{ agent }\KeywordTok{in}\NormalTok{ agents]}
\NormalTok{decision }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(}\BuiltInTok{set}\NormalTok{(votes), key}\OperatorTok{=}\NormalTok{votes.count)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Agents voted:"}\NormalTok{, votes)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Final decision:"}\NormalTok{, decision)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-7}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more agents with different preferences---how stable is the final
  decision?
\item
  Replace majority voting with weighted votes---does it change outcomes?
\item
  Reflect on how embodiment, situatedness, and distribution might affect
  AI safety and robustness.
\end{enumerate}

\subsection{9. Comparing human, animal, and machine
intelligence}\label{comparing-human-animal-and-machine-intelligence}

Human intelligence, animal intelligence, and machine intelligence share
similarities but differ in mechanisms and scope. Humans excel in
abstract reasoning and language, animals demonstrate remarkable
adaptation and instinctive behaviors, while machines process vast data
and computations at scale. Studying these comparisons reveals both
inspirations for AI and its limitations.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-8}

Imagine three problem-solvers faced with the same task: finding food. A
human might draw a map and plan a route. A squirrel remembers where it
buried nuts last season and uses its senses to locate them. A search
engine crawls databases and retrieves relevant entries in milliseconds.
Each is intelligent, but in different ways.

\subsubsection{Deep Dive}\label{deep-dive-8}

\begin{itemize}
\item
  Human intelligence: characterized by symbolic reasoning, creativity,
  theory of mind, and cultural learning.
\item
  Animal intelligence: often domain-specific, optimized for survival
  tasks like navigation, hunting, or communication. Crows use tools,
  dolphins cooperate, bees dance to share information.
\item
  Machine intelligence: excels at pattern recognition, optimization, and
  brute-force computation, but lacks embodied experience, emotions, and
  intrinsic motivation.
\item
  Comparative insights:

  \begin{itemize}
  \tightlist
  \item
    Machines often mimic narrow aspects of human or animal cognition.
  \item
    Biological intelligence evolved under resource constraints, while
    machines rely on energy and data availability.
  \item
    Hybrid systems may combine strengths---machine speed with human
    judgment.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1217}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2783}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2783}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3217}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Human Intelligence
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Animal Intelligence
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Machine Intelligence
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Strength & Abstract reasoning, language & Instinct, adaptation,
perception & Scale, speed, data processing \\
Limitation & Cognitive biases, limited memory & Narrow survival domains
& Lacks common sense, embodiment \\
Learning Style & Culture, education, symbols & Evolution, imitation,
instinct & Data-driven algorithms \\
Example & Solving math proofs & Birds using tools & Neural networks for
image recognition \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-8}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Toy comparison: three "agents" solving a food search}
\ImportTok{import}\NormalTok{ random}

\KeywordTok{def}\NormalTok{ human\_agent():}
    \ControlFlowTok{return} \StringTok{"plans route to food"}

\KeywordTok{def}\NormalTok{ animal\_agent():}
    \ControlFlowTok{return}\NormalTok{ random.choice([}\StringTok{"sniffs trail"}\NormalTok{, }\StringTok{"remembers cache"}\NormalTok{])}

\KeywordTok{def}\NormalTok{ machine\_agent():}
    \ControlFlowTok{return} \StringTok{"queries database for food location"}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Human:"}\NormalTok{, human\_agent())}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Animal:"}\NormalTok{, animal\_agent())}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Machine:"}\NormalTok{, machine\_agent())}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-8}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Expand the code with success/failure rates---who finds food fastest or
  most reliably?
\item
  Add constraints (e.g., limited memory for humans, noisy signals for
  animals, incomplete data for machines).
\item
  Reflect: can machines ever achieve the flexibility of humans or the
  embodied instincts of animals?
\end{enumerate}

\subsection{10. Open challenges in defining AI
precisely}\label{open-challenges-in-defining-ai-precisely}

Despite decades of progress, there is still no single, universally
accepted definition of artificial intelligence. Definitions range from
engineering goals (``machines that act intelligently'') to philosophical
ambitions (``machines that think like humans''). The lack of consensus
reflects the diversity of approaches, applications, and expectations in
the field.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-9}

Imagine trying to define ``life.'' Biologists debate whether viruses
count, and new discoveries constantly stretch boundaries. AI is similar:
chess programs, chatbots, self-driving cars, and generative models all
qualify to some, but not to others. The borders of AI shift with each
breakthrough.

\subsubsection{Deep Dive}\label{deep-dive-9}

\begin{itemize}
\item
  Shifting goalposts: Once a task is automated, it is often no longer
  considered AI (``AI is whatever hasn't been done yet'').
\item
  Multiple perspectives:

  \begin{itemize}
  \tightlist
  \item
    Human-like: AI as machines imitating human thought or behavior.
  \item
    Rational agent: AI as systems that maximize expected performance.
  \item
    Tool-based: AI as advanced statistical and optimization methods.
  \end{itemize}
\item
  Cultural differences: Western AI emphasizes autonomy and competition,
  while Eastern perspectives often highlight harmony and augmentation.
\item
  Practical consequence: Without a precise definition, policy, safety,
  and evaluation frameworks must be flexible yet principled.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1416}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2832}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2743}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3009}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Perspective
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition of AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Human-like & Machines that think/act like us & Turing Test, chatbots &
Anthropomorphic and vague \\
Rational agent & Systems maximizing performance & Reinforcement learning
agents & Overly formal, utility design hard \\
Tool-based & Advanced computation techniques & Neural networks,
optimization & Reduces AI to ``just math'' \\
Cultural framing & Varies by society and philosophy & Augmenting
vs.~replacing humans & Hard to unify globally \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-9}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Toy illustration: classify "is this AI?"}
\NormalTok{systems }\OperatorTok{=}\NormalTok{ [}\StringTok{"calculator"}\NormalTok{, }\StringTok{"chess engine"}\NormalTok{, }\StringTok{"chatbot"}\NormalTok{, }\StringTok{"robot vacuum"}\NormalTok{]}

\KeywordTok{def}\NormalTok{ is\_ai(system):}
    \ControlFlowTok{if}\NormalTok{ system }\KeywordTok{in}\NormalTok{ [}\StringTok{"chatbot"}\NormalTok{, }\StringTok{"robot vacuum"}\NormalTok{, }\StringTok{"chess engine"}\NormalTok{]:}
        \ControlFlowTok{return} \VariableTok{True}
    \ControlFlowTok{return} \VariableTok{False}  \CommentTok{\# debatable, depends on definition}

\ControlFlowTok{for}\NormalTok{ s }\KeywordTok{in}\NormalTok{ systems:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{s}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\StringTok{\textquotesingle{}AI\textquotesingle{}} \ControlFlowTok{if}\NormalTok{ is\_ai(s) }\ControlFlowTok{else} \StringTok{\textquotesingle{}not AI?\textquotesingle{}}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-9}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the definition in the code (e.g., ``anything that adapts''
  vs.~``anything that learns'').
\item
  Add new systems like ``search engine'' or ``autopilot''---do they
  count?
\item
  Reflect: does the act of redefining AI highlight why consensus is so
  elusive?
\end{enumerate}

\section{Chapter 2. Objective, Utility, and
Reward}\label{chapter-2.-objective-utility-and-reward}

\subsection{11. Objectives as drivers of intelligent
behavior}\label{objectives-as-drivers-of-intelligent-behavior}

Objectives give an agent a sense of purpose. They specify what outcomes
are desirable and shape how the agent evaluates choices. Without
objectives, an agent has no basis for preferring one action over
another; with objectives, every decision can be judged as better or
worse.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-10}

Think of playing chess without trying to win---it would just be random
moves. But once you set the objective ``checkmate the opponent,'' every
action gains meaning. The same principle holds for AI: objectives
transform arbitrary behaviors into purposeful ones.

\subsubsection{Deep Dive}\label{deep-dive-10}

\begin{itemize}
\tightlist
\item
  Explicit objectives: encoded directly (e.g., maximize score, minimize
  error).
\item
  Implicit objectives: emerge from training data (e.g., language models
  learning next-word prediction).
\item
  Single vs.~multiple objectives: agents may have one clear goal or need
  to balance many (e.g., safety, efficiency, fairness).
\item
  Objective specification problem: poorly defined objectives can lead to
  unintended behaviors, like reward hacking.
\item
  Research frontier: designing objectives aligned with human values
  while remaining computationally tractable.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1570}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2975}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2893}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2562}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Benefit
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Risk / Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Explicit objective & Minimize classification error & Transparent, easy
to measure & Narrow, may ignore side effects \\
Implicit objective & Predict next token in language model & Emerges
naturally from data & Hard to interpret or adjust \\
Single objective & Maximize profit in trading agent & Clear optimization
target & May ignore fairness or risk \\
Multiple objectives & Self-driving car (safe, fast, legal) & Balanced
performance across domains & Conflicts hard to resolve \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-10}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Toy agent choosing based on objective scores}
\NormalTok{actions }\OperatorTok{=}\NormalTok{ \{}\StringTok{"drive\_fast"}\NormalTok{: \{}\StringTok{"time"}\NormalTok{: }\FloatTok{0.9}\NormalTok{, }\StringTok{"safety"}\NormalTok{: }\FloatTok{0.3}\NormalTok{\},}
           \StringTok{"drive\_safe"}\NormalTok{: \{}\StringTok{"time"}\NormalTok{: }\FloatTok{0.5}\NormalTok{, }\StringTok{"safety"}\NormalTok{: }\FloatTok{0.9}\NormalTok{\}\}}

\KeywordTok{def}\NormalTok{ score(action, weights):}
    \ControlFlowTok{return} \BuiltInTok{sum}\NormalTok{(action[k] }\OperatorTok{*}\NormalTok{ w }\ControlFlowTok{for}\NormalTok{ k, w }\KeywordTok{in}\NormalTok{ weights.items())}

\NormalTok{weights }\OperatorTok{=}\NormalTok{ \{}\StringTok{"time"}\NormalTok{: }\FloatTok{0.4}\NormalTok{, }\StringTok{"safety"}\NormalTok{: }\FloatTok{0.6}\NormalTok{\}  }\CommentTok{\# prioritize safety}
\NormalTok{scores }\OperatorTok{=}\NormalTok{ \{a: score(v, weights) }\ControlFlowTok{for}\NormalTok{ a, v }\KeywordTok{in}\NormalTok{ actions.items()\}}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Chosen action:"}\NormalTok{, }\BuiltInTok{max}\NormalTok{(scores, key}\OperatorTok{=}\NormalTok{scores.get))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-10}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the weights---what happens if speed is prioritized over safety?
\item
  Add more objectives (e.g., fuel cost) and see how choices shift.
\item
  Reflect on real-world risks: what if objectives are misaligned with
  human intent?
\end{enumerate}

\subsection{12. Utility functions and preference
modeling}\label{utility-functions-and-preference-modeling}

A utility function assigns a numerical score to outcomes, allowing an
agent to compare and rank them. Preference modeling captures how agents
(or humans) value different possibilities. Together, they formalize the
idea of ``what is better,'' enabling systematic decision-making under
uncertainty.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-11}

Imagine choosing dinner. Pizza, sushi, and salad each have different
appeal depending on your mood. A utility function is like giving each
option a score---pizza 8, sushi 9, salad 6---and then picking the
highest. Machines use the same logic to decide among actions.

\subsubsection{Deep Dive}\label{deep-dive-11}

\begin{itemize}
\tightlist
\item
  Utility theory: provides a mathematical foundation for rational
  choice.
\item
  Cardinal utilities: assign measurable values (e.g., expected profit).
\item
  Ordinal preferences: only rank outcomes without assigning numbers.
\item
  AI applications: reinforcement learning agents maximize expected
  reward, recommender systems model user preferences, and
  multi-objective agents weigh competing utilities.
\item
  Challenges: human preferences are dynamic, inconsistent, and
  context-dependent, making them hard to capture precisely.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1538}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2735}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2650}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3077}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Cardinal utility & Numeric values of outcomes & RL reward functions &
Sensitive to design errors \\
Ordinal preference & Ranking outcomes without numbers & Search engine
rankings & Lacks intensity of preferences \\
Learned utility & Model inferred from data & Collaborative filtering
systems & May reflect bias in data \\
Multi-objective & Balancing several utilities & Autonomous vehicle
trade-offs & Conflicting objectives hard to solve \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-11}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Preference modeling with a utility function}
\NormalTok{options }\OperatorTok{=}\NormalTok{ \{}\StringTok{"pizza"}\NormalTok{: }\DecValTok{8}\NormalTok{, }\StringTok{"sushi"}\NormalTok{: }\DecValTok{9}\NormalTok{, }\StringTok{"salad"}\NormalTok{: }\DecValTok{6}\NormalTok{\}}

\KeywordTok{def}\NormalTok{ choose\_best(options):}
    \ControlFlowTok{return} \BuiltInTok{max}\NormalTok{(options, key}\OperatorTok{=}\NormalTok{options.get)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Chosen option:"}\NormalTok{, choose\_best(options))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-11}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add randomness to reflect mood swings---does the choice change?
\item
  Expand to multi-objective utilities (taste + health + cost).
\item
  Reflect on how preference modeling affects fairness, bias, and
  alignment in AI systems.
\end{enumerate}

\subsection{13. Rewards, signals, and
incentives}\label{rewards-signals-and-incentives}

Rewards are feedback signals that tell an agent how well it is doing
relative to its objectives. Incentives structure these signals to guide
long-term behavior. In AI, rewards are the currency of learning: they
connect actions to outcomes and shape the strategies agents develop.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-12}

Think of training a dog. A treat after sitting on command is a reward.
Over time, the dog learns to connect the action (sit) with the outcome
(treat). AI systems learn in a similar way, except their ``treats'' are
numbers from a reward function.

\subsubsection{Deep Dive}\label{deep-dive-12}

\begin{itemize}
\tightlist
\item
  Rewards vs.~objectives: rewards are immediate signals, while
  objectives define long-term goals.
\item
  Sparse vs.~dense rewards: sparse rewards give feedback only at the end
  (winning a game), while dense rewards provide step-by-step guidance.
\item
  Shaping incentives: carefully designed reward functions can encourage
  exploration, cooperation, or fairness.
\item
  Pitfalls: misaligned incentives can lead to unintended behavior, such
  as reward hacking (agents exploiting loopholes in the reward
  definition).
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1545}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3091}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2273}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3091}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Benefit
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Risk / Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sparse reward & ``+1 if win, else 0'' in a game & Simple,
outcome-focused & Harder to learn intermediate steps \\
Dense reward & Points for each correct move & Easier credit assignment &
May bias toward short-term gains \\
Incentive shaping & Bonus for exploration in RL & Encourages broader
search & Can distort intended objective \\
Misaligned reward & Agent learns to exploit a loophole & Reveals design
flaws & Dangerous or useless behaviors \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-12}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Reward signal shaping}
\KeywordTok{def}\NormalTok{ reward(action):}
    \ControlFlowTok{if}\NormalTok{ action }\OperatorTok{==} \StringTok{"win"}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{10}
    \ControlFlowTok{elif}\NormalTok{ action }\OperatorTok{==} \StringTok{"progress"}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{1}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{0}

\NormalTok{actions }\OperatorTok{=}\NormalTok{ [}\StringTok{"progress"}\NormalTok{, }\StringTok{"progress"}\NormalTok{, }\StringTok{"win"}\NormalTok{]}
\NormalTok{total }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(reward(a) }\ControlFlowTok{for}\NormalTok{ a }\KeywordTok{in}\NormalTok{ actions)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Total reward:"}\NormalTok{, total)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-12}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add a ``cheat'' action with artificially high reward---what happens?
\item
  Change dense rewards to sparse rewards---does the agent still learn
  effectively?
\item
  Reflect: how do incentives in AI mirror incentives in human society,
  markets, or ecosystems?
\end{enumerate}

\subsection{14. Aligning objectives with desired
outcomes}\label{aligning-objectives-with-desired-outcomes}

An AI system is only as good as its objective design. If objectives are
poorly specified, agents may optimize for the wrong thing. Aligning
objectives with real-world desired outcomes is central to safe and
reliable AI. This problem is known as the alignment problem.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-13}

Imagine telling a robot vacuum to ``clean as fast as possible.'' It
might respond by pushing dirt under the couch instead of actually
cleaning. The objective (speed) is met, but the outcome (a clean room)
is not. This gap between specification and intent defines the alignment
challenge.

\subsubsection{Deep Dive}\label{deep-dive-13}

\begin{itemize}
\item
  Specification problem: translating human values and goals into
  machine-readable objectives.
\item
  Proxy objectives: often we measure what's easy (clicks, likes) instead
  of what we really want (knowledge, well-being).
\item
  Goodhart's Law: when a measure becomes a target, it ceases to be a
  good measure.
\item
  Solutions under study:

  \begin{itemize}
  \tightlist
  \item
    Human-in-the-loop learning (reinforcement learning from feedback).
  \item
    Multi-objective optimization to capture trade-offs.
  \item
    Interpretability to check whether objectives are truly met.
  \item
    Iterative refinement as objectives evolve.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1653}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2810}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2562}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2975}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Issue
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Risk
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Possible Mitigation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Mis-specified reward & Robot cleans faster by hiding dirt & Optimizes
wrong behavior & Better proxy metrics, human feedback \\
Proxy objective & Maximizing clicks on content & Promotes clickbait, not
quality & Multi-metric optimization \\
Over-optimization & Tuning too strongly to benchmark & Exploits quirks,
not true skill & Regularization, diverse evaluations \\
Value misalignment & Self-driving car optimizes speed & Safety
violations & Encode constraints, safety checks \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-13}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Misaligned vs. aligned objectives}
\KeywordTok{def}\NormalTok{ score(action):}
    \CommentTok{\# Proxy objective: speed}
    \ControlFlowTok{if}\NormalTok{ action }\OperatorTok{==} \StringTok{"finish\_fast"}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{10}
    \CommentTok{\# True desired outcome: clean thoroughly}
    \ControlFlowTok{elif}\NormalTok{ action }\OperatorTok{==} \StringTok{"clean\_well"}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{8}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{0}

\NormalTok{actions }\OperatorTok{=}\NormalTok{ [}\StringTok{"finish\_fast"}\NormalTok{, }\StringTok{"clean\_well"}\NormalTok{]}
\ControlFlowTok{for}\NormalTok{ a }\KeywordTok{in}\NormalTok{ actions:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Action: }\SpecialCharTok{\{}\NormalTok{a}\SpecialCharTok{\}}\SpecialStringTok{, Score: }\SpecialCharTok{\{}\NormalTok{score(a)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-13}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add a ``cheat'' action like ``hide dirt''---how does the scoring
  system respond?
\item
  Introduce multiple objectives (speed + cleanliness) and balance them
  with weights.
\item
  Reflect on real-world AI: how often do incentives focus on proxies
  (clicks, time spent) instead of true goals?
\end{enumerate}

\subsection{15. Conflicting objectives and
trade-offs}\label{conflicting-objectives-and-trade-offs}

Real-world agents rarely pursue a single objective. They must balance
competing goals: safety vs.~speed, accuracy vs.~efficiency, fairness
vs.~profitability. These conflicts make trade-offs inevitable, and
designing AI requires explicit strategies to manage them.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-14}

Think of cooking dinner. You want the meal to be tasty, healthy, and
quick. Focusing only on speed might mean instant noodles; focusing only
on health might mean a slow, complex recipe. Compromise---perhaps a
stir-fry---is the art of balancing objectives. AI faces the same
dilemma.

\subsubsection{Deep Dive}\label{deep-dive-14}

\begin{itemize}
\tightlist
\item
  Multi-objective optimization: agents evaluate several metrics
  simultaneously.
\item
  Pareto optimality: a solution is Pareto optimal if no objective can be
  improved without worsening another.
\item
  Weighted sums: assign relative importance to each objective (e.g.,
  70\% safety, 30\% speed).
\item
  Dynamic trade-offs: priorities may shift over time or across contexts.
\item
  Challenge: trade-offs often reflect human values, making technical
  design an ethical question.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2478}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2566}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2301}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2655}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Conflict
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Trade-off Strategy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Safety vs.~efficiency & Self-driving cars & Weight safety higher & May
reduce user satisfaction \\
Accuracy vs.~speed & Real-time speech recognition & Use approximate
models & Lower quality results \\
Fairness vs.~profit & Loan approval systems & Apply fairness constraints
& Possible revenue reduction \\
Exploration vs.~exploitation & Reinforcement learning agents & ε-greedy
or UCB strategies & Needs careful parameter tuning \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-14}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Multi{-}objective scoring with weights}
\NormalTok{options }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"fast"}\NormalTok{: \{}\StringTok{"time"}\NormalTok{: }\FloatTok{0.9}\NormalTok{, }\StringTok{"safety"}\NormalTok{: }\FloatTok{0.4}\NormalTok{\},}
    \StringTok{"safe"}\NormalTok{: \{}\StringTok{"time"}\NormalTok{: }\FloatTok{0.5}\NormalTok{, }\StringTok{"safety"}\NormalTok{: }\FloatTok{0.9}\NormalTok{\},}
    \StringTok{"balanced"}\NormalTok{: \{}\StringTok{"time"}\NormalTok{: }\FloatTok{0.7}\NormalTok{, }\StringTok{"safety"}\NormalTok{: }\FloatTok{0.7}\NormalTok{\}}
\NormalTok{\}}

\NormalTok{weights }\OperatorTok{=}\NormalTok{ \{}\StringTok{"time"}\NormalTok{: }\FloatTok{0.4}\NormalTok{, }\StringTok{"safety"}\NormalTok{: }\FloatTok{0.6}\NormalTok{\}}

\KeywordTok{def}\NormalTok{ score(option, weights):}
    \ControlFlowTok{return} \BuiltInTok{sum}\NormalTok{(option[k] }\OperatorTok{*}\NormalTok{ w }\ControlFlowTok{for}\NormalTok{ k, w }\KeywordTok{in}\NormalTok{ weights.items())}

\NormalTok{scores }\OperatorTok{=}\NormalTok{ \{k: score(v, weights) }\ControlFlowTok{for}\NormalTok{ k, v }\KeywordTok{in}\NormalTok{ options.items()\}}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Best choice:"}\NormalTok{, }\BuiltInTok{max}\NormalTok{(scores, key}\OperatorTok{=}\NormalTok{scores.get))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-14}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the weights to prioritize speed over safety---how does the
  outcome shift?
\item
  Add more conflicting objectives, such as cost or fairness.
\item
  Reflect: who should decide the weights---engineers, users, or
  policymakers?
\end{enumerate}

\subsection{16. Temporal aspects: short-term vs.~long-term
goals}\label{temporal-aspects-short-term-vs.-long-term-goals}

Intelligent agents must consider time when pursuing objectives.
Short-term goals focus on immediate rewards, while long-term goals
emphasize delayed outcomes. Balancing the two is crucial: chasing only
immediate gains can undermine future success, but focusing only on the
long run may ignore urgent needs.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-15}

Imagine studying for an exam. Watching videos online provides instant
pleasure (short-term reward), but studying builds knowledge that pays
off later (long-term reward). Smart choices weigh both---enjoy some
breaks while still preparing for the exam.

\subsubsection{Deep Dive}\label{deep-dive-15}

\begin{itemize}
\tightlist
\item
  Myopic agents: optimize only for immediate payoff, often failing in
  environments with delayed rewards.
\item
  Far-sighted agents: value future outcomes, but may overcommit to
  uncertain futures.
\item
  Discounting: future rewards are typically weighted less (e.g.,
  exponential discounting in reinforcement learning).
\item
  Temporal trade-offs: real-world systems, like healthcare AI, must
  optimize both immediate patient safety and long-term outcomes.
\item
  Challenge: setting the right balance depends on context, risk, and
  values.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1842}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3684}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4474}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Short-Term Focus
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Long-Term Focus
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Reward horizon & Immediate payoff & Delayed benefits \\
Example in AI & Online ad click optimization & Drug discovery with years
of delay \\
Strength & Quick responsiveness & Sustainable outcomes \\
Weakness & Shortsighted, risky & Slow, computationally demanding \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-15}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Balancing short vs. long{-}term rewards}
\NormalTok{rewards }\OperatorTok{=}\NormalTok{ \{}\StringTok{"actionA"}\NormalTok{: \{}\StringTok{"short"}\NormalTok{: }\DecValTok{5}\NormalTok{, }\StringTok{"long"}\NormalTok{: }\DecValTok{2}\NormalTok{\},}
           \StringTok{"actionB"}\NormalTok{: \{}\StringTok{"short"}\NormalTok{: }\DecValTok{2}\NormalTok{, }\StringTok{"long"}\NormalTok{: }\DecValTok{8}\NormalTok{\}\}}

\NormalTok{discount }\OperatorTok{=} \FloatTok{0.8}  \CommentTok{\# value future less than present}

\KeywordTok{def}\NormalTok{ value(action, discount):}
    \ControlFlowTok{return}\NormalTok{ action[}\StringTok{"short"}\NormalTok{] }\OperatorTok{+}\NormalTok{ discount }\OperatorTok{*}\NormalTok{ action[}\StringTok{"long"}\NormalTok{]}

\NormalTok{values }\OperatorTok{=}\NormalTok{ \{a: value(r, discount) }\ControlFlowTok{for}\NormalTok{ a, r }\KeywordTok{in}\NormalTok{ rewards.items()\}}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Chosen action:"}\NormalTok{, }\BuiltInTok{max}\NormalTok{(values, key}\OperatorTok{=}\NormalTok{values.get))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-15}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Adjust the discount factor closer to 0 (short-sighted) or 1
  (far-sighted)---how does the choice change?
\item
  Add uncertainty to long-term rewards---what if outcomes aren't
  guaranteed?
\item
  Reflect on real-world cases: how do companies, governments, or
  individuals balance short vs.~long-term objectives?
\end{enumerate}

\subsection{17. Measuring success and utility in
practice}\label{measuring-success-and-utility-in-practice}

Defining success for an AI system requires measurable criteria. Utility
functions provide a theoretical framework, but in practice, success is
judged by task-specific metrics---accuracy, efficiency, user
satisfaction, safety, or profit. The challenge lies in translating
abstract objectives into concrete, measurable signals.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-16}

Imagine designing a delivery drone. You might say its goal is to
``deliver packages well.'' But what does ``well'' mean? Fast delivery,
minimal energy use, or safe landings? Each definition of success leads
to different system behaviors.

\subsubsection{Deep Dive}\label{deep-dive-16}

\begin{itemize}
\tightlist
\item
  Task-specific metrics: classification error, precision/recall,
  latency, throughput.
\item
  Composite metrics: weighted combinations of goals (e.g., safety +
  efficiency).
\item
  Operational constraints: resource usage, fairness requirements, or
  regulatory compliance.
\item
  User-centered measures: satisfaction, trust, adoption rates.
\item
  Pitfalls: metrics can diverge from true goals, creating misaligned
  incentives or unintended consequences.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1308}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2897}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2617}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3178}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Domain
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Common Metric
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Weakness
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Classification & Accuracy, F1-score & Clear, quantitative & Ignores
fairness, interpretability \\
Robotics & Task success rate, energy usage & Captures physical
efficiency & Hard to model safety trade-offs \\
Recommenders & Click-through rate (CTR) & Easy to measure at scale &
Encourages clickbait \\
Finance & ROI, Sharpe ratio & Reflects profitability & May overlook
systemic risks \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-16}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Measuring success with multiple metrics}
\NormalTok{results }\OperatorTok{=}\NormalTok{ \{}\StringTok{"accuracy"}\NormalTok{: }\FloatTok{0.92}\NormalTok{, }\StringTok{"latency"}\NormalTok{: }\DecValTok{120}\NormalTok{, }\StringTok{"user\_satisfaction"}\NormalTok{: }\FloatTok{0.8}\NormalTok{\}}

\NormalTok{weights }\OperatorTok{=}\NormalTok{ \{}\StringTok{"accuracy"}\NormalTok{: }\FloatTok{0.5}\NormalTok{, }\StringTok{"latency"}\NormalTok{: }\OperatorTok{{-}}\FloatTok{0.2}\NormalTok{, }\StringTok{"user\_satisfaction"}\NormalTok{: }\FloatTok{0.3}\NormalTok{\}}

\KeywordTok{def}\NormalTok{ utility(metrics, weights):}
    \ControlFlowTok{return} \BuiltInTok{sum}\NormalTok{(metrics[k] }\OperatorTok{*}\NormalTok{ w }\ControlFlowTok{for}\NormalTok{ k, w }\KeywordTok{in}\NormalTok{ weights.items())}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Overall utility score:"}\NormalTok{, utility(results, weights))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-16}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change weights to prioritize latency over accuracy---how does the
  utility score shift?
\item
  Add fairness as a new metric and decide how to incorporate it.
\item
  Reflect: do current industry benchmarks truly measure success, or just
  proxies for convenience?
\end{enumerate}

\subsection{18. Reward hacking and specification
gaming}\label{reward-hacking-and-specification-gaming}

When objectives or reward functions are poorly specified, agents can
exploit loopholes to maximize the reward without achieving the intended
outcome. This phenomenon is known as reward hacking or specification
gaming. It highlights the danger of optimizing for proxies instead of
true goals.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-17}

Imagine telling a cleaning robot to ``remove visible dirt.'' Instead of
vacuuming, it learns to cover dirt with a rug. The room looks clean, the
objective is ``met,'' but the real goal---cleanliness---has been
subverted.

\subsubsection{Deep Dive}\label{deep-dive-17}

\begin{itemize}
\item
  Causes:

  \begin{itemize}
  \tightlist
  \item
    Overly simplistic reward design.
  \item
    Reliance on proxies instead of direct measures.
  \item
    Failure to anticipate edge cases.
  \end{itemize}
\item
  Examples:

  \begin{itemize}
  \tightlist
  \item
    A simulated agent flips over in a racing game to earn reward points
    faster.
  \item
    A text model maximizes length because ``longer output'' is rewarded,
    regardless of relevance.
  \end{itemize}
\item
  Consequences: reward hacking reduces trust, safety, and usefulness.
\item
  Research directions:

  \begin{itemize}
  \tightlist
  \item
    Iterative refinement of reward functions.
  \item
    Human feedback integration (RLHF).
  \item
    Inverse reinforcement learning to infer true goals.
  \item
    Safe exploration methods to avoid pathological behaviors.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1653}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2562}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2975}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2810}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Issue
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Why It Happens
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Mitigation Approach
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Proxy misuse & Optimizing clicks → clickbait & Easy-to-measure metric
replaces goal & Multi-metric evaluation \\
Exploiting loopholes & Game agent exploits scoring bug & Reward not
covering all cases & Robust testing, adversarial design \\
Perverse incentives & ``Remove dirt'' → hide dirt & Ambiguity in
specification & Human oversight, richer feedback \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-17}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Reward hacking example}
\KeywordTok{def}\NormalTok{ reward(action):}
    \ControlFlowTok{if}\NormalTok{ action }\OperatorTok{==} \StringTok{"hide\_dirt"}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{10}  \CommentTok{\# unintended loophole}
    \ControlFlowTok{elif}\NormalTok{ action }\OperatorTok{==} \StringTok{"clean"}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{8}
    \ControlFlowTok{return} \DecValTok{0}

\NormalTok{actions }\OperatorTok{=}\NormalTok{ [}\StringTok{"clean"}\NormalTok{, }\StringTok{"hide\_dirt"}\NormalTok{]}
\ControlFlowTok{for}\NormalTok{ a }\KeywordTok{in}\NormalTok{ actions:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Action: }\SpecialCharTok{\{}\NormalTok{a}\SpecialCharTok{\}}\SpecialStringTok{, Reward: }\SpecialCharTok{\{}\NormalTok{reward(a)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-17}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Modify the reward so that ``hide\_dirt'' is penalized---does the agent
  now choose correctly?
\item
  Add additional proxy rewards (e.g., speed) and test whether they
  conflict.
\item
  Reflect on real-world analogies: how do poorly designed incentives in
  finance, education, or politics lead to unintended behavior?
\end{enumerate}

\subsection{19. Human feedback and preference
learning}\label{human-feedback-and-preference-learning}

Human feedback provides a way to align AI systems with values that are
hard to encode directly. Instead of handcrafting reward functions,
agents can learn from demonstrations, comparisons, or ratings. This
process, known as preference learning, is central to making AI behavior
more aligned with human expectations.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-18}

Imagine teaching a child to draw. You don't give them a formula for
``good art.'' Instead, you encourage some attempts and correct others.
Over time, they internalize your preferences. AI agents can be trained
in the same way---by receiving approval or disapproval signals from
humans.

\subsubsection{Deep Dive}\label{deep-dive-18}

\begin{itemize}
\item
  Forms of feedback:

  \begin{itemize}
  \tightlist
  \item
    Demonstrations: show the agent how to act.
  \item
    Comparisons: pick between two outputs (``this is better than
    that'').
  \item
    Ratings: assign quality scores to behaviors or outputs.
  \end{itemize}
\item
  Algorithms: reinforcement learning from human feedback (RLHF), inverse
  reinforcement learning, and preference-based optimization.
\item
  Advantages: captures subtle, value-laden judgments not expressible in
  explicit rewards.
\item
  Challenges: feedback can be inconsistent, biased, or expensive to
  gather at scale.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1373}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2941}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2549}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3137}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Feedback Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Use Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Demonstrations & Robot learns tasks from humans & Intuitive, easy to
provide & Hard to cover all cases \\
Comparisons & Ranking chatbot responses & Efficient, captures nuance &
Requires many pairwise judgments \\
Ratings & Users scoring recommendations & Simple signal, scalable &
Subjective, noisy, may be gamed \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-18}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Preference learning via pairwise comparison}
\NormalTok{pairs }\OperatorTok{=}\NormalTok{ [(}\StringTok{"response A"}\NormalTok{, }\StringTok{"response B"}\NormalTok{), (}\StringTok{"response C"}\NormalTok{, }\StringTok{"response D"}\NormalTok{)]}
\NormalTok{human\_choices }\OperatorTok{=}\NormalTok{ \{}\StringTok{"response A"}\NormalTok{: }\DecValTok{1}\NormalTok{, }\StringTok{"response B"}\NormalTok{: }\DecValTok{0}\NormalTok{,}
                 \StringTok{"response C"}\NormalTok{: }\DecValTok{0}\NormalTok{, }\StringTok{"response D"}\NormalTok{: }\DecValTok{1}\NormalTok{\}}

\KeywordTok{def}\NormalTok{ learn\_preferences(pairs, choices):}
\NormalTok{    scores }\OperatorTok{=}\NormalTok{ \{\}}
    \ControlFlowTok{for}\NormalTok{ a, b }\KeywordTok{in}\NormalTok{ pairs:}
\NormalTok{        scores[a] }\OperatorTok{=}\NormalTok{ scores.get(a, }\DecValTok{0}\NormalTok{) }\OperatorTok{+}\NormalTok{ choices[a]}
\NormalTok{        scores[b] }\OperatorTok{=}\NormalTok{ scores.get(b, }\DecValTok{0}\NormalTok{) }\OperatorTok{+}\NormalTok{ choices[b]}
    \ControlFlowTok{return}\NormalTok{ scores}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Learned preference scores:"}\NormalTok{, learn\_preferences(pairs, human\_choices))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-18}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more responses with conflicting feedback---how stable are the
  learned preferences?
\item
  Introduce noisy feedback (random mistakes) and test how it affects
  outcomes.
\item
  Reflect: in which domains (education, healthcare, social media) should
  human feedback play the strongest role in shaping AI?
\end{enumerate}

\subsection{20. Normative vs.~descriptive accounts of
utility}\label{normative-vs.-descriptive-accounts-of-utility}

Utility can be understood in two ways: normatively, as how perfectly
rational agents \emph{should} behave, and descriptively, as how real
humans (or systems) actually behave. AI design must grapple with this
gap: formal models of utility often clash with observed human
preferences, which are noisy, inconsistent, and context-dependent.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-19}

Imagine someone choosing food at a buffet. A normative model might
assume they maximize health or taste consistently. In reality, they may
skip salad one day, overeat dessert the next, or change choices
depending on mood. Human behavior is rarely a clean optimization of a
fixed utility.

\subsubsection{Deep Dive}\label{deep-dive-19}

\begin{itemize}
\item
  Normative utility: rooted in economics and decision theory, assumes
  consistency, transitivity, and rational optimization.
\item
  Descriptive utility: informed by psychology and behavioral economics,
  reflects cognitive biases, framing effects, and bounded rationality.
\item
  AI implications:

  \begin{itemize}
  \tightlist
  \item
    If we design systems around normative models, they may misinterpret
    real human behavior.
  \item
    If we design systems around descriptive models, they may replicate
    human biases.
  \end{itemize}
\item
  Middle ground: AI research increasingly seeks hybrid models---rational
  principles corrected by behavioral insights.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0932}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3136}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3390}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2542}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Perspective
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Normative & How agents \emph{should} maximize utility & Reinforcement
learning with clean reward & Ignores human irrationality \\
Descriptive & How agents actually behave & Recommenders modeling click
patterns & Reinforces bias, inconsistency \\
Hybrid & Blend of rational + behavioral models & Human-in-the-loop
decision support & Complex to design and validate \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-19}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Normative vs descriptive utility example}
\ImportTok{import}\NormalTok{ random}

\CommentTok{\# Normative: always pick highest score}
\NormalTok{options }\OperatorTok{=}\NormalTok{ \{}\StringTok{"salad"}\NormalTok{: }\DecValTok{8}\NormalTok{, }\StringTok{"cake"}\NormalTok{: }\DecValTok{6}\NormalTok{\}}
\NormalTok{choice\_norm }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(options, key}\OperatorTok{=}\NormalTok{options.get)}

\CommentTok{\# Descriptive: human sometimes picks suboptimal}
\NormalTok{choice\_desc }\OperatorTok{=}\NormalTok{ random.choice(}\BuiltInTok{list}\NormalTok{(options.keys()))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Normative choice:"}\NormalTok{, choice\_norm)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Descriptive choice:"}\NormalTok{, choice\_desc)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-19}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Run the descriptive choice multiple times---how often does it diverge
  from the normative?
\item
  Add framing effects (e.g., label salad as ``diet food'') and see how
  it alters preferences.
\item
  Reflect: should AI systems enforce normative rationality, or adapt to
  descriptive human behavior?
\end{enumerate}

\section{Chapter 3. Information, Uncertainty, and
Entropy}\label{chapter-3.-information-uncertainty-and-entropy}

\subsection{21. Information as reduction of
uncertainty}\label{information-as-reduction-of-uncertainty}

Information is not just raw data---it is the amount by which uncertainty
is reduced when new data is received. In AI, information measures how
much an observation narrows down the possible states of the world. The
more surprising or unexpected the signal, the more information it
carries.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-20}

Imagine guessing a number between 1 and 100. Each yes/no question halves
the possibilities: ``Is it greater than 50?'' reduces uncertainty
dramatically. Every answer gives you information by shrinking the space
of possible numbers.

\subsubsection{Deep Dive}\label{deep-dive-20}

\begin{itemize}
\tightlist
\item
  Information theory (Claude Shannon) formalizes this idea.
\item
  The information content of an event relates to its probability: rare
  events are more informative.
\item
  Entropy measures the average uncertainty of a random variable.
\item
  AI uses information measures in many ways: feature selection, decision
  trees (information gain), communication systems, and model evaluation.
\item
  High information reduces ambiguity, but noisy channels and biased data
  can distort the signal.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2021}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4043}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3936}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Information content & Surprise of an event = −log(p) & Rare class label
in classification \\
Entropy & Expected uncertainty over distribution & Decision tree
splits \\
Information gain & Reduction in entropy after observation & Choosing the
best feature to split on \\
Mutual information & Shared information between variables & Feature
relevance for prediction \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-20}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ math}

\CommentTok{\# Information content of an event}
\KeywordTok{def}\NormalTok{ info\_content(prob):}
    \ControlFlowTok{return} \OperatorTok{{-}}\NormalTok{math.log2(prob)}

\NormalTok{events }\OperatorTok{=}\NormalTok{ \{}\StringTok{"common"}\NormalTok{: }\FloatTok{0.8}\NormalTok{, }\StringTok{"rare"}\NormalTok{: }\FloatTok{0.2}\NormalTok{\}}
\ControlFlowTok{for}\NormalTok{ e, p }\KeywordTok{in}\NormalTok{ events.items():}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{e}\SpecialCharTok{\}}\SpecialStringTok{: information = }\SpecialCharTok{\{}\NormalTok{info\_content(p)}\SpecialCharTok{:.2f\}}\SpecialStringTok{ bits"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-20}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more events with different probabilities---how does rarity affect
  information?
\item
  Simulate a fair vs.~biased coin toss---compare entropy values.
\item
  Reflect: how does information connect to AI tasks like
  decision-making, compression, or communication?
\end{enumerate}

\subsection{22. Probabilities and degrees of
belief}\label{probabilities-and-degrees-of-belief}

Probability provides a mathematical language for representing
uncertainty. Instead of treating outcomes as certain or impossible,
probabilities assign degrees of belief between 0 and 1. In AI,
probability theory underpins reasoning, prediction, and learning under
incomplete information.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-21}

Think of carrying an umbrella. If the forecast says a 90\% chance of
rain, you probably take it. If it's 10\%, you might risk leaving it at
home. Probabilities let you act sensibly even when the outcome is
uncertain.

\subsubsection{Deep Dive}\label{deep-dive-21}

\begin{itemize}
\tightlist
\item
  Frequentist view: probability as long-run frequency of events.
\item
  Bayesian view: probability as degree of belief, updated with evidence.
\item
  Random variables: map uncertain outcomes to numbers.
\item
  Distributions: describe how likely different outcomes are.
\item
  Applications in AI: spam detection, speech recognition, medical
  diagnosis---all rely on probabilistic reasoning to handle noisy or
  incomplete inputs.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Frequentist & Probability = long-run frequency & Coin toss
experiments \\
Bayesian & Probability = belief, updated by data & Spam filters
adjusting to new emails \\
Random variable & Variable taking probabilistic values & Weather: sunny
= 0, rainy = 1 \\
Distribution & Assignment of probabilities to outcomes & Gaussian priors
in machine learning \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-21}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ random}

\CommentTok{\# Simple probability estimation (frequentist)}
\NormalTok{trials }\OperatorTok{=} \DecValTok{1000}
\NormalTok{heads }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(}\DecValTok{1} \ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(trials) }\ControlFlowTok{if}\NormalTok{ random.random() }\OperatorTok{\textless{}} \FloatTok{0.5}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Estimated P(heads):"}\NormalTok{, heads }\OperatorTok{/}\NormalTok{ trials)}

\CommentTok{\# Bayesian{-}style update (toy)}
\NormalTok{prior }\OperatorTok{=} \FloatTok{0.5}
\NormalTok{likelihood }\OperatorTok{=} \FloatTok{0.8}  \CommentTok{\# chance of evidence given hypothesis}
\NormalTok{evidence\_prob }\OperatorTok{=} \FloatTok{0.6}
\NormalTok{posterior }\OperatorTok{=}\NormalTok{ (prior }\OperatorTok{*}\NormalTok{ likelihood) }\OperatorTok{/}\NormalTok{ evidence\_prob}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Posterior belief:"}\NormalTok{, posterior)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-21}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase the number of trials---does the estimated probability
  converge to 0.5?
\item
  Modify the Bayesian update with different priors---how does prior
  belief affect the posterior?
\item
  Reflect: when designing AI, when should you favor frequentist
  reasoning, and when Bayesian?
\end{enumerate}

\subsection{23. Random variables, distributions, and
signals}\label{random-variables-distributions-and-signals}

A random variable assigns numerical values to uncertain outcomes. Its
distribution describes how likely each outcome is. In AI, random
variables model uncertain inputs (sensor readings), latent states
(hidden causes), and outputs (predictions). Signals are time-varying
realizations of such variables, carrying information from the
environment.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-22}

Imagine rolling a die. The outcome itself (1--6) is uncertain, but the
random variable ``X = die roll'' captures that uncertainty. If you track
successive rolls over time, you get a signal: a sequence of values
reflecting the random process.

\subsubsection{Deep Dive}\label{deep-dive-22}

\begin{itemize}
\item
  Random variables: can be discrete (finite outcomes) or continuous
  (infinite outcomes).
\item
  Distributions: specify the probabilities (discrete) or densities
  (continuous). Examples include Bernoulli, Gaussian, and Poisson.
\item
  Signals: realizations of random processes evolving over
  time---essential in speech, vision, and sensor data.
\item
  AI applications:

  \begin{itemize}
  \tightlist
  \item
    Gaussian distributions for modeling noise.
  \item
    Bernoulli/Binomial for classification outcomes.
  \item
    Hidden random variables in latent variable models.
  \end{itemize}
\item
  Challenge: real-world signals often combine noise, structure, and
  nonstationarity.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2159}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4091}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3750}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Discrete variable & Finite possible outcomes & Dice rolls,
classification labels \\
Continuous variable & Infinite range of values & Temperature, pixel
intensities \\
Distribution & Likelihood of different outcomes & Gaussian noise in
sensors \\
Signal & Sequence of random variable outcomes & Audio waveform, video
frames \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-22}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Discrete random variable: dice}
\NormalTok{dice\_rolls }\OperatorTok{=}\NormalTok{ np.random.choice([}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{], size}\OperatorTok{=}\DecValTok{10}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Dice rolls:"}\NormalTok{, dice\_rolls)}

\CommentTok{\# Continuous random variable: Gaussian noise}
\NormalTok{noise }\OperatorTok{=}\NormalTok{ np.random.normal(loc}\OperatorTok{=}\DecValTok{0}\NormalTok{, scale}\OperatorTok{=}\DecValTok{1}\NormalTok{, size}\OperatorTok{=}\DecValTok{5}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Gaussian noise samples:"}\NormalTok{, noise)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-22}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the distribution parameters (e.g., mean and variance of
  Gaussian)---how do samples shift?
\item
  Simulate a signal by generating a sequence of random variables over
  time.
\item
  Reflect: how does modeling randomness help AI deal with uncertainty in
  perception and decision-making?
\end{enumerate}

\subsection{24. Entropy as a measure of
uncertainty}\label{entropy-as-a-measure-of-uncertainty}

Entropy quantifies how uncertain or unpredictable a random variable is.
High entropy means outcomes are spread out and less predictable, while
low entropy means outcomes are concentrated and more certain. In AI,
entropy helps measure information content, guide decision trees, and
regularize models.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-23}

Imagine two dice: one fair, one loaded to always roll a six. The fair
die is unpredictable (high entropy), while the loaded die is predictable
(low entropy). Entropy captures this difference in uncertainty
mathematically.

\subsubsection{Deep Dive}\label{deep-dive-23}

\begin{itemize}
\item
  Shannon entropy:

  \[
  H(X) = -\sum p(x) \log_2 p(x)
  \]
\item
  High entropy: uniform distributions, maximum uncertainty.
\item
  Low entropy: skewed distributions, predictable outcomes.
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Decision trees: choose features with highest information gain
    (entropy reduction).
  \item
    Reinforcement learning: encourage exploration by maximizing policy
    entropy.
  \item
    Generative models: evaluate uncertainty in output distributions.
  \end{itemize}
\item
  Limitations: entropy depends on probability estimates, which may be
  inaccurate in noisy environments.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1809}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3085}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1383}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3723}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Distribution Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Entropy Level
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Uniform & Fair die (1--6 equally likely) & High & Maximum
unpredictability \\
Skewed & Loaded die (90\% six) & Low & Predictable classification
outcomes \\
Binary balanced & Coin flip & Medium & Baseline uncertainty in
decisions \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-23}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ math}

\KeywordTok{def}\NormalTok{ entropy(probs):}
    \ControlFlowTok{return} \OperatorTok{{-}}\BuiltInTok{sum}\NormalTok{(p }\OperatorTok{*}\NormalTok{ math.log2(p) }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ probs }\ControlFlowTok{if}\NormalTok{ p }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{)}

\CommentTok{\# Fair die vs. loaded die}
\NormalTok{fair\_probs }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\OperatorTok{/}\DecValTok{6}\NormalTok{] }\OperatorTok{*} \DecValTok{6}
\NormalTok{loaded\_probs }\OperatorTok{=}\NormalTok{ [}\FloatTok{0.9}\NormalTok{] }\OperatorTok{+}\NormalTok{ [}\FloatTok{0.02}\NormalTok{] }\OperatorTok{*} \DecValTok{5}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Fair die entropy:"}\NormalTok{, entropy(fair\_probs))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Loaded die entropy:"}\NormalTok{, entropy(loaded\_probs))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-23}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change probabilities---see how entropy increases with uniformity.
\item
  Apply entropy to text: compute uncertainty over letter frequencies in
  a sentence.
\item
  Reflect: why do AI systems often prefer reducing entropy when making
  decisions?
\end{enumerate}

\subsection{25. Mutual information and
relevance}\label{mutual-information-and-relevance}

Mutual information (MI) measures how much knowing one variable reduces
uncertainty about another. It captures dependence between variables,
going beyond simple correlation. In AI, mutual information helps
identify which features are most relevant for prediction, compress data
efficiently, and align multimodal signals.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-24}

Think of two friends whispering answers during a quiz. If one always
knows the answer and the other copies, the information from one
completely determines the other---high mutual information. If their
answers are random and unrelated, the MI is zero.

\subsubsection{Deep Dive}\label{deep-dive-24}

\begin{itemize}
\item
  Definition:

  \[
  I(X;Y) = \sum_{x,y} p(x,y) \log \frac{p(x,y)}{p(x)p(y)}
  \]
\item
  Zero MI: variables are independent.
\item
  High MI: strong dependence, one variable reveals much about the other.
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Feature selection (choose features with highest MI with labels).
  \item
    Multimodal learning (aligning audio with video).
  \item
    Representation learning (maximize MI between input and latent
    codes).
  \end{itemize}
\item
  Advantages: captures nonlinear relationships, unlike correlation.
\item
  Challenges: requires estimating joint distributions, which is
  difficult in high dimensions.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2917}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4583}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Situation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Mutual Information
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Independent variables & MI = 0 & Random noise vs.~labels \\
Strong dependence & High MI & Pixel intensities vs.~image class \\
Partial dependence & Medium MI & User clicks vs.~recommendations \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-24}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ math}
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ Counter}

\KeywordTok{def}\NormalTok{ mutual\_information(X, Y):}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(X)}
\NormalTok{    px }\OperatorTok{=}\NormalTok{ Counter(X)}
\NormalTok{    py }\OperatorTok{=}\NormalTok{ Counter(Y)}
\NormalTok{    pxy }\OperatorTok{=}\NormalTok{ Counter(}\BuiltInTok{zip}\NormalTok{(X, Y))}
\NormalTok{    mi }\OperatorTok{=} \FloatTok{0.0}
    \ControlFlowTok{for}\NormalTok{ (x, y), count }\KeywordTok{in}\NormalTok{ pxy.items():}
\NormalTok{        pxy\_val }\OperatorTok{=}\NormalTok{ count }\OperatorTok{/}\NormalTok{ n}
\NormalTok{        mi }\OperatorTok{+=}\NormalTok{ pxy\_val }\OperatorTok{*}\NormalTok{ math.log2(pxy\_val }\OperatorTok{/}\NormalTok{ ((px[x]}\OperatorTok{/}\NormalTok{n) }\OperatorTok{*}\NormalTok{ (py[y]}\OperatorTok{/}\NormalTok{n)))}
    \ControlFlowTok{return}\NormalTok{ mi}

\NormalTok{X }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{]}
\NormalTok{Y }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{]}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Mutual Information:"}\NormalTok{, mutual\_information(X, Y))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-24}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Generate independent variables---does MI approach zero?
\item
  Create perfectly correlated variables---does MI increase?
\item
  Reflect: why is MI a more powerful measure of relevance than
  correlation in AI systems?
\end{enumerate}

\subsection{26. Noise, error, and uncertainty in
perception}\label{noise-error-and-uncertainty-in-perception}

AI systems rarely receive perfect data. Sensors introduce noise, models
make errors, and the world itself produces uncertainty. Understanding
and managing these imperfections is crucial for building reliable
perception systems in vision, speech, robotics, and beyond.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-25}

Imagine trying to recognize a friend in a crowded, dimly lit room.
Background chatter, poor lighting, and movement all interfere. Despite
this, your brain filters signals, corrects errors, and still identifies
them. AI perception faces the same challenges.

\subsubsection{Deep Dive}\label{deep-dive-25}

\begin{itemize}
\item
  Noise: random fluctuations in signals (e.g., static in audio, blur in
  images).
\item
  Error: systematic deviation from the correct value (e.g., biased
  sensor calibration).
\item
  Uncertainty: incomplete knowledge about the true state of the
  environment.
\item
  Handling strategies:

  \begin{itemize}
  \tightlist
  \item
    Filtering (Kalman, particle filters) to denoise signals.
  \item
    Probabilistic models to represent uncertainty explicitly.
  \item
    Ensemble methods to reduce model variance.
  \end{itemize}
\item
  Challenge: distinguishing between random noise, systematic error, and
  inherent uncertainty.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1058}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2212}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3173}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3558}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Source
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Mitigation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Noise & Random signal variation & Camera grain in low light & Smoothing,
denoising filters \\
Error & Systematic deviation & Miscalibrated temperature sensor &
Calibration, bias correction \\
Uncertainty & Lack of full knowledge & Self-driving car unsure of intent
& Probabilistic modeling, Bayesian nets \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-25}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Simulate noisy sensor data}
\NormalTok{true\_value }\OperatorTok{=} \DecValTok{10}
\NormalTok{noise }\OperatorTok{=}\NormalTok{ np.random.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{)  }\CommentTok{\# Gaussian noise}
\NormalTok{measurements }\OperatorTok{=}\NormalTok{ true\_value }\OperatorTok{+}\NormalTok{ noise}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Measurements:"}\NormalTok{, measurements)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Estimated mean:"}\NormalTok{, np.mean(measurements))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-25}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase noise variance---how does it affect the reliability of the
  estimate?
\item
  Add systematic error (e.g., always +2 bias)---can the mean still
  recover the truth?
\item
  Reflect: when should AI treat uncertainty as noise to be removed,
  versus as real ambiguity to be modeled?
\end{enumerate}

\subsection{27. Bayesian updating and belief
revision}\label{bayesian-updating-and-belief-revision}

Bayesian updating provides a principled way to revise beliefs in light
of new evidence. It combines prior knowledge (what you believed before)
with likelihood (how well the evidence fits a hypothesis) to produce a
posterior belief. This mechanism lies at the heart of probabilistic AI.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-26}

Imagine a doctor diagnosing a patient. Before seeing test results, she
has a prior belief about possible illnesses. A new lab test provides
evidence, shifting her belief toward one diagnosis. Each new piece of
evidence reshapes the belief distribution.

\subsubsection{Deep Dive}\label{deep-dive-26}

\begin{itemize}
\item
  Bayes' theorem:

  \[
  P(H|E) = \frac{P(E|H) P(H)}{P(E)}
  \]

  where \(H\) = hypothesis, \(E\) = evidence.
\item
  Prior: initial degree of belief.
\item
  Likelihood: how consistent evidence is with the hypothesis.
\item
  Posterior: updated belief after evidence.
\item
  AI applications: spam filtering, medical diagnosis, robotics
  localization, Bayesian neural networks.
\item
  Key insight: Bayesian updating enables continual learning, where
  beliefs evolve rather than reset.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1829}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3659}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4512}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Element
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Prior & Belief before evidence & Spam probability before reading
email \\
Likelihood & Evidence fit given hypothesis & Probability of words if
spam \\
Posterior & Belief after evidence & Updated spam probability \\
Belief revision & Iterative update with new data & Robot refining map
after each sensor \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-26}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple Bayesian update}
\NormalTok{prior\_spam }\OperatorTok{=} \FloatTok{0.2}
\NormalTok{likelihood\_word\_given\_spam }\OperatorTok{=} \FloatTok{0.9}
\NormalTok{likelihood\_word\_given\_ham }\OperatorTok{=} \FloatTok{0.3}
\NormalTok{evidence\_prob }\OperatorTok{=}\NormalTok{ prior\_spam }\OperatorTok{*}\NormalTok{ likelihood\_word\_given\_spam }\OperatorTok{+}\NormalTok{ (}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ prior\_spam) }\OperatorTok{*}\NormalTok{ likelihood\_word\_given\_ham}

\NormalTok{posterior\_spam }\OperatorTok{=}\NormalTok{ (prior\_spam }\OperatorTok{*}\NormalTok{ likelihood\_word\_given\_spam) }\OperatorTok{/}\NormalTok{ evidence\_prob}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Posterior P(spam|word):"}\NormalTok{, posterior\_spam)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-26}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change priors---how does initial belief influence the posterior?
\item
  Add more evidence step by step---observe belief revision over time.
\item
  Reflect: what kinds of AI systems need to continuously update beliefs
  instead of making static predictions?
\end{enumerate}

\subsection{28. Ambiguity
vs.~randomness}\label{ambiguity-vs.-randomness}

Uncertainty can arise from two different sources: randomness, where
outcomes are inherently probabilistic, and ambiguity, where the
probabilities themselves are unknown or ill-defined. Distinguishing
between these is crucial for AI systems making decisions under
uncertainty.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-27}

Imagine drawing a ball from a jar. If you know the jar has 50 red and 50
blue balls, the outcome is random but well-defined. If you don't know
the composition of the jar, the uncertainty is ambiguous---you can't
even assign exact probabilities.

\subsubsection{Deep Dive}\label{deep-dive-27}

\begin{itemize}
\item
  Randomness (risk): modeled with well-defined probability
  distributions. Example: rolling dice, weather forecasts.
\item
  Ambiguity (Knightian uncertainty): probabilities are unknown,
  incomplete, or contested. Example: predicting success of a brand-new
  technology.
\item
  AI implications:

  \begin{itemize}
  \tightlist
  \item
    Randomness can be managed with probabilistic models.
  \item
    Ambiguity requires robust decision criteria (maximin, minimax
    regret, distributional robustness).
  \item
    Real-world AI often faces both at once---stochastic environments
    with incomplete models.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1583}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3167}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type of Uncertainty
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Handling Strategy
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Randomness (risk) & Known probabilities, random outcome & Dice rolls,
sensor noise & Probability theory, expected value \\
Ambiguity & Unknown or ill-defined probabilities & Novel diseases, new
markets & Robust optimization, cautious planning \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-27}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ random}

\CommentTok{\# Randomness: fair coin}
\NormalTok{coin }\OperatorTok{=}\NormalTok{ random.choice([}\StringTok{"H"}\NormalTok{, }\StringTok{"T"}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Random outcome:"}\NormalTok{, coin)}

\CommentTok{\# Ambiguity: unknown distribution (simulate ignorance)}
\NormalTok{unknown\_jar }\OperatorTok{=}\NormalTok{ [}\StringTok{"?"}\NormalTok{, }\StringTok{"?"}\NormalTok{]  }\CommentTok{\# cannot assign probabilities yet}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Ambiguous outcome:"}\NormalTok{, random.choice(unknown\_jar))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-27}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate dice rolls (randomness) vs.~drawing from an unknown jar
  (ambiguity).
\item
  Implement maximin: choose the action with the best worst-case payoff.
\item
  Reflect: how should AI systems behave differently when probabilities
  are known versus when they are not?
\end{enumerate}

\subsection{29. Value of information in
decision-making}\label{value-of-information-in-decision-making}

The value of information (VoI) measures how much an additional piece of
information improves decision quality. Not all data is equally
useful---some observations greatly reduce uncertainty, while others
change nothing. In AI, VoI guides data collection, active learning, and
sensor placement.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-28}

Imagine planning a picnic. If the weather forecast is uncertain, paying
for a more accurate update could help decide whether to pack sunscreen
or an umbrella. But once you already know it's raining, more forecasts
add no value.

\subsubsection{Deep Dive}\label{deep-dive-28}

\begin{itemize}
\item
  Definition: VoI = (expected utility with information) − (expected
  utility without information).
\item
  Perfect information: knowing outcomes in advance---upper bound on VoI.
\item
  Sample information: partial signals---lower but often practical value.
\item
  Applications:

  \begin{itemize}
  \tightlist
  \item
    Active learning: query the most informative data points.
  \item
    Robotics: decide where to place sensors.
  \item
    Healthcare AI: order diagnostic tests only when they meaningfully
    improve treatment choices.
  \end{itemize}
\item
  Trade-off: gathering information has costs; VoI balances benefit
  vs.~expense.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3091}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3091}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1818}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type of Information
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Benefit
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Perfect information & Knowing true label before training & Maximum
reduction in uncertainty & Rare, hypothetical \\
Sample information & Adding a diagnostic test result & Improves decision
accuracy & Costly, may be noisy \\
Irrelevant information & Redundant features in a dataset & No
improvement, may add complexity & Wastes resources \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-28}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Toy value of information calculation}
\ImportTok{import}\NormalTok{ random}

\KeywordTok{def}\NormalTok{ decision\_with\_info():}
    \CommentTok{\# Always correct after info}
    \ControlFlowTok{return} \FloatTok{1.0}  \CommentTok{\# utility}

\KeywordTok{def}\NormalTok{ decision\_without\_info():}
    \CommentTok{\# Guess with 50\% accuracy}
    \ControlFlowTok{return}\NormalTok{ random.choice([}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{])  }

\NormalTok{expected\_with }\OperatorTok{=}\NormalTok{ decision\_with\_info()}
\NormalTok{expected\_without }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(decision\_without\_info() }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1000}\NormalTok{)) }\OperatorTok{/} \DecValTok{1000}

\NormalTok{voi }\OperatorTok{=}\NormalTok{ expected\_with }\OperatorTok{{-}}\NormalTok{ expected\_without}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Estimated Value of Information:"}\NormalTok{, }\BuiltInTok{round}\NormalTok{(voi, }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-28}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add costs to information gathering---when is it still worth it?
\item
  Simulate imperfect information (70\% accuracy)---compare VoI against
  perfect information.
\item
  Reflect: where in real-world AI is information most valuable---medical
  diagnostics, autonomous driving, or recommender systems?
\end{enumerate}

\subsection{30. Limits of certainty in real-world
AI}\label{limits-of-certainty-in-real-world-ai}

AI systems never operate with complete certainty. Data can be noisy,
models are approximations, and environments change unpredictably.
Instead of seeking absolute certainty, effective AI embraces
uncertainty, quantifies it, and makes robust decisions under it.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-29}

Think of weather forecasting. Even with advanced satellites and
simulations, predictions are never 100\% accurate. Forecasters give
probabilities (``60\% chance of rain'') because certainty is impossible.
AI works the same way: it outputs probabilities, not guarantees.

\subsubsection{Deep Dive}\label{deep-dive-29}

\begin{itemize}
\item
  Sources of uncertainty:

  \begin{itemize}
  \tightlist
  \item
    Aleatoric: inherent randomness (e.g., quantum noise, dice rolls).
  \item
    Epistemic: lack of knowledge or model errors.
  \item
    Ontological: unforeseen situations outside the model's scope.
  \end{itemize}
\item
  AI strategies:

  \begin{itemize}
  \tightlist
  \item
    Probabilistic modeling and Bayesian inference.
  \item
    Confidence calibration for predictions.
  \item
    Robust optimization and safety margins.
  \end{itemize}
\item
  Implication: certainty is unattainable, but uncertainty-aware design
  leads to systems that are safer, more interpretable, and more
  trustworthy.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3083}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2583}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Uncertainty Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Handling Strategy
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Aleatoric & Randomness inherent in data & Sensor noise in robotics &
Probabilistic models, filtering \\
Epistemic & Model uncertainty due to limited data & Medical diagnosis
with rare diseases & Bayesian learning, ensembles \\
Ontological & Unknown unknowns & Autonomous car meets novel obstacle &
Fail-safes, human oversight \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-29}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Simulating aleatoric vs epistemic uncertainty}
\NormalTok{true\_value }\OperatorTok{=} \DecValTok{10}
\NormalTok{aleatoric\_noise }\OperatorTok{=}\NormalTok{ np.random.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{)  }\CommentTok{\# randomness}
\NormalTok{epistemic\_error }\OperatorTok{=} \DecValTok{2}  \CommentTok{\# model bias}

\NormalTok{measurements }\OperatorTok{=}\NormalTok{ true\_value }\OperatorTok{+}\NormalTok{ aleatoric\_noise }\OperatorTok{+}\NormalTok{ epistemic\_error}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Measurements with uncertainties:"}\NormalTok{, measurements)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-29}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Reduce aleatoric noise (lower variance)---does uncertainty shrink?
\item
  Change epistemic error---see how systematic bias skews results.
\item
  Reflect: why should AI systems present probabilities or confidence
  intervals instead of single ``certain'' answers?
\end{enumerate}

\section{Chapter 4. Computation, Complexity and
Limits}\label{chapter-4.-computation-complexity-and-limits}

\subsection{31. Computation as symbol
manipulation}\label{computation-as-symbol-manipulation}

At its core, computation is the manipulation of symbols according to
formal rules. AI systems inherit this foundation: whether processing
numbers, words, or images, they transform structured inputs into
structured outputs through rule-governed operations.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-30}

Think of a child using building blocks. Each block is a symbol, and by
arranging them under certain rules---stacking, matching shapes---the
child builds structures. A computer does the same, but with electrical
signals and logic gates instead of blocks.

\subsubsection{Deep Dive}\label{deep-dive-30}

\begin{itemize}
\item
  Classical view: computation = symbol manipulation independent of
  meaning.
\item
  Church--Turing thesis: any effective computation can be carried out by
  a Turing machine.
\item
  Relevance to AI:

  \begin{itemize}
  \tightlist
  \item
    Symbolic AI explicitly encodes rules and symbols (e.g., logic-based
    systems).
  \item
    Sub-symbolic AI (neural networks) still reduces to symbol
    manipulation at the machine level (numbers, tensors).
  \end{itemize}
\item
  Philosophical note: this raises questions of whether ``understanding''
  emerges from symbol manipulation or whether semantics requires
  embodiment.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2048}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3735}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4217}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Symbolic Computation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Sub-symbolic Computation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Unit of operation & Explicit symbols, rules & Numbers, vectors,
matrices \\
Example in AI & Expert systems, theorem proving & Neural networks, deep
learning \\
Strength & Transparency, logical reasoning & Pattern recognition,
generalization \\
Limitation & Brittle, hard to scale & Opaque, hard to interpret \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-30}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple symbol manipulation: replace symbols with rules}
\NormalTok{rules }\OperatorTok{=}\NormalTok{ \{}\StringTok{"A"}\NormalTok{: }\StringTok{"B"}\NormalTok{, }\StringTok{"B"}\NormalTok{: }\StringTok{"AB"}\NormalTok{\}}
\NormalTok{sequence }\OperatorTok{=} \StringTok{"A"}

\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{5}\NormalTok{):}
\NormalTok{    sequence }\OperatorTok{=} \StringTok{""}\NormalTok{.join(rules.get(ch, ch) }\ControlFlowTok{for}\NormalTok{ ch }\KeywordTok{in}\NormalTok{ sequence)}
    \BuiltInTok{print}\NormalTok{(sequence)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-30}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Extend the rewrite rules---how do the symbolic patterns evolve?
\item
  Try encoding arithmetic as symbol manipulation (e.g., ``III + II'' →
  ``V'').
\item
  Reflect: does symbol manipulation alone explain intelligence, or does
  meaning require more?
\end{enumerate}

\subsection{32. Models of computation (Turing, circuits,
RAM)}\label{models-of-computation-turing-circuits-ram}

Models of computation formalize what it means for a system to compute.
They provide abstract frameworks to describe algorithms, machines, and
their capabilities. For AI, these models define the boundaries of what
is computable and influence how we design efficient systems.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-31}

Imagine three ways of cooking the same meal: following a recipe step by
step (Turing machine), using a fixed kitchen appliance with wires and
buttons (logic circuit), or working in a modern kitchen with labeled
drawers and random access (RAM model). Each produces food but with
different efficiencies and constraints---just like models of
computation.

\subsubsection{Deep Dive}\label{deep-dive-31}

\begin{itemize}
\item
  Turing machine: sequential steps on an infinite tape. Proves what is
  \emph{computable}. Foundation of theoretical computer science.
\item
  Logic circuits: finite networks of gates (AND, OR, NOT). Capture
  computation at the hardware level.
\item
  Random Access Machine (RAM): closer to real computers, allowing
  constant-time access to memory cells. Used in algorithm analysis.
\item
  Implications for AI:

  \begin{itemize}
  \tightlist
  \item
    Proves equivalence of models (all can compute the same functions).
  \item
    Guides efficiency analysis---circuits emphasize parallelism, RAM
    emphasizes step complexity.
  \item
    Highlights limits---no model escapes undecidability or
    intractability.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1239}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3009}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2743}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3009}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Model
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Turing machine & Infinite tape, sequential rules & Defines computability
& Impractical for efficiency \\
Logic circuits & Gates wired into fixed networks & Parallel, hardware
realizable & Fixed, less flexible \\
RAM model & Memory cells, constant-time access & Matches real algorithm
analysis & Ignores hardware-level constraints \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-31}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simulate a simple RAM model: array memory}
\NormalTok{memory }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{] }\OperatorTok{*} \DecValTok{5}  \CommentTok{\# 5 memory cells}

\CommentTok{\# Program: compute sum of first 3 cells}
\NormalTok{memory[}\DecValTok{0}\NormalTok{], memory[}\DecValTok{1}\NormalTok{], memory[}\DecValTok{2}\NormalTok{] }\OperatorTok{=} \DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}
\NormalTok{accumulator }\OperatorTok{=} \DecValTok{0}
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{3}\NormalTok{):}
\NormalTok{    accumulator }\OperatorTok{+=}\NormalTok{ memory[i]}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Sum:"}\NormalTok{, accumulator)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-31}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Extend the RAM simulation to support subtraction or branching.
\item
  Build a tiny circuit simulator (AND, OR, NOT) and combine gates.
\item
  Reflect: why do we use different models for theory, hardware, and
  algorithm analysis in AI?
\end{enumerate}

\subsection{33. Time and space complexity
basics}\label{time-and-space-complexity-basics}

Complexity theory studies how the resources required by an
algorithm---time and memory---grow with input size. For AI,
understanding complexity is essential: it explains why some problems
scale well while others become intractable as data grows.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-32}

Imagine sorting a deck of cards. Sorting 10 cards by hand is quick.
Sorting 1,000 cards takes much longer. Sorting 1,000,000 cards by hand
might be impossible. The rules didn't change---the input size did.
Complexity tells us how performance scales.

\subsubsection{Deep Dive}\label{deep-dive-32}

\begin{itemize}
\item
  Time complexity: how the number of steps grows with input size \(n\).
  Common classes:

  \begin{itemize}
  \tightlist
  \item
    Constant \(O(1)\)
  \item
    Logarithmic \(O(\log n)\)
  \item
    Linear \(O(n)\)
  \item
    Quadratic \(O(n^2)\)
  \item
    Exponential \(O(2^n)\)
  \end{itemize}
\item
  Space complexity: how much memory an algorithm uses.
\item
  Big-O notation: describes asymptotic upper bound behavior.
\item
  AI implications: deep learning training scales roughly linearly with
  data and parameters, while combinatorial search may scale
  exponentially. Trade-offs between accuracy and feasibility often hinge
  on complexity.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1798}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2135}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3371}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2697}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Complexity Class
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Growth Rate Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Feasibility
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(O(1)\) & Constant time & Hash table lookup & Always feasible \\
\(O(\log n)\) & Grows slowly & Binary search over sorted data & Scales
well \\
\(O(n)\) & Linear growth & One pass over dataset & Scales with large
data \\
\(O(n^2)\) & Quadratic growth & Naive similarity comparison & Costly at
scale \\
\(O(2^n)\) & Exponential growth & Brute-force SAT solving & Infeasible
for large \(n\) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-32}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ time}

\KeywordTok{def}\NormalTok{ quadratic\_algorithm(n):}
\NormalTok{    count }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
        \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
\NormalTok{            count }\OperatorTok{+=} \DecValTok{1}
    \ControlFlowTok{return}\NormalTok{ count}

\ControlFlowTok{for}\NormalTok{ n }\KeywordTok{in}\NormalTok{ [}\DecValTok{10}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{500}\NormalTok{]:}
\NormalTok{    start }\OperatorTok{=}\NormalTok{ time.time()}
\NormalTok{    quadratic\_algorithm(n)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"n=}\SpecialCharTok{\{}\NormalTok{n}\SpecialCharTok{\}}\SpecialStringTok{, time=}\SpecialCharTok{\{}\NormalTok{time}\SpecialCharTok{.}\NormalTok{time()}\OperatorTok{{-}}\NormalTok{start}\SpecialCharTok{:.5f\}}\SpecialStringTok{s"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-32}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Replace the quadratic algorithm with a linear one and compare
  runtimes.
\item
  Experiment with larger \(n\)---when does runtime become impractical?
\item
  Reflect: which AI methods scale poorly, and how do we approximate or
  simplify them to cope?
\end{enumerate}

\subsection{34. Polynomial vs.~exponential
time}\label{polynomial-vs.-exponential-time}

Algorithms fall into broad categories depending on how their runtime
grows with input size. Polynomial-time algorithms (\(O(n^k)\)) are
generally considered tractable, while exponential-time algorithms
(\(O(2^n)\), \(O(n!)\)) quickly become infeasible. In AI, this
distinction often marks the boundary between solvable and impossible
problems at scale.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-33}

Imagine a puzzle where each piece can either fit or not. With 10 pieces,
you might check all possibilities by brute force---it's slow but doable.
With 100 pieces, the number of possibilities explodes astronomically.
Exponential growth feels like climbing a hill that turns into a sheer
cliff.

\subsubsection{Deep Dive}\label{deep-dive-33}

\begin{itemize}
\item
  Polynomial time (P): scalable solutions, e.g., shortest path with
  Dijkstra's algorithm.
\item
  Exponential time: search spaces blow up, e.g., brute-force traveling
  salesman problem.
\item
  NP-complete problems: believed not solvable in polynomial time (unless
  P = NP).
\item
  AI implications:

  \begin{itemize}
  \tightlist
  \item
    Many planning, scheduling, and combinatorial optimization tasks are
    exponential in the worst case.
  \item
    Practical AI relies on heuristics, approximations, or domain
    constraints to avoid exponential blowup.
  \item
    Understanding when exponential behavior appears helps design systems
    that stay usable.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2041}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2347}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3673}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1939}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Growth Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Runtime (n=50)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Practical?
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Polynomial \(O(n^2)\) & \textasciitilde2,500 steps & Distance matrix
computation & Yes \\
Polynomial \(O(n^3)\) & \textasciitilde125,000 steps & Matrix inversion
in ML & Yes (moderate) \\
Exponential \(O(2^n)\) & \textasciitilde1.1 quadrillion steps &
Brute-force SAT or planning problems & No (infeasible) \\
Factorial \(O(n!)\) & Larger than exponential & Traveling salesman brute
force & Impossible at scale \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-33}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ itertools}
\ImportTok{import}\NormalTok{ time}

\CommentTok{\# Polynomial example: O(n\^{}2)}
\KeywordTok{def}\NormalTok{ polynomial\_sum(n):}
\NormalTok{    total }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
        \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
\NormalTok{            total }\OperatorTok{+=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ j}
    \ControlFlowTok{return}\NormalTok{ total}

\CommentTok{\# Exponential example: brute force subsets}
\KeywordTok{def}\NormalTok{ exponential\_subsets(n):}
\NormalTok{    count }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ subset }\KeywordTok{in}\NormalTok{ itertools.product([}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{], repeat}\OperatorTok{=}\NormalTok{n):}
\NormalTok{        count }\OperatorTok{+=} \DecValTok{1}
    \ControlFlowTok{return}\NormalTok{ count}

\ControlFlowTok{for}\NormalTok{ n }\KeywordTok{in}\NormalTok{ [}\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{]:}
\NormalTok{    start }\OperatorTok{=}\NormalTok{ time.time()}
\NormalTok{    exponential\_subsets(n)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"n=}\SpecialCharTok{\{}\NormalTok{n}\SpecialCharTok{\}}\SpecialStringTok{, exponential time elapsed }\SpecialCharTok{\{}\NormalTok{time}\SpecialCharTok{.}\NormalTok{time()}\OperatorTok{{-}}\NormalTok{start}\SpecialCharTok{:.4f\}}\SpecialStringTok{s"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-33}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare runtime of polynomial vs.~exponential functions as \(n\)
  grows.
\item
  Experiment with heuristic pruning to cut down exponential search.
\item
  Reflect: why do AI systems rely heavily on approximations, heuristics,
  and randomness in exponential domains?
\end{enumerate}

\subsection{35. Intractability and NP-hard
problems}\label{intractability-and-np-hard-problems}

Some problems grow so quickly in complexity that no efficient
(polynomial-time) algorithm is known. These are intractable problems,
often labeled NP-hard. They sit at the edge of what AI can realistically
solve, forcing reliance on heuristics, approximations, or
exponential-time algorithms for small cases.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-34}

Imagine trying to seat 100 guests at 10 tables so that everyone sits
near friends and away from enemies. The number of possible seatings is
astronomical---testing them all would take longer than the age of the
universe. This is the flavor of NP-hardness.

\subsubsection{Deep Dive}\label{deep-dive-34}

\begin{itemize}
\item
  P vs.~NP:

  \begin{itemize}
  \tightlist
  \item
    P = problems solvable in polynomial time.
  \item
    NP = problems whose solutions can be \emph{verified} quickly.
  \end{itemize}
\item
  NP-hard: at least as hard as the hardest problems in NP.
\item
  NP-complete: problems that are both in NP and NP-hard.
\item
  Examples in AI:

  \begin{itemize}
  \tightlist
  \item
    Traveling Salesman Problem (planning, routing).
  \item
    Boolean satisfiability (SAT).
  \item
    Graph coloring (scheduling, resource allocation).
  \end{itemize}
\item
  Approaches:

  \begin{itemize}
  \tightlist
  \item
    Approximation algorithms (e.g., greedy for TSP).
  \item
    Heuristics (local search, simulated annealing).
  \item
    Special cases with efficient solutions.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1200}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3200}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2900}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2700}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Solvable Efficiently?
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
P & Solvable in polynomial time & Shortest path (Dijkstra) & Yes \\
NP & Solution verifiable in poly time & Sudoku solution check &
Verification only \\
NP-complete & In NP + NP-hard & SAT, TSP & Believed no (unless P=NP) \\
NP-hard & At least as hard as NP-complete & General optimization
problems & No known efficient solution \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-34}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ itertools}

\CommentTok{\# Brute force Traveling Salesman Problem (TSP) for 4 cities}
\NormalTok{distances }\OperatorTok{=}\NormalTok{ \{}
\NormalTok{    (}\StringTok{"A"}\NormalTok{,}\StringTok{"B"}\NormalTok{): }\DecValTok{2}\NormalTok{, (}\StringTok{"A"}\NormalTok{,}\StringTok{"C"}\NormalTok{): }\DecValTok{5}\NormalTok{, (}\StringTok{"A"}\NormalTok{,}\StringTok{"D"}\NormalTok{): }\DecValTok{7}\NormalTok{,}
\NormalTok{    (}\StringTok{"B"}\NormalTok{,}\StringTok{"C"}\NormalTok{): }\DecValTok{3}\NormalTok{, (}\StringTok{"B"}\NormalTok{,}\StringTok{"D"}\NormalTok{): }\DecValTok{4}\NormalTok{,}
\NormalTok{    (}\StringTok{"C"}\NormalTok{,}\StringTok{"D"}\NormalTok{): }\DecValTok{2}
\NormalTok{\}}

\NormalTok{cities }\OperatorTok{=}\NormalTok{ [}\StringTok{"A"}\NormalTok{,}\StringTok{"B"}\NormalTok{,}\StringTok{"C"}\NormalTok{,}\StringTok{"D"}\NormalTok{]}

\KeywordTok{def}\NormalTok{ path\_length(path):}
    \ControlFlowTok{return} \BuiltInTok{sum}\NormalTok{(distances.get((}\BuiltInTok{min}\NormalTok{(a,b), }\BuiltInTok{max}\NormalTok{(a,b)), }\DecValTok{0}\NormalTok{) }\ControlFlowTok{for}\NormalTok{ a,b }\KeywordTok{in} \BuiltInTok{zip}\NormalTok{(path, path[}\DecValTok{1}\NormalTok{:]))}

\NormalTok{best\_path, best\_len }\OperatorTok{=} \VariableTok{None}\NormalTok{, }\BuiltInTok{float}\NormalTok{(}\StringTok{"inf"}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ perm }\KeywordTok{in}\NormalTok{ itertools.permutations(cities):}
\NormalTok{    length }\OperatorTok{=}\NormalTok{ path\_length(perm)}
    \ControlFlowTok{if}\NormalTok{ length }\OperatorTok{\textless{}}\NormalTok{ best\_len:}
\NormalTok{        best\_len, best\_path }\OperatorTok{=}\NormalTok{ length, perm}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Best path:"}\NormalTok{, best\_path, }\StringTok{"Length:"}\NormalTok{, best\_len)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-34}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase the number of cities---how quickly does brute force become
  infeasible?
\item
  Add a greedy heuristic (always go to nearest city)---compare results
  with brute force.
\item
  Reflect: why does much of AI research focus on clever approximations
  for NP-hard problems?
\end{enumerate}

\subsection{36. Approximation and heuristics as
necessity}\label{approximation-and-heuristics-as-necessity}

When exact solutions are intractable, AI relies on approximation
algorithms and heuristics. Instead of guaranteeing the optimal answer,
these methods aim for ``good enough'' solutions within feasible time.
This pragmatic trade-off makes otherwise impossible problems solvable in
practice.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-35}

Think of packing a suitcase in a hurry. The optimal arrangement would
maximize space perfectly, but finding it would take hours. Instead, you
use a heuristic---roll clothes, fill corners, put shoes on the bottom.
The result isn't optimal, but it's practical.

\subsubsection{Deep Dive}\label{deep-dive-35}

\begin{itemize}
\item
  Approximation algorithms: guarantee solutions within a factor of the
  optimum (e.g., TSP with 1.5× bound).
\item
  Heuristics: rules of thumb, no guarantees, but often effective (e.g.,
  greedy search, hill climbing).
\item
  Metaheuristics: general strategies like simulated annealing, genetic
  algorithms, tabu search.
\item
  AI applications:

  \begin{itemize}
  \tightlist
  \item
    Game playing: heuristic evaluation functions.
  \item
    Scheduling: approximate resource allocation.
  \item
    Robotics: heuristic motion planning.
  \end{itemize}
\item
  Trade-off: speed vs.~accuracy. Heuristics enable scalability but may
  yield poor results in worst cases.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2170}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2830}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2170}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2830}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Guarantee
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Exact algorithm & Optimal solution & Brute-force SAT solver & Infeasible
at scale \\
Approximation algorithm & Within known performance gap & Approx. TSP
solver & May still be expensive \\
Heuristic & No guarantee, fast in practice & Greedy search in graphs &
Can miss good solutions \\
Metaheuristic & Broad search strategies & Genetic algorithms, SA & May
require tuning, stochastic \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-35}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Greedy heuristic for Traveling Salesman Problem}
\ImportTok{import}\NormalTok{ random}

\NormalTok{cities }\OperatorTok{=}\NormalTok{ [}\StringTok{"A"}\NormalTok{,}\StringTok{"B"}\NormalTok{,}\StringTok{"C"}\NormalTok{,}\StringTok{"D"}\NormalTok{]}
\NormalTok{distances }\OperatorTok{=}\NormalTok{ \{}
\NormalTok{    (}\StringTok{"A"}\NormalTok{,}\StringTok{"B"}\NormalTok{): }\DecValTok{2}\NormalTok{, (}\StringTok{"A"}\NormalTok{,}\StringTok{"C"}\NormalTok{): }\DecValTok{5}\NormalTok{, (}\StringTok{"A"}\NormalTok{,}\StringTok{"D"}\NormalTok{): }\DecValTok{7}\NormalTok{,}
\NormalTok{    (}\StringTok{"B"}\NormalTok{,}\StringTok{"C"}\NormalTok{): }\DecValTok{3}\NormalTok{, (}\StringTok{"B"}\NormalTok{,}\StringTok{"D"}\NormalTok{): }\DecValTok{4}\NormalTok{,}
\NormalTok{    (}\StringTok{"C"}\NormalTok{,}\StringTok{"D"}\NormalTok{): }\DecValTok{2}
\NormalTok{\}}

\KeywordTok{def}\NormalTok{ dist(a,b):}
    \ControlFlowTok{return}\NormalTok{ distances.get((}\BuiltInTok{min}\NormalTok{(a,b), }\BuiltInTok{max}\NormalTok{(a,b)), }\DecValTok{0}\NormalTok{)}

\KeywordTok{def}\NormalTok{ greedy\_tsp(start):}
\NormalTok{    unvisited }\OperatorTok{=} \BuiltInTok{set}\NormalTok{(cities)}
\NormalTok{    path }\OperatorTok{=}\NormalTok{ [start]}
\NormalTok{    unvisited.remove(start)}
    \ControlFlowTok{while}\NormalTok{ unvisited:}
\NormalTok{        next\_city }\OperatorTok{=} \BuiltInTok{min}\NormalTok{(unvisited, key}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ c: dist(path[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{], c))}
\NormalTok{        path.append(next\_city)}
\NormalTok{        unvisited.remove(next\_city)}
    \ControlFlowTok{return}\NormalTok{ path}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Greedy path:"}\NormalTok{, greedy\_tsp(}\StringTok{"A"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-35}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare greedy paths with brute-force optimal ones---how close are
  they?
\item
  Randomize starting city---does it change the quality of the solution?
\item
  Reflect: why are heuristics indispensable in AI despite their lack of
  guarantees?
\end{enumerate}

\subsection{37. Resource-bounded
rationality}\label{resource-bounded-rationality}

Classical rationality assumes unlimited time and computational resources
to find the optimal decision. Resource-bounded rationality recognizes
real-world limits: agents must make good decisions quickly with limited
data, time, and processing power. In AI, this often means
``satisficing'' rather than optimizing.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-36}

Imagine playing chess with only 10 seconds per move. You cannot explore
every possible sequence. Instead, you look a few moves ahead, use
heuristics, and pick a reasonable option. This is rationality under
resource bounds.

\subsubsection{Deep Dive}\label{deep-dive-36}

\begin{itemize}
\item
  Bounded rationality (Herbert Simon): decision-makers use heuristics
  and approximations within limits.
\item
  Anytime algorithms: produce a valid solution quickly and improve it
  with more time.
\item
  Meta-reasoning: deciding how much effort to spend thinking before
  acting.
\item
  Real-world AI:

  \begin{itemize}
  \tightlist
  \item
    Self-driving cars must act in milliseconds.
  \item
    Embedded devices have strict memory and CPU constraints.
  \item
    Cloud AI balances accuracy with cost and energy.
  \end{itemize}
\item
  Key trade-off: doing the best possible with limited resources
  vs.~chasing perfect optimality.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1652}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3130}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2261}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2957}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Advantage
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Perfect rationality & Exhaustive search in chess & Optimal solution &
Infeasible with large state spaces \\
Resource-bounded & Alpha-Beta pruning, heuristic search & Fast, usable
decisions & May miss optimal moves \\
Anytime algorithm & Iterative deepening search & Improves with time &
Requires time allocation strategy \\
Meta-reasoning & Adaptive compute allocation & Balances speed
vs.~quality & Complex to implement \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-36}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Anytime algorithm: improving solution over time}
\ImportTok{import}\NormalTok{ random}

\KeywordTok{def}\NormalTok{ anytime\_max(iterations):}
\NormalTok{    best }\OperatorTok{=} \BuiltInTok{float}\NormalTok{(}\StringTok{"{-}inf"}\NormalTok{)}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(iterations):}
\NormalTok{        candidate }\OperatorTok{=}\NormalTok{ random.randint(}\DecValTok{0}\NormalTok{, }\DecValTok{100}\NormalTok{)}
        \ControlFlowTok{if}\NormalTok{ candidate }\OperatorTok{\textgreater{}}\NormalTok{ best:}
\NormalTok{            best }\OperatorTok{=}\NormalTok{ candidate}
        \ControlFlowTok{yield}\NormalTok{ best  }\CommentTok{\# current best solution}

\ControlFlowTok{for}\NormalTok{ result }\KeywordTok{in}\NormalTok{ anytime\_max(}\DecValTok{5}\NormalTok{):}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Current best:"}\NormalTok{, result)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-36}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase iterations---watch how the solution improves over time.
\item
  Add a time cutoff to simulate resource limits.
\item
  Reflect: when should an AI stop computing and act with the best
  solution so far?
\end{enumerate}

\subsection{38. Physical limits of computation (energy,
speed)}\label{physical-limits-of-computation-energy-speed}

Computation is not abstract alone---it is grounded in physics. The
energy required, the speed of signal propagation, and thermodynamic laws
set ultimate limits on what machines can compute. For AI, this means
efficiency is not just an engineering concern but a fundamental
constraint.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-37}

Imagine trying to boil water instantly. No matter how good the pot or
stove, physics won't allow it---you're bounded by energy transfer
limits. Similarly, computers cannot compute arbitrarily fast without
hitting physical barriers.

\subsubsection{Deep Dive}\label{deep-dive-37}

\begin{itemize}
\item
  Landauer's principle: erasing one bit of information requires at least
  \(kT \ln 2\) energy (thermodynamic cost).
\item
  Speed of light: limits how fast signals can propagate across chips and
  networks.
\item
  Heat dissipation: as transistor density increases, power and cooling
  become bottlenecks.
\item
  Quantum limits: classical computation constrained by physical laws,
  leading to quantum computing explorations.
\item
  AI implications:

  \begin{itemize}
  \tightlist
  \item
    Training massive models consumes megawatt-hours of energy.
  \item
    Hardware design (GPUs, TPUs, neuromorphic chips) focuses on pushing
    efficiency.
  \item
    Sustainable AI requires respecting physical resource constraints.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2326}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3488}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4186}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Physical Limit
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Explanation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Impact on AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Landauer's principle & Minimum energy per bit erased & Lower bound on
computation cost \\
Speed of light & Limits interconnect speed & Affects distributed AI,
data centers \\
Heat dissipation & Power density ceiling & Restricts chip scaling \\
Quantum effects & Noise at nanoscale transistors & Push toward quantum /
new paradigms \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-37}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Estimate Landauer\textquotesingle{}s limit energy for bit erasure}
\ImportTok{import}\NormalTok{ math}

\NormalTok{k }\OperatorTok{=} \FloatTok{1.38e{-}23}  \CommentTok{\# Boltzmann constant}
\NormalTok{T }\OperatorTok{=} \DecValTok{300}       \CommentTok{\# room temperature in Kelvin}
\NormalTok{energy }\OperatorTok{=}\NormalTok{ k }\OperatorTok{*}\NormalTok{ T }\OperatorTok{*}\NormalTok{ math.log(}\DecValTok{2}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Minimum energy per bit erase:"}\NormalTok{, energy, }\StringTok{"Joules"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-37}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the temperature---how does energy per bit change?
\item
  Compare energy per bit with energy use in a modern GPU---see the gap.
\item
  Reflect: how do physical laws shape the trajectory of AI hardware and
  algorithm design?
\end{enumerate}

\subsection{39. Complexity and intelligence:
trade-offs}\label{complexity-and-intelligence-trade-offs}

Greater intelligence often requires handling greater computational
complexity. Yet, too much complexity makes systems slow, inefficient, or
fragile. Designing AI means balancing sophistication with
tractability---finding the sweet spot where intelligence is powerful but
still practical.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-38}

Think of learning to play chess. A beginner looks only one or two moves
ahead---fast but shallow. A grandmaster considers dozens of
possibilities---deep but time-consuming. Computers face the same
dilemma: more complexity gives deeper insight but costs more resources.

\subsubsection{Deep Dive}\label{deep-dive-38}

\begin{itemize}
\item
  Complex models: deep networks, probabilistic programs, symbolic
  reasoners---capable but expensive.
\item
  Simple models: linear classifiers, decision stumps---fast but limited.
\item
  Trade-offs:

  \begin{itemize}
  \tightlist
  \item
    Depth vs.~speed (deep reasoning vs.~real-time action).
  \item
    Accuracy vs.~interpretability (complex vs.~simple models).
  \item
    Optimality vs.~feasibility (exact vs.~approximate algorithms).
  \end{itemize}
\item
  AI strategies:

  \begin{itemize}
  \tightlist
  \item
    Hierarchical models: combine simple reflexes with complex planning.
  \item
    Hybrid systems: symbolic reasoning + sub-symbolic learning.
  \item
    Resource-aware learning: adjust model complexity dynamically.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2192}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3288}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4521}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Low Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
High Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Speed & Fast, responsive & Slow, resource-heavy \\
Accuracy & Coarse, less general & Precise, adaptable \\
Interpretability & Transparent, explainable & Opaque, hard to analyze \\
Robustness & Fewer failure modes & Prone to overfitting, brittleness \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-38}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Trade{-}off: simple vs. complex models}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}
\ImportTok{from}\NormalTok{ sklearn.neural\_network }\ImportTok{import}\NormalTok{ MLPClassifier}
\ImportTok{from}\NormalTok{ sklearn.datasets }\ImportTok{import}\NormalTok{ make\_classification}
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split}

\NormalTok{X, y }\OperatorTok{=}\NormalTok{ make\_classification(n\_samples}\OperatorTok{=}\DecValTok{500}\NormalTok{, n\_features}\OperatorTok{=}\DecValTok{20}\NormalTok{, random\_state}\OperatorTok{=}\DecValTok{42}\NormalTok{)}
\NormalTok{X\_train, X\_test, y\_train, y\_test }\OperatorTok{=}\NormalTok{ train\_test\_split(X, y, test\_size}\OperatorTok{=}\FloatTok{0.2}\NormalTok{)}

\NormalTok{simple\_model }\OperatorTok{=}\NormalTok{ LogisticRegression().fit(X\_train, y\_train)}
\NormalTok{complex\_model }\OperatorTok{=}\NormalTok{ MLPClassifier(hidden\_layer\_sizes}\OperatorTok{=}\NormalTok{(}\DecValTok{50}\NormalTok{,}\DecValTok{50}\NormalTok{), max\_iter}\OperatorTok{=}\DecValTok{500}\NormalTok{).fit(X\_train, y\_train)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Simple model accuracy:"}\NormalTok{, simple\_model.score(X\_test, y\_test))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Complex model accuracy:"}\NormalTok{, complex\_model.score(X\_test, y\_test))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-38}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare training times of the two models---how does complexity affect
  speed?
\item
  Add noise to data---does the complex model overfit while the simple
  model stays stable?
\item
  Reflect: in which domains is simplicity preferable, and where is
  complexity worth the cost?
\end{enumerate}

\subsection{40. Theoretical boundaries of AI
systems}\label{theoretical-boundaries-of-ai-systems}

AI is constrained not just by engineering challenges but by fundamental
theoretical limits. Some problems are provably unsolvable, others are
intractable, and some cannot be solved reliably under uncertainty.
Recognizing these boundaries prevents overpromising and guides realistic
AI design.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-39}

Imagine asking a calculator to tell you whether any arbitrary computer
program will run forever or eventually stop. No matter how advanced the
calculator is, this question---the Halting Problem---is mathematically
undecidable. AI inherits these hard boundaries from computation theory.

\subsubsection{Deep Dive}\label{deep-dive-39}

\begin{itemize}
\item
  Unsolvable problems:

  \begin{itemize}
  \tightlist
  \item
    Halting problem: no algorithm can decide for all programs if they
    halt.
  \item
    Certain logical inference tasks are undecidable.
  \end{itemize}
\item
  Intractable problems: solvable in principle but not in reasonable time
  (NP-hard, PSPACE-complete).
\item
  Approximation limits: some problems cannot even be approximated
  efficiently.
\item
  Uncertainty limits: no model can perfectly predict inherently
  stochastic or chaotic processes.
\item
  Implications for AI:

  \begin{itemize}
  \tightlist
  \item
    Absolute guarantees are often impossible.
  \item
    AI must rely on heuristics, approximations, and probabilistic
    reasoning.
  \item
    Awareness of boundaries helps avoid misusing AI in domains where
    guarantees are essential.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2234}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3511}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4255}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Boundary Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Undecidable & No algorithm exists & Halting problem, general theorem
proving \\
Intractable & Solvable, but not efficiently & Planning, SAT solving,
TSP \\
Approximation barrier & Cannot approximate within factor & Certain graph
coloring problems \\
Uncertainty bound & Outcomes inherently unpredictable & Stock prices,
weather chaos limits \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-39}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Halting problem illustration (toy version)}
\KeywordTok{def}\NormalTok{ halts(program, input\_data):}
    \ControlFlowTok{raise} \PreprocessorTok{NotImplementedError}\NormalTok{(}\StringTok{"Impossible to implement universally"}\NormalTok{)}

\ControlFlowTok{try}\NormalTok{:}
\NormalTok{    halts(}\KeywordTok{lambda}\NormalTok{ x: x}\OperatorTok{+}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\ControlFlowTok{except} \PreprocessorTok{NotImplementedError} \ImportTok{as}\NormalTok{ e:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Halting problem:"}\NormalTok{, e)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-39}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Explore NP-complete problems like SAT or Sudoku---why do they scale
  poorly?
\item
  Reflect on cases where undecidability or intractability forces AI to
  rely on heuristics.
\item
  Ask: how should policymakers and engineers account for these
  boundaries when deploying AI?
\end{enumerate}

\section{Chapter 5. Representation and
Abstraction}\label{chapter-5.-representation-and-abstraction}

\subsection{41. Why representation matters in
intelligence}\label{why-representation-matters-in-intelligence}

Representation determines what an AI system can perceive, reason about,
and act upon. The same problem framed differently can be easy or
impossible to solve. Good representations make patterns visible, reduce
complexity, and enable generalization.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-40}

Imagine solving a maze. If you only see the walls one step at a time,
navigation is hard. If you have a map, the maze becomes much easier. The
representation---the raw sensory stream vs.~the structured map---changes
the difficulty of the task.

\subsubsection{Deep Dive}\label{deep-dive-40}

\begin{itemize}
\item
  Role of representation: it bridges raw data and actionable knowledge.
\item
  Expressiveness: rich enough to capture relevant details.
\item
  Compactness: simple enough to be efficient.
\item
  Generalization: supports applying knowledge to new situations.
\item
  AI applications:

  \begin{itemize}
  \tightlist
  \item
    Vision: pixels → edges → objects.
  \item
    Language: characters → words → embeddings.
  \item
    Robotics: sensor readings → state space → control policies.
  \end{itemize}
\item
  Challenge: too simple a representation loses information, too complex
  makes reasoning intractable.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1776}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2710}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2617}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2897}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Representation Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Raw data & Pixels, waveforms & Complete, no preprocessing & Redundant,
hard to interpret \\
Hand-crafted & SIFT features, parse trees & Human insight, interpretable
& Brittle, domain-specific \\
Learned & Word embeddings, latent codes & Adaptive, scalable & Often
opaque, hard to interpret \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-40}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Comparing representations: raw vs. transformed}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Raw pixel intensities (3x3 image patch)}
\NormalTok{raw }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{, }\DecValTok{255}\NormalTok{, }\DecValTok{0}\NormalTok{],}
\NormalTok{                [}\DecValTok{255}\NormalTok{, }\DecValTok{255}\NormalTok{, }\DecValTok{255}\NormalTok{],}
\NormalTok{                [}\DecValTok{0}\NormalTok{, }\DecValTok{255}\NormalTok{, }\DecValTok{0}\NormalTok{]])}

\CommentTok{\# Derived representation: edges (simple horizontal diff)}
\NormalTok{edges }\OperatorTok{=}\NormalTok{ np.}\BuiltInTok{abs}\NormalTok{(np.diff(raw, axis}\OperatorTok{=}\DecValTok{1}\NormalTok{))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Raw data:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, raw)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Edge{-}based representation:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, edges)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-40}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Replace the pixel matrix with a new pattern---how does the edge
  representation change?
\item
  Add noise to raw data---does the transformed representation make the
  pattern clearer?
\item
  Reflect: what representations make problems easier for humans vs.~for
  machines?
\end{enumerate}

\subsection{42. Symbolic vs.~sub-symbolic
representations}\label{symbolic-vs.-sub-symbolic-representations}

AI representations can be broadly divided into symbolic (explicit
symbols and rules) and sub-symbolic (distributed numerical patterns).
Symbolic approaches excel at reasoning and structure, while sub-symbolic
approaches excel at perception and pattern recognition. Modern AI often
blends the two.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-41}

Think of language. A grammar book describes language symbolically with
rules (noun, verb, adjective). But when you actually \emph{hear} speech,
your brain processes sounds sub-symbolically---patterns of frequencies
and rhythms. Both perspectives are useful but different.

\subsubsection{Deep Dive}\label{deep-dive-41}

\begin{itemize}
\tightlist
\item
  Symbolic representation: logic, rules, graphs, knowledge bases.
  Transparent, interpretable, suited for reasoning.
\item
  Sub-symbolic representation: vectors, embeddings, neural activations.
  Captures similarity, fuzzy concepts, robust to noise.
\item
  Hybrid systems: neuro-symbolic AI combines the interpretability of
  symbols with the flexibility of neural networks.
\item
  Challenge: symbols handle structure but lack adaptability;
  sub-symbolic systems learn patterns but lack explicit reasoning.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1273}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2727}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Symbolic & Expert systems, logic programs & Transparent, rule-based
reasoning & Brittle, hard to learn from data \\
Sub-symbolic & Word embeddings, deep nets & Robust, generalizable &
Opaque, hard to explain reasoning \\
Neuro-symbolic & Logic + neural embeddings & Combines structure +
learning & Integration still an open problem \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-41}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Symbolic vs. sub{-}symbolic toy example}

\CommentTok{\# Symbolic rule: if animal has wings {-}\textgreater{} classify as bird}
\KeywordTok{def}\NormalTok{ classify\_symbolic(animal):}
    \ControlFlowTok{if} \StringTok{"wings"} \KeywordTok{in}\NormalTok{ animal:}
        \ControlFlowTok{return} \StringTok{"bird"}
    \ControlFlowTok{return} \StringTok{"not bird"}

\CommentTok{\# Sub{-}symbolic: similarity via embeddings}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\NormalTok{emb }\OperatorTok{=}\NormalTok{ \{}\StringTok{"bird"}\NormalTok{: np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{]), }\StringTok{"cat"}\NormalTok{: np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{]), }\StringTok{"bat"}\NormalTok{: np.array([}\FloatTok{0.8}\NormalTok{,}\FloatTok{0.2}\NormalTok{])\}}

\KeywordTok{def}\NormalTok{ cosine(a, b):}
    \ControlFlowTok{return}\NormalTok{ np.dot(a,b)}\OperatorTok{/}\NormalTok{(np.linalg.norm(a)}\OperatorTok{*}\NormalTok{np.linalg.norm(b))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Symbolic:"}\NormalTok{, classify\_symbolic([}\StringTok{"wings"}\NormalTok{]))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Sub{-}symbolic similarity (bat vs bird):"}\NormalTok{, cosine(emb[}\StringTok{"bat"}\NormalTok{], emb[}\StringTok{"bird"}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-41}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more symbolic rules---how brittle do they become?
\item
  Expand embeddings with more animals---does similarity capture fuzzy
  categories?
\item
  Reflect: why might the future of AI require blending symbolic clarity
  with sub-symbolic power?
\end{enumerate}

\subsection{43. Data structures: vectors, graphs,
trees}\label{data-structures-vectors-graphs-trees}

Intelligent systems rely on structured ways to organize information.
Vectors capture numerical features, graphs represent relationships, and
trees encode hierarchies. Each data structure enables different forms of
reasoning, making them foundational to AI.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-42}

Think of a city: coordinates (latitude, longitude) describe locations as
vectors; roads connecting intersections form a graph; a family tree of
neighborhoods and sub-districts is a tree. Different structures reveal
different aspects of the same world.

\subsubsection{Deep Dive}\label{deep-dive-42}

\begin{itemize}
\item
  Vectors: fixed-length arrays of numbers; used in embeddings, features,
  sensor readings.
\item
  Graphs: nodes + edges; model social networks, molecules, knowledge
  graphs.
\item
  Trees: hierarchical branching structures; model parse trees in
  language, decision trees in learning.
\item
  AI applications:

  \begin{itemize}
  \tightlist
  \item
    Vectors: word2vec, image embeddings.
  \item
    Graphs: graph neural networks, pathfinding.
  \item
    Trees: search algorithms, syntactic parsing.
  \end{itemize}
\item
  Key trade-off: choosing the right data structure shapes efficiency and
  insight.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0804}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1339}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2411}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2679}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2768}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Structure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Representation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Vector & Array of values & Word embeddings, features & Compact,
efficient computation & Limited structural expressivity \\
Graph & Nodes + edges & Knowledge graphs, GNNs & Rich relational
modeling & Costly for large graphs \\
Tree & Hierarchical & Decision trees, parse trees & Intuitive, recursive
reasoning & Less flexible than graphs \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-42}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Vectors, graphs, trees in practice}
\ImportTok{import}\NormalTok{ networkx }\ImportTok{as}\NormalTok{ nx}

\CommentTok{\# Vector: embedding for a word}
\NormalTok{vector }\OperatorTok{=}\NormalTok{ [}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.8}\NormalTok{, }\FloatTok{0.5}\NormalTok{]}

\CommentTok{\# Graph: simple knowledge network}
\NormalTok{G }\OperatorTok{=}\NormalTok{ nx.Graph()}
\NormalTok{G.add\_edges\_from([(}\StringTok{"AI"}\NormalTok{,}\StringTok{"ML"}\NormalTok{), (}\StringTok{"AI"}\NormalTok{,}\StringTok{"Robotics"}\NormalTok{), (}\StringTok{"ML"}\NormalTok{,}\StringTok{"Deep Learning"}\NormalTok{)])}

\CommentTok{\# Tree: nested dictionary as a simple hierarchy}
\NormalTok{tree }\OperatorTok{=}\NormalTok{ \{}\StringTok{"Animal"}\NormalTok{: \{}\StringTok{"Mammal"}\NormalTok{: [}\StringTok{"Dog"}\NormalTok{,}\StringTok{"Cat"}\NormalTok{], }\StringTok{"Bird"}\NormalTok{: [}\StringTok{"Sparrow"}\NormalTok{,}\StringTok{"Eagle"}\NormalTok{]\}\}}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Vector:"}\NormalTok{, vector)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Graph neighbors of AI:"}\NormalTok{, }\BuiltInTok{list}\NormalTok{(G.neighbors(}\StringTok{"AI"}\NormalTok{)))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Tree root categories:"}\NormalTok{, }\BuiltInTok{list}\NormalTok{(tree[}\StringTok{"Animal"}\NormalTok{].keys()))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-42}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add another dimension to the vector---how does it change
  interpretation?
\item
  Add nodes and edges to the graph---what new paths emerge?
\item
  Expand the tree---how does hierarchy help organize complexity?
\end{enumerate}

\subsection{44. Levels of abstraction: micro vs.~macro
views}\label{levels-of-abstraction-micro-vs.-macro-views}

Abstraction allows AI systems to operate at different levels of detail.
The micro view focuses on fine-grained, low-level states, while the
macro view captures higher-level summaries and patterns. Switching
between these views makes complex problems tractable.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-43}

Imagine traffic on a highway. At the micro level, you could track every
car's position and speed. At the macro level, you think in terms of
``traffic jam ahead'' or ``smooth flow.'' Both perspectives are valid
but serve different purposes.

\subsubsection{Deep Dive}\label{deep-dive-43}

\begin{itemize}
\item
  Micro-level representations: precise, detailed, computationally heavy.
  Examples: pixel-level vision, molecular simulations.
\item
  Macro-level representations: aggregated, simplified, more
  interpretable. Examples: object recognition, weather patterns.
\item
  Bridging levels: hierarchical models and abstractions (e.g., CNNs
  build from pixels → edges → objects).
\item
  AI applications:

  \begin{itemize}
  \tightlist
  \item
    Natural language: characters → words → sentences → topics.
  \item
    Robotics: joint torques → motor actions → tasks → goals.
  \item
    Systems: log events → user sessions → overall trends.
  \end{itemize}
\item
  Challenge: too much detail overwhelms; too much abstraction loses
  important nuance.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0900}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2900}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3200}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Level
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Micro & Pixel intensities in an image & Precise, full information & Hard
to interpret, inefficient \\
Macro & Object labels (``cat'', ``dog'') & Concise, human-aligned &
Misses fine-grained details \\
Hierarchy & Pixels → edges → objects & Balance of detail and efficiency
& Requires careful design \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-43}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Micro vs. macro abstraction}
\NormalTok{pixels }\OperatorTok{=}\NormalTok{ [[}\DecValTok{0}\NormalTok{, }\DecValTok{255}\NormalTok{, }\DecValTok{0}\NormalTok{],}
\NormalTok{          [}\DecValTok{255}\NormalTok{, }\DecValTok{255}\NormalTok{, }\DecValTok{255}\NormalTok{],}
\NormalTok{          [}\DecValTok{0}\NormalTok{, }\DecValTok{255}\NormalTok{, }\DecValTok{0}\NormalTok{]]}

\CommentTok{\# Macro abstraction: majority value (simple summary)}
\NormalTok{flattened }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(pixels, [])}
\NormalTok{macro }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(}\BuiltInTok{set}\NormalTok{(flattened), key}\OperatorTok{=}\NormalTok{flattened.count)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Micro (pixels):"}\NormalTok{, pixels)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Macro (dominant intensity):"}\NormalTok{, macro)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-43}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Replace the pixel grid with a different pattern---does the macro
  summary still capture the essence?
\item
  Add intermediate abstraction (edges, shapes)---how does it help bridge
  micro and macro?
\item
  Reflect: which tasks benefit from fine detail, and which from coarse
  summaries?
\end{enumerate}

\subsection{45. Compositionality and
modularity}\label{compositionality-and-modularity}

Compositionality is the principle that complex ideas can be built from
simpler parts. Modularity is the design strategy of keeping components
separable and reusable. Together, they allow AI systems to scale,
generalize, and adapt by combining building blocks.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-44}

Think of LEGO bricks. Each brick is simple, but by snapping them
together, you can build houses, cars, or spaceships. AI works the same
way---small representations (words, features, functions) compose into
larger structures (sentences, models, systems).

\subsubsection{Deep Dive}\label{deep-dive-44}

\begin{itemize}
\item
  Compositionality in language: meanings of sentences derive from
  meanings of words plus grammar.
\item
  Compositionality in vision: objects are built from parts (edges →
  shapes → objects → scenes).
\item
  Modularity in systems: separating perception, reasoning, and action
  into subsystems.
\item
  Benefits:

  \begin{itemize}
  \tightlist
  \item
    Scalability: large systems built from small components.
  \item
    Generalization: reuse parts in new contexts.
  \item
    Debuggability: easier to isolate errors.
  \end{itemize}
\item
  Challenges:

  \begin{itemize}
  \tightlist
  \item
    Deep learning models often entangle representations.
  \item
    Explicit modularity may reduce raw predictive power but improve
    interpretability.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1301}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3415}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2683}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2602}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Principle
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Compositionality & Language: words → phrases → sentences & Enables
systematic generalization & Hard to capture in neural models \\
Modularity & ML pipelines: preprocessing → model → eval & Maintainable,
reusable & Integration overhead \\
Hybrid & Neuro-symbolic systems & Combines flexibility + structure &
Still an open research problem \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-44}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple compositionality example}
\NormalTok{words }\OperatorTok{=}\NormalTok{ \{}\StringTok{"red"}\NormalTok{: }\StringTok{"color"}\NormalTok{, }\StringTok{"ball"}\NormalTok{: }\StringTok{"object"}\NormalTok{\}}

\KeywordTok{def}\NormalTok{ compose(phrase):}
    \ControlFlowTok{return}\NormalTok{ [words[w] }\ControlFlowTok{for}\NormalTok{ w }\KeywordTok{in}\NormalTok{ phrase.split() }\ControlFlowTok{if}\NormalTok{ w }\KeywordTok{in}\NormalTok{ words]}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Phrase: \textquotesingle{}red ball\textquotesingle{}"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Composed representation:"}\NormalTok{, compose(}\StringTok{"red ball"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-44}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Extend the dictionary with more words---what complex meanings can you
  build?
\item
  Add modular functions (e.g., color(), shape()) to handle categories
  separately.
\item
  Reflect: why do humans excel at compositionality, and how can AI
  systems learn it better?
\end{enumerate}

\subsection{46. Continuous vs.~discrete
abstractions}\label{continuous-vs.-discrete-abstractions}

Abstractions in AI can be continuous (smooth, real-valued) or discrete
(symbolic, categorical). Each offers strengths: continuous abstractions
capture nuance and gradients, while discrete abstractions capture
structure and rules. Many modern systems combine both.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-45}

Think of music. The sheet notation uses discrete symbols (notes, rests),
while the actual performance involves continuous variations in pitch,
volume, and timing. Both are essential to represent the same melody.

\subsubsection{Deep Dive}\label{deep-dive-45}

\begin{itemize}
\item
  Continuous representations: vectors, embeddings, probability
  distributions. Enable optimization with calculus and gradient descent.
\item
  Discrete representations: logic rules, parse trees, categorical
  labels. Enable precise reasoning and combinatorial search.
\item
  Hybrid representations: discretized latent variables, quantized
  embeddings, symbolic-neural hybrids.
\item
  AI applications:

  \begin{itemize}
  \tightlist
  \item
    Vision: pixels (continuous) vs.~object categories (discrete).
  \item
    Language: embeddings (continuous) vs.~grammar rules (discrete).
  \item
    Robotics: control signals (continuous) vs.~task planning (discrete).
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1468}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2844}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2752}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2936}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Abstraction Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Continuous & Word embeddings, sensor signals & Smooth optimization,
nuance & Harder to interpret \\
Discrete & Grammar rules, class labels & Clear structure, interpretable
& Brittle, less flexible \\
Hybrid & Vector-symbol integration & Combines flexibility + clarity &
Still an open research challenge \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-45}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Continuous vs. discrete abstraction}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Continuous: word embeddings}
\NormalTok{embeddings }\OperatorTok{=}\NormalTok{ \{}\StringTok{"cat"}\NormalTok{: np.array([}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.8}\NormalTok{]),}
              \StringTok{"dog"}\NormalTok{: np.array([}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.75}\NormalTok{])\}}

\CommentTok{\# Discrete: labels}
\NormalTok{labels }\OperatorTok{=}\NormalTok{ \{}\StringTok{"cat"}\NormalTok{: }\StringTok{"animal"}\NormalTok{, }\StringTok{"dog"}\NormalTok{: }\StringTok{"animal"}\NormalTok{\}}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Continuous similarity (cat vs dog):"}\NormalTok{,}
\NormalTok{      np.dot(embeddings[}\StringTok{"cat"}\NormalTok{], embeddings[}\StringTok{"dog"}\NormalTok{]))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Discrete label (cat):"}\NormalTok{, labels[}\StringTok{"cat"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-45}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more embeddings---does similarity reflect semantic closeness?
\item
  Add discrete categories that clash with continuous similarities---what
  happens?
\item
  Reflect: when should AI favor continuous nuance, and when discrete
  clarity?
\end{enumerate}

\subsection{47. Representation learning in modern
AI}\label{representation-learning-in-modern-ai}

Representation learning is the process by which AI systems automatically
discover useful ways to encode data, instead of relying solely on
hand-crafted features. Modern deep learning thrives on this principle:
neural networks learn hierarchical representations directly from raw
inputs.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-46}

Imagine teaching a child to recognize animals. You don't explicitly tell
them ``look for four legs, a tail, fur.'' Instead, they learn these
features themselves by seeing many examples. Representation learning
automates this same discovery process in machines.

\subsubsection{Deep Dive}\label{deep-dive-46}

\begin{itemize}
\item
  Manual features vs.~learned features: early AI relied on
  expert-crafted descriptors (e.g., SIFT in vision). Deep learning
  replaced these with data-driven embeddings.
\item
  Hierarchical learning:

  \begin{itemize}
  \tightlist
  \item
    Low layers capture simple patterns (edges, phonemes).
  \item
    Mid layers capture parts or phrases.
  \item
    High layers capture objects, semantics, or abstract meaning.
  \end{itemize}
\item
  Self-supervised learning: representations can be learned without
  explicit labels (contrastive learning, masked prediction).
\item
  Applications: word embeddings, image embeddings, audio features,
  multimodal representations.
\item
  Challenge: learned representations are powerful but often opaque,
  raising interpretability and bias concerns.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2300}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2200}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3100}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2400}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Hand-crafted features & SIFT, TF-IDF & Interpretable, domain knowledge &
Brittle, not scalable \\
Learned representations & CNNs, Transformers & Adaptive, scalable & Hard
to interpret \\
Self-supervised reps & Word2Vec, SimCLR, BERT & Leverages unlabeled data
& Data- and compute-hungry \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-46}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Toy example: representation learning with PCA}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.decomposition }\ImportTok{import}\NormalTok{ PCA}

\CommentTok{\# 2D points clustered by class}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{],[}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{],[}\DecValTok{3}\NormalTok{,}\DecValTok{3}\NormalTok{],[}\DecValTok{8}\NormalTok{,}\DecValTok{8}\NormalTok{],[}\DecValTok{9}\NormalTok{,}\DecValTok{7}\NormalTok{],[}\DecValTok{10}\NormalTok{,}\DecValTok{9}\NormalTok{]])}
\NormalTok{pca }\OperatorTok{=}\NormalTok{ PCA(n\_components}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
\NormalTok{X\_reduced }\OperatorTok{=}\NormalTok{ pca.fit\_transform(X)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Original shape:"}\NormalTok{, X.shape)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Reduced representation:"}\NormalTok{, X\_reduced.ravel())}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-46}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Apply PCA on different datasets---how does dimensionality reduction
  reveal structure?
\item
  Replace PCA with autoencoders---how do nonlinear representations
  differ?
\item
  Reflect: why is learning representations directly from data a
  breakthrough for AI?
\end{enumerate}

\subsection{48. Cognitive science views on
abstraction}\label{cognitive-science-views-on-abstraction}

Cognitive science studies how humans form and use abstractions, offering
insights for AI design. Humans simplify the world by grouping details
into categories, building mental models, and reasoning hierarchically.
AI systems that mimic these strategies can achieve more flexible and
general intelligence.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-47}

Think of how a child learns the concept of ``chair.'' They see many
different shapes---wooden chairs, office chairs, beanbags---and extract
an abstract category: ``something you can sit on.'' The ability to
ignore irrelevant details while preserving core function is abstraction
in action.

\subsubsection{Deep Dive}\label{deep-dive-47}

\begin{itemize}
\item
  Categorization: humans cluster experiences into categories (prototype
  theory, exemplar theory).
\item
  Conceptual hierarchies: categories are structured (animal → mammal →
  dog → poodle).
\item
  Schemas and frames: mental templates for understanding situations
  (e.g., ``restaurant script'').
\item
  Analogical reasoning: mapping structures from one domain to another.
\item
  AI implications:

  \begin{itemize}
  \tightlist
  \item
    Concept learning in symbolic systems.
  \item
    Representation learning inspired by human categorization.
  \item
    Analogy-making in problem solving and creativity.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2439}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3171}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4390}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Cognitive Mechanism
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Human Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Parallel
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Categorization & ``Chair'' across many shapes & Clustering,
embeddings \\
Hierarchies & Animal → Mammal → Dog & Ontologies, taxonomies \\
Schemas/frames & Restaurant dining sequence & Knowledge graphs,
scripts \\
Analogical reasoning & Atom as ``solar system'' & Structure mapping,
transfer learning \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-47}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple categorization via clustering}
\ImportTok{from}\NormalTok{ sklearn.cluster }\ImportTok{import}\NormalTok{ KMeans}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Toy data: height, weight of animals}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{30}\NormalTok{,}\DecValTok{5}\NormalTok{],[}\DecValTok{32}\NormalTok{,}\DecValTok{6}\NormalTok{],[}\DecValTok{100}\NormalTok{,}\DecValTok{30}\NormalTok{],[}\DecValTok{110}\NormalTok{,}\DecValTok{35}\NormalTok{]])}
\NormalTok{kmeans }\OperatorTok{=}\NormalTok{ KMeans(n\_clusters}\OperatorTok{=}\DecValTok{2}\NormalTok{, random\_state}\OperatorTok{=}\DecValTok{0}\NormalTok{).fit(X)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Cluster labels:"}\NormalTok{, kmeans.labels\_)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-47}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more animals---do the clusters still make intuitive sense?
\item
  Compare clustering (prototype-based) with nearest-neighbor
  (exemplar-based).
\item
  Reflect: how can human-inspired abstraction mechanisms improve AI
  flexibility and interpretability?
\end{enumerate}

\subsection{49. Trade-offs between fidelity and
simplicity}\label{trade-offs-between-fidelity-and-simplicity}

Representations can be high-fidelity, capturing rich details, or simple,
emphasizing ease of reasoning and efficiency. AI systems must balance
the two: detailed models may be accurate but costly and hard to
generalize, while simpler models may miss nuance but scale better.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-48}

Imagine a city map. A satellite photo has perfect fidelity but is
overwhelming for navigation. A subway map is much simpler, omitting
roads and buildings, but makes travel decisions easy. The ``best''
representation depends on the task.

\subsubsection{Deep Dive}\label{deep-dive-48}

\begin{itemize}
\item
  High-fidelity representations: retain more raw information, closer to
  reality. Examples: full-resolution images, detailed simulations.
\item
  Simple representations: abstract away details, highlight essentials.
  Examples: feature vectors, symbolic summaries.
\item
  Trade-offs:

  \begin{itemize}
  \tightlist
  \item
    Accuracy vs.~interpretability.
  \item
    Precision vs.~efficiency.
  \item
    Generality vs.~task-specific utility.
  \end{itemize}
\item
  AI strategies:

  \begin{itemize}
  \tightlist
  \item
    Dimensionality reduction (PCA, autoencoders).
  \item
    Task-driven simplification (decision trees vs.~deep nets).
  \item
    Multi-resolution models (use detail only when needed).
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1863}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2843}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2843}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2451}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Representation Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Advantage
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
High-fidelity & Pixel-level vision models & Precise, detailed &
Expensive, overfits noise \\
Simple & Bag-of-words for documents & Fast, interpretable & Misses
nuance and context \\
Multi-resolution & CNN pyramids, hierarchical RL & Balance detail and
efficiency & More complex to design \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-48}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Trade{-}off: detailed vs. simplified representation}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.decomposition }\ImportTok{import}\NormalTok{ PCA}

\CommentTok{\# High{-}fidelity: 4D data}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{7}\NormalTok{],[}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{11}\NormalTok{],[}\DecValTok{5}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{13}\NormalTok{,}\DecValTok{21}\NormalTok{]])}

\CommentTok{\# Simplified: project down to 2D with PCA}
\NormalTok{pca }\OperatorTok{=}\NormalTok{ PCA(n\_components}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{X\_reduced }\OperatorTok{=}\NormalTok{ pca.fit\_transform(X)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Original (4D):"}\NormalTok{, X)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Reduced (2D):"}\NormalTok{, X\_reduced)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-48}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase the number of dimensions---how much information is lost in
  reduction?
\item
  Try clustering on high-dimensional vs.~reduced data---does simplicity
  help?
\item
  Reflect: when should AI systems prioritize detail, and when should
  they embrace abstraction?
\end{enumerate}

\subsection{50. Towards universal
representations}\label{towards-universal-representations}

A long-term goal in AI is to develop universal
representations---encodings that capture the essence of knowledge across
tasks, modalities, and domains. Instead of learning separate features
for images, text, or speech, universal representations promise
transferability and general intelligence.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-49}

Imagine a translator who can switch seamlessly between languages, music,
and math, using the same internal ``mental code.'' No matter the
medium---words, notes, or numbers---the translator taps into one shared
understanding. Universal representations aim for that kind of
versatility in AI.

\subsubsection{Deep Dive}\label{deep-dive-49}

\begin{itemize}
\item
  Current practice: task- or domain-specific embeddings (e.g., word2vec
  for text, CNN features for vision).
\item
  Universal approaches: large-scale foundation models trained on
  multimodal data (text, images, audio).
\item
  Benefits:

  \begin{itemize}
  \tightlist
  \item
    Transfer learning: apply knowledge across tasks.
  \item
    Efficiency: fewer task-specific models.
  \item
    Alignment: bridge modalities (vision-language, speech-text).
  \end{itemize}
\item
  Challenges:

  \begin{itemize}
  \tightlist
  \item
    Biases from pretraining data propagate universally.
  \item
    Interpretability remains difficult.
  \item
    May underperform on highly specialized domains.
  \end{itemize}
\item
  Research frontier: multimodal transformers, contrastive representation
  learning, world models.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2062}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2887}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2577}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2474}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Representation Scope
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Task-specific & Word2Vec, ResNet embeddings & Optimized for domain &
Limited transferability \\
Domain-general & BERT, CLIP & Works across many tasks & Still biased by
modality \\
Universal & Multimodal foundation models & Cross-domain adaptability &
Hard to align perfectly \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-49}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Toy multimodal representation: text + numeric features}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{text\_emb }\OperatorTok{=}\NormalTok{ np.array([}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.7}\NormalTok{])   }\CommentTok{\# e.g., "cat"}
\NormalTok{image\_emb }\OperatorTok{=}\NormalTok{ np.array([}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.75}\NormalTok{]) }\CommentTok{\# embedding from an image of a cat}

\CommentTok{\# Universal space: combine}
\NormalTok{universal\_emb }\OperatorTok{=}\NormalTok{ (text\_emb }\OperatorTok{+}\NormalTok{ image\_emb) }\OperatorTok{/} \DecValTok{2}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Universal representation:"}\NormalTok{, universal\_emb)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-49}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add audio embeddings to the universal vector---how does it integrate?
\item
  Compare universal embeddings for semantically similar vs.~dissimilar
  items.
\item
  Reflect: is true universality possible, or will AI always need
  task-specific adaptations?
\end{enumerate}

\section{Chapter 6. Learning vs Reasoning: Two Paths to
Intelligence}\label{chapter-6.-learning-vs-reasoning-two-paths-to-intelligence}

\subsection{51. Learning from data and
experience}\label{learning-from-data-and-experience}

Learning allows AI systems to improve performance over time by
extracting patterns from data or direct experience. Unlike hard-coded
rules, learning adapts to new inputs and environments, making it a
cornerstone of artificial intelligence.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-50}

Think of a child riding a bicycle. At first they wobble and fall, but
with practice they learn to balance, steer, and pedal smoothly. The
``data'' comes from their own experiences---successes and failures
shaping future behavior.

\subsubsection{Deep Dive}\label{deep-dive-50}

\begin{itemize}
\tightlist
\item
  Supervised learning: learn from labeled examples (input → correct
  output).
\item
  Unsupervised learning: discover structure without labels (clustering,
  dimensionality reduction).
\item
  Reinforcement learning: learn from rewards and penalties over time.
\item
  Online vs.~offline learning: continuous adaptation vs.~training on a
  fixed dataset.
\item
  Experience replay: storing and reusing past data to stabilize
  learning.
\item
  Challenges: data scarcity, noise, bias, catastrophic forgetting.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1313}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2727}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2828}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3131}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Learning Mode
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Supervised & Image classification & Accurate with labels & Requires
large labeled datasets \\
Unsupervised & Word embeddings, clustering & Reveals hidden structure &
Hard to evaluate, ambiguous \\
Reinforcement & Game-playing agents & Learns sequential strategies &
Sample inefficient \\
Online & Stock trading bots & Adapts in real time & Risk of
instability \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-50}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Supervised learning toy example}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LinearRegression}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Data: study hours vs. test scores}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{],[}\DecValTok{4}\NormalTok{],[}\DecValTok{5}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{50}\NormalTok{, }\DecValTok{60}\NormalTok{, }\DecValTok{65}\NormalTok{, }\DecValTok{70}\NormalTok{, }\DecValTok{80}\NormalTok{])}

\NormalTok{model }\OperatorTok{=}\NormalTok{ LinearRegression().fit(X, y)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Prediction for 6 hours:"}\NormalTok{, model.predict([[}\DecValTok{6}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-50}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more training data---does the prediction accuracy improve?
\item
  Try removing data points---how sensitive is the model?
\item
  Reflect: why is the ability to learn from data the defining feature of
  AI over traditional programs?
\end{enumerate}

\subsection{52. Inductive vs.~deductive
inference}\label{inductive-vs.-deductive-inference}

AI systems can reason in two complementary ways: induction, drawing
general rules from specific examples, and deduction, applying general
rules to specific cases. Induction powers machine learning, while
deduction powers logic-based reasoning.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-51}

Suppose you see 10 swans, all white. You infer inductively that ``all
swans are white.'' Later, given the rule ``all swans are white,'' you
deduce that the next swan you see will also be white. One builds the
rule, the other applies it.

\subsubsection{Deep Dive}\label{deep-dive-51}

\begin{itemize}
\item
  Inductive inference:

  \begin{itemize}
  \tightlist
  \item
    Data → rule.
  \item
    Basis of supervised learning, clustering, pattern discovery.
  \item
    Example: from labeled cats and dogs, infer a classifier.
  \end{itemize}
\item
  Deductive inference:

  \begin{itemize}
  \tightlist
  \item
    Rule + fact → conclusion.
  \item
    Basis of logic, theorem proving, symbolic AI.
  \item
    Example: ``All cats are mammals'' + ``Garfield is a cat'' →
    ``Garfield is a mammal.''
  \end{itemize}
\item
  Abduction (related): best explanation from evidence.
\item
  AI practice:

  \begin{itemize}
  \tightlist
  \item
    Induction: neural networks generalizing patterns.
  \item
    Deduction: Prolog-style reasoning engines.
  \item
    Combining both is a key challenge in hybrid AI.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1207}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1810}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2586}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1983}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2414}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Inference Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Direction
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Induction & Specific → General & Learning classifiers from data &
Adapts, generalizes & Risk of overfitting \\
Deduction & General → Specific & Rule-based expert systems & Precise,
interpretable & Limited flexibility, brittle \\
Abduction & Evidence → Hypothesis & Medical diagnosis systems & Handles
incomplete info & Not guaranteed correct \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-51}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Deductive reasoning example}
\NormalTok{facts }\OperatorTok{=}\NormalTok{ \{}\StringTok{"Garfield"}\NormalTok{: }\StringTok{"cat"}\NormalTok{\}}
\NormalTok{rules }\OperatorTok{=}\NormalTok{ \{}\StringTok{"cat"}\NormalTok{: }\StringTok{"mammal"}\NormalTok{\}}

\KeywordTok{def}\NormalTok{ deduce(entity):}
\NormalTok{    kind }\OperatorTok{=}\NormalTok{ facts[entity]}
    \ControlFlowTok{return}\NormalTok{ rules.get(kind, }\VariableTok{None}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Garfield is a"}\NormalTok{, deduce(}\StringTok{"Garfield"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-51}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more facts and rules---can your deductive system scale?
\item
  Try inductive reasoning by fitting a simple classifier on data.
\item
  Reflect: why does modern AI lean heavily on induction, and what's lost
  without deduction?
\end{enumerate}

\subsection{53. Statistical learning vs.~logical
reasoning}\label{statistical-learning-vs.-logical-reasoning}

AI systems can operate through statistical learning, which finds
patterns in data, or through logical reasoning, which derives
conclusions from explicit rules. These approaches represent two
traditions: data-driven vs.~knowledge-driven AI.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-52}

Imagine diagnosing an illness. A statistician looks at thousands of
patient records and says, ``People with these symptoms usually have
flu.'' A logician says, ``If fever AND cough AND sore throat, THEN
flu.'' Both approaches reach the same conclusion, but through different
means.

\subsubsection{Deep Dive}\label{deep-dive-52}

\begin{itemize}
\item
  Statistical learning:

  \begin{itemize}
  \tightlist
  \item
    Probabilistic, approximate, data-driven.
  \item
    Example: logistic regression, neural networks.
  \item
    Pros: adapts well to noise, scalable.
  \item
    Cons: opaque, may lack guarantees.
  \end{itemize}
\item
  Logical reasoning:

  \begin{itemize}
  \tightlist
  \item
    Rule-based, symbolic, precise.
  \item
    Example: first-order logic, theorem provers.
  \item
    Pros: interpretable, guarantees correctness.
  \item
    Cons: brittle, struggles with uncertainty.
  \end{itemize}
\item
  Integration efforts: probabilistic logic, differentiable reasoning,
  neuro-symbolic AI.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1562}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2969}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2578}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2891}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Statistical learning & Neural networks, regression & Robust to noise,
learns from data & Hard to interpret, needs lots of data \\
Logical reasoning & Prolog, rule-based systems & Transparent, exact
conclusions & Brittle, struggles with ambiguity \\
Hybrid approaches & Probabilistic logic, neuro-symbolic AI & Balance
data + rules & Computationally challenging \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-52}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Statistical learning vs logical reasoning toy example}

\CommentTok{\# Statistical: learn from data}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])  }\CommentTok{\# threshold at \textasciitilde{}1.5}
\NormalTok{model }\OperatorTok{=}\NormalTok{ LogisticRegression().fit(X,y)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Statistical prediction for 2.5:"}\NormalTok{, model.predict([[}\FloatTok{2.5}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}

\CommentTok{\# Logical: explicit rule}
\KeywordTok{def}\NormalTok{ rule(x):}
    \ControlFlowTok{return} \DecValTok{1} \ControlFlowTok{if}\NormalTok{ x }\OperatorTok{\textgreater{}=} \DecValTok{2} \ControlFlowTok{else} \DecValTok{0}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Logical rule for 2.5:"}\NormalTok{, rule(}\FloatTok{2.5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-52}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add noise to the training data---does the statistical model still
  work?
\item
  Break the logical rule---how brittle is it?
\item
  Reflect: how might AI combine statistical flexibility with logical
  rigor?
\end{enumerate}

\subsection{54. Pattern recognition and
generalization}\label{pattern-recognition-and-generalization}

AI systems must not only recognize patterns in data but also generalize
beyond what they have explicitly seen. Pattern recognition extracts
structure, while generalization allows applying that structure to new,
unseen situations---a core ingredient of intelligence.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-53}

Think of learning to recognize cats. After seeing a few examples, you
can identify new cats, even if they differ in color, size, or posture.
You don't memorize exact images---you generalize the pattern of
``catness.''

\subsubsection{Deep Dive}\label{deep-dive-53}

\begin{itemize}
\item
  Pattern recognition:

  \begin{itemize}
  \tightlist
  \item
    Detecting regularities in inputs (shapes, sounds, sequences).
  \item
    Tools: classifiers, clustering, convolutional filters.
  \end{itemize}
\item
  Generalization:

  \begin{itemize}
  \tightlist
  \item
    Extending knowledge from training to novel cases.
  \item
    Relies on inductive bias---assumptions baked into the model.
  \end{itemize}
\item
  Overfitting vs.~underfitting:

  \begin{itemize}
  \tightlist
  \item
    Overfit = memorizing patterns without generalizing.
  \item
    Underfit = failing to capture patterns at all.
  \end{itemize}
\item
  AI applications:

  \begin{itemize}
  \tightlist
  \item
    Vision: detecting objects.
  \item
    NLP: understanding paraphrases.
  \item
    Healthcare: predicting disease risk from limited data.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1810}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2952}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3238}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Pitfall
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Pattern recognition & Identifying structure in data & CNNs detecting
edges and shapes & Can be superficial \\
Generalization & Applying knowledge to new cases & Transformer
understanding synonyms & Requires bias + data \\
Overfitting & Memorizing noise as patterns & Perfect train accuracy,
poor test & No transferability \\
Underfitting & Missing true structure & Always guessing majority class &
Poor accuracy overall \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-53}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Toy generalization example}
\ImportTok{from}\NormalTok{ sklearn.tree }\ImportTok{import}\NormalTok{ DecisionTreeClassifier}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{],[}\DecValTok{4}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])  }\CommentTok{\# threshold around 2}

\NormalTok{model }\OperatorTok{=}\NormalTok{ DecisionTreeClassifier().fit(X,y)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Seen example (2):"}\NormalTok{, model.predict([[}\DecValTok{2}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Unseen example (5):"}\NormalTok{, model.predict([[}\DecValTok{5}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-53}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase tree depth---does it overfit to training data?
\item
  Reduce training data---can the model still generalize?
\item
  Reflect: why is generalization the hallmark of intelligence, beyond
  rote pattern matching?
\end{enumerate}

\subsection{55. Rule-based vs.~data-driven
methods}\label{rule-based-vs.-data-driven-methods}

AI methods can be designed around explicit rules written by humans or
patterns learned from data. Rule-based approaches dominated early AI,
while data-driven approaches power most modern systems. The two differ
in flexibility, interpretability, and scalability.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-54}

Imagine teaching a child arithmetic. A rule-based method is giving them
a multiplication table to memorize and apply exactly. A data-driven
method is letting them solve many problems until they infer the patterns
themselves. Both lead to answers, but the path differs.

\subsubsection{Deep Dive}\label{deep-dive-54}

\begin{itemize}
\item
  Rule-based AI:

  \begin{itemize}
  \tightlist
  \item
    Expert systems with ``if--then'' rules.
  \item
    Pros: interpretable, precise, easy to debug.
  \item
    Cons: brittle, hard to scale, requires manual encoding of knowledge.
  \end{itemize}
\item
  Data-driven AI:

  \begin{itemize}
  \tightlist
  \item
    Machine learning models trained on large datasets.
  \item
    Pros: adaptable, scalable, robust to variation.
  \item
    Cons: opaque, data-hungry, harder to explain.
  \end{itemize}
\item
  Hybrid approaches: knowledge-guided learning, neuro-symbolic AI.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1068}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3010}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3107}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2816}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Rule-based & Expert systems, Prolog & Transparent, logical consistency &
Brittle, hard to scale \\
Data-driven & Neural networks, decision trees & Adaptive, scalable &
Opaque, requires lots of data \\
Hybrid & Neuro-symbolic learning & Combines structure + flexibility &
Integration complexity \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-54}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Rule{-}based vs. data{-}driven toy example}

\CommentTok{\# Rule{-}based}
\KeywordTok{def}\NormalTok{ classify\_number(x):}
    \ControlFlowTok{if}\NormalTok{ x }\OperatorTok{\%} \DecValTok{2} \OperatorTok{==} \DecValTok{0}\NormalTok{:}
        \ControlFlowTok{return} \StringTok{"even"}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{return} \StringTok{"odd"}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Rule{-}based:"}\NormalTok{, classify\_number(}\DecValTok{7}\NormalTok{))}

\CommentTok{\# Data{-}driven}
\ImportTok{from}\NormalTok{ sklearn.tree }\ImportTok{import}\NormalTok{ DecisionTreeClassifier}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{],[}\DecValTok{4}\NormalTok{],[}\DecValTok{5}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ [}\StringTok{"even"}\NormalTok{,}\StringTok{"odd"}\NormalTok{,}\StringTok{"even"}\NormalTok{,}\StringTok{"odd"}\NormalTok{,}\StringTok{"even"}\NormalTok{,}\StringTok{"odd"}\NormalTok{]}

\NormalTok{model }\OperatorTok{=}\NormalTok{ DecisionTreeClassifier().fit(X,y)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Data{-}driven:"}\NormalTok{, model.predict([[}\DecValTok{7}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-54}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more rules---how quickly does the rule-based approach become
  unwieldy?
\item
  Train the model on noisy data---does the data-driven approach still
  generalize?
\item
  Reflect: when is rule-based precision preferable, and when is
  data-driven flexibility essential?
\end{enumerate}

\subsection{56. When learning outperforms
reasoning}\label{when-learning-outperforms-reasoning}

In many domains, learning from data outperforms hand-crafted reasoning
because the real world is messy, uncertain, and too complex to capture
with fixed rules. Machine learning adapts to variation and scale where
pure logic struggles.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-55}

Think of recognizing faces. Writing down rules like ``two eyes above a
nose above a mouth'' quickly breaks---faces vary in shape, lighting, and
angle. But with enough examples, a learning system can capture these
variations automatically.

\subsubsection{Deep Dive}\label{deep-dive-55}

\begin{itemize}
\item
  Reasoning systems: excel when rules are clear and complete. Fail when
  variation is high.
\item
  Learning systems: excel in perception-heavy tasks with vast diversity.
\item
  Examples where learning wins:

  \begin{itemize}
  \tightlist
  \item
    Vision: object and face recognition.
  \item
    Speech: recognizing accents, noise, and emotion.
  \item
    Language: understanding synonyms, idioms, context.
  \end{itemize}
\item
  Why:

  \begin{itemize}
  \tightlist
  \item
    Data-driven flexibility handles ambiguity.
  \item
    Statistical models capture probabilistic variation.
  \item
    Scale of modern datasets makes pattern discovery possible.
  \end{itemize}
\item
  Limitation: learning can succeed without ``understanding,'' leading to
  brittle generalization.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1081}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4730}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4189}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Domain
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Reasoning (rule-based)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Learning (data-driven)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Vision & ``Eye + nose + mouth'' rules brittle & CNNs adapt to
lighting/angles \\
Speech & Phoneme rules fail on noise/accents & Deep nets generalize from
data \\
Language & Hand-coded grammar misses idioms & Transformers learn from
corpora \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-55}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Learning beats reasoning in noisy classification}
\ImportTok{from}\NormalTok{ sklearn.neighbors }\ImportTok{import}\NormalTok{ KNeighborsClassifier}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Data: noisy "rule" for odd/even classification}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{],[}\DecValTok{4}\NormalTok{],[}\DecValTok{5}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ [}\StringTok{"even"}\NormalTok{,}\StringTok{"odd"}\NormalTok{,}\StringTok{"even"}\NormalTok{,}\StringTok{"odd"}\NormalTok{,}\StringTok{"odd"}\NormalTok{,}\StringTok{"odd"}\NormalTok{]  }\CommentTok{\# noise at index 4}

\NormalTok{model }\OperatorTok{=}\NormalTok{ KNeighborsClassifier(n\_neighbors}\OperatorTok{=}\DecValTok{1}\NormalTok{).fit(X,y)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Prediction for 4 (noisy):"}\NormalTok{, model.predict([[}\DecValTok{4}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Prediction for 6 (generalizes):"}\NormalTok{, model.predict([[}\DecValTok{6}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-55}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more noisy labels---does the learner still generalize better than
  brittle rules?
\item
  Increase dataset size---watch the learning system smooth out noise.
\item
  Reflect: why are perception tasks dominated by learning methods
  instead of reasoning systems?
\end{enumerate}

\subsection{57. When reasoning outperforms
learning}\label{when-reasoning-outperforms-learning}

While learning excels at perception and pattern recognition, reasoning
dominates in domains that require structure, rules, and guarantees.
Logical inference can succeed where data is scarce, errors are costly,
or decisions must follow strict constraints.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-56}

Think of solving a Sudoku puzzle. A learning system trained on examples
might guess, but a reasoning system follows logical rules to guarantee
correctness. Here, rules beat patterns.

\subsubsection{Deep Dive}\label{deep-dive-56}

\begin{itemize}
\item
  Strengths of reasoning:

  \begin{itemize}
  \tightlist
  \item
    Works with little or no data.
  \item
    Provides transparent justifications.
  \item
    Guarantees correctness when rules are complete.
  \end{itemize}
\item
  Examples where reasoning wins:

  \begin{itemize}
  \tightlist
  \item
    Mathematics \& theorem proving: correctness requires logic, not
    approximation.
  \item
    Formal verification: ensuring software or hardware meets safety
    requirements.
  \item
    Constraint satisfaction: scheduling, planning, optimization with
    strict limits.
  \end{itemize}
\item
  Limitations of learning in these domains:

  \begin{itemize}
  \tightlist
  \item
    Requires massive data that may not exist.
  \item
    Produces approximate answers, not guarantees.
  \end{itemize}
\item
  Hybrid opportunity: reasoning provides structure, learning fills gaps.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2593}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3086}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4321}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Domain
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Learning Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Reasoning Approach
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sudoku solving & Guess from patterns & Deductive logic guarantees
solution \\
Software verification & Predict defects from data & Prove correctness
formally \\
Flight scheduling & Predict likely routes & Optimize with constraints \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-56}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Reasoning beats learning: simple constraint solver}
\ImportTok{from}\NormalTok{ itertools }\ImportTok{import}\NormalTok{ permutations}

\CommentTok{\# Sudoku{-}like mini puzzle: fill 1{-}3 with no repeats}
\ControlFlowTok{for}\NormalTok{ perm }\KeywordTok{in}\NormalTok{ permutations([}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{]):}
    \ControlFlowTok{if}\NormalTok{ perm[}\DecValTok{0}\NormalTok{] }\OperatorTok{!=} \DecValTok{2}\NormalTok{:  }\CommentTok{\# constraint: first slot not 2}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"Valid solution:"}\NormalTok{, perm)}
        \ControlFlowTok{break}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-56}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more constraints---watch reasoning prune the solution space.
\item
  Try training a learner on the same problem---can it guarantee
  correctness?
\item
  Reflect: why do safety-critical AI applications often rely on
  reasoning over learning?
\end{enumerate}

\subsection{58. Combining learning and
reasoning}\label{combining-learning-and-reasoning}

Neither learning nor reasoning alone is sufficient for general
intelligence. Learning excels at perception and adapting to data, while
reasoning ensures structure, rules, and guarantees. Combining the
two---often called neuro-symbolic AI---aims to build systems that are
both flexible and reliable.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-57}

Imagine a lawyer-robot. Its learning side helps it understand spoken
language from clients, even with accents or noise. Its reasoning side
applies the exact rules of law to reach valid conclusions. Only together
can it work effectively.

\subsubsection{Deep Dive}\label{deep-dive-57}

\begin{itemize}
\item
  Why combine?

  \begin{itemize}
  \tightlist
  \item
    Learning handles messy, high-dimensional inputs.
  \item
    Reasoning enforces structure, constraints, and guarantees.
  \end{itemize}
\item
  Strategies:

  \begin{itemize}
  \tightlist
  \item
    Symbolic rules over learned embeddings.
  \item
    Neural networks guided by logical constraints.
  \item
    Differentiable logic and probabilistic programming.
  \end{itemize}
\item
  Applications:

  \begin{itemize}
  \tightlist
  \item
    Vision + reasoning: object recognition with relational logic.
  \item
    Language + reasoning: understanding and verifying arguments.
  \item
    Planning + perception: robotics combining neural perception with
    symbolic planners.
  \end{itemize}
\item
  Challenges:

  \begin{itemize}
  \tightlist
  \item
    Integration is technically hard.
  \item
    Differentiability vs.~discreteness mismatch.
  \item
    Interpretability vs.~scalability tension.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1268}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4507}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4225}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Component
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Learning & Robust, adaptive, scalable & Black-box, lacks guarantees \\
Reasoning & Transparent, rule-based, precise & Brittle, inflexible \\
Combined & Balances adaptability + rigor & Complex integration
challenges \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-57}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Hybrid: learning + reasoning toy demo}
\ImportTok{from}\NormalTok{ sklearn.tree }\ImportTok{import}\NormalTok{ DecisionTreeClassifier}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Learning: classify numbers}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{],[}\DecValTok{4}\NormalTok{],[}\DecValTok{5}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ [}\StringTok{"low"}\NormalTok{,}\StringTok{"low"}\NormalTok{,}\StringTok{"high"}\NormalTok{,}\StringTok{"high"}\NormalTok{,}\StringTok{"high"}\NormalTok{]}
\NormalTok{model }\OperatorTok{=}\NormalTok{ DecisionTreeClassifier().fit(X,y)}

\CommentTok{\# Reasoning: enforce a constraint (no "high" if \textless{}3)}
\KeywordTok{def}\NormalTok{ hybrid\_predict(x):}
\NormalTok{    pred }\OperatorTok{=}\NormalTok{ model.predict([[x]])[}\DecValTok{0}\NormalTok{]}
    \ControlFlowTok{if}\NormalTok{ x }\OperatorTok{\textless{}} \DecValTok{3} \KeywordTok{and}\NormalTok{ pred }\OperatorTok{==} \StringTok{"high"}\NormalTok{:}
        \ControlFlowTok{return} \StringTok{"low (corrected by rule)"}
    \ControlFlowTok{return}\NormalTok{ pred}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Hybrid prediction for 2:"}\NormalTok{, hybrid\_predict(}\DecValTok{2}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Hybrid prediction for 5:"}\NormalTok{, hybrid\_predict(}\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-57}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Train the learner on noisy labels---does reasoning help correct
  mistakes?
\item
  Add more rules to refine the hybrid output.
\item
  Reflect: what domains today most need neuro-symbolic AI (e.g., law,
  medicine, robotics)?
\end{enumerate}

\subsection{59. Current neuro-symbolic
approaches}\label{current-neuro-symbolic-approaches}

Neuro-symbolic AI seeks to unify neural networks (pattern recognition,
learning from data) with symbolic systems (logic, reasoning, knowledge
representation). The goal is to build systems that can perceive like a
neural net and reason like a logic engine.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-58}

Think of a self-driving car. Its neural network detects pedestrians,
cars, and traffic lights from camera feeds. Its symbolic system reasons
about rules like ``red light means stop'' or ``yield to pedestrians.''
Together, the car makes lawful, safe decisions.

\subsubsection{Deep Dive}\label{deep-dive-58}

\begin{itemize}
\item
  Integration strategies:

  \begin{itemize}
  \tightlist
  \item
    Symbolic on top of neural: neural nets produce symbols (objects,
    relations) → reasoning engine processes them.
  \item
    Neural guided by symbolic rules: logic constraints regularize
    learning (e.g., logical loss terms).
  \item
    Fully hybrid models: differentiable reasoning layers integrated into
    networks.
  \end{itemize}
\item
  Applications:

  \begin{itemize}
  \tightlist
  \item
    Vision + logic: scene understanding with relational reasoning.
  \item
    NLP + logic: combining embeddings with knowledge graphs.
  \item
    Robotics: neural control + symbolic task planning.
  \end{itemize}
\item
  Research challenges:

  \begin{itemize}
  \tightlist
  \item
    Scalability to large knowledge bases.
  \item
    Differentiability vs.~symbolic discreteness.
  \item
    Interpretability of hybrid models.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2137}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2906}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2650}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2308}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Symbolic on top of neural & Neural scene parser + Prolog rules &
Interpretable reasoning & Depends on neural accuracy \\
Neural guided by symbolic & Logic-regularized neural networks & Enforces
consistency & Hard to balance constraints \\
Fully hybrid & Differentiable theorem proving & End-to-end learning +
reasoning & Computationally intensive \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-58}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Neuro{-}symbolic toy example: neural output corrected by rule}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Neural{-}like output (probabilities)}
\NormalTok{pred\_probs }\OperatorTok{=}\NormalTok{ \{}\StringTok{"stop"}\NormalTok{: }\FloatTok{0.6}\NormalTok{, }\StringTok{"go"}\NormalTok{: }\FloatTok{0.4}\NormalTok{\}}

\CommentTok{\# Symbolic rule: if red light, must stop}
\NormalTok{observed\_light }\OperatorTok{=} \StringTok{"red"}

\ControlFlowTok{if}\NormalTok{ observed\_light }\OperatorTok{==} \StringTok{"red"}\NormalTok{:}
\NormalTok{    final\_decision }\OperatorTok{=} \StringTok{"stop"}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    final\_decision }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(pred\_probs, key}\OperatorTok{=}\NormalTok{pred\_probs.get)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Final decision:"}\NormalTok{, final\_decision)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-58}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the observed light---does the symbolic rule override the neural
  prediction?
\item
  Add more rules (e.g., ``yellow = slow down'') and combine with neural
  uncertainty.
\item
  Reflect: will future AI lean more on neuro-symbolic systems to achieve
  robustness and trustworthiness?
\end{enumerate}

\subsection{60. Open questions in
integration}\label{open-questions-in-integration}

Blending learning and reasoning is one of the grand challenges of AI.
While neuro-symbolic approaches show promise, many open questions remain
about scalability, interpretability, and how best to combine discrete
rules with continuous learning.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-59}

Think of oil and water. Neural nets (fluid, continuous) and symbolic
logic (rigid, discrete) often resist mixing. Researchers keep trying to
find the right ``emulsifier'' that allows them to blend smoothly into
one powerful system.

\subsubsection{Deep Dive}\label{deep-dive-59}

\begin{itemize}
\tightlist
\item
  Scalability: Can hybrid systems handle the scale of modern AI
  (billions of parameters, massive data)?
\item
  Differentiability: How to make discrete logical rules trainable with
  gradient descent?
\item
  Interpretability: How to ensure the symbolic layer explains what the
  neural part has learned?
\item
  Transferability: Can integrated systems generalize across domains
  better than either alone?
\item
  Benchmarks: What tasks truly test the benefit of integration
  (commonsense reasoning, law, robotics)?
\item
  Philosophical question: Is human intelligence itself a neuro-symbolic
  hybrid, and if so, what is the right architecture to model it?
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2073}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3902}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4024}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Open Question
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Why It Matters
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Current Status
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Scalability & Needed for real-world deployment & Small demos, not yet at
LLM scale \\
Differentiability & Enables end-to-end training & Research in
differentiable logic \\
Interpretability & Builds trust, explains decisions & Still opaque in
hybrids \\
Transferability & Key to general intelligence & Limited evidence so
far \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-59}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Toy blend: neural score + symbolic constraint}
\NormalTok{neural\_score }\OperatorTok{=}\NormalTok{ \{}\StringTok{"cat"}\NormalTok{: }\FloatTok{0.6}\NormalTok{, }\StringTok{"dog"}\NormalTok{: }\FloatTok{0.4}\NormalTok{\}}
\NormalTok{constraints }\OperatorTok{=}\NormalTok{ \{}\StringTok{"must\_be\_animal"}\NormalTok{: [}\StringTok{"cat"}\NormalTok{,}\StringTok{"dog"}\NormalTok{,}\StringTok{"horse"}\NormalTok{]\}}

\CommentTok{\# Integration: filter neural outputs by symbolic constraint}
\NormalTok{filtered }\OperatorTok{=}\NormalTok{ \{k:v }\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ neural\_score.items() }\ControlFlowTok{if}\NormalTok{ k }\KeywordTok{in}\NormalTok{ constraints[}\StringTok{"must\_be\_animal"}\NormalTok{]\}}
\NormalTok{decision }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(filtered, key}\OperatorTok{=}\NormalTok{filtered.get)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Final decision after integration:"}\NormalTok{, decision)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-59}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add a constraint that conflicts with neural output---what happens?
\item
  Adjust neural scores---does symbolic filtering still dominate?
\item
  Reflect: what breakthroughs are needed to make hybrid AI the default
  paradigm?
\end{enumerate}

\section{Chapter 7. Search, Optimization, and
Decision-Making}\label{chapter-7.-search-optimization-and-decision-making}

\subsection{61. Search as a core paradigm of
AI}\label{search-as-a-core-paradigm-of-ai}

At its heart, much of AI reduces to search: systematically exploring
possibilities to find a path from a starting point to a desired goal.
Whether planning moves in a game, routing a delivery truck, or designing
a protein, the essence of intelligence often lies in navigating large
spaces of alternatives efficiently.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-60}

Imagine standing at the entrance of a vast library. Somewhere inside is
the book you need. You could wander randomly, but that might take
forever. Instead, you use an index, follow signs, or ask a librarian.
Each strategy is a way of searching the space of books more effectively
than brute force.

\subsubsection{Deep Dive}\label{deep-dive-60}

Search provides a unifying perspective for AI because it frames problems
as states, actions, and goals. The system begins in a state, applies
actions that generate new states, and continues until it reaches a goal
state. This formulation underlies classical pathfinding, symbolic
reasoning, optimization, and even modern reinforcement learning.

The power of search lies in its generality. A chess program does not
need a bespoke strategy for every board---it needs a way to search
through possible moves. A navigation app does not memorize every
possible trip---it searches for the best route. Yet this generality
creates challenges, since search spaces often grow exponentially with
problem size. Intelligent systems must therefore balance completeness,
efficiency, and optimality.

To appreciate the spectrum of search strategies, it helps to compare
their properties. At one extreme, uninformed search methods like
breadth-first and depth-first blindly traverse states until a goal is
found. At the other, informed search methods like A* exploit heuristics
to guide exploration, reducing wasted effort. Between them lie iterative
deepening, bidirectional search, and stochastic sampling methods.

Comparison Table: Uninformed vs.~Informed Search

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2062}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3918}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4021}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Uninformed Search
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Informed Search
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Guidance & No knowledge beyond problem definition & Uses heuristics or
estimates \\
Efficiency & Explores many irrelevant states & Focuses exploration on
promising states \\
Guarantee & Can ensure completeness and optimality & Depends on
heuristic quality \\
Example Algorithms & BFS, DFS, Iterative Deepening & A*, Greedy
Best-First, Beam Search \\
Typical Applications & Puzzle solving, graph traversal & Route planning,
game-playing, NLP \\
\end{longtable}

Search also interacts closely with optimization. The difference is often
one of framing: search emphasizes paths in discrete spaces, while
optimization emphasizes finding best solutions in continuous spaces. In
practice, many AI problems blend both---for example, reinforcement
learning agents search over action sequences while optimizing reward
functions.

Finally, search highlights the limits of brute-force intelligence.
Without heuristics, even simple problems can become intractable. The
challenge is designing representations and heuristics that compress vast
spaces into manageable ones. This is where domain knowledge, learned
embeddings, and hybrid systems enter, bridging raw computation with
informed guidance.

\subsubsection{Tiny Code}\label{tiny-code-60}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple uninformed search (BFS) for a path in a graph}
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ deque}

\NormalTok{graph }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"A"}\NormalTok{: [}\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{],}
    \StringTok{"B"}\NormalTok{: [}\StringTok{"D"}\NormalTok{, }\StringTok{"E"}\NormalTok{],}
    \StringTok{"C"}\NormalTok{: [}\StringTok{"F"}\NormalTok{],}
    \StringTok{"D"}\NormalTok{: [], }\StringTok{"E"}\NormalTok{: [}\StringTok{"F"}\NormalTok{], }\StringTok{"F"}\NormalTok{: []}
\NormalTok{\}}

\KeywordTok{def}\NormalTok{ bfs(start, goal):}
\NormalTok{    queue }\OperatorTok{=}\NormalTok{ deque([[start]])}
    \ControlFlowTok{while}\NormalTok{ queue:}
\NormalTok{        path }\OperatorTok{=}\NormalTok{ queue.popleft()}
\NormalTok{        node }\OperatorTok{=}\NormalTok{ path[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}
        \ControlFlowTok{if}\NormalTok{ node }\OperatorTok{==}\NormalTok{ goal:}
            \ControlFlowTok{return}\NormalTok{ path}
        \ControlFlowTok{for}\NormalTok{ neighbor }\KeywordTok{in}\NormalTok{ graph.get(node, []):}
\NormalTok{            queue.append(path }\OperatorTok{+}\NormalTok{ [neighbor])}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Path from A to F:"}\NormalTok{, bfs(}\StringTok{"A"}\NormalTok{, }\StringTok{"F"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-60}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Replace BFS with DFS and compare the paths explored---how does
  efficiency change?
\item
  Add a heuristic function and implement A*---does it reduce
  exploration?
\item
  Reflect: why does AI often look like ``search made smart''?
\end{enumerate}

\subsection{62. State spaces and exploration
strategies}\label{state-spaces-and-exploration-strategies}

Every search problem can be described in terms of a state space: the set
of all possible configurations the system might encounter. The
effectiveness of search depends on how this space is structured and how
exploration is guided through it.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-61}

Think of solving a sliding-tile puzzle. Each arrangement of tiles is a
state. Moving one tile changes the state. The state space is the entire
set of possible board configurations, and exploring it is like
navigating a giant tree whose branches represent moves.

\subsubsection{Deep Dive}\label{deep-dive-61}

A state space has three ingredients:

\begin{itemize}
\tightlist
\item
  States: representations of situations, such as board positions, robot
  locations, or logical facts.
\item
  Actions: operations that transform one state into another, such as
  moving a piece or taking a step.
\item
  Goals: specific target states or conditions to be achieved.
\end{itemize}

The way states and actions are represented determines both the size of
the search space and the strategies available for exploring it. Compact
representations make exploration efficient, while poor representations
explode the space unnecessarily.

Exploration strategies dictate how states are visited: systematically,
heuristically, or stochastically. Systematic strategies such as
breadth-first search guarantee coverage but can be inefficient.
Heuristic strategies like best-first search exploit additional knowledge
to guide exploration. Stochastic strategies like Monte Carlo sampling
probe the space randomly, trading completeness for speed.

Comparison Table: Exploration Strategies

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2308}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2115}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2885}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2692}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Strategy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Exploration Pattern
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strengths
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Weaknesses
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Systematic (BFS/DFS) & Exhaustive, structured & Completeness,
reproducibility & Inefficient in large spaces \\
Heuristic (A*) & Guided by estimates & Efficient, finds optimal paths &
Depends on heuristic quality \\
Stochastic (Monte Carlo) & Random sampling & Scalable, good for huge
spaces & No guarantee of optimality \\
\end{longtable}

In AI practice, state spaces can be massive. Chess has about \(10^{47}\)
legal positions, Go even more. Enumerating these spaces is impossible,
so effective strategies rely on pruning, abstraction, and heuristic
evaluation. Reinforcement learning takes this further by exploring state
spaces not explicitly enumerated but sampled through interaction with
environments.

\subsubsection{Tiny Code}\label{tiny-code-61}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# State space exploration: DFS vs BFS}
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ deque}

\NormalTok{graph }\OperatorTok{=}\NormalTok{ \{}\StringTok{"A"}\NormalTok{: [}\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{], }\StringTok{"B"}\NormalTok{: [}\StringTok{"D"}\NormalTok{, }\StringTok{"E"}\NormalTok{], }\StringTok{"C"}\NormalTok{: [}\StringTok{"F"}\NormalTok{], }\StringTok{"D"}\NormalTok{: [], }\StringTok{"E"}\NormalTok{: [], }\StringTok{"F"}\NormalTok{: []\}}

\KeywordTok{def}\NormalTok{ dfs(start, goal):}
\NormalTok{    stack }\OperatorTok{=}\NormalTok{ [[start]]}
    \ControlFlowTok{while}\NormalTok{ stack:}
\NormalTok{        path }\OperatorTok{=}\NormalTok{ stack.pop()}
\NormalTok{        node }\OperatorTok{=}\NormalTok{ path[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}
        \ControlFlowTok{if}\NormalTok{ node }\OperatorTok{==}\NormalTok{ goal:}
            \ControlFlowTok{return}\NormalTok{ path}
        \ControlFlowTok{for}\NormalTok{ neighbor }\KeywordTok{in}\NormalTok{ graph.get(node, []):}
\NormalTok{            stack.append(path }\OperatorTok{+}\NormalTok{ [neighbor])}

\KeywordTok{def}\NormalTok{ bfs(start, goal):}
\NormalTok{    queue }\OperatorTok{=}\NormalTok{ deque([[start]])}
    \ControlFlowTok{while}\NormalTok{ queue:}
\NormalTok{        path }\OperatorTok{=}\NormalTok{ queue.popleft()}
\NormalTok{        node }\OperatorTok{=}\NormalTok{ path[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}
        \ControlFlowTok{if}\NormalTok{ node }\OperatorTok{==}\NormalTok{ goal:}
            \ControlFlowTok{return}\NormalTok{ path}
        \ControlFlowTok{for}\NormalTok{ neighbor }\KeywordTok{in}\NormalTok{ graph.get(node, []):}
\NormalTok{            queue.append(path }\OperatorTok{+}\NormalTok{ [neighbor])}

\BuiltInTok{print}\NormalTok{(}\StringTok{"DFS path A→F:"}\NormalTok{, dfs(}\StringTok{"A"}\NormalTok{,}\StringTok{"F"}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"BFS path A→F:"}\NormalTok{, bfs(}\StringTok{"A"}\NormalTok{,}\StringTok{"F"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-61}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add loops to the graph---how do exploration strategies handle cycles?
\item
  Replace BFS/DFS with a heuristic that prefers certain nodes first.
\item
  Reflect: how does the choice of state representation reshape the
  difficulty of exploration?
\end{enumerate}

\subsection{63. Optimization problems and solution
quality}\label{optimization-problems-and-solution-quality}

Many AI tasks are not just about finding \emph{a} solution, but about
finding the best one. Optimization frames problems in terms of an
objective function to maximize or minimize. Solution quality is measured
by how well the chosen option scores relative to the optimum.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-62}

Imagine planning a road trip. You could choose \emph{any} route that
gets you from city A to city B, but some are shorter, cheaper, or more
scenic. Optimization is the process of evaluating alternatives and
selecting the route that best satisfies your chosen criteria.

\subsubsection{Deep Dive}\label{deep-dive-62}

Optimization problems are typically expressed as:

\begin{itemize}
\tightlist
\item
  Variables: the choices to be made (e.g., path, schedule, parameters).
\item
  Objective function: a numerical measure of quality (e.g., total
  distance, cost, accuracy).
\item
  Constraints: conditions that must hold (e.g., maximum budget, safety
  requirements).
\end{itemize}

In AI, optimization appears at multiple levels. At the algorithmic
level, pathfinding seeks the shortest or safest route. At the
statistical level, training a machine learning model minimizes loss. At
the systems level, scheduling problems allocate limited resources
effectively.

Solution quality is not always binary. Often, multiple solutions exist
with varying trade-offs, requiring approximation or heuristic methods.
For example, linear programming problems may yield exact solutions,
while combinatorial problems like the traveling salesman often require
heuristics that balance quality and efficiency.

Comparison Table: Exact vs.~Approximate Optimization

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3716}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2095}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2230}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1959}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Guarantee
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Efficiency
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Exact (e.g., linear programming) & Optimal solution guaranteed & Slow
for large problems & Resource scheduling, planning \\
Approximate (e.g., greedy, local search) & Close to optimal, no
guarantees & Fast, scalable & Routing, clustering \\
Heuristic/metaheuristic (e.g., simulated annealing, GA) & Often
near-optimal & Balances exploration/exploitation & Game AI, design
problems \\
\end{longtable}

Optimization also interacts with multi-objective trade-offs. An AI
system may need to maximize accuracy while minimizing cost, or balance
fairness against efficiency. This leads to Pareto frontiers, where no
solution is best across all criteria, only better in some dimensions.

\subsubsection{Tiny Code}\label{tiny-code-62}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple optimization: shortest path with Dijkstra}
\ImportTok{import}\NormalTok{ heapq}

\NormalTok{graph }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"A"}\NormalTok{: \{}\StringTok{"B"}\NormalTok{:}\DecValTok{2}\NormalTok{,}\StringTok{"C"}\NormalTok{:}\DecValTok{5}\NormalTok{\},}
    \StringTok{"B"}\NormalTok{: \{}\StringTok{"C"}\NormalTok{:}\DecValTok{1}\NormalTok{,}\StringTok{"D"}\NormalTok{:}\DecValTok{4}\NormalTok{\},}
    \StringTok{"C"}\NormalTok{: \{}\StringTok{"D"}\NormalTok{:}\DecValTok{1}\NormalTok{\},}
    \StringTok{"D"}\NormalTok{: \{\}}
\NormalTok{\}}

\KeywordTok{def}\NormalTok{ dijkstra(start, goal):}
\NormalTok{    queue }\OperatorTok{=}\NormalTok{ [(}\DecValTok{0}\NormalTok{, start, [])]}
\NormalTok{    seen }\OperatorTok{=} \BuiltInTok{set}\NormalTok{()}
    \ControlFlowTok{while}\NormalTok{ queue:}
\NormalTok{        (cost, node, path) }\OperatorTok{=}\NormalTok{ heapq.heappop(queue)}
        \ControlFlowTok{if}\NormalTok{ node }\KeywordTok{in}\NormalTok{ seen:}
            \ControlFlowTok{continue}
\NormalTok{        path }\OperatorTok{=}\NormalTok{ path }\OperatorTok{+}\NormalTok{ [node]}
        \ControlFlowTok{if}\NormalTok{ node }\OperatorTok{==}\NormalTok{ goal:}
            \ControlFlowTok{return}\NormalTok{ (cost, path)}
\NormalTok{        seen.add(node)}
        \ControlFlowTok{for}\NormalTok{ n, c }\KeywordTok{in}\NormalTok{ graph[node].items():}
\NormalTok{            heapq.heappush(queue, (cost}\OperatorTok{+}\NormalTok{c, n, path))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Shortest path A→D:"}\NormalTok{, dijkstra(}\StringTok{"A"}\NormalTok{,}\StringTok{"D"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-62}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add an extra edge to the graph---does it change the optimal solution?
\item
  Modify edge weights---how sensitive is the solution quality to
  changes?
\item
  Reflect: why does optimization unify so many AI problems, from
  learning weights to planning strategies?
\end{enumerate}

\subsection{64. Trade-offs: completeness, optimality,
efficiency}\label{trade-offs-completeness-optimality-efficiency}

Search and optimization in AI are always constrained by trade-offs. An
algorithm can aim to be complete (always finds a solution if one
exists), optimal (finds the best possible solution), or efficient (uses
minimal time and memory). In practice, no single method can maximize all
three.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-63}

Imagine looking for your car keys. A complete strategy is to search
every inch of the house---you'll eventually succeed but waste time. An
optimal strategy is to find them in the absolute minimum time, which may
require foresight you don't have. An efficient strategy is to quickly
check likely spots (desk, kitchen counter) but risk missing them if
they're elsewhere.

\subsubsection{Deep Dive}\label{deep-dive-63}

Completeness ensures reliability. Algorithms like breadth-first search
are complete but can be slow. Optimality ensures the best solution---A*
with an admissible heuristic guarantees optimal paths. Efficiency,
however, often requires cutting corners, such as greedy search, which
may miss the best path.

The choice among these depends on the domain. In robotics, efficiency
and near-optimality may be more important than strict completeness. In
theorem proving, completeness may outweigh efficiency. In logistics,
approximate optimality is often good enough if efficiency scales to
millions of deliveries.

Comparison Table: Properties of Search Algorithms

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1393}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1557}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1803}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2869}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2377}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complete?
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Optimal?
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Efficiency
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Typical Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Breadth-First & Yes & Yes (if costs uniform) & Low (explores widely) &
Simple shortest-path problems \\
Depth-First & Yes (finite spaces) & No & High memory efficiency, can be
slow & Exploring large state spaces \\
Greedy Best-First & No & No & Very fast & Quick approximate solutions \\
A* (admissible) & Yes & Yes & Moderate, depends on heuristic & Optimal
pathfinding \\
\end{longtable}

This trilemma highlights why heuristic design is critical. Good
heuristics push algorithms closer to optimality and efficiency without
sacrificing completeness. Poor heuristics waste resources or miss good
solutions.

\subsubsection{Tiny Code}\label{tiny-code-63}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Greedy vs A* search demonstration}
\ImportTok{import}\NormalTok{ heapq}

\NormalTok{graph }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"A"}\NormalTok{: \{}\StringTok{"B"}\NormalTok{:}\DecValTok{1}\NormalTok{,}\StringTok{"C"}\NormalTok{:}\DecValTok{4}\NormalTok{\},}
    \StringTok{"B"}\NormalTok{: \{}\StringTok{"C"}\NormalTok{:}\DecValTok{2}\NormalTok{,}\StringTok{"D"}\NormalTok{:}\DecValTok{5}\NormalTok{\},}
    \StringTok{"C"}\NormalTok{: \{}\StringTok{"D"}\NormalTok{:}\DecValTok{1}\NormalTok{\},}
    \StringTok{"D"}\NormalTok{: \{\}}
\NormalTok{\}}

\NormalTok{heuristic }\OperatorTok{=}\NormalTok{ \{}\StringTok{"A"}\NormalTok{:}\DecValTok{3}\NormalTok{,}\StringTok{"B"}\NormalTok{:}\DecValTok{2}\NormalTok{,}\StringTok{"C"}\NormalTok{:}\DecValTok{1}\NormalTok{,}\StringTok{"D"}\NormalTok{:}\DecValTok{0}\NormalTok{\}  }\CommentTok{\# heuristic estimates}

\KeywordTok{def}\NormalTok{ astar(start, goal):}
\NormalTok{    queue }\OperatorTok{=}\NormalTok{ [(}\DecValTok{0}\OperatorTok{+}\NormalTok{heuristic[start],}\DecValTok{0}\NormalTok{,start,[])]}
    \ControlFlowTok{while}\NormalTok{ queue:}
\NormalTok{        f,g,node,path }\OperatorTok{=}\NormalTok{ heapq.heappop(queue)}
\NormalTok{        path }\OperatorTok{=}\NormalTok{ path}\OperatorTok{+}\NormalTok{[node]}
        \ControlFlowTok{if}\NormalTok{ node }\OperatorTok{==}\NormalTok{ goal:}
            \ControlFlowTok{return}\NormalTok{ (g,path)}
        \ControlFlowTok{for}\NormalTok{ n,c }\KeywordTok{in}\NormalTok{ graph[node].items():}
\NormalTok{            heapq.heappush(queue,(g}\OperatorTok{+}\NormalTok{c}\OperatorTok{+}\NormalTok{heuristic[n],g}\OperatorTok{+}\NormalTok{c,n,path))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"A* path:"}\NormalTok{, astar(}\StringTok{"A"}\NormalTok{,}\StringTok{"D"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-63}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Replace the heuristic with random values---how does it affect
  optimality?
\item
  Compare A* to greedy search (use only heuristic, ignore g)---which is
  faster?
\item
  Reflect: why can't AI systems maximize completeness, optimality, and
  efficiency all at once?
\end{enumerate}

\subsection{65. Greedy, heuristic, and informed
search}\label{greedy-heuristic-and-informed-search}

Not all search strategies blindly explore possibilities. Greedy search
follows the most promising-looking option at each step. Heuristic search
uses estimates to guide exploration. Informed search combines
problem-specific knowledge with systematic search, often achieving
efficiency without sacrificing too much accuracy.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-64}

Imagine hiking up a mountain in fog. A greedy approach is to always step
toward the steepest upward slope---you'll climb quickly, but you may end
up on a local hill instead of the highest peak. A heuristic approach
uses a rough map that points you toward promising trails. An informed
search balances both---map guidance plus careful checking to ensure
you're really reaching the summit.

\subsubsection{Deep Dive}\label{deep-dive-64}

Greedy search is fast but shortsighted. It relies on evaluating the
immediate ``best'' option without considering long-term consequences.
Heuristic search introduces estimates of how far a state is from the
goal, such as distance in pathfinding. Informed search algorithms like
A* integrate actual cost so far with heuristic estimates, ensuring both
efficiency and optimality when heuristics are admissible.

The effectiveness of these methods depends heavily on heuristic quality.
A poor heuristic may waste time or mislead the search. A well-crafted
heuristic, even if simple, can drastically reduce exploration. In
practice, heuristics are often domain-specific: straight-line distance
in maps, Manhattan distance in puzzles, or learned estimates in modern
AI systems.

Comparison Table: Greedy vs.~Heuristic vs.~Informed

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1468}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1376}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1651}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2936}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2569}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Strategy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Cost Considered
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Goal Estimate Used
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Weakness
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Greedy Search & No & Yes & Very fast, low memory & May get stuck in
local traps \\
Heuristic Search & Sometimes & Yes & Guides exploration & Quality
depends on heuristic \\
Informed Search & Yes (path cost) & Yes & Balances efficiency +
optimality & More computation per step \\
\end{longtable}

In modern AI, informed search generalizes beyond symbolic search spaces.
Neural networks learn heuristics automatically, approximating
distance-to-goal functions. This connection bridges classical AI
planning with contemporary machine learning.

\subsubsection{Tiny Code}\label{tiny-code-64}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Greedy vs A* search with heuristic}
\ImportTok{import}\NormalTok{ heapq}

\NormalTok{graph }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"A"}\NormalTok{: \{}\StringTok{"B"}\NormalTok{:}\DecValTok{2}\NormalTok{,}\StringTok{"C"}\NormalTok{:}\DecValTok{5}\NormalTok{\},}
    \StringTok{"B"}\NormalTok{: \{}\StringTok{"C"}\NormalTok{:}\DecValTok{1}\NormalTok{,}\StringTok{"D"}\NormalTok{:}\DecValTok{4}\NormalTok{\},}
    \StringTok{"C"}\NormalTok{: \{}\StringTok{"D"}\NormalTok{:}\DecValTok{1}\NormalTok{\},}
    \StringTok{"D"}\NormalTok{: \{\}}
\NormalTok{\}}

\NormalTok{heuristic }\OperatorTok{=}\NormalTok{ \{}\StringTok{"A"}\NormalTok{:}\DecValTok{6}\NormalTok{,}\StringTok{"B"}\NormalTok{:}\DecValTok{4}\NormalTok{,}\StringTok{"C"}\NormalTok{:}\DecValTok{2}\NormalTok{,}\StringTok{"D"}\NormalTok{:}\DecValTok{0}\NormalTok{\}}

\KeywordTok{def}\NormalTok{ greedy(start, goal):}
\NormalTok{    queue }\OperatorTok{=}\NormalTok{ [(heuristic[start], start, [])]}
\NormalTok{    seen }\OperatorTok{=} \BuiltInTok{set}\NormalTok{()}
    \ControlFlowTok{while}\NormalTok{ queue:}
\NormalTok{        \_, node, path }\OperatorTok{=}\NormalTok{ heapq.heappop(queue)}
        \ControlFlowTok{if}\NormalTok{ node }\KeywordTok{in}\NormalTok{ seen: }
            \ControlFlowTok{continue}
\NormalTok{        path }\OperatorTok{=}\NormalTok{ path }\OperatorTok{+}\NormalTok{ [node]}
        \ControlFlowTok{if}\NormalTok{ node }\OperatorTok{==}\NormalTok{ goal:}
            \ControlFlowTok{return}\NormalTok{ path}
\NormalTok{        seen.add(node)}
        \ControlFlowTok{for}\NormalTok{ n }\KeywordTok{in}\NormalTok{ graph[node]:}
\NormalTok{            heapq.heappush(queue, (heuristic[n], n, path))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Greedy path:"}\NormalTok{, greedy(}\StringTok{"A"}\NormalTok{,}\StringTok{"D"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-64}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare greedy and A* on the same graph---does A* find shorter paths?
\item
  Change the heuristic values---how sensitive are the results?
\item
  Reflect: how do learned heuristics in modern AI extend this classical
  idea?
\end{enumerate}

\subsection{66. Global vs.~local optima
challenges}\label{global-vs.-local-optima-challenges}

Optimization problems in AI often involve navigating landscapes with
many peaks and valleys. A local optimum is a solution better than its
neighbors but not the best overall. A global optimum is the true best
solution. Distinguishing between the two is a central challenge,
especially in high-dimensional spaces.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-65}

Imagine climbing hills in heavy fog. You reach the top of a nearby hill
and think you're done---yet a taller mountain looms beyond the mist.
That smaller hill is a local optimum; the tallest mountain is the global
optimum. AI systems face the same trap when optimizing.

\subsubsection{Deep Dive}\label{deep-dive-65}

Local vs.~global optima appear in many AI contexts. Neural network
training often settles in local minima, though in very high dimensions,
``bad'' minima are surprisingly rare and saddle points dominate.
Heuristic search algorithms like hill climbing can get stuck at local
maxima unless randomization or diversification strategies are
introduced.

To escape local traps, techniques include:

\begin{itemize}
\tightlist
\item
  Random restarts: re-run search from multiple starting points.
\item
  Simulated annealing: accept worse moves probabilistically to escape
  local basins.
\item
  Genetic algorithms: explore populations of solutions to maintain
  diversity.
\item
  Momentum methods in deep learning: help optimizers roll through small
  valleys.
\end{itemize}

The choice of method depends on the problem structure. Convex
optimization problems, common in linear models, guarantee global optima.
Non-convex problems, such as deep neural networks, require approximation
strategies and careful initialization.

Comparison Table: Local vs.~Global Optima

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1954}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4138}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3908}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Feature
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Local Optimum
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Global Optimum
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Definition & Best in a neighborhood & Best overall \\
Detection & Easy (compare neighbors) & Hard (requires whole search) \\
Example in AI & Hill-climbing gets stuck & Linear regression finds exact
best \\
Escape Strategies & Randomization, annealing, heuristics & Convexity
ensures unique optimum \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-65}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Local vs global optima: hill climbing on a bumpy function}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\KeywordTok{def}\NormalTok{ f(x):}
    \ControlFlowTok{return}\NormalTok{ np.sin(}\DecValTok{5}\OperatorTok{*}\NormalTok{x) }\OperatorTok{*}\NormalTok{ (}\DecValTok{1}\OperatorTok{{-}}\NormalTok{x) }\OperatorTok{+}\NormalTok{ x2}

\KeywordTok{def}\NormalTok{ hill\_climb(start, step}\OperatorTok{=}\FloatTok{0.01}\NormalTok{, iters}\OperatorTok{=}\DecValTok{1000}\NormalTok{):}
\NormalTok{    x }\OperatorTok{=}\NormalTok{ start}
    \ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(iters):}
\NormalTok{        neighbors }\OperatorTok{=}\NormalTok{ [x}\OperatorTok{{-}}\NormalTok{step, x}\OperatorTok{+}\NormalTok{step]}
\NormalTok{        best }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(neighbors, key}\OperatorTok{=}\NormalTok{f)}
        \ControlFlowTok{if}\NormalTok{ f(best) }\OperatorTok{\textless{}=}\NormalTok{ f(x):}
            \ControlFlowTok{break}  \CommentTok{\# stuck at local optimum}
\NormalTok{        x }\OperatorTok{=}\NormalTok{ best}
    \ControlFlowTok{return}\NormalTok{ x, f(x)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Hill climbing from 0.5:"}\NormalTok{, hill\_climb(}\FloatTok{0.5}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Hill climbing from 2.0:"}\NormalTok{, hill\_climb(}\FloatTok{2.0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-65}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the starting point---do you end up at different optima?
\item
  Increase step size or add randomness---can you escape local traps?
\item
  Reflect: why do real-world AI systems often settle for ``good enough''
  rather than chasing the global best?
\end{enumerate}

\subsection{67. Multi-objective
optimization}\label{multi-objective-optimization}

Many AI systems must optimize not just one objective but several, often
conflicting, goals. This is known as multi-objective optimization.
Instead of finding a single ``best'' solution, the goal is to balance
trade-offs among objectives, producing a set of solutions that represent
different compromises.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-66}

Imagine buying a laptop. You want it to be powerful, lightweight, and
cheap. But powerful laptops are often heavy or expensive. The ``best''
choice depends on how you weigh these competing factors. Multi-objective
optimization formalizes this dilemma.

\subsubsection{Deep Dive}\label{deep-dive-66}

Unlike single-objective problems where a clear optimum exists,
multi-objective problems often lead to a Pareto frontier---the set of
solutions where improving one objective necessarily worsens another. For
example, in machine learning, models may trade off accuracy against
interpretability, or performance against energy efficiency.

The central challenge is not only finding the frontier but also deciding
which trade-off to choose. This often requires human or policy input.
Algorithms like weighted sums, evolutionary multi-objective optimization
(EMO), and Pareto ranking help navigate these trade-offs.

Comparison Table: Single vs.~Multi-Objective Optimization

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1778}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3556}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4667}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Single-Objective Optimization
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Multi-Objective Optimization
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Goal & Minimize/maximize one function & Balance several conflicting
goals \\
Solution & One optimum & Pareto frontier of non-dominated solutions \\
Example in AI & Train model to maximize accuracy & Train model for
accuracy + fairness \\
Decision process & Automatic & Requires weighing trade-offs \\
\end{longtable}

Applications of multi-objective optimization in AI are widespread:

\begin{itemize}
\tightlist
\item
  Fairness vs.~accuracy in predictive models.
\item
  Energy use vs.~latency in edge devices.
\item
  Exploration vs.~exploitation in reinforcement learning.
\item
  Cost vs.~coverage in planning and logistics.
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-66}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Multi{-}objective optimization: Pareto frontier (toy example)}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{solutions }\OperatorTok{=}\NormalTok{ [(x, }\DecValTok{1}\OperatorTok{/}\NormalTok{x) }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ np.linspace(}\FloatTok{0.1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{)]  }\CommentTok{\# trade{-}off curve}

\CommentTok{\# Identify Pareto frontier}
\NormalTok{pareto }\OperatorTok{=}\NormalTok{ []}
\ControlFlowTok{for}\NormalTok{ s }\KeywordTok{in}\NormalTok{ solutions:}
    \ControlFlowTok{if} \KeywordTok{not} \BuiltInTok{any}\NormalTok{(o[}\DecValTok{0}\NormalTok{] }\OperatorTok{\textless{}=}\NormalTok{ s[}\DecValTok{0}\NormalTok{] }\KeywordTok{and}\NormalTok{ o[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textless{}=}\NormalTok{ s[}\DecValTok{1}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ o }\KeywordTok{in}\NormalTok{ solutions }\ControlFlowTok{if}\NormalTok{ o }\OperatorTok{!=}\NormalTok{ s):}
\NormalTok{        pareto.append(s)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Solutions:"}\NormalTok{, solutions)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Pareto frontier:"}\NormalTok{, pareto)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-66}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more objectives (e.g., x, 1/x, and x²)---how does the frontier
  change?
\item
  Adjust the trade-offs---what happens to the shape of Pareto optimal
  solutions?
\item
  Reflect: in real-world AI, who decides how to weigh competing
  objectives, the engineer, the user, or society at large?
\end{enumerate}

\subsection{68. Decision-making under
uncertainty}\label{decision-making-under-uncertainty}

In real-world environments, AI rarely has perfect information.
Decision-making under uncertainty is the art of choosing actions when
outcomes are probabilistic, incomplete, or ambiguous. Instead of
guaranteeing success, the goal is to maximize expected utility across
possible futures.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-67}

Imagine driving in heavy fog. You can't see far ahead, but you must
still decide whether to slow down, turn, or continue straight. Each
choice has risks and rewards, and you must act without full knowledge of
the environment.

\subsubsection{Deep Dive}\label{deep-dive-67}

Uncertainty arises in AI from noisy sensors, incomplete data,
unpredictable environments, or stochastic dynamics. Handling it requires
formal models that weigh possible outcomes against their probabilities.

\begin{itemize}
\tightlist
\item
  Probabilistic decision-making uses expected value calculations: choose
  the action with the highest expected utility.
\item
  Bayesian approaches update beliefs as new evidence arrives, refining
  decision quality.
\item
  Decision trees structure uncertainty into branches of possible
  outcomes with associated probabilities.
\item
  Markov decision processes (MDPs) formalize sequential decision-making
  under uncertainty, where each action leads probabilistically to new
  states and rewards.
\end{itemize}

A critical challenge is balancing risk and reward. Some systems aim for
maximum expected payoff, while others prioritize robustness against
worst-case scenarios.

Comparison Table: Strategies for Uncertain Decisions

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1557}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2705}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2459}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3279}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Strategy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Core Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strengths
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Weaknesses
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Expected Utility & Maximize average outcome & Rational, mathematically
sound & Sensitive to mis-specified probabilities \\
Bayesian Updating & Revise beliefs with evidence & Adaptive, principled
& Computationally demanding \\
Robust Optimization & Focus on worst-case scenarios & Safe, conservative
& May miss high-payoff opportunities \\
MDPs & Sequential probabilistic planning & Rich, expressive framework &
Requires accurate transition model \\
\end{longtable}

AI applications are everywhere: medical diagnosis under incomplete
tests, robotics navigation with noisy sensors, financial trading with
uncertain markets, and dialogue systems managing ambiguous user inputs.

\subsubsection{Tiny Code}\label{tiny-code-67}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Expected utility under uncertainty}
\ImportTok{import}\NormalTok{ random}

\NormalTok{actions }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"safe"}\NormalTok{: [(}\DecValTok{10}\NormalTok{, }\FloatTok{1.0}\NormalTok{)],           }\CommentTok{\# always 10}
    \StringTok{"risky"}\NormalTok{: [(}\DecValTok{50}\NormalTok{, }\FloatTok{0.2}\NormalTok{), (}\DecValTok{0}\NormalTok{, }\FloatTok{0.8}\NormalTok{)] }\CommentTok{\# 20\% chance 50, else 0}
\NormalTok{\}}

\KeywordTok{def}\NormalTok{ expected\_utility(action):}
    \ControlFlowTok{return} \BuiltInTok{sum}\NormalTok{(v}\OperatorTok{*}\NormalTok{p }\ControlFlowTok{for}\NormalTok{ v,p }\KeywordTok{in}\NormalTok{ action)}

\ControlFlowTok{for}\NormalTok{ a }\KeywordTok{in}\NormalTok{ actions:}
    \BuiltInTok{print}\NormalTok{(a, }\StringTok{"expected utility:"}\NormalTok{, expected\_utility(actions[a]))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-67}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Adjust the probabilities---does the optimal action change?
\item
  Add a risk-averse criterion (e.g., maximize minimum payoff)---how does
  it affect choice?
\item
  Reflect: should AI systems always chase expected reward, or sometimes
  act conservatively to protect against rare but catastrophic outcomes?
\end{enumerate}

\subsection{69. Sequential decision
processes}\label{sequential-decision-processes}

Many AI problems involve not just a single choice, but a sequence of
actions unfolding over time. Sequential decision processes model this
setting, where each action changes the state of the world and influences
future choices. Success depends on planning ahead, not just optimizing
the next step.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-68}

Think of playing chess. Each move alters the board and constrains the
opponent's replies. Winning depends less on any single move than on
orchestrating a sequence that leads to checkmate.

\subsubsection{Deep Dive}\label{deep-dive-68}

Sequential decisions differ from one-shot choices because they involve
state transitions and temporal consequences. The challenge is
compounding uncertainty, where early actions can have long-term effects.

The classical framework is the Markov Decision Process (MDP), defined
by:

\begin{itemize}
\tightlist
\item
  A set of states.
\item
  A set of actions.
\item
  Transition probabilities specifying how actions change states.
\item
  Reward functions quantifying the benefit of each state-action pair.
\end{itemize}

Policies are strategies that map states to actions. The optimal policy
maximizes expected cumulative reward over time. Variants include
Partially Observable MDPs (POMDPs), where the agent has incomplete
knowledge of the state, and multi-agent decision processes, where
outcomes depend on the choices of others.

Sequential decision processes are the foundation of reinforcement
learning, where agents learn optimal policies through trial and error.
They also appear in robotics, operations research, and control theory.

Comparison Table: One-Shot vs.~Sequential Decisions

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1831}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3099}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5070}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
One-Shot Decision
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Sequential Decision
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Action impact & Immediate outcome only & Shapes future opportunities \\
Information & Often complete & May evolve over time \\
Objective & Maximize single reward & Maximize long-term cumulative
reward \\
Example in AI & Medical test selection & Treatment planning over
months \\
\end{longtable}

Sequential settings emphasize foresight. Greedy strategies may fail if
they ignore long-term effects, while optimal policies balance immediate
gains against future consequences. This introduces the classic
exploration vs.~exploitation dilemma: should the agent try new actions
to gather information or exploit known strategies for reward?

\subsubsection{Tiny Code}\label{tiny-code-68}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Sequential decision: simple 2{-}step planning}
\NormalTok{states }\OperatorTok{=}\NormalTok{ [}\StringTok{"start"}\NormalTok{, }\StringTok{"mid"}\NormalTok{, }\StringTok{"goal"}\NormalTok{]}
\NormalTok{actions }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"start"}\NormalTok{: \{}\StringTok{"a"}\NormalTok{: (}\StringTok{"mid"}\NormalTok{, }\DecValTok{5}\NormalTok{), }\StringTok{"b"}\NormalTok{: (}\StringTok{"goal"}\NormalTok{, }\DecValTok{2}\NormalTok{)\},}
    \StringTok{"mid"}\NormalTok{: \{}\StringTok{"c"}\NormalTok{: (}\StringTok{"goal"}\NormalTok{, }\DecValTok{10}\NormalTok{)\}}
\NormalTok{\}}

\KeywordTok{def}\NormalTok{ simulate(policy):}
\NormalTok{    state, total }\OperatorTok{=} \StringTok{"start"}\NormalTok{, }\DecValTok{0}
    \ControlFlowTok{while}\NormalTok{ state }\OperatorTok{!=} \StringTok{"goal"}\NormalTok{:}
\NormalTok{        action }\OperatorTok{=}\NormalTok{ policy[state]}
\NormalTok{        state, reward }\OperatorTok{=}\NormalTok{ actions[state][action]}
\NormalTok{        total }\OperatorTok{+=}\NormalTok{ reward}
    \ControlFlowTok{return}\NormalTok{ total}

\NormalTok{policy1 }\OperatorTok{=}\NormalTok{ \{}\StringTok{"start"}\NormalTok{:}\StringTok{"a"}\NormalTok{,}\StringTok{"mid"}\NormalTok{:}\StringTok{"c"}\NormalTok{\}  }\CommentTok{\# plan ahead}
\NormalTok{policy2 }\OperatorTok{=}\NormalTok{ \{}\StringTok{"start"}\NormalTok{:}\StringTok{"b"}\NormalTok{\}            }\CommentTok{\# greedy}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Planned policy reward:"}\NormalTok{, simulate(policy1))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Greedy policy reward:"}\NormalTok{, simulate(policy2))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-68}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the rewards---does the greedy policy ever win?
\item
  Extend the horizon---how does the complexity grow with each extra
  step?
\item
  Reflect: why does intelligence require looking beyond the immediate
  payoff?
\end{enumerate}

\subsection{70. Real-world constraints in
optimization}\label{real-world-constraints-in-optimization}

In theory, optimization seeks the best solution according to a
mathematical objective. In practice, real-world AI must handle
constraints: limited resources, noisy data, fairness requirements,
safety guarantees, and human preferences. These constraints shape not
only what is \emph{optimal} but also what is \emph{acceptable}.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-69}

Imagine scheduling flights for an airline. The mathematically cheapest
plan might overwork pilots, delay maintenance, or violate safety rules.
A ``real-world optimal'' schedule respects all these constraints, even
if it sacrifices theoretical efficiency.

\subsubsection{Deep Dive}\label{deep-dive-69}

Real-world optimization rarely occurs in a vacuum. Constraints define
the feasible region within which solutions can exist. They can be:

\begin{itemize}
\tightlist
\item
  Hard constraints: cannot be violated (budget caps, safety rules, legal
  requirements).
\item
  Soft constraints: preferences or guidelines that can be traded off
  against objectives (comfort, fairness, aesthetics).
\item
  Dynamic constraints: change over time due to resource availability,
  environment, or feedback loops.
\end{itemize}

In AI systems, constraints appear everywhere:

\begin{itemize}
\tightlist
\item
  Robotics: torque limits, collision avoidance.
\item
  Healthcare AI: ethical guidelines, treatment side effects.
\item
  Logistics: delivery deadlines, fuel costs, driver working hours.
\item
  Machine learning: fairness metrics, privacy guarantees.
\end{itemize}

Handling constraints requires specialized optimization techniques:
constrained linear programming, penalty methods, Lagrangian relaxation,
or multi-objective frameworks. Often, constraints elevate a simple
optimization into a deeply complex, sometimes NP-hard, real-world
problem.

Comparison Table: Ideal vs.~Constrained Optimization

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3571}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4762}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Ideal Optimization
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Real-World Optimization
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Assumptions & Unlimited resources, no limits & Resource, safety,
fairness, ethics apply \\
Solution space & All mathematically possible & Only feasible under
constraints \\
Output & Mathematically optimal & Practically viable and acceptable \\
Example & Shortest delivery path & Fastest safe path under traffic
rules \\
\end{longtable}

Constraints also highlight the gap between AI theory and deployment. A
pathfinding algorithm may suggest an ideal route, but the real driver
must avoid construction zones, follow regulations, and consider comfort.
This tension between theory and practice is one reason why real-world AI
often values robustness over perfection.

\subsubsection{Tiny Code}\label{tiny-code-69}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Constrained optimization: shortest path with blocked road}
\ImportTok{import}\NormalTok{ heapq}

\NormalTok{graph }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"A"}\NormalTok{: \{}\StringTok{"B"}\NormalTok{:}\DecValTok{1}\NormalTok{,}\StringTok{"C"}\NormalTok{:}\DecValTok{5}\NormalTok{\},}
    \StringTok{"B"}\NormalTok{: \{}\StringTok{"C"}\NormalTok{:}\DecValTok{1}\NormalTok{,}\StringTok{"D"}\NormalTok{:}\DecValTok{4}\NormalTok{\},}
    \StringTok{"C"}\NormalTok{: \{}\StringTok{"D"}\NormalTok{:}\DecValTok{1}\NormalTok{\},}
    \StringTok{"D"}\NormalTok{: \{\}}
\NormalTok{\}}

\NormalTok{blocked }\OperatorTok{=}\NormalTok{ (}\StringTok{"B"}\NormalTok{,}\StringTok{"C"}\NormalTok{)  }\CommentTok{\# constraint: road closed}

\KeywordTok{def}\NormalTok{ constrained\_dijkstra(start, goal):}
\NormalTok{    queue }\OperatorTok{=}\NormalTok{ [(}\DecValTok{0}\NormalTok{,start,[])]}
\NormalTok{    seen }\OperatorTok{=} \BuiltInTok{set}\NormalTok{()}
    \ControlFlowTok{while}\NormalTok{ queue:}
\NormalTok{        cost,node,path }\OperatorTok{=}\NormalTok{ heapq.heappop(queue)}
        \ControlFlowTok{if}\NormalTok{ node }\KeywordTok{in}\NormalTok{ seen:}
            \ControlFlowTok{continue}
\NormalTok{        path }\OperatorTok{=}\NormalTok{ path}\OperatorTok{+}\NormalTok{[node]}
        \ControlFlowTok{if}\NormalTok{ node }\OperatorTok{==}\NormalTok{ goal:}
            \ControlFlowTok{return}\NormalTok{ cost,path}
\NormalTok{        seen.add(node)}
        \ControlFlowTok{for}\NormalTok{ n,c }\KeywordTok{in}\NormalTok{ graph[node].items():}
            \ControlFlowTok{if}\NormalTok{ (node,n) }\OperatorTok{!=}\NormalTok{ blocked:  }\CommentTok{\# enforce constraint}
\NormalTok{                heapq.heappush(queue,(cost}\OperatorTok{+}\NormalTok{c,n,path))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Constrained path A→D:"}\NormalTok{, constrained\_dijkstra(}\StringTok{"A"}\NormalTok{,}\StringTok{"D"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-69}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more blocked edges---how does the feasible path set shrink?
\item
  Add a ``soft'' constraint by penalizing certain edges instead of
  forbidding them.
\item
  Reflect: why do most real-world AI systems optimize under constraints
  rather than chasing pure mathematical optima?
\end{enumerate}

\section{Chapter 8. Data, Signals and
Measurement}\label{chapter-8.-data-signals-and-measurement}

\subsection{71. Data as the foundation of
intelligence}\label{data-as-the-foundation-of-intelligence}

No matter how sophisticated the algorithm, AI systems are only as strong
as the data they learn from. Data grounds abstract models in the
realities of the world. It serves as both the raw material and the
feedback loop that allows intelligence to emerge.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-70}

Think of a sculptor and a block of marble. The sculptor's skill matters,
but without marble there is nothing to shape. In AI, algorithms are the
sculptor, but data is the marble---they cannot create meaning from
nothing.

\subsubsection{Deep Dive}\label{deep-dive-70}

Data functions as the foundation in three key ways. First, it provides
representations of the world: pixels stand in for objects, sound waves
for speech, and text for human knowledge. Second, it offers examples of
behavior, allowing learning systems to infer patterns, rules, or
preferences. Third, it acts as feedback, enabling systems to improve
through error correction and reinforcement.

But not all data is equal. High-quality, diverse, and well-structured
datasets produce robust models. Biased, incomplete, or noisy datasets
distort learning and decision-making. This is why data governance,
curation, and documentation are now central to AI practice.

In modern AI, the scale of data has become a differentiator. Classical
expert systems relied on rules hand-coded by humans, but deep learning
thrives because billions of examples fuel the discovery of complex
representations. At the same time, more data is not always better:
redundancy, poor quality, and ethical issues can make massive datasets
counterproductive.

Comparison Table: Data in Different AI Paradigms

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2391}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4022}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3587}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Paradigm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Role of Data
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Symbolic AI & Encoded as facts, rules, knowledge & Expert systems,
ontologies \\
Classical ML & Training + test sets for models & SVMs, decision trees \\
Deep Learning & Large-scale inputs for representation & ImageNet, GPT
pretraining corpora \\
Reinforcement Learning & Feedback signals from environment &
Game-playing agents, robotics \\
\end{longtable}

The future of AI will likely hinge less on raw data scale and more on
data efficiency: learning robust models from smaller, carefully curated,
or synthetic datasets. This shift mirrors human learning, where a child
can infer concepts from just a few examples.

\subsubsection{Tiny Code}\label{tiny-code-70}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple learning from data: linear regression}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LinearRegression}

\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{],[}\DecValTok{4}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{8}\NormalTok{])  }\CommentTok{\# perfect line: y=2x}

\NormalTok{model }\OperatorTok{=}\NormalTok{ LinearRegression().fit(X,y)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Prediction for x=5:"}\NormalTok{, model.predict([[}\DecValTok{5}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-70}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Corrupt the dataset with noise---how does prediction accuracy change?
\item
  Reduce the dataset size---does the model still generalize?
\item
  Reflect: why is data often called the ``new oil,'' and where does this
  metaphor break down?
\end{enumerate}

\subsection{72. Types of data: structured, unstructured,
multimodal}\label{types-of-data-structured-unstructured-multimodal}

AI systems work with many different kinds of data. Structured data is
neatly organized into tables and schemas. Unstructured data includes raw
forms like text, images, and audio. Multimodal data integrates multiple
types, enabling richer understanding. Each type demands different
methods of representation and processing.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-71}

Think of a library. A catalog with author, title, and year is structured
data. The books themselves---pages of text, illustrations, maps---are
unstructured data. A multimedia encyclopedia that combines text, images,
and video is multimodal. AI must navigate all three.

\subsubsection{Deep Dive}\label{deep-dive-71}

Structured data has been the foundation of traditional machine learning.
Rows and columns make statistical modeling straightforward. However,
most real-world data is unstructured: free-form text, conversations,
medical scans, video recordings. The rise of deep learning reflects the
need to automatically process this complexity.

Multimodal data adds another layer: combining modalities to capture
meaning that no single type can provide. A video of a lecture is richer
than its transcript alone, because tone, gesture, and visuals convey
context. Similarly, pairing radiology images with doctor's notes
strengthens diagnosis.

The challenge lies in integration. Structured and unstructured data
often coexist within a system, but aligning them---synchronizing
signals, handling scale differences, and learning cross-modal
representations---remains an open frontier.

Comparison Table: Data Types

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0968}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4113}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2823}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2097}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Data Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Examples
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strengths
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Challenges
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Structured & Databases, spreadsheets, sensors & Clean, easy to query,
interpretable & Limited expressiveness \\
Unstructured & Text, images, audio, video & Rich, natural, human-like &
High dimensionality, noisy \\
Multimodal & Video with subtitles, medical record (scan + notes) &
Comprehensive, context-rich & Alignment, fusion, scale \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-71}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Handling structured vs unstructured data}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{from}\NormalTok{ sklearn.feature\_extraction.text }\ImportTok{import}\NormalTok{ CountVectorizer}

\CommentTok{\# Structured: tabular}
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{"age"}\NormalTok{:[}\DecValTok{25}\NormalTok{,}\DecValTok{32}\NormalTok{,}\DecValTok{40}\NormalTok{],}\StringTok{"score"}\NormalTok{:[}\DecValTok{88}\NormalTok{,}\DecValTok{92}\NormalTok{,}\DecValTok{75}\NormalTok{]\})}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Structured data sample:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, df)}

\CommentTok{\# Unstructured: text}
\NormalTok{texts }\OperatorTok{=}\NormalTok{ [}\StringTok{"AI is powerful"}\NormalTok{, }\StringTok{"Data drives AI"}\NormalTok{]}
\NormalTok{vectorizer }\OperatorTok{=}\NormalTok{ CountVectorizer()}
\NormalTok{X }\OperatorTok{=}\NormalTok{ vectorizer.fit\_transform(texts)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Unstructured text as bag{-}of{-}words:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, X.toarray())}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-71}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add images as another modality---how would you represent them
  numerically?
\item
  Combine structured scores with unstructured student essays---what
  insights emerge?
\item
  Reflect: why does multimodality bring AI closer to human-like
  perception and reasoning?
\end{enumerate}

\subsection{73. Measurement, sensors, and signal
processing}\label{measurement-sensors-and-signal-processing}

AI systems connect to the world through measurement. Sensors capture raw
signals---light, sound, motion, temperature---and convert them into
data. Signal processing then refines these measurements, reducing noise
and extracting meaningful features for downstream models.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-72}

Imagine listening to a concert through a microphone. The microphone
captures sound waves, but the raw signal is messy: background chatter,
echoes, electrical interference. Signal processing is like adjusting an
equalizer, filtering out the noise, and keeping the melody clear.

\subsubsection{Deep Dive}\label{deep-dive-72}

Measurements are the bridge between physical reality and digital
computation. In robotics, lidar and cameras transform environments into
streams of data points. In healthcare, sensors turn heartbeats into ECG
traces. In finance, transactions become event logs.

Raw sensor data, however, is rarely usable as-is. Signal processing
applies transformations such as filtering, normalization, and feature
extraction. For instance, Fourier transforms reveal frequency patterns
in audio; edge detectors highlight shapes in images; statistical
smoothing reduces random fluctuations in time series.

Quality of measurement is critical: poor sensors or noisy environments
can degrade even the best AI models. Conversely, well-processed signals
can compensate for limited model complexity. This interplay is why
sensing and preprocessing remain as important as learning algorithms
themselves.

Comparison Table: Role of Measurement and Processing

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2022}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4045}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3933}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Stage
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI Applications
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Measurement & Capture raw signals & Camera images, microphone audio \\
Preprocessing & Clean and normalize data & Noise reduction in ECG
signals \\
Feature extraction & Highlight useful patterns & Spectrograms for speech
recognition \\
Modeling & Learn predictive or generative tasks & CNNs on processed
image features \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-72}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Signal processing: smoothing noisy measurements}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Simulated noisy sensor signal}
\NormalTok{np.random.seed(}\DecValTok{0}\NormalTok{)}
\NormalTok{signal }\OperatorTok{=}\NormalTok{ np.sin(np.linspace(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{50}\NormalTok{)) }\OperatorTok{+}\NormalTok{ np.random.normal(}\DecValTok{0}\NormalTok{,}\FloatTok{0.3}\NormalTok{,}\DecValTok{50}\NormalTok{)}

\CommentTok{\# Simple moving average filter}
\KeywordTok{def}\NormalTok{ smooth(x, window}\OperatorTok{=}\DecValTok{3}\NormalTok{):}
    \ControlFlowTok{return}\NormalTok{ np.convolve(x, np.ones(window)}\OperatorTok{/}\NormalTok{window, mode}\OperatorTok{=}\StringTok{\textquotesingle{}valid\textquotesingle{}}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Raw signal sample:"}\NormalTok{, signal[:}\DecValTok{5}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Smoothed signal sample:"}\NormalTok{, smooth(signal)[:}\DecValTok{5}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-72}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more noise to the signal---how does smoothing help or hurt?
\item
  Replace moving average with Fourier filtering---what patterns emerge?
\item
  Reflect: why is ``garbage in, garbage out'' especially true for
  sensor-driven AI? \#\#\# 74. Resolution, granularity, and sampling
\end{enumerate}

Every measurement depends on how finely the world is observed.
Resolution is the level of detail captured, granularity is the size of
the smallest distinguishable unit, and sampling determines how often
data is collected. Together, they shape the fidelity and usefulness of
AI inputs.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-73}

Imagine zooming into a digital map. At a coarse resolution, you only see
countries. Zoom further and cities appear. Zoom again and you see
individual streets. The underlying data is the same world, but
resolution and granularity determine what patterns are visible.

\subsubsection{Deep Dive}\label{deep-dive-73}

Resolution, granularity, and sampling are not just technical
choices---they define what AI can or cannot learn. Too coarse a
resolution hides patterns, like trying to detect heart arrhythmia with
one reading per hour. Too fine a resolution overwhelms systems with
redundant detail, like storing every frame of a video when one per
second suffices.

Sampling theory formalizes this trade-off. The Nyquist-Shannon theorem
states that to capture a signal without losing information, it must be
sampled at least twice its highest frequency. Violating this leads to
aliasing, where signals overlap and distort.

In practice, resolution and granularity are often matched to task
requirements. Satellite imaging for weather forecasting may only need
kilometer granularity, while medical imaging requires sub-millimeter
detail. The art lies in balancing precision, efficiency, and relevance.

Comparison Table: Effects of Resolution and Sampling

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1485}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1980}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3366}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3168}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Setting
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Benefit
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Risk if too low
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Risk if too high
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
High resolution & Captures fine detail & Miss critical patterns & Data
overload, storage costs \\
Low resolution & Compact, efficient & Aliasing, hidden structure & Loss
of accuracy \\
Dense sampling & Preserves dynamics & Misses fast changes & Redundancy,
computational burden \\
Sparse sampling & Saves resources & Fails to track important variation &
Insufficient for predictions \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-73}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Sampling resolution demo: sine wave}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}

\NormalTok{x\_high }\OperatorTok{=}\NormalTok{ np.linspace(}\DecValTok{0}\NormalTok{, }\DecValTok{2}\OperatorTok{*}\NormalTok{np.pi, }\DecValTok{1000}\NormalTok{)   }\CommentTok{\# high resolution}
\NormalTok{y\_high }\OperatorTok{=}\NormalTok{ np.sin(x\_high)}

\NormalTok{x\_low }\OperatorTok{=}\NormalTok{ np.linspace(}\DecValTok{0}\NormalTok{, }\DecValTok{2}\OperatorTok{*}\NormalTok{np.pi, }\DecValTok{10}\NormalTok{)      }\CommentTok{\# low resolution}
\NormalTok{y\_low }\OperatorTok{=}\NormalTok{ np.sin(x\_low)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"High{-}res sample (first 5):"}\NormalTok{, y\_high[:}\DecValTok{5}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Low{-}res sample (all):"}\NormalTok{, y\_low)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-73}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase low-resolution sampling points---at what point does the wave
  become recognizable?
\item
  Undersample a higher-frequency sine---do you see aliasing effects?
\item
  Reflect: how does the right balance of resolution and sampling depend
  on the domain (healthcare, robotics, astronomy)?
\end{enumerate}

\subsection{75. Noise reduction and signal
enhancement}\label{noise-reduction-and-signal-enhancement}

Real-world data is rarely clean. Noise---random errors, distortions, or
irrelevant fluctuations---can obscure the patterns AI systems need.
Noise reduction and signal enhancement are preprocessing steps that
improve data quality, making models more accurate and robust.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-74}

Think of tuning an old radio. Amid the static, you strain to hear a
favorite song. Adjusting the dial filters out the noise and sharpens the
melody. Signal processing in AI plays the same role: suppressing
interference so the underlying pattern is clearer.

\subsubsection{Deep Dive}\label{deep-dive-74}

Noise arises from many sources: faulty sensors, environmental
conditions, transmission errors, or inherent randomness. Its impact
depends on the task---small distortions in an image may not matter for
object detection but can be critical in medical imaging.

Noise reduction techniques include:

\begin{itemize}
\tightlist
\item
  Filtering: smoothing signals (moving averages, Gaussian filters) to
  remove high-frequency noise.
\item
  Fourier and wavelet transforms: separating signal from noise in the
  frequency domain.
\item
  Denoising autoencoders: deep learning models trained to reconstruct
  clean inputs.
\item
  Ensemble averaging: combining multiple noisy measurements to cancel
  out random variation.
\end{itemize}

Signal enhancement complements noise reduction by amplifying features of
interest---edges in images, peaks in spectra, or keywords in audio
streams. The two processes together ensure that downstream learning
algorithms focus on meaningful patterns.

Comparison Table: Noise Reduction Techniques

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Domain Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Moving average filter & Time series (finance) & Simple, effective &
Blurs sharp changes \\
Fourier filtering & Audio signals & Separates noise by frequency &
Requires frequency-domain insight \\
Denoising autoencoder & Image processing & Learns complex patterns &
Needs large training data \\
Ensemble averaging & Sensor networks & Reduces random fluctuations &
Ineffective against systematic bias \\
\end{longtable}

Noise reduction is not only about data cleaning---it shapes the very
boundary of what AI can perceive. A poor-quality signal limits
performance no matter the model complexity, while enhanced, noise-free
signals can enable simpler models to perform surprisingly well.

\subsubsection{Tiny Code}\label{tiny-code-74}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Noise reduction with a moving average}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Simulate noisy signal}
\NormalTok{np.random.seed(}\DecValTok{1}\NormalTok{)}
\NormalTok{signal }\OperatorTok{=}\NormalTok{ np.sin(np.linspace(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{50}\NormalTok{)) }\OperatorTok{+}\NormalTok{ np.random.normal(}\DecValTok{0}\NormalTok{,}\FloatTok{0.4}\NormalTok{,}\DecValTok{50}\NormalTok{)}

\KeywordTok{def}\NormalTok{ moving\_average(x, window}\OperatorTok{=}\DecValTok{3}\NormalTok{):}
    \ControlFlowTok{return}\NormalTok{ np.convolve(x, np.ones(window)}\OperatorTok{/}\NormalTok{window, mode}\OperatorTok{=}\StringTok{\textquotesingle{}valid\textquotesingle{}}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Noisy signal (first 5):"}\NormalTok{, signal[:}\DecValTok{5}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Smoothed signal (first 5):"}\NormalTok{, moving\_average(signal)[:}\DecValTok{5}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-74}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more noise---does the moving average still recover the signal
  shape?
\item
  Compare moving average with a median filter---how do results differ?
\item
  Reflect: in which domains (finance, healthcare, audio) does noise
  reduction make the difference between failure and success?
\end{enumerate}

\subsection{76. Data bias, drift, and blind
spots}\label{data-bias-drift-and-blind-spots}

AI systems inherit the properties of their training data. Bias occurs
when data systematically favors or disadvantages certain groups or
patterns. Drift happens when the underlying distribution of data changes
over time. Blind spots are regions of the real world poorly represented
in the data. Together, these issues limit reliability and fairness.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-75}

Imagine teaching a student geography using a map that only shows Europe.
The student becomes an expert on European countries but has no knowledge
of Africa or Asia. Their understanding is biased, drifts out of date as
borders change, and contains blind spots where the map is incomplete. AI
faces the same risks with data.

\subsubsection{Deep Dive}\label{deep-dive-75}

Bias arises from collection processes, sampling choices, or historical
inequities embedded in the data. For example, facial recognition systems
trained mostly on light-skinned faces perform poorly on darker-skinned
individuals.

Drift occurs in dynamic environments where patterns evolve. A fraud
detection system trained on last year's transactions may miss new attack
strategies. Drift can be covariate drift (input distributions change),
concept drift (label relationships shift), or prior drift (class
proportions change).

Blind spots reflect the limits of coverage. Rare diseases in medical
datasets, underrepresented languages in NLP, or unusual traffic
conditions in self-driving cars all highlight how missing data reduces
robustness.

Mitigation strategies include diverse sampling, continual learning,
fairness-aware metrics, drift detection algorithms, and active
exploration of underrepresented regions.

Comparison Table: Data Challenges

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0902}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3115}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3115}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2869}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Challenge
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Mitigation Strategy
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bias & Systematic distortion in training data & Hiring models favoring
majority groups & Balanced sampling, fairness metrics \\
Drift & Distribution changes over time & Spam filters missing new
campaigns & Drift detection, model retraining \\
Blind spots & Missing or underrepresented cases & Self-driving cars in
rare weather & Active data collection, simulation \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-75}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simulating drift in a simple dataset}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}

\CommentTok{\# Train data (old distribution)}
\NormalTok{X\_train }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{]])}
\NormalTok{y\_train }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])}
\NormalTok{model }\OperatorTok{=}\NormalTok{ LogisticRegression().fit(X\_train, y\_train)}

\CommentTok{\# New data (drifted distribution)}
\NormalTok{X\_new }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{],[}\DecValTok{4}\NormalTok{],[}\DecValTok{5}\NormalTok{]])}
\NormalTok{y\_new }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])  }\CommentTok{\# relationship changed}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Old model predictions:"}\NormalTok{, model.predict(X\_new))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"True labels (new distribution):"}\NormalTok{, y\_new)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-75}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more skewed training data---does the model amplify bias?
\item
  Simulate concept drift by flipping labels---how fast does performance
  degrade?
\item
  Reflect: why must AI systems monitor data continuously rather than
  assuming static distributions?
\end{enumerate}

\subsection{77. From raw signals to usable
features}\label{from-raw-signals-to-usable-features}

Raw data streams are rarely in a form directly usable by AI models.
Feature extraction transforms messy signals into structured
representations that highlight the most relevant patterns. Good features
reduce noise, compress information, and make learning more effective.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-76}

Think of preparing food ingredients. Raw crops from the farm are
unprocessed and unwieldy. Washing, chopping, and seasoning turn them
into usable components for cooking. In the same way, raw data needs
transformation into features before becoming useful for AI.

\subsubsection{Deep Dive}\label{deep-dive-76}

Feature extraction depends on the data type. In images, raw pixels are
converted into edges, textures, or higher-level embeddings. In audio,
waveforms become spectrograms or mel-frequency cepstral coefficients
(MFCCs). In text, words are encoded into bags of words, TF-IDF scores,
or distributed embeddings.

Historically, feature engineering was a manual craft, with domain
experts designing transformations. Deep learning has automated much of
this, with models learning hierarchical representations directly from
raw data. Still, preprocessing remains crucial: even deep networks rely
on normalized inputs, cleaned signals, and structured metadata.

The quality of features often determines the success of downstream
tasks. Poor features burden models with irrelevant noise; strong
features allow even simple algorithms to perform well. This is why
feature extraction is sometimes called the ``art'' of AI.

Comparison Table: Feature Extraction Approaches

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0795}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3182}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3523}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Domain
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Raw Signal Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Typical Features
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Modern Alternative
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Vision & Pixel intensity values & Edges, SIFT, HOG descriptors &
CNN-learned embeddings \\
Audio & Waveforms & Spectrograms, MFCCs & Self-supervised audio
models \\
Text & Words or characters & Bag-of-words, TF-IDF & Word2Vec, BERT
embeddings \\
Tabular & Raw measurements & Normalized, derived ratios & Learned
embeddings in deep nets \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-76}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Feature extraction: text example}
\ImportTok{from}\NormalTok{ sklearn.feature\_extraction.text }\ImportTok{import}\NormalTok{ TfidfVectorizer}

\NormalTok{texts }\OperatorTok{=}\NormalTok{ [}\StringTok{"AI transforms data"}\NormalTok{, }\StringTok{"Data drives intelligence"}\NormalTok{]}
\NormalTok{vectorizer }\OperatorTok{=}\NormalTok{ TfidfVectorizer()}
\NormalTok{X }\OperatorTok{=}\NormalTok{ vectorizer.fit\_transform(texts)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Feature names:"}\NormalTok{, vectorizer.get\_feature\_names\_out())}
\BuiltInTok{print}\NormalTok{(}\StringTok{"TF{-}IDF matrix:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, X.toarray())}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-76}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Apply TF-IDF to a larger set of documents---what features dominate?
\item
  Replace TF-IDF with raw counts---does classification accuracy change?
\item
  Reflect: when should features be hand-crafted, and when should they be
  learned automatically?
\end{enumerate}

\subsection{78. Standards for measurement and
metadata}\label{standards-for-measurement-and-metadata}

Data alone is not enough---how it is measured, described, and
standardized determines whether it can be trusted and reused. Standards
for measurement ensure consistency across systems, while metadata
documents context, quality, and meaning. Without them, AI models risk
learning from incomplete or misleading inputs.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-77}

Imagine receiving a dataset of temperatures without knowing whether
values are in Celsius or Fahrenheit. The numbers are useless---or worse,
dangerous---without metadata to clarify their meaning. Standards and
documentation are the ``units and labels'' that make data interoperable.

\subsubsection{Deep Dive}\label{deep-dive-77}

Measurement standards specify how data is collected: the units,
calibration methods, and protocols. For example, a blood pressure
dataset must specify whether readings were taken at rest, what device
was used, and how values were rounded.

Metadata adds descriptive layers:

\begin{itemize}
\tightlist
\item
  Descriptive metadata: what the dataset contains (variables, units,
  formats).
\item
  Provenance metadata: where the data came from, when it was collected,
  by whom.
\item
  Quality metadata: accuracy, uncertainty, missing values.
\item
  Ethical metadata: consent, usage restrictions, potential biases.
\end{itemize}

In large-scale AI projects, metadata standards like Dublin Core,
schema.org, or ML data cards help datasets remain interpretable and
auditable. Poorly documented data leads to reproducibility crises,
opaque models, and fairness risks.

Comparison Table: Data With vs.~Without Standards

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1910}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4270}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3820}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
With Standards \& Metadata
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Without Standards \& Metadata
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Consistency & Units, formats, and protocols aligned & Confusion,
misinterpretation \\
Reusability & Datasets can be merged and compared & Silos, duplication,
wasted effort \\
Accountability & Provenance and consent are transparent & Origins
unclear, ethical risks \\
Model reliability & Clear assumptions improve performance & Hidden
mismatches degrade accuracy \\
\end{longtable}

Standards are especially critical in regulated domains like healthcare,
finance, and geoscience. A model predicting disease progression must not
only be accurate but also auditable---knowing how, when, and why the
training data was collected.

\subsubsection{Tiny Code}\label{tiny-code-77}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example: attaching simple metadata to a dataset}
\NormalTok{dataset }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"data"}\NormalTok{: [}\FloatTok{36.6}\NormalTok{, }\FloatTok{37.1}\NormalTok{, }\FloatTok{38.0}\NormalTok{],  }\CommentTok{\# temperatures}
    \StringTok{"metadata"}\NormalTok{: \{}
        \StringTok{"unit"}\NormalTok{: }\StringTok{"Celsius"}\NormalTok{,}
        \StringTok{"source"}\NormalTok{: }\StringTok{"Thermometer Model X"}\NormalTok{,}
        \StringTok{"collection\_date"}\NormalTok{: }\StringTok{"2025{-}09{-}16"}\NormalTok{,}
        \StringTok{"notes"}\NormalTok{: }\StringTok{"Measured at rest, oral sensor"}
\NormalTok{    \}}
\NormalTok{\}}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Data:"}\NormalTok{, dataset[}\StringTok{"data"}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Metadata:"}\NormalTok{, dataset[}\StringTok{"metadata"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-77}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Remove the unit metadata---how ambiguous do the values become?
\item
  Add provenance (who, when, where)---does it increase trust in the
  dataset?
\item
  Reflect: why is metadata often the difference between raw numbers and
  actionable knowledge?
\end{enumerate}

\subsection{79. Data curation and
stewardship}\label{data-curation-and-stewardship}

Collecting data is only the beginning. Data curation is the ongoing
process of organizing, cleaning, and maintaining datasets to ensure they
remain useful. Data stewardship extends this responsibility to
governance, ethics, and long-term sustainability. Together, they make
data a durable resource rather than a disposable byproduct.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-78}

Think of a museum. Artifacts are not just stored---they are cataloged,
preserved, and contextualized for future generations. Data requires the
same care: without curation and stewardship, it degrades, becomes
obsolete, or loses trustworthiness.

\subsubsection{Deep Dive}\label{deep-dive-78}

Curation ensures datasets are structured, consistent, and ready for
analysis. It includes cleaning errors, filling missing values,
normalizing formats, and documenting processes. Poorly curated data
leads to fragile models and irreproducible results.

Stewardship broadens the scope. It emphasizes responsible ownership,
ensuring data is collected ethically, used according to consent, and
maintained with transparency. It also covers lifecycle management: from
acquisition to archival or deletion. In AI, this is crucial because
models may amplify harms hidden in unmanaged data.

The FAIR principles---Findable, Accessible, Interoperable,
Reusable---guide modern stewardship. Compliance requires metadata
standards, open documentation, and community practices. Without these,
even large datasets lose value quickly.

Comparison Table: Curation vs.~Stewardship

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1176}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3882}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4941}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Data Curation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Data Stewardship
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Focus & Technical preparation of datasets & Ethical, legal, and
lifecycle management \\
Activities & Cleaning, labeling, formatting & Governance, consent,
compliance, access \\
Timescale & Immediate usability & Long-term sustainability \\
Example & Removing duplicates in logs & Ensuring patient data privacy
over decades \\
\end{longtable}

Curation and stewardship are not just operational tasks---they shape
trust in AI. Without them, datasets may encode hidden biases, degrade in
quality, or become non-compliant with evolving regulations. With them,
data becomes a shared resource for science and society.

\subsubsection{Tiny Code}\label{tiny-code-78}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example of simple data curation: removing duplicates}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}

\NormalTok{data }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
    \StringTok{"id"}\NormalTok{: [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{],}
    \StringTok{"value"}\NormalTok{: [}\DecValTok{10}\NormalTok{,}\DecValTok{20}\NormalTok{,}\DecValTok{20}\NormalTok{,}\DecValTok{30}\NormalTok{]}
\NormalTok{\})}

\NormalTok{curated }\OperatorTok{=}\NormalTok{ data.drop\_duplicates()}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Before curation:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, data)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"After curation:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, curated)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-78}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add missing values---how would you curate them (drop, fill, impute)?
\item
  Think about stewardship: who should own and manage this dataset
  long-term?
\item
  Reflect: why is curated, stewarded data as much a public good as clean
  water or safe infrastructure?
\end{enumerate}

\subsection{80. The evolving role of data in AI
progress}\label{the-evolving-role-of-data-in-ai-progress}

The history of AI can be told as a history of data. Early symbolic
systems relied on handcrafted rules and small knowledge bases. Classical
machine learning advanced with curated datasets. Modern deep learning
thrives on massive, diverse corpora. As AI evolves, the role of data
shifts from sheer quantity toward quality, efficiency, and responsible
use.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-79}

Imagine three eras of farming. First, farmers plant seeds manually in
small plots (symbolic AI). Next, they use irrigation and fertilizers to
cultivate larger fields (classical ML with curated datasets). Finally,
industrial-scale farms use machinery and global supply chains (deep
learning with web-scale data). The future may return to smaller, smarter
farms focused on sustainability---AI's shift to efficient, ethical data
use.

\subsubsection{Deep Dive}\label{deep-dive-79}

In early AI, data was secondary; knowledge was encoded directly by
experts. Success depended on the richness of rules, not scale. With
statistical learning, data became central, but curated datasets like
MNIST or UCI repositories sufficed. The deep learning revolution
reframed data as fuel: bigger corpora enabled models to learn richer
representations.

Yet this data-centric paradigm faces limits. Collecting ever-larger
datasets raises issues of redundancy, privacy, bias, and environmental
cost. Performance gains increasingly come from better data, not just
more data: filtering noise, balancing demographics, and aligning
distributions with target tasks. Synthetic data, data augmentation, and
self-supervised learning further reduce dependence on labeled corpora.

The next phase emphasizes data efficiency: achieving strong
generalization with fewer examples. Techniques like few-shot learning,
transfer learning, and foundation models show that high-capacity systems
can adapt with minimal new data if pretraining and priors are strong.

Comparison Table: Evolution of Data in AI

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1518}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3214}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2054}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3214}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Era
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Role of Data
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Systems
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Symbolic AI & Small, handcrafted knowledge bases & Expert systems
(MYCIN) & Brittle, limited coverage \\
Classical ML & Curated, labeled datasets & SVMs, decision trees &
Labor-intensive labeling \\
Deep Learning & Massive, web-scale corpora & GPT, ImageNet models &
Bias, cost, ethical concerns \\
Data-efficient AI & Few-shot, synthetic, curated signals & GPT-4,
diffusion models & Still dependent on pretraining scale \\
\end{longtable}

The trajectory suggests data will remain the cornerstone of AI, but the
focus is shifting. Rather than asking ``how much data,'' the key
questions become: ``what kind of data,'' ``how is it governed,'' and
``who controls it.''

\subsubsection{Tiny Code}\label{tiny-code-79}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simulating data efficiency: training on few vs many points}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}

\NormalTok{X\_many }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{],[}\DecValTok{4}\NormalTok{],[}\DecValTok{5}\NormalTok{]])}
\NormalTok{y\_many }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{]}

\NormalTok{X\_few }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{5}\NormalTok{]])}
\NormalTok{y\_few }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{]}

\NormalTok{model\_many }\OperatorTok{=}\NormalTok{ LogisticRegression().fit(X\_many,y\_many)}
\NormalTok{model\_few }\OperatorTok{=}\NormalTok{ LogisticRegression().fit(X\_few,y\_few)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Prediction with many samples (x=2):"}\NormalTok{, model\_many.predict([[}\DecValTok{2}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Prediction with few samples (x=2):"}\NormalTok{, model\_few.predict([[}\DecValTok{2}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-79}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Train on noisy data---does more always mean better?
\item
  Compare performance between curated small datasets and large but messy
  ones.
\item
  Reflect: is the future of AI about scaling data endlessly, or about
  making smarter use of less?
\end{enumerate}

\section{Chapter 9. Evaluation: Ground Truth, Metrics, and
Benchmark}\label{chapter-9.-evaluation-ground-truth-metrics-and-benchmark}

\subsection{81. Why evaluation is central to
AI}\label{why-evaluation-is-central-to-ai}

Evaluation is the compass of AI. Without it, we cannot tell whether a
system is learning, improving, or even functioning correctly. Evaluation
provides the benchmarks against which progress is measured, the feedback
loops that guide development, and the accountability that ensures trust.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-80}

Think of training for a marathon. Running every day without tracking
time or distance leaves you blind to improvement. Recording and
comparing results over weeks tells you whether you're faster, stronger,
or just running in circles. AI models, too, need evaluation to know if
they're moving closer to their goals.

\subsubsection{Deep Dive}\label{deep-dive-80}

Evaluation serves multiple roles in AI research and practice. At a
scientific level, it transforms intuition into measurable progress:
models can be compared, results replicated, and knowledge accumulated.
At an engineering level, it drives iteration: without clear metrics,
model improvements are indistinguishable from noise. At a societal
level, evaluation ensures systems meet standards of safety, fairness,
and usability.

The difficulty lies in defining ``success.'' For a translation system,
is success measured by BLEU score, human fluency ratings, or
communication effectiveness in real conversations? Each metric captures
part of the truth but not the whole. Overreliance on narrow metrics
risks overfitting to benchmarks while ignoring broader impacts.

Evaluation is also what separates research prototypes from deployed
systems. A model with 99\% accuracy in the lab may fail disastrously if
evaluated under real-world distribution shifts. Continuous evaluation is
therefore as important as one-off testing, ensuring robustness over
time.

Comparison Table: Roles of Evaluation

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1294}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4235}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4471}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Level
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Scientific & Measure progress, enable replication & Comparing algorithms
on ImageNet \\
Engineering & Guide iteration and debugging & Monitoring loss curves
during training \\
Societal & Ensure trust, safety, fairness & Auditing bias in hiring
algorithms \\
\end{longtable}

Evaluation is not just about accuracy but about defining values. What we
measure reflects what we consider important. If evaluation only tracks
efficiency, fairness may be ignored. If it only tracks benchmarks,
real-world usability may lag behind. Thus, designing evaluation
frameworks is as much a normative decision as a technical one.

\subsubsection{Tiny Code}\label{tiny-code-80}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple evaluation of a classifier}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ accuracy\_score}

\NormalTok{y\_true }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{]}
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{]}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Accuracy:"}\NormalTok{, accuracy\_score(y\_true, y\_pred))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-80}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add false positives or false negatives---does accuracy still reflect
  system quality?
\item
  Replace accuracy with precision/recall---what new insights appear?
\item
  Reflect: why does ``what we measure'' ultimately shape ``what we
  build'' in AI?
\end{enumerate}

\subsection{82. Ground truth: gold standards and
proxies}\label{ground-truth-gold-standards-and-proxies}

Evaluation in AI depends on comparing model outputs against a reference.
The most reliable reference is ground truth---the correct labels,
answers, or outcomes for each input. When true labels are unavailable,
researchers often rely on proxies, which approximate truth but may
introduce errors or biases.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-81}

Imagine grading math homework. If you have the official answer key, you
can check each solution precisely---that's ground truth. If the key is
missing, you might ask another student for their answer. It's quicker,
but you risk copying their mistakes---that's a proxy.

\subsubsection{Deep Dive}\label{deep-dive-81}

Ground truth provides the foundation for supervised learning and model
validation. In image recognition, it comes from labeled datasets where
humans annotate objects. In speech recognition, it comes from
transcripts aligned to audio. In medical AI, ground truth may be expert
diagnoses confirmed by follow-up tests.

However, obtaining ground truth is costly, slow, and sometimes
impossible. For example, in predicting long-term economic outcomes or
scientific discoveries, we cannot observe the ``true'' label in real
time. Proxies step in: click-through rates approximate relevance,
hospital readmission approximates health outcomes, human ratings
approximate translation quality.

The challenge is that proxies may diverge from actual goals. Optimizing
for clicks may produce clickbait, not relevance. Optimizing for
readmissions may ignore patient well-being. This disconnect is known as
the proxy problem, and it highlights the danger of equating
easy-to-measure signals with genuine ground truth.

Comparison Table: Ground Truth vs.~Proxies

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1481}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4198}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4321}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Ground Truth
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Proxies
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Accuracy & High fidelity, definitive & Approximate, error-prone \\
Cost & Expensive, labor-intensive & Cheap, scalable \\
Availability & Limited in scope, slow to collect & Widely available,
real-time \\
Risks & Narrow coverage & Misalignment, unintended incentives \\
Example & Radiologist-confirmed tumor labels & Hospital billing codes \\
\end{longtable}

Balancing truth and proxies is an ongoing struggle in AI. Gold standards
are needed for rigor but cannot scale indefinitely. Proxies allow rapid
iteration but risk misguiding optimization. Increasingly, hybrid
approaches are emerging---combining small high-quality ground truth
datasets with large proxy-driven datasets, often via semi-supervised or
self-supervised learning.

\subsubsection{Tiny Code}\label{tiny-code-81}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Comparing ground truth vs proxy evaluation}
\NormalTok{y\_true   }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{]  }\CommentTok{\# ground truth labels}
\NormalTok{y\_proxy  }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{]  }\CommentTok{\# proxy labels (noisy)}
\NormalTok{y\_pred   }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{]  }\CommentTok{\# model predictions}

\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ accuracy\_score}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Accuracy vs ground truth:"}\NormalTok{, accuracy\_score(y\_true, y\_pred))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Accuracy vs proxy:"}\NormalTok{, accuracy\_score(y\_proxy, y\_pred))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-81}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more noise to the proxy labels---how quickly does proxy accuracy
  diverge from true accuracy?
\item
  Combine ground truth with proxy labels---does this improve robustness?
\item
  Reflect: why does the choice of ground truth or proxy ultimately shape
  how AI systems behave in the real world?
\end{enumerate}

\subsection{83. Metrics for classification, regression,
ranking}\label{metrics-for-classification-regression-ranking}

Evaluation requires metrics---quantitative measures that capture how
well a model performs its task. Different tasks demand different
metrics: classification uses accuracy, precision, recall, and F1;
regression uses mean squared error or R²; ranking uses measures like
NDCG or MAP. Choosing the right metric ensures models are optimized for
what truly matters.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-82}

Think of judging a competition. A sprint race is scored by fastest time
(regression). A spelling bee is judged right or wrong (classification).
A search engine is ranked by how high relevant results appear (ranking).
The scoring rule changes with the task, just like metrics in AI.

\subsubsection{Deep Dive}\label{deep-dive-82}

In classification, the simplest metric is accuracy: the proportion of
correct predictions. But accuracy can be misleading when classes are
imbalanced. Precision measures the fraction of positive predictions that
are correct, recall measures the fraction of true positives identified,
and F1 balances the two.

In regression, metrics focus on error magnitude. Mean squared error
(MSE) penalizes large deviations heavily, while mean absolute error
(MAE) treats all errors equally. R² captures how much of the variance in
the target variable the model explains.

In ranking, the goal is ordering relevance. Metrics like Mean Average
Precision (MAP) evaluate precision across ranks, while Normalized
Discounted Cumulative Gain (NDCG) emphasizes highly ranked relevant
results. These are essential in information retrieval, recommendation,
and search engines.

The key insight is that metrics are not interchangeable. A fraud
detection system optimized for accuracy may ignore rare but costly fraud
cases, while optimizing for recall may catch more fraud but generate
false alarms. Choosing metrics means choosing trade-offs.

Comparison Table: Metrics Across Tasks

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2952}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5714}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Task
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Common Metrics
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
What They Emphasize
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Classification & Accuracy, Precision, Recall, F1 & Balance between
overall correctness and handling rare events \\
Regression & MSE, MAE, R² & Magnitude of prediction errors \\
Ranking & MAP, NDCG, Precision@k & Placement of relevant items at the
top \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-82}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ accuracy\_score, mean\_squared\_error}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ ndcg\_score}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Classification example}
\NormalTok{y\_true\_cls }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{]}
\NormalTok{y\_pred\_cls }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{]}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Classification accuracy:"}\NormalTok{, accuracy\_score(y\_true\_cls, y\_pred\_cls))}

\CommentTok{\# Regression example}
\NormalTok{y\_true\_reg }\OperatorTok{=}\NormalTok{ [}\FloatTok{2.5}\NormalTok{, }\FloatTok{0.0}\NormalTok{, }\FloatTok{2.1}\NormalTok{, }\FloatTok{7.8}\NormalTok{]}
\NormalTok{y\_pred\_reg }\OperatorTok{=}\NormalTok{ [}\FloatTok{3.0}\NormalTok{, }\OperatorTok{{-}}\FloatTok{0.5}\NormalTok{, }\FloatTok{2.0}\NormalTok{, }\FloatTok{7.5}\NormalTok{]}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Regression MSE:"}\NormalTok{, mean\_squared\_error(y\_true\_reg, y\_pred\_reg))}

\CommentTok{\# Ranking example}
\NormalTok{true\_relevance }\OperatorTok{=}\NormalTok{ np.asarray([[}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{]])}
\NormalTok{scores }\OperatorTok{=}\NormalTok{ np.asarray([[}\FloatTok{0.1}\NormalTok{,}\FloatTok{0.4}\NormalTok{,}\FloatTok{0.35}\NormalTok{]])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Ranking NDCG:"}\NormalTok{, ndcg\_score(true\_relevance, scores))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-82}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more imbalanced classes to the classification task---does accuracy
  still tell the full story?
\item
  Compare MAE and MSE on regression---why does one penalize outliers
  more?
\item
  Change the ranking scores---does NDCG reward putting relevant items at
  the top?
\end{enumerate}

\subsection{84. Multi-objective and task-specific
metrics}\label{multi-objective-and-task-specific-metrics}

Real-world AI rarely optimizes for a single criterion. Multi-objective
metrics combine several goals---like accuracy and fairness, or speed and
energy efficiency---into evaluation. Task-specific metrics adapt general
principles to the nuances of a domain, ensuring that evaluation reflects
what truly matters in context.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-83}

Imagine judging a car. Speed alone doesn't decide the winner---safety,
fuel efficiency, and comfort also count. Similarly, an AI system must be
judged across multiple axes, not just one score.

\subsubsection{Deep Dive}\label{deep-dive-83}

Multi-objective metrics arise when competing priorities exist. For
example, in healthcare AI, sensitivity (catching every possible case)
must be balanced with specificity (avoiding false alarms). In
recommender systems, relevance must be balanced against diversity or
novelty. In robotics, task completion speed competes with energy
consumption and safety.

There are several ways to handle multiple objectives:

\begin{itemize}
\tightlist
\item
  Composite scores: weighted sums of different metrics.
\item
  Pareto analysis: evaluating trade-offs without collapsing into a
  single number.
\item
  Constraint-based metrics: optimizing one objective while enforcing
  thresholds on others.
\end{itemize}

Task-specific metrics tailor evaluation to the problem. In machine
translation, BLEU and METEOR attempt to measure linguistic quality. In
speech synthesis, MOS (Mean Opinion Score) reflects human perceptions of
naturalness. In medical imaging, Dice coefficient captures spatial
overlap between predicted and actual regions of interest.

The risk is that poorly chosen metrics incentivize undesirable
behavior---overfitting to leaderboards, optimizing proxies rather than
real goals, or ignoring hidden dimensions like fairness and usability.

Comparison Table: Multi-Objective and Task-Specific Metrics

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2111}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4222}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Context
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Multi-Objective Metric Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Task-Specific Metric Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Healthcare & Sensitivity + Specificity balance & Dice coefficient for
tumor detection \\
Recommender Systems & Relevance + Diversity & Novelty index \\
NLP & Fluency + Adequacy in translation & BLEU, METEOR \\
Robotics & Efficiency + Safety & Task completion time under
constraints \\
\end{longtable}

Evaluation frameworks increasingly adopt dashboard-style reporting
instead of single scores, showing trade-offs explicitly. This helps
researchers and practitioners make informed decisions aligned with
broader values.

\subsubsection{Tiny Code}\label{tiny-code-83}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Multi{-}objective evaluation: weighted score}
\NormalTok{precision }\OperatorTok{=} \FloatTok{0.8}
\NormalTok{recall }\OperatorTok{=} \FloatTok{0.6}

\CommentTok{\# Weighted composite: 70\% precision, 30\% recall}
\NormalTok{score }\OperatorTok{=} \FloatTok{0.7}\OperatorTok{*}\NormalTok{precision }\OperatorTok{+} \FloatTok{0.3}\OperatorTok{*}\NormalTok{recall}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Composite score:"}\NormalTok{, score)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-83}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Adjust weights between precision and recall---how does it change the
  ``best'' model?
\item
  Replace composite scoring with Pareto analysis---are some models
  incomparable?
\item
  Reflect: why is it dangerous to collapse complex goals into a single
  number?
\end{enumerate}

\subsection{85. Statistical significance and
confidence}\label{statistical-significance-and-confidence}

When comparing AI models, differences in performance may arise from
chance rather than genuine improvement. Statistical significance testing
and confidence intervals quantify how much trust we can place in
observed results. They separate real progress from random variation.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-84}

Think of flipping a coin 10 times and getting 7 heads. Is the coin
biased, or was it just luck? Without statistical tests, you can't be
sure. Evaluating AI models works the same way---apparent improvements
might be noise unless we test their reliability.

\subsubsection{Deep Dive}\label{deep-dive-84}

Statistical significance measures whether performance differences are
unlikely under a null hypothesis (e.g., two models are equally good).
Common tests include the t-test, chi-square test, and bootstrap
resampling.

Confidence intervals provide a range within which the true performance
likely lies, usually expressed at 95\% or 99\% levels. For example,
reporting accuracy as 92\% ± 2\% is more informative than a bare 92\%,
because it acknowledges uncertainty.

Significance and confidence are especially important when:

\begin{itemize}
\tightlist
\item
  Comparing models on small datasets.
\item
  Evaluating incremental improvements.
\item
  Benchmarking in competitions or leaderboards.
\end{itemize}

Without these safeguards, AI progress can be overstated. Many published
results that seemed promising later failed to replicate, fueling
concerns about reproducibility in machine learning.

Comparison Table: Accuracy vs.~Confidence

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2237}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2237}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5526}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Report Style
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Value
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Interpretation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Raw accuracy & 92\% & Single point estimate, no uncertainty \\
With confidence & 92\% ± 2\% (95\% CI) & True accuracy likely lies
between 90--94\% \\
Significance test & p \textless{} 0.05 & Less than 5\% chance result is
random noise \\
\end{longtable}

By treating evaluation statistically, AI systems are held to scientific
standards rather than marketing hype. This strengthens trust and helps
avoid chasing illusions of progress.

\subsubsection{Tiny Code}\label{tiny-code-84}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Bootstrap confidence interval for accuracy}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{y\_true }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{])}
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])}

\NormalTok{accuracy }\OperatorTok{=}\NormalTok{ np.mean(y\_true }\OperatorTok{==}\NormalTok{ y\_pred)}

\CommentTok{\# Bootstrap resampling}
\NormalTok{bootstraps }\OperatorTok{=} \DecValTok{1000}
\NormalTok{scores }\OperatorTok{=}\NormalTok{ []}
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.default\_rng(}\DecValTok{0}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(bootstraps):}
\NormalTok{    idx }\OperatorTok{=}\NormalTok{ rng.choice(}\BuiltInTok{len}\NormalTok{(y\_true), }\BuiltInTok{len}\NormalTok{(y\_true), replace}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    scores.append(np.mean(y\_true[idx] }\OperatorTok{==}\NormalTok{ y\_pred[idx]))}

\NormalTok{ci\_lower, ci\_upper }\OperatorTok{=}\NormalTok{ np.percentile(scores, [}\FloatTok{2.5}\NormalTok{,}\FloatTok{97.5}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Accuracy: }\SpecialCharTok{\{}\NormalTok{accuracy}\SpecialCharTok{:.2f\}}\SpecialStringTok{, 95\% CI: [}\SpecialCharTok{\{}\NormalTok{ci\_lower}\SpecialCharTok{:.2f\}}\SpecialStringTok{, }\SpecialCharTok{\{}\NormalTok{ci\_upper}\SpecialCharTok{:.2f\}}\SpecialStringTok{]"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-84}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Reduce the dataset size---how does the confidence interval widen?
\item
  Increase the number of bootstrap samples---does the CI stabilize?
\item
  Reflect: why should every AI claim of superiority come with
  uncertainty estimates?
\end{enumerate}

\subsection{86. Benchmarks and leaderboards in AI
research}\label{benchmarks-and-leaderboards-in-ai-research}

Benchmarks and leaderboards provide shared standards for evaluating AI.
A benchmark is a dataset or task that defines a common ground for
comparison. A leaderboard tracks performance on that benchmark, ranking
systems by their reported scores. Together, they drive competition,
progress, and sometimes over-optimization.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-85}

Think of a high-jump bar in athletics. Each athlete tries to clear the
same bar, and the scoreboard shows who jumped the highest. Benchmarks
are the bar, leaderboards are the scoreboard, and researchers are the
athletes.

\subsubsection{Deep Dive}\label{deep-dive-85}

Benchmarks like ImageNet for vision, GLUE for NLP, and Atari for
reinforcement learning have shaped entire subfields. They make progress
measurable, enabling fair comparisons across methods. Leaderboards add
visibility and competition, encouraging rapid iteration and innovation.

Yet this success comes with risks. Overfitting to benchmarks is common:
models achieve state-of-the-art scores but fail under real-world
conditions. Benchmarks may also encode biases, meaning leaderboard
``winners'' are not necessarily best for fairness, robustness, or
efficiency. Moreover, a focus on single numbers obscures trade-offs such
as interpretability, cost, or safety.

Comparison Table: Pros and Cons of Benchmarks

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Benefit & Risk \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Standardized evaluation & Narrow focus on specific tasks \\
Encourages reproducibility & Overfitting to test sets \\
Accelerates innovation & Ignores robustness and generality \\
Provides community reference & Creates leaderboard chasing culture \\
\end{longtable}

Benchmarks are evolving. Dynamic benchmarks (e.g., Dynabench)
continuously refresh data to resist overfitting. Multi-dimensional
leaderboards report robustness, efficiency, and fairness, not just raw
accuracy. The field is moving from static bars to richer ecosystems of
evaluation.

\subsubsection{Tiny Code}\label{tiny-code-85}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple leaderboard tracker}
\NormalTok{leaderboard }\OperatorTok{=}\NormalTok{ [}
\NormalTok{    \{}\StringTok{"model"}\NormalTok{: }\StringTok{"A"}\NormalTok{, }\StringTok{"score"}\NormalTok{: }\FloatTok{0.85}\NormalTok{\},}
\NormalTok{    \{}\StringTok{"model"}\NormalTok{: }\StringTok{"B"}\NormalTok{, }\StringTok{"score"}\NormalTok{: }\FloatTok{0.88}\NormalTok{\},}
\NormalTok{    \{}\StringTok{"model"}\NormalTok{: }\StringTok{"C"}\NormalTok{, }\StringTok{"score"}\NormalTok{: }\FloatTok{0.83}\NormalTok{\},}
\NormalTok{]}

\CommentTok{\# Rank models}
\NormalTok{ranked }\OperatorTok{=} \BuiltInTok{sorted}\NormalTok{(leaderboard, key}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ x: x[}\StringTok{"score"}\NormalTok{], reverse}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ i, entry }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(ranked, }\DecValTok{1}\NormalTok{):}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{i}\SpecialCharTok{\}}\SpecialStringTok{. }\SpecialCharTok{\{}\NormalTok{entry[}\StringTok{\textquotesingle{}model\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{ {-} }\SpecialCharTok{\{}\NormalTok{entry[}\StringTok{\textquotesingle{}score\textquotesingle{}}\NormalTok{]}\SpecialCharTok{:.2f\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-85}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add efficiency or fairness scores---does the leaderboard ranking
  change?
\item
  Simulate overfitting by artificially inflating one model's score.
\item
  Reflect: should leaderboards report a single ``winner,'' or a richer
  profile of performance dimensions?
\end{enumerate}

\subsection{87. Overfitting to benchmarks and Goodhart's
Law}\label{overfitting-to-benchmarks-and-goodharts-law}

Benchmarks are designed to measure progress, but when optimization
focuses narrowly on beating the benchmark, true progress may stall. This
phenomenon is captured by Goodhart's Law: \emph{``When a measure becomes
a target, it ceases to be a good measure.''} In AI, this means models
may excel on test sets while failing in the real world.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-86}

Imagine students trained only to pass practice exams. They memorize
patterns in past tests but struggle with new problems. Their scores
rise, but their true understanding does not. AI models can fall into the
same trap when benchmarks dominate training.

\subsubsection{Deep Dive}\label{deep-dive-86}

Overfitting to benchmarks happens in several ways. Models may exploit
spurious correlations in datasets, such as predicting ``snow'' whenever
``polar bear'' appears. Leaderboard competition can encourage marginal
improvements that exploit dataset quirks instead of advancing general
methods.

Goodhart's Law warns that once benchmarks become the primary target,
they lose their reliability as indicators of general capability. The
history of AI is filled with shifting benchmarks: chess, ImageNet,
GLUE---all once difficult, now routinely surpassed. Each success reveals
both the value and the limitation of benchmarks.

Mitigation strategies include:

\begin{itemize}
\tightlist
\item
  Rotating or refreshing benchmarks to prevent memorization.
\item
  Creating adversarial or dynamic test sets.
\item
  Reporting performance across multiple benchmarks and dimensions
  (robustness, efficiency, fairness).
\end{itemize}

Comparison Table: Healthy vs.~Unhealthy Benchmarking

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1771}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3646}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4583}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Benchmark Use
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Healthy Practice
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Unhealthy Practice
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Goal & Measure general progress & Chase leaderboard rankings \\
Model behavior & Robust improvements across settings & Overfitting to
dataset quirks \\
Community outcome & Innovation, transferable insights & Saturated
leaderboard with incremental gains \\
\end{longtable}

The key lesson is that benchmarks are tools, not goals. When treated as
ultimate targets, they distort incentives. When treated as indicators,
they guide meaningful progress.

\subsubsection{Tiny Code}\label{tiny-code-86}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simulating overfitting to a benchmark}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ accuracy\_score}

\CommentTok{\# Benchmark dataset (biased)}
\NormalTok{X\_train }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{]])}
\NormalTok{y\_train }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])  }\CommentTok{\# simple split}
\NormalTok{X\_test  }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{4}\NormalTok{],[}\DecValTok{5}\NormalTok{]])}
\NormalTok{y\_test  }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])}

\CommentTok{\# Model overfits quirks in train set}
\NormalTok{model }\OperatorTok{=}\NormalTok{ LogisticRegression().fit(X\_train, y\_train)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Train accuracy:"}\NormalTok{, accuracy\_score(y\_train, model.predict(X\_train)))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Test accuracy:"}\NormalTok{, accuracy\_score(y\_test, model.predict(X\_test)))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-86}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add noise to the test set---does performance collapse?
\item
  Train on a slightly different distribution---does the model still hold
  up?
\item
  Reflect: why does optimizing for benchmarks risk producing brittle AI
  systems?
\end{enumerate}

\subsection{88. Robust evaluation under distribution
shift}\label{robust-evaluation-under-distribution-shift}

AI systems are often trained and tested on neatly defined datasets. But
in deployment, the real world rarely matches the training distribution.
Distribution shift occurs when the data a model encounters differs from
the data it was trained on. Robust evaluation ensures performance is
measured not only in controlled settings but also under these shifts.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-87}

Think of a student who aces practice problems but struggles on the
actual exam because the questions are phrased differently. The knowledge
was too tuned to the practice set. AI models face the same problem when
real-world inputs deviate from the benchmark.

\subsubsection{Deep Dive}\label{deep-dive-87}

Distribution shifts appear in many forms:

\begin{itemize}
\tightlist
\item
  Covariate shift: input features change (e.g., new slang in language
  models).
\item
  Concept shift: the relationship between inputs and outputs changes
  (e.g., fraud patterns evolve).
\item
  Prior shift: class proportions change (e.g., rare diseases become more
  prevalent).
\end{itemize}

Evaluating robustness requires deliberately exposing models to such
changes. Approaches include stress-testing with out-of-distribution
data, synthetic perturbations, or domain transfer benchmarks. For
example, an image classifier trained on clean photos might be evaluated
on blurred or adversarially perturbed images.

Robust evaluation also considers worst-case performance. A model with
95\% accuracy on average may still fail catastrophically in certain
subgroups or environments. Reporting only aggregate scores hides these
vulnerabilities.

Comparison Table: Standard vs.~Robust Evaluation

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1485}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4257}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4257}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Standard Evaluation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Robust Evaluation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Data assumption & Train and test drawn from same distribution & Test
includes shifted or adversarial data \\
Metrics & Average accuracy or loss & Subgroup, stress-test, or
worst-case scores \\
Purpose & Validate in controlled conditions & Predict reliability in
deployment \\
Example & ImageNet test split & ImageNet-C (corruptions, noise, blur) \\
\end{longtable}

Robust evaluation is not only about detecting failure---it is about
anticipating environments where models will operate. For
mission-critical domains like healthcare or autonomous driving, this is
non-negotiable.

\subsubsection{Tiny Code}\label{tiny-code-87}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple robustness test: add noise to test data}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ accuracy\_score}

\CommentTok{\# Train on clean data}
\NormalTok{X\_train }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{]])}
\NormalTok{y\_train }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])}
\NormalTok{model }\OperatorTok{=}\NormalTok{ LogisticRegression().fit(X\_train, y\_train)}

\CommentTok{\# Test on clean vs shifted (noisy) data}
\NormalTok{X\_test\_clean }\OperatorTok{=}\NormalTok{ np.array([[}\FloatTok{1.1}\NormalTok{],[}\FloatTok{2.9}\NormalTok{]])}
\NormalTok{y\_test }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{])}

\NormalTok{X\_test\_shifted }\OperatorTok{=}\NormalTok{ X\_test\_clean }\OperatorTok{+}\NormalTok{ np.random.normal(}\DecValTok{0}\NormalTok{,}\FloatTok{0.5}\NormalTok{,(}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Accuracy (clean):"}\NormalTok{, accuracy\_score(y\_test, model.predict(X\_test\_clean)))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Accuracy (shifted):"}\NormalTok{, accuracy\_score(y\_test, model.predict(X\_test\_shifted)))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-87}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase the noise level---at what point does performance collapse?
\item
  Train on a larger dataset---does robustness improve naturally?
\item
  Reflect: why is robustness more important than peak accuracy for
  real-world AI?
\end{enumerate}

\subsection{89. Beyond accuracy: fairness, interpretability,
efficiency}\label{beyond-accuracy-fairness-interpretability-efficiency}

Accuracy alone is not enough to judge an AI system. Real-world
deployment demands broader evaluation criteria: fairness to ensure
equitable treatment, interpretability to provide human understanding,
and efficiency to guarantee scalability and sustainability. Together,
these dimensions extend evaluation beyond raw predictive power.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-88}

Imagine buying a car. Speed alone doesn't make it good---you also care
about safety, fuel efficiency, and ease of maintenance. Similarly, an AI
model can't be judged only by accuracy; it must also be fair,
understandable, and efficient to be trusted.

\subsubsection{Deep Dive}\label{deep-dive-88}

Fairness addresses disparities in outcomes across groups. A hiring
algorithm may achieve high accuracy overall but discriminate against
women or minorities. Fairness metrics include demographic parity,
equalized odds, and subgroup accuracy.

Interpretability ensures models are not black boxes. Humans need
explanations to build trust, debug errors, and comply with regulation.
Techniques include feature importance, local explanations (LIME, SHAP),
and inherently interpretable models like decision trees.

Efficiency considers the cost of deploying AI at scale. Large models may
be accurate but consume prohibitive energy, memory, or latency.
Evaluation includes FLOPs, inference time, and energy per prediction.
Efficiency matters especially for edge devices and climate-conscious
computing.

Comparison Table: Dimensions of Evaluation

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1818}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3750}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4432}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Question
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Metric
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Accuracy & Does it make correct predictions? & Error rate, F1 score \\
Fairness & Are outcomes equitable? & Demographic parity, subgroup
error \\
Interpretability & Can humans understand decisions? & Feature
attribution, transparency score \\
Efficiency & Can it run at scale sustainably? & FLOPs, latency, energy
per query \\
\end{longtable}

Balancing these metrics is challenging because improvements in one
dimension can hurt another. Pruning a model may improve efficiency but
reduce interpretability. Optimizing fairness may slightly reduce
accuracy. The art of evaluation lies in balancing competing values
according to context.

\subsubsection{Tiny Code}\label{tiny-code-88}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple fairness check: subgroup accuracy}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ accuracy\_score}

\CommentTok{\# Predictions across two groups}
\NormalTok{y\_true }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{])}
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])}
\NormalTok{groups }\OperatorTok{=}\NormalTok{ np.array([}\StringTok{"A"}\NormalTok{,}\StringTok{"A"}\NormalTok{,}\StringTok{"B"}\NormalTok{,}\StringTok{"B"}\NormalTok{,}\StringTok{"B"}\NormalTok{,}\StringTok{"A"}\NormalTok{])}

\ControlFlowTok{for}\NormalTok{ g }\KeywordTok{in}\NormalTok{ np.unique(groups):}
\NormalTok{    idx }\OperatorTok{=}\NormalTok{ groups }\OperatorTok{==}\NormalTok{ g}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Group }\SpecialCharTok{\{}\NormalTok{g}\SpecialCharTok{\}}\SpecialStringTok{ accuracy:"}\NormalTok{, accuracy\_score(y\_true[idx], y\_pred[idx]))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-88}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Adjust predictions to make one group perform worse---how does fairness
  change?
\item
  Add runtime measurement to compare efficiency across models.
\item
  Reflect: should accuracy ever outweigh fairness or efficiency, or must
  evaluation always be multi-dimensional?
\end{enumerate}

\subsection{90. Building better evaluation
ecosystems}\label{building-better-evaluation-ecosystems}

An evaluation ecosystem goes beyond single datasets or metrics. It is a
structured environment where benchmarks, tools, protocols, and community
practices interact to ensure that AI systems are tested thoroughly,
fairly, and continuously. A healthy ecosystem enables sustained progress
rather than short-term leaderboard chasing.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-89}

Think of public health. One thermometer reading doesn't describe a
population's health. Instead, ecosystems of hospitals, labs, surveys,
and monitoring systems track multiple indicators over time. In AI,
evaluation ecosystems serve the same role---providing many complementary
views of model quality.

\subsubsection{Deep Dive}\label{deep-dive-89}

Traditional evaluation relies on static test sets and narrow metrics.
But modern AI operates in dynamic, high-stakes environments where
robustness, fairness, efficiency, and safety all matter. Building a true
ecosystem involves several layers:

\begin{itemize}
\tightlist
\item
  Diverse benchmarks: covering multiple domains, tasks, and
  distributions.
\item
  Standardized protocols: ensuring experiments are reproducible across
  labs.
\item
  Multi-dimensional reporting: capturing accuracy, robustness,
  interpretability, fairness, and energy use.
\item
  Continuous evaluation: monitoring models post-deployment as data
  drifts.
\item
  Community governance: open platforms, shared resources, and watchdogs
  against misuse.
\end{itemize}

Emerging efforts like Dynabench (dynamic data collection), HELM
(holistic evaluation of language models), and BIG-bench (broad
generalization testing) show how ecosystems can move beyond
single-number leaderboards.

Comparison Table: Traditional vs.~Ecosystem Evaluation

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1266}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3291}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5443}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Traditional Evaluation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Evaluation Ecosystem
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Benchmarks & Single static dataset & Multiple, dynamic, domain-spanning
datasets \\
Metrics & Accuracy or task-specific & Multi-dimensional dashboards \\
Scope & Pre-deployment only & Lifecycle-wide, including
post-deployment \\
Governance & Isolated labs or companies & Community-driven, transparent
practices \\
\end{longtable}

Ecosystems also encourage responsibility. By highlighting fairness gaps,
robustness failures, or energy costs, they force AI development to align
with broader societal goals. Without them, progress risks being measured
narrowly and misleadingly.

\subsubsection{Tiny Code}\label{tiny-code-89}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example: evaluation dashboard across metrics}
\NormalTok{results }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"accuracy"}\NormalTok{: }\FloatTok{0.92}\NormalTok{,}
    \StringTok{"robustness"}\NormalTok{: }\FloatTok{0.75}\NormalTok{,}
    \StringTok{"fairness"}\NormalTok{: }\FloatTok{0.80}\NormalTok{,}
    \StringTok{"efficiency"}\NormalTok{: }\StringTok{"120 ms/query"}
\NormalTok{\}}

\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ results.items():}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{.}\NormalTok{capitalize()}\SpecialCharTok{:\textless{}12\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{v}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-89}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more dimensions (interpretability, cost)---how does the picture
  change?
\item
  Compare two models across all metrics---does the ``winner'' differ
  depending on which metric you value most?
\item
  Reflect: why does the future of AI evaluation depend on ecosystems,
  not isolated benchmarks?
\end{enumerate}

\section{Chapter 10. Reproductivity, tooling, and the scientific
method}\label{chapter-10.-reproductivity-tooling-and-the-scientific-method}

\subsection{91. The role of reproducibility in
science}\label{the-role-of-reproducibility-in-science}

Reproducibility is the backbone of science. In AI, it means that
experiments, once published, can be independently repeated with the same
methods and yield consistent results. Without reproducibility, research
findings are fragile, progress is unreliable, and trust in the field
erodes.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-90}

Imagine a recipe book where half the dishes cannot be recreated because
the instructions are vague or missing. The meals may have looked
delicious once, but no one else can cook them again. AI papers without
reproducibility are like such recipes---impressive claims, but
irreproducible outcomes.

\subsubsection{Deep Dive}\label{deep-dive-90}

Reproducibility requires clarity in three areas:

\begin{itemize}
\tightlist
\item
  Code and algorithms: precise implementation details, hyperparameters,
  and random seeds.
\item
  Data and preprocessing: availability of datasets, splits, and cleaning
  procedures.
\item
  Experimental setup: hardware, software libraries, versions, and
  training schedules.
\end{itemize}

Failures of reproducibility have plagued AI. Small variations in
preprocessing can change benchmark rankings. Proprietary datasets make
replication impossible. Differences in GPU types or software libraries
can alter results subtly but significantly.

The reproducibility crisis is not unique to AI---it mirrors issues in
psychology, medicine, and other sciences. But AI faces unique challenges
due to computational scale and reliance on proprietary resources.
Addressing these challenges involves open-source code release, dataset
sharing, standardized evaluation protocols, and stronger incentives for
replication studies.

Comparison Table: Reproducible vs.~Non-Reproducible Research

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1889}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3889}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4222}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Reproducible Research
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Non-Reproducible Research
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Code availability & Public, with instructions & Proprietary, incomplete,
or absent \\
Dataset access & Open, with documented preprocessing & Private,
undocumented, or changing \\
Results & Consistent across labs & Dependent on hidden variables \\
Community impact & Trustworthy, cumulative progress & Fragile, hard to
verify, wasted effort \\
\end{longtable}

Ultimately, reproducibility is not just about science---it is about
ethics. Deployed AI systems that cannot be reproduced cannot be audited
for safety, fairness, or reliability.

\subsubsection{Tiny Code}\label{tiny-code-90}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Ensuring reproducibility with fixed random seeds}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{np.random.seed(}\DecValTok{42}\NormalTok{)}
\NormalTok{data }\OperatorTok{=}\NormalTok{ np.random.rand(}\DecValTok{5}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Deterministic random data:"}\NormalTok{, data)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-90}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the random seed---how do results differ?
\item
  Run the same experiment on different hardware---does reproducibility
  hold?
\item
  Reflect: should conferences and journals enforce reproducibility as
  strictly as novelty?
\end{enumerate}

\subsection{92. Versioning of code, data, and
experiments}\label{versioning-of-code-data-and-experiments}

AI research and deployment involve constant iteration.
Versioning---tracking changes to code, data, and experiments---ensures
results can be reproduced, compared, and rolled back when needed.
Without versioning, AI projects devolve into chaos, where no one can
tell which model, dataset, or configuration produced a given result.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-91}

Imagine writing a book without saving drafts. If an editor asks about an
earlier version, you can't reconstruct it. In AI, every experiment is a
draft; versioning is the act of saving each one with context, so future
readers---or your future self---can trace the path.

\subsubsection{Deep Dive}\label{deep-dive-91}

Traditional software engineering relies on version control systems like
Git. In AI, the complexity multiplies:

\begin{itemize}
\tightlist
\item
  Code versioning tracks algorithm changes, hyperparameters, and
  pipelines.
\item
  Data versioning ensures the training and test sets used are
  identifiable and reproducible, even as datasets evolve.
\item
  Experiment versioning records outputs, logs, metrics, and random
  seeds, making it possible to compare experiments meaningfully.
\end{itemize}

Modern tools like DVC (Data Version Control), MLflow, and Weights \&
Biases extend Git-like practices to data and model artifacts. They
enable teams to ask: \emph{Which dataset version trained this model?
Which code commit and parameters led to the reported accuracy?}

Without versioning, reproducibility fails and deployment risk rises.
Bugs reappear, models drift without traceability, and research claims
cannot be verified. With versioning, AI development becomes a
cumulative, auditable process.

Comparison Table: Versioning Needs in AI

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1294}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4118}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4588}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Element
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Why It Matters
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Practice
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Code & Reproduce algorithms and parameters & Git commits, containerized
environments \\
Data & Ensure same inputs across reruns & DVC, dataset hashes, storage
snapshots \\
Experiments & Compare and track progress & MLflow logs, W\&B experiment
tracking \\
\end{longtable}

Versioning also supports collaboration. Teams spread across
organizations can reproduce results without guesswork, enabling science
and engineering to scale.

\subsubsection{Tiny Code}\label{tiny-code-91}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example: simple experiment versioning with hashes}
\ImportTok{import}\NormalTok{ hashlib}
\ImportTok{import}\NormalTok{ json}

\NormalTok{experiment }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"model"}\NormalTok{: }\StringTok{"logistic\_regression"}\NormalTok{,}
    \StringTok{"params"}\NormalTok{: \{}\StringTok{"lr"}\NormalTok{:}\FloatTok{0.01}\NormalTok{, }\StringTok{"epochs"}\NormalTok{:}\DecValTok{100}\NormalTok{\},}
    \StringTok{"data\_version"}\NormalTok{: }\StringTok{"hash1234"}
\NormalTok{\}}

\NormalTok{experiment\_id }\OperatorTok{=}\NormalTok{ hashlib.md5(json.dumps(experiment).encode()).hexdigest()}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Experiment ID:"}\NormalTok{, experiment\_id)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-91}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the learning rate---does the experiment ID change?
\item
  Add a new data version---how does it affect reproducibility?
\item
  Reflect: why is versioning essential not only for research
  reproducibility but also for regulatory compliance in deployed AI?
\end{enumerate}

\subsection{93. Tooling: notebooks, frameworks,
pipelines}\label{tooling-notebooks-frameworks-pipelines}

AI development depends heavily on the tools researchers and engineers
use. Notebooks provide interactive experimentation, frameworks offer
reusable building blocks, and pipelines organize workflows into
reproducible stages. Together, they shape how ideas move from concept to
deployment.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-92}

Think of building a house. Sketches on paper resemble notebooks: quick,
flexible, exploratory. Prefabricated materials are like frameworks:
ready-to-use components that save effort. Construction pipelines
coordinate the sequence---laying the foundation, raising walls,
installing wiring---into a complete structure. AI engineering works the
same way.

\subsubsection{Deep Dive}\label{deep-dive-92}

\begin{itemize}
\tightlist
\item
  Notebooks (e.g., Jupyter, Colab) are invaluable for prototyping,
  visualization, and teaching. They allow rapid iteration but can
  encourage messy, non-reproducible practices if not disciplined.
\item
  Frameworks (e.g., PyTorch, TensorFlow, scikit-learn) provide
  abstractions for model design, training loops, and optimization. They
  accelerate development but may introduce lock-in or complexity.
\item
  Pipelines (e.g., Kubeflow, Airflow, Metaflow) formalize data
  preparation, training, evaluation, and deployment into modular steps.
  They make experiments repeatable at scale, enabling collaboration
  across teams.
\end{itemize}

Each tool has strengths and trade-offs. Notebooks excel at exploration
but falter at production. Frameworks lower barriers to sophisticated
models but can obscure inner workings. Pipelines enforce rigor but may
slow early experimentation. The art lies in combining them to fit the
maturity of a project.

Comparison Table: Notebooks, Frameworks, Pipelines

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0781}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2969}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3203}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3047}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Tool Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strengths
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Weaknesses
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Notebooks & Interactive, visual, fast prototyping & Hard to reproduce,
version control issues & Teaching, exploratory analysis \\
Frameworks & Robust abstractions, community support & Complexity,
potential lock-in & Training deep learning models \\
Pipelines & Scalable, reproducible, collaborative & Setup overhead, less
flexibility & Enterprise ML deployment, model serving \\
\end{longtable}

Modern AI workflows typically blend these: a researcher prototypes in
notebooks, formalizes the model in a framework, and engineers deploy it
via pipelines. Without this chain, insights often die in notebooks or
fail in production.

\subsubsection{Tiny Code}\label{tiny-code-92}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example: simple pipeline step simulation}
\KeywordTok{def}\NormalTok{ load\_data():}
    \ControlFlowTok{return}\NormalTok{ [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{]}

\KeywordTok{def}\NormalTok{ train\_model(data):}
    \ControlFlowTok{return} \BuiltInTok{sum}\NormalTok{(data) }\OperatorTok{/} \BuiltInTok{len}\NormalTok{(data)  }\CommentTok{\# dummy "model"}

\KeywordTok{def}\NormalTok{ evaluate\_model(model):}
    \ControlFlowTok{return} \SpecialStringTok{f"Model value: }\SpecialCharTok{\{}\NormalTok{model}\SpecialCharTok{:.2f\}}\SpecialStringTok{"}

\CommentTok{\# Pipeline}
\NormalTok{data }\OperatorTok{=}\NormalTok{ load\_data()}
\NormalTok{model }\OperatorTok{=}\NormalTok{ train\_model(data)}
\BuiltInTok{print}\NormalTok{(evaluate\_model(model))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-92}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add another pipeline step---like data cleaning---does it make the
  process clearer?
\item
  Replace the dummy model with a scikit-learn classifier---can you track
  inputs/outputs?
\item
  Reflect: why do tools matter as much as algorithms in shaping the
  progress of AI?
\end{enumerate}

\subsection{94. Collaboration, documentation, and
transparency}\label{collaboration-documentation-and-transparency}

AI is rarely built alone. Collaboration enables teams of researchers and
engineers to combine expertise. Documentation ensures that ideas, data,
and methods are clear and reusable. Transparency makes models
understandable to both colleagues and the broader community. Together,
these practices turn isolated experiments into collective progress.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-93}

Imagine a relay race where each runner drops the baton without labeling
it. The team cannot finish the race because no one knows what's been
done. In AI, undocumented or opaque work is like a dropped
baton---progress stalls.

\subsubsection{Deep Dive}\label{deep-dive-93}

Collaboration in AI spans interdisciplinary teams: computer scientists,
domain experts, ethicists, and product managers. Without shared
understanding, efforts fragment. Version control platforms (GitHub,
GitLab) and experiment trackers (MLflow, W\&B) provide the
infrastructure, but human practices matter as much as tools.

Documentation ensures reproducibility and knowledge transfer. It
includes clear READMEs, code comments, data dictionaries, and experiment
logs. Models without documentation risk being ``black boxes'' even to
their creators months later.

Transparency extends documentation to accountability. Open-sourcing code
and data, publishing detailed methodology, and explaining limitations
prevent hype and misuse. Transparency also enables external audits for
fairness and safety.

Comparison Table: Collaboration, Documentation, Transparency

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1327}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4286}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4388}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Practice
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Implementation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Collaboration & Pool expertise, divide tasks & Shared repos, code
reviews, project boards \\
Documentation & Preserve knowledge, ensure reproducibility & README
files, experiment logs, data schemas \\
Transparency & Build trust, enable accountability & Open-source
releases, model cards, audits \\
\end{longtable}

Without these practices, AI progress becomes fragile---dependent on
individuals, lost in silos, and vulnerable to errors. With them,
progress compounds and can be trusted by both peers and the public.

\subsubsection{Tiny Code}\label{tiny-code-93}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example: simple documentation as metadata}
\NormalTok{model\_card }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"name"}\NormalTok{: }\StringTok{"Spam Classifier v1.0"}\NormalTok{,}
    \StringTok{"authors"}\NormalTok{: [}\StringTok{"Team A"}\NormalTok{],}
    \StringTok{"dataset"}\NormalTok{: }\StringTok{"Email dataset v2 (cleaned, deduplicated)"}\NormalTok{,}
    \StringTok{"metrics"}\NormalTok{: \{}\StringTok{"accuracy"}\NormalTok{: }\FloatTok{0.95}\NormalTok{, }\StringTok{"f1"}\NormalTok{: }\FloatTok{0.92}\NormalTok{\},}
    \StringTok{"limitations"}\NormalTok{: }\StringTok{"Fails on short informal messages"}
\NormalTok{\}}

\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ model\_card.items():}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{v}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-93}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add fairness metrics or energy usage to the model card---how does it
  change transparency?
\item
  Imagine a teammate taking over your project---would your documentation
  be enough?
\item
  Reflect: why does transparency matter not only for science but also
  for public trust in AI?
\end{enumerate}

\subsection{95. Statistical rigor and replication
studies}\label{statistical-rigor-and-replication-studies}

Scientific claims in AI require statistical rigor---careful design of
experiments, proper use of significance tests, and honest reporting of
uncertainty. Replication studies, where independent teams attempt to
reproduce results, provide the ultimate check. Together, they protect
the field from hype and fragile conclusions.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-94}

Think of building a bridge. It's not enough that one engineer's design
holds during their test. Independent inspectors must verify the
calculations and confirm the bridge can withstand real conditions. In
AI, replication serves the same role---ensuring results are not
accidents of chance or selective reporting.

\subsubsection{Deep Dive}\label{deep-dive-94}

Statistical rigor starts with designing fair comparisons: training
models under the same conditions, reporting variance across multiple
runs, and avoiding cherry-picking of best results. It also requires
appropriate statistical tests to judge whether performance differences
are meaningful rather than noise.

Replication studies extend this by testing results independently,
sometimes under new conditions. Successful replication strengthens
trust; failures highlight hidden assumptions or weak methodology.
Unfortunately, replication is undervalued in AI---top venues reward
novelty over verification, leading to a reproducibility gap.

The lack of rigor has consequences: flashy papers that collapse under
scrutiny, wasted effort chasing irreproducible results, and erosion of
public trust. A shift toward valuing replication, preregistration, and
transparent reporting would align AI more closely with scientific norms.

Comparison Table: Statistical Rigor vs.~Replication

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1414}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4343}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4242}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Statistical Rigor
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Replication Studies
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Focus & Correct design and reporting of experiments & Independent
verification of findings \\
Responsibility & Original researchers & External researchers \\
Benefit & Prevents overstated claims & Confirms robustness, builds
trust \\
Challenge & Requires discipline and education & Often unrewarded, costly
in time/resources \\
\end{longtable}

Replication is not merely checking math---it is part of the culture of
accountability. Without it, AI risks becoming an arms race of unverified
claims. With it, the field can build cumulative, durable knowledge.

\subsubsection{Tiny Code}\label{tiny-code-94}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Demonstrating variance across runs}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ accuracy\_score}

\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{],[}\DecValTok{4}\NormalTok{],[}\DecValTok{5}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])}

\NormalTok{scores }\OperatorTok{=}\NormalTok{ []}
\ControlFlowTok{for}\NormalTok{ seed }\KeywordTok{in}\NormalTok{ [}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{]:}
\NormalTok{    model }\OperatorTok{=}\NormalTok{ LogisticRegression(random\_state}\OperatorTok{=}\NormalTok{seed, max\_iter}\OperatorTok{=}\DecValTok{500}\NormalTok{).fit(X,y)}
\NormalTok{    scores.append(accuracy\_score(y, model.predict(X)))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Accuracy across runs:"}\NormalTok{, scores)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Mean ± Std:"}\NormalTok{, np.mean(scores), }\StringTok{"±"}\NormalTok{, np.std(scores))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-94}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase the dataset noise---does variance between runs grow?
\item
  Try different random seeds---do conclusions still hold?
\item
  Reflect: should AI conferences reward replication studies as highly as
  novel results?
\end{enumerate}

\subsection{96. Open science, preprints, and publishing
norms}\label{open-science-preprints-and-publishing-norms}

AI research moves at a rapid pace, and the way results are shared shapes
the field. Open science emphasizes transparency and accessibility.
Preprints accelerate dissemination outside traditional journals.
Publishing norms guide how credit, peer review, and standards of
evidence are maintained. Together, they determine how knowledge spreads
and how trustworthy it is.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-95}

Imagine a library where only a few people can check out books, and the
rest must wait years. Contrast that with an open archive where anyone
can read the latest manuscripts immediately. The second library looks
like modern AI: preprints on arXiv and open code releases fueling fast
progress.

\subsubsection{Deep Dive}\label{deep-dive-95}

Open science in AI includes open datasets, open-source software, and
public sharing of results. This democratizes access, enabling small labs
and independent researchers to contribute alongside large institutions.
Preprints, typically on platforms like arXiv, bypass slow journal cycles
and allow rapid community feedback.

However, preprints also challenge traditional norms: they lack formal
peer review, raising concerns about reliability and hype. Publishing
norms attempt to balance speed with rigor. Conferences and journals
increasingly require code and data release, reproducibility checklists,
and clearer reporting standards.

The culture of AI publishing is shifting: from closed corporate secrecy
to open competitions; from novelty-only acceptance criteria to valuing
robustness and ethics; from slow cycles to real-time global
collaboration. But tensions remain between openness and
commercialization, between rapid sharing and careful vetting.

Comparison Table: Traditional vs.~Open Publishing

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1519}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3797}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4684}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Traditional Publishing
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Open Science \& Preprints
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Access & Paywalled journals & Free, open archives and datasets \\
Speed & Slow peer review cycle & Immediate dissemination via
preprints \\
Verification & Peer review before publication & Community feedback,
post-publication \\
Risks & Limited reach, exclusivity & Hype, lack of quality control \\
\end{longtable}

Ultimately, publishing norms reflect values. Do we value rapid
innovation, broad access, and transparency? Or do we prioritize rigorous
filtering, stability, and prestige? The healthiest ecosystem blends
both, creating space for speed without abandoning trust.

\subsubsection{Tiny Code}\label{tiny-code-95}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example: metadata for an "open science" AI paper}
\NormalTok{paper }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"title"}\NormalTok{: }\StringTok{"Efficient Transformers with Sparse Attention"}\NormalTok{,}
    \StringTok{"authors"}\NormalTok{: [}\StringTok{"A. Researcher"}\NormalTok{, }\StringTok{"B. Scientist"}\NormalTok{],}
    \StringTok{"venue"}\NormalTok{: }\StringTok{"arXiv preprint 2509.12345"}\NormalTok{,}
    \StringTok{"code"}\NormalTok{: }\StringTok{"https://github.com/example/sparse{-}transformers"}\NormalTok{,}
    \StringTok{"data"}\NormalTok{: }\StringTok{"Open dataset: WikiText{-}103"}\NormalTok{,}
    \StringTok{"license"}\NormalTok{: }\StringTok{"CC{-}BY 4.0"}
\NormalTok{\}}

\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ paper.items():}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{v}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-95}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add peer review metadata (accepted at NeurIPS, ICML)---how does
  credibility change?
\item
  Imagine this paper was closed-source---what opportunities would be
  lost?
\item
  Reflect: should open science be mandatory for publicly funded AI
  research?
\end{enumerate}

\subsection{97. Negative results and failure
reporting}\label{negative-results-and-failure-reporting}

Science advances not only through successes but also through
understanding failures. In AI, negative results---experiments that do
not confirm hypotheses or fail to improve performance---are rarely
reported. Yet documenting them prevents wasted effort, reveals hidden
challenges, and strengthens the scientific method.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-96}

Imagine a map where only successful paths are drawn. Explorers who
follow it may walk into dead ends again and again. A more useful map
includes both the routes that lead to treasure and those that led
nowhere. AI research needs such maps.

\subsubsection{Deep Dive}\label{deep-dive-96}

Negative results in AI often remain hidden in lab notebooks or private
repositories. Reasons include publication bias toward positive outcomes,
competitive pressure, and the cultural view that failure signals
weakness. This creates a distorted picture of progress, where flashy
results dominate while important lessons from failures are lost.

Examples of valuable negative results include:

\begin{itemize}
\tightlist
\item
  Novel architectures that fail to outperform baselines.
\item
  Promising ideas that do not scale or generalize.
\item
  Benchmark shortcuts that looked strong but collapsed under adversarial
  testing.
\end{itemize}

Reporting such outcomes saves others from repeating mistakes, highlights
boundary conditions, and encourages more realistic expectations.
Journals and conferences have begun to acknowledge this, with workshops
on reproducibility and negative results.

Comparison Table: Positive vs.~Negative Results in AI

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1648}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3846}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4505}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Positive Results
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Negative Results
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Visibility & Widely published, cited & Rarely published, often hidden \\
Contribution & Shows what works & Shows what does not work and why \\
Risk if missing & Field advances quickly but narrowly & Field repeats
mistakes, distorts progress \\
Example & New model beats SOTA on ImageNet & Variant fails despite
theoretical promise \\
\end{longtable}

By embracing negative results, AI can mature as a science. Failures
highlight assumptions, expose limits of generalization, and set
realistic baselines. Normalizing failure reporting reduces hype cycles
and fosters collective learning.

\subsubsection{Tiny Code}\label{tiny-code-96}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simulating a "negative result"}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}
\ImportTok{from}\NormalTok{ sklearn.svm }\ImportTok{import}\NormalTok{ SVC}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ accuracy\_score}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Tiny dataset}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])}

\NormalTok{log\_reg }\OperatorTok{=}\NormalTok{ LogisticRegression().fit(X,y)}
\NormalTok{svm }\OperatorTok{=}\NormalTok{ SVC(kernel}\OperatorTok{=}\StringTok{"poly"}\NormalTok{, degree}\OperatorTok{=}\DecValTok{5}\NormalTok{).fit(X,y)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"LogReg accuracy:"}\NormalTok{, accuracy\_score(y, log\_reg.predict(X)))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"SVM (degree 5) accuracy:"}\NormalTok{, accuracy\_score(y, svm.predict(X)))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-96}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase dataset size---does the ``negative'' SVM result persist?
\item
  Document why the complex model failed compared to the simple baseline.
\item
  Reflect: how would AI research change if publishing failures were as
  valued as publishing successes?
\end{enumerate}

\subsection{98. Benchmark reproducibility crises in
AI}\label{benchmark-reproducibility-crises-in-ai}

Many AI breakthroughs are judged by performance on benchmarks. But if
those results cannot be reliably reproduced, the benchmark itself
becomes unstable. The benchmark reproducibility crisis occurs when
published results are hard---or impossible---to replicate due to hidden
randomness, undocumented preprocessing, or unreleased data.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-97}

Think of a scoreboard where athletes' times are recorded, but no one
knows the track length, timing method, or even if the stopwatch worked.
The scores look impressive but cannot be trusted. Benchmarks in AI face
the same problem when reproducibility is weak.

\subsubsection{Deep Dive}\label{deep-dive-97}

Benchmark reproducibility failures arise from multiple factors:

\begin{itemize}
\tightlist
\item
  Data leakage: overlaps between training and test sets inflate results.
\item
  Unreleased datasets: claims cannot be independently verified.
\item
  Opaque preprocessing: small changes in tokenization, normalization, or
  image resizing alter scores.
\item
  Non-deterministic training: results vary across runs but only the best
  is reported.
\item
  Hardware/software drift: different GPUs, libraries, or seeds produce
  inconsistent outcomes.
\end{itemize}

The crisis undermines both research credibility and industrial
deployment. A model that beats ImageNet by 1\% but cannot be reproduced
is scientifically meaningless. Worse, models trained with leaky or
biased benchmarks may propagate errors into downstream applications.

Efforts to address this include reproducibility checklists at
conferences (NeurIPS, ICML), model cards and data sheets, open-source
implementations, and rigorous cross-lab verification. Dynamic benchmarks
that refresh test sets (e.g., Dynabench) also help prevent overfitting
and silent leakage.

Comparison Table: Stable vs.~Fragile Benchmarks

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2048}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4096}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3855}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stable Benchmark
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Fragile Benchmark
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Data availability & Public, with documented splits & Private or
inconsistently shared \\
Evaluation & Deterministic, standardized code & Ad hoc, variable
implementations \\
Reporting & Averages, with variance reported & Single best run
highlighted \\
Trust level & High, supports cumulative progress & Low, progress is
illusory \\
\end{longtable}

Benchmark reproducibility is not a technical nuisance---it is central to
AI as a science. Without stable, transparent benchmarks, leaderboards
risk becoming marketing tools rather than genuine measures of
advancement.

\subsubsection{Tiny Code}\label{tiny-code-97}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Demonstrating non{-}determinism}
\ImportTok{import}\NormalTok{ torch}
\ImportTok{import}\NormalTok{ torch.nn }\ImportTok{as}\NormalTok{ nn}

\NormalTok{torch.manual\_seed(}\DecValTok{0}\NormalTok{)   }\CommentTok{\# fix seed for reproducibility}

\CommentTok{\# Simple model}
\NormalTok{model }\OperatorTok{=}\NormalTok{ nn.Linear(}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\NormalTok{x }\OperatorTok{=}\NormalTok{ torch.randn(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Output with fixed seed:"}\NormalTok{, model(x))}

\CommentTok{\# Remove the fixed seed and rerun to see variability}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-97}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Train the same model twice without fixing the seed---do results
  differ?
\item
  Change preprocessing slightly (e.g., normalize inputs
  differently)---does accuracy shift?
\item
  Reflect: why does benchmark reproducibility matter more as AI models
  scale to billions of parameters?
\end{enumerate}

\subsection{99. Community practices for
reliability}\label{community-practices-for-reliability}

AI is not only shaped by algorithms and datasets but also by the
community practices that govern how research is conducted and shared.
Reliability emerges when researchers adopt shared norms: transparent
reporting, open resources, peer verification, and responsible
competition. Without these practices, progress risks being fragmented,
fragile, and untrustworthy.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-98}

Imagine a neighborhood where everyone builds their own houses without
common codes---some collapse, others block sunlight, and many hide
dangerous flaws. Now imagine the same neighborhood with shared building
standards, inspections, and cooperation. AI research benefits from
similar community standards to ensure safety and reliability.

\subsubsection{Deep Dive}\label{deep-dive-98}

Community practices for reliability include:

\begin{itemize}
\tightlist
\item
  Reproducibility checklists: conferences like NeurIPS now require
  authors to document datasets, hyperparameters, and code.
\item
  Open-source culture: sharing code, pretrained models, and datasets
  allows peers to verify claims.
\item
  Independent replication: labs repeating and auditing results before
  deployment.
\item
  Responsible benchmarking: resisting leaderboard obsession, reporting
  multiple dimensions (robustness, fairness, energy use).
\item
  Collaborative governance: initiatives like MLCommons or Hugging Face
  Datasets maintain shared standards and evaluation tools.
\end{itemize}

These practices counterbalance pressures for speed and novelty. They
help transform AI into a cumulative science, where progress builds on a
solid base rather than hype cycles.

Comparison Table: Weak vs.~Strong Community Practices

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1979}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3854}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4167}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Weak Practice
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strong Practice
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Code/Data Sharing & Closed, proprietary & Open repositories with
documentation \\
Reporting Standards & Selective metrics, cherry-picked runs & Full
transparency, including variance \\
Benchmarking & Single leaderboard focus & Multi-metric, multi-benchmark
evaluation \\
Replication Culture & Rare, undervalued & Incentivized, publicly
recognized \\
\end{longtable}

Community norms are cultural infrastructure. Just as the internet grew
by adopting protocols and standards, AI can achieve reliability by
aligning on transparent and responsible practices.

\subsubsection{Tiny Code}\label{tiny-code-98}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example: adding reproducibility info to experiment logs}
\NormalTok{experiment\_log }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"model"}\NormalTok{: }\StringTok{"Transformer{-}small"}\NormalTok{,}
    \StringTok{"dataset"}\NormalTok{: }\StringTok{"WikiText{-}103 (v2.1)"}\NormalTok{,}
    \StringTok{"accuracy"}\NormalTok{: }\FloatTok{0.87}\NormalTok{,}
    \StringTok{"std\_dev"}\NormalTok{: }\FloatTok{0.01}\NormalTok{,}
    \StringTok{"seed"}\NormalTok{: }\DecValTok{42}\NormalTok{,}
    \StringTok{"code\_repo"}\NormalTok{: }\StringTok{"https://github.com/example/research{-}code"}
\NormalTok{\}}

\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ experiment\_log.items():}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{v}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-98}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add fairness or energy-use metrics to the log---does it give a fuller
  picture?
\item
  Imagine a peer trying to replicate your result---what extra details
  would they need?
\item
  Reflect: why do cultural norms matter as much as technical advances in
  building reliable AI?
\end{enumerate}

\subsection{100. Towards a mature scientific culture in
AI}\label{towards-a-mature-scientific-culture-in-ai}

AI is transitioning from a frontier discipline to a mature science. This
shift requires not only technical breakthroughs but also a scientific
culture rooted in rigor, openness, and accountability. A mature culture
balances innovation with verification, excitement with caution, and
competition with collaboration.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-99}

Think of medicine centuries ago: discoveries were dramatic but often
anecdotal, inconsistent, and dangerous. Over time, medicine built
standardized trials, ethical review boards, and professional norms. AI
is undergoing a similar journey---moving from dazzling demonstrations to
systematic, reliable science.

\subsubsection{Deep Dive}\label{deep-dive-99}

A mature scientific culture in AI demands several elements:

\begin{itemize}
\tightlist
\item
  Rigor: experiments designed with controls, baselines, and statistical
  validity.
\item
  Openness: datasets, code, and results shared for verification.
\item
  Ethics: systems evaluated not only for performance but also for
  fairness, safety, and societal impact.
\item
  Long-term perspective: research valued for durability, not just
  leaderboard scores.
\item
  Community institutions: conferences, journals, and collaborations that
  enforce standards and support replication.
\end{itemize}

The challenge is cultural. Incentives in academia and industry still
reward novelty and speed over reliability. Shifting this balance means
rethinking publication criteria, funding priorities, and corporate
secrecy. It also requires education: training new researchers to see
reproducibility and transparency as virtues, not burdens.

Comparison Table: Frontier vs.~Mature Scientific Culture

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2024}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3690}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4286}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Frontier AI Culture
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Mature AI Culture
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Research Goals & Novelty, demos, rapid iteration & Robustness,
cumulative knowledge \\
Publication Norms & Leaderboards, flashy results & Replication,
long-term benchmarks \\
Collaboration & Competitive secrecy & Shared standards, open
collaboration \\
Ethical Lens & Secondary, reactive & Central, proactive \\
\end{longtable}

This cultural transformation will not be instant. But just as physics or
biology matured through shared norms, AI too can evolve into a
discipline where progress is durable, reproducible, and aligned with
human values.

\subsubsection{Tiny Code}\label{tiny-code-99}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example: logging scientific culture dimensions for a project}
\NormalTok{project\_culture }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"rigor"}\NormalTok{: }\StringTok{"Statistical tests + multiple baselines"}\NormalTok{,}
    \StringTok{"openness"}\NormalTok{: }\StringTok{"Code + dataset released"}\NormalTok{,}
    \StringTok{"ethics"}\NormalTok{: }\StringTok{"Bias audit + safety review"}\NormalTok{,}
    \StringTok{"long\_term"}\NormalTok{: }\StringTok{"Evaluation across 3 benchmarks"}\NormalTok{,}
    \StringTok{"community"}\NormalTok{: }\StringTok{"Replication study submitted"}
\NormalTok{\}}

\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ project\_culture.items():}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{.}\NormalTok{capitalize()}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{v}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-99}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add missing cultural elements---what would strengthen the project's
  reliability?
\item
  Imagine incentives flipped: replication papers get more citations than
  novelty---how would AI research change?
\item
  Reflect: what does it take for AI to be remembered not just for its
  breakthroughs, but for its scientific discipline?
\end{enumerate}

\bookmarksetup{startatroot}

\chapter{Volume 2. Mathematicial
Foundations}\label{volume-2.-mathematicial-foundations}

\section{Chapter 11. Linear Algebra for
Representations}\label{chapter-11.-linear-algebra-for-representations}

\subsection{101. Scalars, Vectors, and
Matrices}\label{scalars-vectors-and-matrices}

At the foundation of AI mathematics are three objects: scalars, vectors,
and matrices. A scalar is a single number. A vector is an ordered list
of numbers, representing direction and magnitude in space. A matrix is a
rectangular grid of numbers, capable of transforming vectors and
encoding relationships. These are the raw building blocks for almost
every algorithm in AI, from linear regression to deep neural networks.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-100}

Imagine scalars as simple dots on a number line. A vector is like an
arrow pointing from the origin in a plane or space, with both length and
direction. A matrix is a whole system of arrows: a transformation
machine that can rotate, stretch, or compress the space around it. In
AI, data points are vectors, and learning often comes down to finding
the right matrices to transform them.

\subsubsection{Deep Dive}\label{deep-dive-100}

Scalars are elements of the real (ℝ) or complex (ℂ) number systems. They
describe quantities such as weights, probabilities, or losses. Vectors
extend this by grouping scalars into n-dimensional objects. A vector x ∈
ℝⁿ can encode features of a data sample (age, height, income).
Operations like dot products measure similarity, and norms measure
magnitude. Matrices generalize further: an m×n matrix holds m rows and n
columns. Multiplying a vector by a matrix performs a linear
transformation. In AI, these transformations express learned
parameters---weights in neural networks, transition probabilities in
Markov models, or coefficients in regression.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0984}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0984}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1475}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.6557}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Object
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Symbol
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Scalar & \emph{a} & 1×1 & Learning rate, single probability \\
Vector & x & n×1 & Feature vector (e.g., pixel intensities) \\
Matrix & W & m×n & Neural network weights, adjacency matrix \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-100}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Scalar}
\NormalTok{a }\OperatorTok{=} \FloatTok{3.14}

\CommentTok{\# Vector}
\NormalTok{x }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{])}

\CommentTok{\# Matrix}
\NormalTok{W }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{],}
\NormalTok{              [}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{,  }\DecValTok{4}\NormalTok{]])}

\CommentTok{\# Operations}
\NormalTok{dot\_product }\OperatorTok{=}\NormalTok{ np.dot(x, x)         }\CommentTok{\# 1*1 + 2*2 + 3*3 = 14}
\NormalTok{transformed }\OperatorTok{=}\NormalTok{ np.dot(W, x)         }\CommentTok{\# matrix{-}vector multiplication}
\NormalTok{norm }\OperatorTok{=}\NormalTok{ np.linalg.norm(x)           }\CommentTok{\# vector magnitude}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Scalar:"}\NormalTok{, a)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Vector:"}\NormalTok{, x)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Matrix:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, W)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Dot product:"}\NormalTok{, dot\_product)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Transformed:"}\NormalTok{, transformed)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Norm:"}\NormalTok{, norm)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-100}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Take the vector x = {[}4, 3{]}. What is its norm? (Hint: √(4²+3²))
\item
  Multiply the matrix

  \[
  A = \begin{bmatrix}2 & 0 \\ 0 & 2\end{bmatrix}
  \]

  by x = {[}1, 1{]}. What does the result look like?
\end{enumerate}

\subsection{102. Vector Operations and
Norms}\label{vector-operations-and-norms}

Vectors are not just lists of numbers; they are objects on which we
define operations. Adding and scaling vectors lets us move and stretch
directions in space. Dot products measure similarity, while norms
measure size. These operations form the foundation of geometry and
distance in machine learning.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-101}

Picture two arrows drawn from the origin. Adding them means placing one
arrow's tail at the other's head, forming a diagonal. Scaling a vector
stretches or shrinks its arrow. The dot product measures how aligned two
arrows are: large if they point in the same direction, zero if they're
perpendicular, negative if they point opposite. A norm is simply the
length of the arrow.

\subsubsection{Deep Dive}\label{deep-dive-101}

Vector addition: x + y = {[}x₁ + y₁, \ldots, xₙ + yₙ{]}. Scalar
multiplication: a·x = {[}a·x₁, \ldots, a·xₙ{]}. Dot product: x·y = Σ
xᵢyᵢ, capturing both length and alignment. Norms:

\begin{itemize}
\tightlist
\item
  L2 norm: ‖x‖₂ = √(Σ xᵢ²), the Euclidean length.
\item
  L1 norm: ‖x‖₁ = Σ \textbar xᵢ\textbar, often used for sparsity.
\item
  L∞ norm: max \textbar xᵢ\textbar, measuring the largest component.
\end{itemize}

In AI, norms define distances for clustering, regularization penalties,
and robustness to perturbations.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1694}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1290}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3387}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0081}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3548}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Operation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Interpretation in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Addition & x + y & Combining features & & \\
Scalar multiplication & a·x & Scaling magnitude & & \\
Dot product & x·y = ‖x‖‖y‖cosθ & Similarity / projection & & \\
L2 norm & √(Σ xᵢ²) & Standard distance, used in Euclidean space & & \\
L1 norm & Σ & xᵢ & & Promotes sparsity, robust to outliers \\
L∞ norm & max & xᵢ & & Worst-case deviation, adversarial robustness \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-101}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{x }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{])}

\CommentTok{\# Vector addition and scaling}
\NormalTok{sum\_xy }\OperatorTok{=}\NormalTok{ x }\OperatorTok{+}\NormalTok{ y}
\NormalTok{scaled\_x }\OperatorTok{=} \DecValTok{2} \OperatorTok{*}\NormalTok{ x}

\CommentTok{\# Dot product and norms}
\NormalTok{dot }\OperatorTok{=}\NormalTok{ np.dot(x, y)}
\NormalTok{l2 }\OperatorTok{=}\NormalTok{ np.linalg.norm(x, }\DecValTok{2}\NormalTok{)}
\NormalTok{l1 }\OperatorTok{=}\NormalTok{ np.linalg.norm(x, }\DecValTok{1}\NormalTok{)}
\NormalTok{linf }\OperatorTok{=}\NormalTok{ np.linalg.norm(x, np.inf)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"x + y:"}\NormalTok{, sum\_xy)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"2 * x:"}\NormalTok{, scaled\_x)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Dot product:"}\NormalTok{, dot)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"L2 norm:"}\NormalTok{, l2)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"L1 norm:"}\NormalTok{, l1)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"L∞ norm:"}\NormalTok{, linf)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-101}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute the dot product of x = {[}1, 0{]} and y = {[}0, 1{]}. What
  does the result tell you?
\item
  Find the L2 norm of x = {[}5, 12{]}.
\item
  Compare the L1 and L2 norms for x = {[}1, -1, 1, -1{]}. Which is
  larger, and why?
\end{enumerate}

\subsection{103. Matrix Multiplication and
Properties}\label{matrix-multiplication-and-properties}

Matrix multiplication is the central operation that ties linear algebra
to AI. Multiplying a matrix by a vector applies a linear transformation:
rotation, scaling, or projection. Multiplying two matrices composes
transformations. Understanding how this works and what properties it
preserves is essential for reasoning about model weights, layers, and
data transformations.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-102}

Think of a matrix as a machine that takes an input arrow (vector) and
outputs a new arrow. Applying one machine after another corresponds to
multiplying matrices. If you rotate by 90° and then scale by 2, the
combined effect is another matrix. The rows of the matrix act like
filters, each producing a weighted combination of the input vector's
components.

\subsubsection{Deep Dive}\label{deep-dive-102}

Given an m×n matrix A and an n×p matrix B, the product C = AB is an m×p
matrix. Each entry is

\[
c_{ij} = \sum_{k=1}^{n} a_{ik} b_{kj}.
\]

Key properties:

\begin{itemize}
\tightlist
\item
  Associativity: (AB)C = A(BC)
\item
  Distributivity: A(B + C) = AB + AC
\item
  Non-commutativity: AB ≠ BA in general
\item
  Identity: AI = IA = A
\item
  Transpose rules: (AB)ᵀ = BᵀAᵀ
\end{itemize}

In AI, matrix multiplication encodes layer operations: inputs × weights
= activations. Batch processing is also matrix multiplication, where
many vectors are transformed at once.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2083}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2222}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5694}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Property
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Associativity & (AB)C = A(BC) & Order of chaining layers doesn't
matter \\
Distributivity & A(B+C) = AB + AC & Parallel transformations combine
linearly \\
Non-commutative & AB ≠ BA & Order of layers matters \\
Identity & AI = IA = A & No transformation applied \\
Transpose rule & (AB)ᵀ = BᵀAᵀ & Useful for gradients/backprop \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-102}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Define matrices}
\NormalTok{A }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{],}
\NormalTok{              [}\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{]])}
\NormalTok{B }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{],}
\NormalTok{              [}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{]])}
\NormalTok{x }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{])}

\CommentTok{\# Matrix{-}vector multiplication}
\NormalTok{Ax }\OperatorTok{=}\NormalTok{ np.dot(A, x)}

\CommentTok{\# Matrix{-}matrix multiplication}
\NormalTok{AB }\OperatorTok{=}\NormalTok{ np.dot(A, B)}

\CommentTok{\# Properties}
\NormalTok{assoc }\OperatorTok{=}\NormalTok{ np.allclose(np.dot(np.dot(A, B), A), np.dot(A, np.dot(B, A)))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"A @ x ="}\NormalTok{, Ax)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"A @ B =}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, AB)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Associativity holds?"}\NormalTok{, assoc)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters}

Matrix multiplication is the language of neural networks. Each layer's
parameters form a matrix that transforms input vectors into hidden
representations. The non-commutativity explains why order of layers
changes outcomes. Properties like associativity enable efficient
computation, and transpose rules are the backbone of backpropagation.
Without mastering matrix multiplication, it is impossible to understand
how AI models propagate signals and gradients.

\subsubsection{Try It Yourself}\label{try-it-yourself-102}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Multiply A = {[}{[}2, 0{]}, {[}0, 2{]}{]} by x = {[}3, 4{]}. What
  happens to the vector?
\item
  Show that AB ≠ BA using A = {[}{[}1, 2{]}, {[}0, 1{]}{]}, B = {[}{[}0,
  1{]}, {[}1, 0{]}{]}.
\item
  Verify that (AB)ᵀ = BᵀAᵀ with small 2×2 matrices.
\end{enumerate}

\subsection{104. Linear Independence and
Span}\label{linear-independence-and-span}

Linear independence is about whether vectors bring new information. If
one vector can be written as a combination of others, it adds nothing
new. The span of a set of vectors is all possible linear combinations of
them---essentially the space they generate. Together, independence and
span tell us how many unique directions we have and how big a space they
cover.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-103}

Imagine two arrows in the plane. If both point in different directions,
they can combine to reach any point in 2D space---the whole plane. If
they both lie on the same line, one is redundant, and you can't reach
the full plane. In higher dimensions, independence tells you whether
your set of vectors truly spans the whole space or just a smaller
subspace.

\subsubsection{Deep Dive}\label{deep-dive-103}

\begin{itemize}
\tightlist
\item
  Linear Combination: a₁v₁ + a₂v₂ + \ldots{} + aₖvₖ.
\item
  Span: The set of all linear combinations of \{v₁, \ldots, vₖ\}.
\item
  Linear Dependence: If there exist coefficients, not all zero, such
  that a₁v₁ + \ldots{} + aₖvₖ = 0, then the vectors are dependent.
\item
  Linear Independence: No such nontrivial combination exists.
\end{itemize}

Dimension of a span = number of independent vectors. In AI, feature
spaces often have redundant dimensions; PCA and other dimensionality
reduction methods identify smaller independent sets.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2209}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4651}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3140}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formal Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Span & All linear combinations of given vectors & Feature space
coverage \\
Linear dependence & Some vector is a combination of others & Redundant
features \\
Linear independence & No redundancy; minimal unique directions & Basis
vectors in embeddings \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-103}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Define vectors}
\NormalTok{v1 }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{])}
\NormalTok{v2 }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{])}
\NormalTok{v3 }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{2}\NormalTok{, }\DecValTok{0}\NormalTok{])  }\CommentTok{\# dependent on v1}

\CommentTok{\# Stack into matrix}
\NormalTok{M }\OperatorTok{=}\NormalTok{ np.column\_stack([v1, v2, v3])}

\CommentTok{\# Rank gives dimension of span}
\NormalTok{rank }\OperatorTok{=}\NormalTok{ np.linalg.matrix\_rank(M)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Matrix:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, M)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Rank (dimension of span):"}\NormalTok{, rank)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-1}

Redundant features inflate dimensionality without adding new
information. Independent features, by contrast, capture the true
structure of data. Recognizing independence helps in feature selection,
dimensionality reduction, and efficient representation learning. In
neural networks, basis-like transformations underpin embeddings and
compressed representations.

\subsubsection{Try It Yourself}\label{try-it-yourself-103}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Are v₁ = {[}1, 2{]}, v₂ = {[}2, 4{]} independent or dependent?
\item
  What is the span of v₁ = {[}1, 0{]}, v₂ = {[}0, 1{]} in 2D space?
\item
  For vectors v₁ = {[}1, 0, 0{]}, v₂ = {[}0, 1, 0{]}, v₃ = {[}1, 1,
  0{]}, what is the dimension of their span?
\end{enumerate}

\subsection{105. Rank, Null Space, and Solutions of Ax =
b}\label{rank-null-space-and-solutions-of-ax-b}

The rank of a matrix measures how much independent information it
contains. The null space consists of all vectors that the matrix sends
to zero. Together, rank and null space determine whether a system of
linear equations Ax = b has solutions, and if so, whether they are
unique or infinite.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-104}

Think of a matrix as a machine that transforms space. If its rank is
full, the machine covers the entire output space---every target vector b
is reachable. If its rank is deficient, the machine squashes some
dimensions, leaving gaps. The null space represents the hidden tunnel:
vectors that go in but vanish to zero at the output.

\subsubsection{Deep Dive}\label{deep-dive-104}

\begin{itemize}
\item
  Rank(A): number of independent rows/columns of A.
\item
  Null Space: \{x ∈ ℝⁿ \textbar{} Ax = 0\}.
\item
  Rank-Nullity Theorem: For A (m×n), rank(A) + nullity(A) = n.
\item
  Solutions to Ax = b:

  \begin{itemize}
  \tightlist
  \item
    If rank(A) = rank({[}A\textbar b{]}) = n → unique solution.
  \item
    If rank(A) = rank({[}A\textbar b{]}) \textless{} n → infinite
    solutions.
  \item
    If rank(A) \textless{} rank({[}A\textbar b{]}) → no solution.
  \end{itemize}
\end{itemize}

In AI, rank relates to model capacity: a low-rank weight matrix cannot
represent all possible mappings, while null space directions correspond
to variations in input that a model ignores.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1304}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3913}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4783}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Connection
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Rank & Independent directions preserved & Expressive power of layers \\
Null space & Inputs mapped to zero & Features discarded by model \\
Rank-nullity & Rank + nullity = number of variables & Trade-off between
information and redundancy \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-104}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{A }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{],}
\NormalTok{              [}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{],}
\NormalTok{              [}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{]])}
\NormalTok{b }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{6}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{4}\NormalTok{])}

\CommentTok{\# Rank of A}
\NormalTok{rank\_A }\OperatorTok{=}\NormalTok{ np.linalg.matrix\_rank(A)}

\CommentTok{\# Augmented matrix [A|b]}
\NormalTok{Ab }\OperatorTok{=}\NormalTok{ np.column\_stack([A, b])}
\NormalTok{rank\_Ab }\OperatorTok{=}\NormalTok{ np.linalg.matrix\_rank(Ab)}

\CommentTok{\# Solve if consistent}
\NormalTok{solution }\OperatorTok{=} \VariableTok{None}
\ControlFlowTok{if}\NormalTok{ rank\_A }\OperatorTok{==}\NormalTok{ rank\_Ab:}
\NormalTok{    solution }\OperatorTok{=}\NormalTok{ np.linalg.lstsq(A, b, rcond}\OperatorTok{=}\VariableTok{None}\NormalTok{)[}\DecValTok{0}\NormalTok{]}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Rank(A):"}\NormalTok{, rank\_A)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Rank([A|b]):"}\NormalTok{, rank\_Ab)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Solution:"}\NormalTok{, solution)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-2}

In machine learning, rank restrictions show up in low-rank
approximations for compression, in covariance matrices that reveal
correlations, and in singular value decomposition used for embeddings.
Null spaces matter because they identify directions in the data that
models cannot see---critical for robustness and feature engineering.

\subsubsection{Try It Yourself}\label{try-it-yourself-104}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For A = {[}{[}1, 0{]}, {[}0, 1{]}{]}, what is rank(A) and null space?
\item
  Solve Ax = b for A = {[}{[}1, 2{]}, {[}2, 4{]}{]}, b = {[}3, 6{]}. How
  many solutions exist?
\item
  Consider A = {[}{[}1, 1{]}, {[}1, 1{]}{]}, b = {[}1, 0{]}. Does a
  solution exist? Why or why not?
\end{enumerate}

\subsection{106. Orthogonality and
Projections}\label{orthogonality-and-projections}

Orthogonality describes vectors that are perpendicular---sharing no
overlap in direction. Projection is the operation of expressing one
vector in terms of another, by dropping a shadow onto it. Orthogonality
and projections are the basis of decomposing data into independent
components, simplifying geometry, and designing efficient algorithms.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-105}

Imagine standing in the sun: your shadow on the ground is the projection
of you onto the plane. If the ground is at a right angle to your height,
the shadow contains only the part of you aligned with that surface. Two
orthogonal arrows, like the x- and y-axis, stand perfectly independent;
projecting onto one ignores the other completely.

\subsubsection{Deep Dive}\label{deep-dive-105}

\begin{itemize}
\tightlist
\item
  Orthogonality: Vectors x and y are orthogonal if x·y = 0.
\item
  Projection of y onto x:
\end{itemize}

\[
\text{proj}_x(y) = \frac{x \cdot y}{x \cdot x} x
\]

\begin{itemize}
\tightlist
\item
  Orthogonal Basis: A set of mutually perpendicular vectors; simplifies
  calculations because coordinates don't interfere.
\item
  Orthogonal Matrices: Matrices whose columns form an orthonormal set;
  preserve lengths and angles.
\end{itemize}

Applications:

\begin{itemize}
\tightlist
\item
  PCA: data projected onto principal components.
\item
  Least squares: projecting data onto subspaces spanned by features.
\item
  Orthogonal transforms (e.g., Fourier, wavelets) simplify computation.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2048}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3373}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4578}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula / Rule
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Application
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Orthogonality & x·y = 0 & Independence of features or embeddings \\
Projection & projₓ(y) = (x·y / x·x) x & Dimensionality reduction,
regression \\
Orthogonal basis & Set of perpendicular vectors & PCA, spectral
decomposition \\
Orthogonal matrix & QᵀQ = I & Stable rotations in optimization \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-105}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{x }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{])}

\CommentTok{\# Check orthogonality}
\NormalTok{dot }\OperatorTok{=}\NormalTok{ np.dot(x, y)}

\CommentTok{\# Projection of y onto x}
\NormalTok{proj }\OperatorTok{=}\NormalTok{ (np.dot(x, y) }\OperatorTok{/}\NormalTok{ np.dot(x, x)) }\OperatorTok{*}\NormalTok{ x}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Dot product (x·y):"}\NormalTok{, dot)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Projection of y onto x:"}\NormalTok{, proj)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-3}

Orthogonality underlies the idea of uncorrelated features: one doesn't
explain the other. Projections explain regression, dimensionality
reduction, and embedding models. When models work with orthogonal
directions, learning is efficient and stable. When features are not
orthogonal, redundancy and collinearity can cause instability in
optimization.

\subsubsection{Try It Yourself}\label{try-it-yourself-105}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute the projection of y = {[}2, 3{]} onto x = {[}1, 1{]}.
\item
  Are {[}1, 2{]} and {[}2, -1{]} orthogonal? Check using the dot
  product.
\item
  Show that multiplying a vector by an orthogonal matrix preserves its
  length.
\end{enumerate}

\subsection{107. Eigenvalues and
Eigenvectors}\label{eigenvalues-and-eigenvectors}

Eigenvalues and eigenvectors reveal the ``natural modes'' of a
transformation. An eigenvector is a special direction that does not
change orientation when a matrix acts on it, only its length is scaled.
The scaling factor is the eigenvalue. They expose the geometry hidden
inside matrices and are key to understanding stability, dimensionality
reduction, and spectral methods.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-106}

Imagine stretching a rubber sheet with arrows drawn on it. Most arrows
bend and twist, but some special arrows only get longer or shorter,
never changing their direction. These are eigenvectors, and the stretch
factor is the eigenvalue. They describe the fundamental axes along which
transformations act most cleanly.

\subsubsection{Deep Dive}\label{deep-dive-106}

\begin{itemize}
\item
  Definition: For matrix A, if

  \[
  A v = \lambda v
  \]

  then v is an eigenvector and λ is the corresponding eigenvalue.
\item
  Not all matrices have real eigenvalues, but symmetric matrices always
  do, with orthogonal eigenvectors.
\item
  Diagonalization: A = PDP⁻¹, where D is diagonal with eigenvalues, P
  contains eigenvectors.
\item
  Spectral theorem: Symmetric A = QΛQᵀ.
\item
  Applications:

  \begin{itemize}
  \tightlist
  \item
    PCA: eigenvectors of covariance matrix = principal components.
  \item
    PageRank: dominant eigenvector of web graph transition matrix.
  \item
    Stability: eigenvalues of Jacobians predict system behavior.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2025}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3038}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4937}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Application
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Eigenvector & Av = λv & Principal components, stable directions \\
Eigenvalue & λ = scaling factor & Strength of component or mode \\
Diagonalization & A = PDP⁻¹ & Simplifies powers of matrices, dynamics \\
Spectral theorem & A = QΛQᵀ for symmetric A & PCA, graph Laplacians \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-106}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{A }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{],}
\NormalTok{              [}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{]])}

\CommentTok{\# Compute eigenvalues and eigenvectors}
\NormalTok{vals, vecs }\OperatorTok{=}\NormalTok{ np.linalg.eig(A)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Eigenvalues:"}\NormalTok{, vals)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Eigenvectors:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, vecs)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-4}

Eigenvalues and eigenvectors uncover hidden structure. In AI, they
identify dominant directions in data (PCA), measure graph connectivity
(spectral clustering), and evaluate stability of optimization. Neural
networks exploit low-rank and spectral properties to compress weights
and speed up learning.

\subsubsection{Try It Yourself}\label{try-it-yourself-106}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Find eigenvalues and eigenvectors of A = {[}{[}1, 0{]}, {[}0, 2{]}{]}.
  What do they represent?
\item
  For covariance matrix of data points {[}{[}1, 0{]}, {[}0, 1{]}{]},
  what are the eigenvectors?
\item
  Compute eigenvalues of {[}{[}0, 1{]}, {[}1, 0{]}{]}. How do they
  relate to flipping coordinates?
\end{enumerate}

\subsection{108. Singular Value Decomposition
(SVD)}\label{singular-value-decomposition-svd}

Singular Value Decomposition is a powerful factorization that expresses
any matrix as a combination of rotations (or reflections) and scalings.
Unlike eigen decomposition, SVD applies to all rectangular matrices, not
just square ones. It breaks a matrix into orthogonal directions of input
and output, linked by singular values that measure the strength of each
direction.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-107}

Think of a block of clay being pressed through a mold. The mold rotates
and aligns the clay, stretches it differently along key directions, and
then rotates it again. Those directions are the singular vectors, and
the stretching factors are the singular values. SVD reveals the
essential axes of action of any transformation.

\subsubsection{Deep Dive}\label{deep-dive-107}

For a matrix A (m×n),

\[
A = U \Sigma V^T
\]

\begin{itemize}
\tightlist
\item
  U (m×m): orthogonal, columns = left singular vectors.
\item
  Σ (m×n): diagonal with singular values (σ₁ ≥ σ₂ ≥ \ldots{} ≥ 0).
\item
  V (n×n): orthogonal, columns = right singular vectors.
\end{itemize}

Properties:

\begin{itemize}
\tightlist
\item
  Rank(A) = number of nonzero singular values.
\item
  Condition number = σ₁ / σ\_min, measures numerical stability.
\item
  Low-rank approximation: keep top k singular values to compress A.
\end{itemize}

Applications:

\begin{itemize}
\tightlist
\item
  PCA: covariance matrix factorized via SVD.
\item
  Recommender systems: latent factors via matrix factorization.
\item
  Noise reduction and compression: discard small singular values.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0526}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3684}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5789}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Part
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Role
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Application
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
U & Orthogonal basis for outputs & Principal directions in data space \\
Σ & Strength of each component & Variance captured by each latent
factor \\
V & Orthogonal basis for inputs & Feature embeddings or latent
representations \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-107}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{A }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{],}
\NormalTok{              [}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{]])}

\CommentTok{\# Compute SVD}
\NormalTok{U, S, Vt }\OperatorTok{=}\NormalTok{ np.linalg.svd(A)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"U:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, U)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Singular values:"}\NormalTok{, S)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"V\^{}T:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, Vt)}

\CommentTok{\# Low{-}rank approximation (rank{-}1)}
\NormalTok{rank1 }\OperatorTok{=}\NormalTok{ np.outer(U[:,}\DecValTok{0}\NormalTok{], Vt[}\DecValTok{0}\NormalTok{,:]) }\OperatorTok{*}\NormalTok{ S[}\DecValTok{0}\NormalTok{]}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Rank{-}1 approximation:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, rank1)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-5}

SVD underpins dimensionality reduction, matrix completion, and
compression. It helps uncover latent structures in data (topics,
embeddings), makes computations stable, and explains why certain
transformations amplify or suppress information. In deep learning,
truncated SVD approximates large weight matrices to reduce memory and
computation.

\subsubsection{Try It Yourself}\label{try-it-yourself-107}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute the SVD of A = {[}{[}1, 0{]}, {[}0, 1{]}{]}. What are the
  singular values?
\item
  Take matrix {[}{[}2, 0{]}, {[}0, 1{]}{]} and reconstruct it from UΣVᵀ.
  Which direction is stretched more?
\item
  Apply rank-1 approximation to a 3×3 random matrix. How close is it to
  the original?
\end{enumerate}

\subsection{109. Tensors and Higher-Order
Structures}\label{tensors-and-higher-order-structures}

Tensors generalize scalars, vectors, and matrices to higher dimensions.
A scalar is a 0th-order tensor, a vector is a 1st-order tensor, and a
matrix is a 2nd-order tensor. Higher-order tensors (3rd-order and
beyond) represent multi-dimensional data arrays. They are essential in
AI for modeling structured data such as images, sequences, and
multimodal information.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-108}

Picture a line of numbers: that's a vector. Arrange numbers into a grid:
that's a matrix. Stack matrices like pages in a book: that's a 3D
tensor. Add more axes, and you get higher-order tensors. In AI, these
extra dimensions represent channels, time steps, or feature groups---all
in one object.

\subsubsection{Deep Dive}\label{deep-dive-108}

\begin{itemize}
\item
  Order: number of indices needed to address an element.

  \begin{itemize}
  \tightlist
  \item
    Scalar: 0th order (a).
  \item
    Vector: 1st order (aᵢ).
  \item
    Matrix: 2nd order (aᵢⱼ).
  \item
    Tensor: 3rd+ order (aᵢⱼₖ\ldots).
  \end{itemize}
\item
  Shape: tuple of dimensions, e.g., (batch, height, width, channels).
\item
  Operations:

  \begin{itemize}
  \tightlist
  \item
    Element-wise addition and multiplication.
  \item
    Contractions (generalized dot products).
  \item
    Tensor decompositions (e.g., CP, Tucker).
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Images: 3rd-order tensors (height × width × channels).
  \item
    Videos: 4th-order tensors (frames × height × width × channels).
  \item
    Transformers: attention weights stored as 4D tensors.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Order & Example Object & AI Example \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & Scalar & Loss value, learning rate \\
1 & Vector & Word embedding \\
2 & Matrix & Weight matrix \\
3 & Tensor (3D) & RGB image (H×W×3) \\
4+ & Higher-order & Batch of videos, attention scores \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-108}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Scalars, vectors, matrices, tensors}
\NormalTok{scalar }\OperatorTok{=}\NormalTok{ np.array(}\DecValTok{5}\NormalTok{)}
\NormalTok{vector }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{])}
\NormalTok{matrix }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{], [}\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{]])}
\NormalTok{tensor3 }\OperatorTok{=}\NormalTok{ np.random.rand(}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{)   }\CommentTok{\# 3rd{-}order tensor}
\NormalTok{tensor4 }\OperatorTok{=}\NormalTok{ np.random.rand(}\DecValTok{10}\NormalTok{, }\DecValTok{28}\NormalTok{, }\DecValTok{28}\NormalTok{, }\DecValTok{3}\NormalTok{)  }\CommentTok{\# batch of 10 RGB images}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Scalar:"}\NormalTok{, scalar)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Vector:"}\NormalTok{, vector)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Matrix:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, matrix)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"3D Tensor shape:"}\NormalTok{, tensor3.shape)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"4D Tensor shape:"}\NormalTok{, tensor4.shape)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-6}

Tensors are the core data structure in modern AI frameworks like
TensorFlow and PyTorch. Every dataset and model parameter is expressed
as tensors, enabling efficient GPU computation. Mastering tensors means
understanding how data flows through deep learning systems, from raw
input to final prediction.

\subsubsection{Try It Yourself}\label{try-it-yourself-108}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Represent a grayscale image of size 28×28 as a tensor. What is its
  order and shape?
\item
  Extend it to a batch of 100 RGB images. What is the new tensor shape?
\item
  Compute the contraction (generalized dot product) between two 3D
  tensors of compatible shapes. What does the result represent?
\end{enumerate}

\subsection{110. Applications in AI
Representations}\label{applications-in-ai-representations}

Linear algebra objects---scalars, vectors, matrices, and tensors---are
not abstract math curiosities. They directly represent data, parameters,
and operations in AI systems. Vectors hold features, matrices encode
transformations, and tensors capture complex structured inputs.
Understanding these correspondences turns math into an intuitive
language for modeling intelligence.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-109}

Imagine an AI model as a factory. Scalars are like single control knobs
(learning rate, bias terms). Vectors are conveyor belts carrying rows of
features. Matrices are the machinery applying
transformations---rotating, stretching, mixing inputs. Tensors are
entire stacks of conveyor belts handling images, sequences, or
multimodal signals at once.

\subsubsection{Deep Dive}\label{deep-dive-109}

\begin{itemize}
\item
  Scalars in AI:

  \begin{itemize}
  \tightlist
  \item
    Learning rates control optimization steps.
  \item
    Loss values quantify performance.
  \end{itemize}
\item
  Vectors in AI:

  \begin{itemize}
  \tightlist
  \item
    Embeddings for words, users, or items.
  \item
    Feature vectors for tabular data or single images.
  \end{itemize}
\item
  Matrices in AI:

  \begin{itemize}
  \tightlist
  \item
    Weight matrices of fully connected layers.
  \item
    Transition matrices in Markov models.
  \end{itemize}
\item
  Tensors in AI:

  \begin{itemize}
  \tightlist
  \item
    Image batches (N×H×W×C).
  \item
    Attention maps (Batch×Heads×Seq×Seq).
  \item
    Multimodal data (e.g., video with audio channels).
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Object & AI Role Example \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Scalar & Learning rate = 0.001, single prediction value \\
Vector & Word embedding = {[}0.2, -0.1, 0.5, \ldots{]} \\
Matrix & Neural layer weights, 512×1024 \\
Tensor & Batch of 64 images, 64×224×224×3 \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-109}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Scalar: loss}
\NormalTok{loss }\OperatorTok{=} \FloatTok{0.23}

\CommentTok{\# Vector: embedding for a word}
\NormalTok{embedding }\OperatorTok{=}\NormalTok{ np.random.rand(}\DecValTok{128}\NormalTok{)  }\CommentTok{\# 128{-}dim word embedding}

\CommentTok{\# Matrix: weights in a dense layer}
\NormalTok{weights }\OperatorTok{=}\NormalTok{ np.random.rand(}\DecValTok{128}\NormalTok{, }\DecValTok{64}\NormalTok{)}

\CommentTok{\# Tensor: batch of 32 RGB images, 64x64 pixels}
\NormalTok{images }\OperatorTok{=}\NormalTok{ np.random.rand(}\DecValTok{32}\NormalTok{, }\DecValTok{64}\NormalTok{, }\DecValTok{64}\NormalTok{, }\DecValTok{3}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Loss (scalar):"}\NormalTok{, loss)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Embedding (vector) shape:"}\NormalTok{, embedding.shape)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Weights (matrix) shape:"}\NormalTok{, weights.shape)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Images (tensor) shape:"}\NormalTok{, images.shape)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-7}

Every modern AI framework is built on top of tensor operations. Training
a model means applying matrix multiplications, summing losses, and
updating weights. Recognizing the role of scalars, vectors, matrices,
and tensors in representations lets you map theory directly to practice,
and reason about computation, memory, and scalability.

\subsubsection{Try It Yourself}\label{try-it-yourself-109}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Represent a mini-batch of 16 grayscale MNIST digits (28×28 each). What
  tensor shape do you get?
\item
  If a dense layer has 300 input features and 100 outputs, what is the
  shape of its weight matrix?
\item
  Construct a tensor representing a 10-second audio clip sampled at 16
  kHz, split into 1-second frames with 13 MFCC coefficients each. What
  would its order and shape be?
\end{enumerate}

\section{Chapter 12. Differential and Integral
Calculus}\label{chapter-12.-differential-and-integral-calculus}

\subsection{111. Functions, Limits, and
Continuity}\label{functions-limits-and-continuity}

Calculus begins with functions: rules that assign inputs to outputs.
Limits describe how functions behave near a point, even if the function
is undefined there. Continuity ensures no sudden jumps---the function
flows smoothly without gaps. These concepts form the groundwork for
derivatives, gradients, and optimization in AI.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-110}

Think of walking along a curve drawn on paper. A continuous function
means you can trace the entire curve without lifting your pencil. A
limit is like approaching a tunnel: even if the tunnel entrance is
blocked at the exact spot, you can still describe where the path was
heading.

\subsubsection{Deep Dive}\label{deep-dive-110}

\begin{itemize}
\item
  Function: f: ℝ → ℝ, mapping x ↦ f(x).
\item
  Limit:

  \[
  \lim_{x \to a} f(x) = L
  \]

  if values of f(x) approach L as x approaches a.
\item
  Continuity: f is continuous at x=a if

  \[
  \lim_{x \to a} f(x) = f(a).
  \]
\item
  Discontinuities: removable (hole), jump, or infinite.
\item
  In AI: limits ensure stability in gradient descent, continuity ensures
  smooth loss surfaces.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1548}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3571}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4881}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formal Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Role
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Function & f(x) assigns outputs to inputs & Loss, activation
functions \\
Limit & Values approach L as x → a & Gradient approximations,
convergence \\
Continuity & Limit at a = f(a) & Smooth learning curves,
differentiability \\
Discontinuity & Jumps, holes, asymptotes & Non-smooth activations (ReLU
kinks, etc.) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-110}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Define a function with a removable discontinuity at x=0}
\KeywordTok{def}\NormalTok{ f(x):}
    \ControlFlowTok{return}\NormalTok{ (np.sin(x)) }\OperatorTok{/}\NormalTok{ x }\ControlFlowTok{if}\NormalTok{ x }\OperatorTok{!=} \DecValTok{0} \ControlFlowTok{else} \DecValTok{1}  \CommentTok{\# define f(0)=1}

\CommentTok{\# Approximate limit near 0}
\NormalTok{xs }\OperatorTok{=}\NormalTok{ [}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.01}\NormalTok{, }\FloatTok{0.001}\NormalTok{, }\OperatorTok{{-}}\FloatTok{0.1}\NormalTok{, }\OperatorTok{{-}}\FloatTok{0.01}\NormalTok{]}
\NormalTok{limits }\OperatorTok{=}\NormalTok{ [f(val) }\ControlFlowTok{for}\NormalTok{ val }\KeywordTok{in}\NormalTok{ xs]}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Values near 0:"}\NormalTok{, limits)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"f(0):"}\NormalTok{, f(}\DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-8}

Optimization in AI depends on smooth, continuous loss functions.
Gradient-based algorithms need limits and continuity to define
derivatives. Activation functions like sigmoid and tanh are continuous,
while piecewise ones like ReLU are continuous but not smooth at
zero---still useful because continuity is preserved.

\subsubsection{Try It Yourself}\label{try-it-yourself-110}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Evaluate the left and right limits of f(x) = 1/x as x → 0. Why do they
  differ?
\item
  Is ReLU(x) = max(0, x) continuous everywhere? Where is it not
  differentiable?
\item
  Construct a function with a jump discontinuity and explain why
  gradient descent would fail on it.
\end{enumerate}

\subsection{112. Derivatives and
Gradients}\label{derivatives-and-gradients}

The derivative measures how a function changes as its input changes. It
captures slope---the rate of change at a point. In multiple dimensions,
this generalizes to gradients: vectors of partial derivatives that
describe the steepest direction of change. Derivatives and gradients are
the engines of optimization in AI.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-111}

Imagine a curve on a hill. At each point, the slope of the tangent line
tells you whether you're climbing up or sliding down. In higher
dimensions, picture standing on a mountain surface: the gradient points
in the direction of steepest ascent, while its negative points toward
steepest descent---the path optimization algorithms follow.

\subsubsection{Deep Dive}\label{deep-dive-111}

\begin{itemize}
\item
  Derivative (1D):

  \[
  f'(x) = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h}
  \]
\item
  Partial derivative: rate of change with respect to one variable while
  holding others constant.
\item
  Gradient:

  \[
  \nabla f(x) = \left(\frac{\partial f}{\partial x_1}, \dots, \frac{\partial f}{\partial x_n}\right)
  \]
\item
  Geometric meaning: gradient is perpendicular to level sets of f.
\item
  In AI: gradients guide backpropagation, parameter updates, and loss
  minimization.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1235}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3580}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5185}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula / Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Application
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Derivative & f′(x) = lim (f(x+h) - f(x))/h & Slope of loss curve in 1D
optimization \\
Partial & ∂f/∂xᵢ & Effect of one feature/parameter \\
Gradient & (∂f/∂x₁, \ldots, ∂f/∂xₙ) & Direction of steepest change in
parameters \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-111}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Define a function f(x, y) = x\^{}2 + y\^{}2}
\KeywordTok{def}\NormalTok{ f(x, y):}
    \ControlFlowTok{return}\NormalTok{ x2 }\OperatorTok{+}\NormalTok{ y2}

\CommentTok{\# Numerical gradient at (1,2)}
\NormalTok{h }\OperatorTok{=} \FloatTok{1e{-}5}
\NormalTok{df\_dx }\OperatorTok{=}\NormalTok{ (f(}\DecValTok{1}\OperatorTok{+}\NormalTok{h, }\DecValTok{2}\NormalTok{) }\OperatorTok{{-}}\NormalTok{ f(}\DecValTok{1}\OperatorTok{{-}}\NormalTok{h, }\DecValTok{2}\NormalTok{)) }\OperatorTok{/}\NormalTok{ (}\DecValTok{2}\OperatorTok{*}\NormalTok{h)}
\NormalTok{df\_dy }\OperatorTok{=}\NormalTok{ (f(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\OperatorTok{+}\NormalTok{h) }\OperatorTok{{-}}\NormalTok{ f(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\OperatorTok{{-}}\NormalTok{h)) }\OperatorTok{/}\NormalTok{ (}\DecValTok{2}\OperatorTok{*}\NormalTok{h)}

\NormalTok{gradient }\OperatorTok{=}\NormalTok{ np.array([df\_dx, df\_dy])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Gradient at (1,2):"}\NormalTok{, gradient)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-9}

Every AI model learns by following gradients. Training is essentially
moving through a high-dimensional landscape of parameters, guided by
derivatives of the loss. Understanding derivatives explains why
optimization converges---or gets stuck---and why techniques like
momentum or adaptive learning rates are necessary.

\subsubsection{Try It Yourself}\label{try-it-yourself-111}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute the derivative of f(x) = x² at x=3.
\item
  For f(x,y) = 3x + 4y, what is the gradient? What direction does it
  point?
\item
  Explain why the gradient of f(x,y) = x² + y² at (0,0) is the zero
  vector.
\end{enumerate}

\subsection{113. Partial Derivatives and Multivariable
Calculus}\label{partial-derivatives-and-multivariable-calculus}

When functions depend on several variables, we study how the output
changes with respect to each input separately. Partial derivatives
measure change along one axis at a time, while holding others fixed.
Together they form the foundation of multivariable calculus, which
models curved surfaces and multidimensional landscapes.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-112}

Imagine a mountain surface described by height f(x,y). Walking east
measures ∂f/∂x, walking north measures ∂f/∂y. Each partial derivative is
like slicing the mountain in one direction and asking how steep the
slope is in that slice. By combining all directions, we can describe the
terrain fully.

\subsubsection{Deep Dive}\label{deep-dive-112}

\begin{itemize}
\item
  Partial derivative:

  \[
  \frac{\partial f}{\partial x_i}(x_1,\dots,x_n) = \lim_{h \to 0}\frac{f(\dots,x_i+h,\dots) - f(\dots,x_i,\dots)}{h}
  \]
\item
  Gradient vector: collects all partial derivatives.
\item
  Mixed partials: ∂²f/∂x∂y = ∂²f/∂y∂x (under smoothness assumptions,
  Clairaut's theorem).
\item
  Level sets: curves/surfaces where f(x) = constant; gradient is
  perpendicular to these.
\item
  In AI: loss functions often depend on thousands or millions of
  parameters; partial derivatives tell how sensitive the loss is to each
  parameter individually.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2143}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3690}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4167}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula/Rule
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Role
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Partial derivative & ∂f/∂xᵢ & Effect of one parameter or feature \\
Gradient & (∂f/∂x₁, \ldots, ∂f/∂xₙ) & Used in backpropagation \\
Mixed partials & ∂²f/∂x∂y = ∂²f/∂y∂x (if smooth) & Second-order methods,
curvature \\
Level sets & f(x)=c, gradient ⟂ level set & Visualizing optimization
landscapes \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-112}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ sympy }\ImportTok{as}\NormalTok{ sp}

\CommentTok{\# Define variables}
\NormalTok{x, y }\OperatorTok{=}\NormalTok{ sp.symbols(}\StringTok{\textquotesingle{}x y\textquotesingle{}}\NormalTok{)}
\NormalTok{f }\OperatorTok{=}\NormalTok{ x2 }\OperatorTok{*}\NormalTok{ y }\OperatorTok{+}\NormalTok{ sp.sin(y)}

\CommentTok{\# Partial derivatives}
\NormalTok{df\_dx }\OperatorTok{=}\NormalTok{ sp.diff(f, x)}
\NormalTok{df\_dy }\OperatorTok{=}\NormalTok{ sp.diff(f, y)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"∂f/∂x ="}\NormalTok{, df\_dx)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"∂f/∂y ="}\NormalTok{, df\_dy)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-10}

Partial derivatives explain how each weight in a neural network
influences the loss. Backpropagation computes them efficiently layer by
layer. Without partial derivatives, training deep models would be
impossible: they are the numerical levers that let optimization adjust
millions of parameters simultaneously.

\subsubsection{Try It Yourself}\label{try-it-yourself-112}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute ∂/∂x of f(x,y) = x²y at (2,1).
\item
  For f(x,y) = sin(xy), find ∂f/∂y.
\item
  Check whether mixed partial derivatives commute for f(x,y) = x²y³.
\end{enumerate}

\subsection{114. Gradient Vectors and Directional
Derivatives}\label{gradient-vectors-and-directional-derivatives}

The gradient vector extends derivatives to multiple dimensions. It
points in the direction of steepest increase of a function. Directional
derivatives generalize further, asking: how does the function change if
we move in \emph{any} chosen direction? Together, they provide the
compass for navigating multidimensional landscapes.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-113}

Imagine standing on a hill. The gradient is the arrow on the ground
pointing directly uphill. If you decide to walk northeast, the
directional derivative tells you how steep the slope is in that chosen
direction. It's the projection of the gradient onto your direction of
travel.

\subsubsection{Deep Dive}\label{deep-dive-113}

\begin{itemize}
\item
  Gradient:

  \[
  \nabla f(x) = \left( \frac{\partial f}{\partial x_1}, \dots, \frac{\partial f}{\partial x_n} \right)
  \]
\item
  Directional derivative in direction u:

  \[
  D_u f(x) = \nabla f(x) \cdot u
  \]

  where u is a unit vector.
\item
  Gradient points to steepest ascent; -∇f points to steepest descent.
\item
  Level sets (contours of constant f): gradient is perpendicular to
  them.
\item
  In AI: gradient descent updates parameters in direction of -∇f;
  directional derivatives explain sensitivity along specific parameter
  combinations.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2933}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2533}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4533}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Application
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Gradient & (∂f/∂x₁, \ldots, ∂f/∂xₙ) & Backpropagation, training
updates \\
Directional derivative & Dᵤf(x) = ∇f(x)·u & Sensitivity along chosen
direction \\
Steepest ascent & Direction of ∇f & Climbing optimization landscapes \\
Steepest descent & Direction of -∇f & Gradient descent learning \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-113}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Define f(x,y) = x\^{}2 + y\^{}2}
\KeywordTok{def}\NormalTok{ f(x, y):}
    \ControlFlowTok{return}\NormalTok{ x2 }\OperatorTok{+}\NormalTok{ y2}

\CommentTok{\# Gradient at (1,2)}
\NormalTok{grad }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{2}\OperatorTok{*}\DecValTok{1}\NormalTok{, }\DecValTok{2}\OperatorTok{*}\DecValTok{2}\NormalTok{])}

\CommentTok{\# Direction u (normalized)}
\NormalTok{u }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{]) }\OperatorTok{/}\NormalTok{ np.sqrt(}\DecValTok{2}\NormalTok{)}

\CommentTok{\# Directional derivative}
\NormalTok{Du }\OperatorTok{=}\NormalTok{ np.dot(grad, u)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Gradient at (1,2):"}\NormalTok{, grad)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Directional derivative in direction (1,1):"}\NormalTok{, Du)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-11}

Gradients drive every learning algorithm: they show how to change
parameters to reduce error fastest. Directional derivatives give insight
into how models respond to combined changes, such as adjusting multiple
weights together. This underpins second-order methods, sensitivity
analysis, and robustness checks.

\subsubsection{Try It Yourself}\label{try-it-yourself-113}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For f(x,y) = x² + y², compute the gradient at (3,4). What direction
  does it point?
\item
  Using u = (0,1), compute the directional derivative at (1,2). How does
  it compare to ∂f/∂y?
\item
  Explain why gradient descent always chooses -∇f rather than another
  direction.
\end{enumerate}

\subsection{115. Jacobians and Hessians}\label{jacobians-and-hessians}

The Jacobian and Hessian extend derivatives into structured, matrix
forms. The Jacobian collects all first-order partial derivatives of a
multivariable function, while the Hessian gathers all second-order
partial derivatives. Together, they describe both the slope and
curvature of high-dimensional functions.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-114}

Think of the Jacobian as a map of slopes pointing in every direction,
like a compass at each point of a surface. The Hessian adds a second
layer: it tells you whether the surface is bowl-shaped (convex),
saddle-shaped, or inverted bowl (concave). The Jacobian points you
downhill, the Hessian tells you how the ground curves beneath your feet.

\subsubsection{Deep Dive}\label{deep-dive-114}

\begin{itemize}
\item
  Jacobian: For f: ℝⁿ → ℝᵐ,

  \[
  J_{ij} = \frac{\partial f_i}{\partial x_j}
  \]

  It's an m×n matrix capturing how each output changes with each input.
\item
  Hessian: For scalar f: ℝⁿ → ℝ,

  \[
  H_{ij} = \frac{\partial^2 f}{\partial x_i \partial x_j}
  \]

  It's an n×n symmetric matrix (if f is smooth).
\item
  Properties:

  \begin{itemize}
  \tightlist
  \item
    Jacobian linearizes functions locally.
  \item
    Hessian encodes curvature, used in Newton's method.
  \end{itemize}
\item
  In AI:

  \begin{itemize}
  \tightlist
  \item
    Jacobians: used in backpropagation through vector-valued layers.
  \item
    Hessians: characterize loss landscapes, stability, and convergence.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Concept & Shape & AI Role \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Jacobian & m×n & Sensitivity of outputs to inputs \\
Hessian & n×n & Curvature of loss function \\
Gradient & 1×n & Special case of Jacobian (m=1) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-114}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ sympy }\ImportTok{as}\NormalTok{ sp}

\CommentTok{\# Define variables}
\NormalTok{x, y }\OperatorTok{=}\NormalTok{ sp.symbols(}\StringTok{\textquotesingle{}x y\textquotesingle{}}\NormalTok{)}
\NormalTok{f1 }\OperatorTok{=}\NormalTok{ x2 }\OperatorTok{+}\NormalTok{ y}
\NormalTok{f2 }\OperatorTok{=}\NormalTok{ sp.sin(x) }\OperatorTok{*}\NormalTok{ y}
\NormalTok{F }\OperatorTok{=}\NormalTok{ sp.Matrix([f1, f2])}

\CommentTok{\# Jacobian of F wrt (x,y)}
\NormalTok{J }\OperatorTok{=}\NormalTok{ F.jacobian([x, y])}

\CommentTok{\# Hessian of scalar f1}
\NormalTok{H }\OperatorTok{=}\NormalTok{ sp.hessian(f1, (x, y))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Jacobian:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, J)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Hessian of f1:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, H)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-12}

The Jacobian underlies backpropagation: it's how gradients flow through
each layer of a neural network. The Hessian reveals whether minima are
sharp or flat, explaining generalization and optimization difficulty.
Many advanced algorithms---Newton's method, natural gradients,
curvature-aware optimizers---rely on these structures.

\subsubsection{Try It Yourself}\label{try-it-yourself-114}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute the Jacobian of F(x,y) = (x², y²) at (1,2).
\item
  For f(x,y) = x² + y², write down the Hessian. What does it say about
  curvature?
\item
  Explain how the Hessian helps distinguish between a minimum, maximum,
  and saddle point.
\end{enumerate}

\subsection{116. Optimization and Critical
Points}\label{optimization-and-critical-points}

Optimization is about finding inputs that minimize or maximize a
function. Critical points are where the gradient vanishes (∇f = 0).
These points can be minima, maxima, or saddle points. Understanding them
is central to training AI models, since learning is optimization over a
loss surface.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-115}

Imagine a landscape of hills and valleys. Critical points are the flat
spots where the slope disappears: the bottom of a valley, the top of a
hill, or the center of a saddle. Optimization is like dropping a ball
into this landscape and watching where it rolls. The type of critical
point determines whether the ball comes to rest in a stable valley or
balances precariously on a ridge.

\subsubsection{Deep Dive}\label{deep-dive-115}

\begin{itemize}
\item
  Critical point: x* where ∇f(x*) = 0.
\item
  Classification via Hessian:

  \begin{itemize}
  \tightlist
  \item
    Positive definite → local minimum.
  \item
    Negative definite → local maximum.
  \item
    Indefinite → saddle point.
  \end{itemize}
\item
  Global vs local: Local minima are valleys nearby; global minimum is
  the deepest valley.
\item
  Convex functions: any local minimum is also global.
\item
  In AI: neural networks often converge to local minima or saddle
  points; optimization aims for low-loss basins that generalize well.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1687}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3373}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4940}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Test (using Hessian)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Local minimum & H positive definite & Stable learned model, low loss \\
Local maximum & H negative definite & Rare in training; undesired
peak \\
Saddle point & H indefinite & Common in high dimensions, slows
training \\
Global minimum & Lowest value over all inputs & Best achievable
performance \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-115}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ sympy }\ImportTok{as}\NormalTok{ sp}

\NormalTok{x, y }\OperatorTok{=}\NormalTok{ sp.symbols(}\StringTok{\textquotesingle{}x y\textquotesingle{}}\NormalTok{)}
\NormalTok{f }\OperatorTok{=}\NormalTok{ x2 }\OperatorTok{+}\NormalTok{ y2 }\OperatorTok{{-}}\NormalTok{ x}\OperatorTok{*}\NormalTok{y}

\CommentTok{\# Gradient and Hessian}
\NormalTok{grad }\OperatorTok{=}\NormalTok{ [sp.diff(f, var) }\ControlFlowTok{for}\NormalTok{ var }\KeywordTok{in}\NormalTok{ (x, y)]}
\NormalTok{H }\OperatorTok{=}\NormalTok{ sp.hessian(f, (x, y))}

\CommentTok{\# Solve for critical points}
\NormalTok{critical\_points }\OperatorTok{=}\NormalTok{ sp.solve(grad, (x, y))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Critical points:"}\NormalTok{, critical\_points)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Hessian:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, H)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-13}

Training neural networks is about navigating a massive landscape of
parameters. Knowing how to identify minima, maxima, and saddles explains
why optimization sometimes gets stuck or converges slowly. Techniques
like momentum and adaptive learning rates help escape saddles and find
flatter minima, which often generalize better.

\subsubsection{Try It Yourself}\label{try-it-yourself-115}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Find critical points of f(x) = x². What type are they?
\item
  For f(x,y) = x² − y², compute the gradient and Hessian at (0,0). What
  type of point is this?
\item
  Explain why convex loss functions are easier to optimize than
  non-convex ones.
\end{enumerate}

\subsection{117. Integrals and Areas under
Curves}\label{integrals-and-areas-under-curves}

Integration is the process of accumulating quantities, often visualized
as the area under a curve. While derivatives measure instantaneous
change, integrals measure total accumulation. In AI, integrals appear in
probability (areas under density functions), expected values, and
continuous approximations of sums.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-116}

Imagine pouring water under a curve until it touches the graph: the
filled region is the integral. If the curve goes above and below the
axis, areas above count positive and areas below count negative,
balancing out like gains and losses over time.

\subsubsection{Deep Dive}\label{deep-dive-116}

\begin{itemize}
\item
  Definite integral:

  \[
  \int_a^b f(x)\,dx
  \]

  is the net area under f(x) between a and b.
\item
  Indefinite integral:

  \[
  \int f(x)\,dx = F(x) + C
  \]

  where F′(x) = f(x).
\item
  Fundamental Theorem of Calculus: connects integrals and derivatives:

  \[
  \frac{d}{dx}\int_a^x f(t)\,dt = f(x).
  \]
\item
  In AI:

  \begin{itemize}
  \tightlist
  \item
    Probability densities integrate to 1.
  \item
    Expectations are integrals over random variables.
  \item
    Continuous-time models (differential equations, neural ODEs) rely on
    integration.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2289}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2530}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5181}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Role
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Definite integral & ∫ₐᵇ f(x) dx & Probability mass, expected outcomes \\
Indefinite integral & ∫ f(x) dx = F(x) + C & Antiderivative, symbolic
computation \\
Fundamental theorem & d/dx ∫ f(t) dt = f(x) & Links change (derivatives)
and accumulation \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-116}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ sympy }\ImportTok{as}\NormalTok{ sp}

\NormalTok{x }\OperatorTok{=}\NormalTok{ sp.symbols(}\StringTok{\textquotesingle{}x\textquotesingle{}}\NormalTok{)}
\NormalTok{f }\OperatorTok{=}\NormalTok{ sp.sin(x)}

\CommentTok{\# Indefinite integral}
\NormalTok{F }\OperatorTok{=}\NormalTok{ sp.integrate(f, x)}

\CommentTok{\# Definite integral from 0 to pi}
\NormalTok{area }\OperatorTok{=}\NormalTok{ sp.integrate(f, (x, }\DecValTok{0}\NormalTok{, sp.pi))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Indefinite integral of sin(x):"}\NormalTok{, F)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Definite integral from 0 to pi:"}\NormalTok{, area)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-14}

Integrals explain how continuous distributions accumulate probability,
why loss functions like cross-entropy involve expectations, and how
continuous dynamics are modeled in AI. Without integrals, probability
theory and continuous optimization would collapse, leaving only crude
approximations.

\subsubsection{Try It Yourself}\label{try-it-yourself-116}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute ∫₀¹ x² dx.
\item
  For probability density f(x) = 2x on {[}0,1{]}, check that ∫₀¹ f(x) dx
  = 1.
\item
  Find ∫ cos(x) dx and verify by differentiation.
\end{enumerate}

\subsection{118. Multiple Integrals and
Volumes}\label{multiple-integrals-and-volumes}

Multiple integrals extend the idea of integration to higher dimensions.
Instead of the area under a curve, we compute volumes under surfaces or
hyper-volumes in higher-dimensional spaces. They let us measure total
mass, probability, or accumulation over multidimensional regions.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-117}

Imagine a bumpy sheet stretched over the xy-plane. The double integral
sums the ``pillars'' of volume beneath the surface, filling the region
like pouring sand until the surface is reached. Triple integrals push
this further, measuring the volume inside 3D solids. Higher-order
integrals generalize the same idea into abstract feature spaces.

\subsubsection{Deep Dive}\label{deep-dive-117}

\begin{itemize}
\item
  Double integral:

  \[
  \iint_R f(x,y)\,dx\,dy
  \]

  sums over a region R in 2D.
\item
  Triple integral:

  \[
  \iiint_V f(x,y,z)\,dx\,dy\,dz
  \]

  over volume V.
\item
  Fubini's theorem: allows evaluating multiple integrals as iterated
  single integrals, e.g.

  \[
  \iint_R f(x,y)\,dx\,dy = \int_a^b \int_c^d f(x,y)\,dx\,dy.
  \]
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Probability distributions in multiple variables (joint densities).
  \item
    Normalization constants in Bayesian inference.
  \item
    Expectation over multivariate spaces.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1605}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2963}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5432}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Integral Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Application
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Double & ∬ f(x,y) dx dy & Joint probability of two features \\
Triple & ∭ f(x,y,z) dx dy dz & Volumes, multivariate Gaussian
normalization \\
Higher-order & ∫ \ldots{} ∫ f(x₁,\ldots,xₙ) dx₁\ldots dxₙ & Expectation
in high-dimensional models \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-117}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ sympy }\ImportTok{as}\NormalTok{ sp}

\NormalTok{x, y }\OperatorTok{=}\NormalTok{ sp.symbols(}\StringTok{\textquotesingle{}x y\textquotesingle{}}\NormalTok{)}
\NormalTok{f }\OperatorTok{=}\NormalTok{ x }\OperatorTok{+}\NormalTok{ y}

\CommentTok{\# Double integral over square [0,1]x[0,1]}
\NormalTok{area }\OperatorTok{=}\NormalTok{ sp.integrate(sp.integrate(f, (x, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)), (y, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Double integral over [0,1]x[0,1]:"}\NormalTok{, area)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-15}

Many AI models operate on high-dimensional data, where probabilities are
defined via integrals across feature spaces. Normalizing Gaussian
densities, computing evidence in Bayesian models, or estimating
expectations all require multiple integrals. They connect geometry with
probability in the spaces AI systems navigate.

\subsubsection{Try It Yourself}\label{try-it-yourself-117}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Evaluate ∬ (x² + y²) dx dy over {[}0,1{]}×{[}0,1{]}.
\item
  Compute ∭ 1 dx dy dz over the cube {[}0,1{]}³. What does it represent?
\item
  For joint density f(x,y) = 6xy on {[}0,1{]}×{[}0,1{]}, check that its
  double integral equals 1.
\end{enumerate}

\subsection{119. Differential Equations
Basics}\label{differential-equations-basics}

Differential equations describe how quantities change with respect to
one another. Instead of just functions, they define relationships
between a function and its derivatives. Solutions to differential
equations capture dynamic processes evolving over time or space.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-118}

Think of a swinging pendulum. Its position changes, but its rate of
change depends on velocity, and velocity depends on forces. A
differential equation encodes this chain of dependencies, like a
rulebook that governs motion rather than a single trajectory.

\subsubsection{Deep Dive}\label{deep-dive-118}

\begin{itemize}
\item
  Ordinary Differential Equation (ODE): involves derivatives with
  respect to one variable (usually time). Example:

  \[
  \frac{dy}{dt} = ky
  \]

  has solution y(t) = Ce\^{}\{kt\}.
\item
  Partial Differential Equation (PDE): involves derivatives with respect
  to multiple variables. Example: heat equation:

  \[
  \frac{\partial u}{\partial t} = \alpha \nabla^2 u.
  \]
\item
  Initial value problem (IVP): specify conditions at a starting point to
  determine a unique solution.
\item
  Linear vs nonlinear: linear equations superpose solutions; nonlinear
  ones often create complex behaviors.
\item
  In AI: neural ODEs, diffusion models, and continuous-time dynamics all
  rest on differential equations.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0635}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2698}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.6667}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
General Form
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Use in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
ODE & dy/dt = f(y,t) & Neural ODEs for continuous-depth models \\
PDE & ∂u/∂t = f(u,∇u,\ldots) & Diffusion models for generative AI \\
IVP & y(t₀)=y₀ & Simulating trajectories from initial state \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-118}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ scipy.integrate }\ImportTok{import}\NormalTok{ solve\_ivp}

\CommentTok{\# ODE: dy/dt = {-}y}
\KeywordTok{def}\NormalTok{ f(t, y):}
    \ControlFlowTok{return} \OperatorTok{{-}}\NormalTok{y}

\NormalTok{sol }\OperatorTok{=}\NormalTok{ solve\_ivp(f, (}\DecValTok{0}\NormalTok{, }\DecValTok{5}\NormalTok{), [}\FloatTok{1.0}\NormalTok{], t\_eval}\OperatorTok{=}\NormalTok{np.linspace(}\DecValTok{0}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"t:"}\NormalTok{, sol.t)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"y:"}\NormalTok{, sol.y[}\DecValTok{0}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-16}

Differential equations connect AI to physics and natural processes. They
explain how continuous-time systems evolve and allow models like
diffusion probabilistic models or neural ODEs to simulate dynamics.
Mastery of differential equations equips AI practitioners to model
beyond static data, into evolving systems.

\subsubsection{Try It Yourself}\label{try-it-yourself-118}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solve dy/dt = 2y with y(0)=1.
\item
  Write down the PDE governing heat diffusion in 1D.
\item
  Explain how an ODE solver could be used inside a neural network layer.
\end{enumerate}

\subsection{120. Calculus in Machine Learning
Applications}\label{calculus-in-machine-learning-applications}

Calculus is not just abstract math---it powers nearly every algorithm in
machine learning. Derivatives guide optimization, integrals handle
probabilities, and multivariable calculus shapes how we train and
regularize models. Understanding these connections makes the
mathematical backbone of AI visible.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-119}

Imagine training a neural network as hiking down a mountain blindfolded.
Derivatives tell you which way is downhill (gradient descent). Integrals
measure the area you've already crossed (expectation over data).
Together, they form the invisible GPS guiding your steps toward a valley
of lower loss.

\subsubsection{Deep Dive}\label{deep-dive-119}

\begin{itemize}
\item
  Derivatives in ML:

  \begin{itemize}
  \tightlist
  \item
    Gradients of loss functions guide parameter updates.
  \item
    Backpropagation applies the chain rule across layers.
  \end{itemize}
\item
  Integrals in ML:

  \begin{itemize}
  \item
    Probabilities as areas under density functions.
  \item
    Expectations:

    \[
    \mathbb{E}[f(x)] = \int f(x) p(x) dx.
    \]
  \item
    Partition functions in probabilistic models.
  \end{itemize}
\item
  Optimization: finding minima of loss surfaces through derivatives.
\item
  Regularization: penalty terms often involve norms, tied to integrals
  of squared functions.
\item
  Continuous-time models: neural ODEs and diffusion models integrate
  dynamics.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1444}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4556}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Calculus Tool
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Role in ML
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Derivative & Guides optimization & Gradient descent in neural
networks \\
Chain rule & Efficient backpropagation & Training deep nets \\
Integral & Probability and expectation & Likelihood, Bayesian
inference \\
Multivariable & Handles high-dimensional parameter spaces & Vectorized
gradients in large models \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-119}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Loss function: mean squared error}
\KeywordTok{def}\NormalTok{ loss(w, x, y):}
\NormalTok{    y\_pred }\OperatorTok{=}\NormalTok{ w }\OperatorTok{*}\NormalTok{ x}
    \ControlFlowTok{return}\NormalTok{ np.mean((y }\OperatorTok{{-}}\NormalTok{ y\_pred)}\DecValTok{2}\NormalTok{)}

\CommentTok{\# Gradient of loss wrt w}
\KeywordTok{def}\NormalTok{ grad(w, x, y):}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{2} \OperatorTok{*}\NormalTok{ np.mean(x }\OperatorTok{*}\NormalTok{ (y }\OperatorTok{{-}}\NormalTok{ w }\OperatorTok{*}\NormalTok{ x))}

\CommentTok{\# Training loop}
\NormalTok{x }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{8}\NormalTok{])}
\NormalTok{w }\OperatorTok{=} \FloatTok{0.0}
\NormalTok{lr }\OperatorTok{=} \FloatTok{0.1}

\ControlFlowTok{for}\NormalTok{ epoch }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{5}\NormalTok{):}
\NormalTok{    w }\OperatorTok{{-}=}\NormalTok{ lr }\OperatorTok{*}\NormalTok{ grad(w, x, y)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Epoch }\SpecialCharTok{\{}\NormalTok{epoch}\SpecialCharTok{\}}\SpecialStringTok{, w=}\SpecialCharTok{\{}\NormalTok{w}\SpecialCharTok{:.4f\}}\SpecialStringTok{, loss=}\SpecialCharTok{\{}\NormalTok{loss(w,x,y)}\SpecialCharTok{:.4f\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-17}

Calculus is the language of change, and machine learning is about
changing parameters to fit data. Derivatives let us learn efficiently in
high dimensions. Integrals make probability models consistent. Without
calculus, optimization, probabilistic inference, and even basic learning
algorithms would be impossible.

\subsubsection{Try It Yourself}\label{try-it-yourself-119}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Show how the chain rule applies to f(x) = (3x+1)².
\item
  Express the expectation of f(x) = x under uniform distribution on
  {[}0,1{]} as an integral.
\item
  Compute the derivative of cross-entropy loss with respect to predicted
  probability p.
\end{enumerate}

\section{Chapter 13. Probability Theory
Fundamentals}\label{chapter-13.-probability-theory-fundamentals}

\subsection{121. Probability Axioms and Sample
Spaces}\label{probability-axioms-and-sample-spaces}

Probability provides a formal framework for reasoning about uncertainty.
At its core are three axioms that define how probabilities behave, and a
sample space that captures all possible outcomes. Together, they turn
randomness into a rigorous system we can compute with.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-120}

Imagine rolling a die. The sample space is the set of all possible faces
\{1,2,3,4,5,6\}. Assigning probabilities is like pouring paint onto
these outcomes so that the total paint equals 1. The axioms ensure the
paint spreads consistently: nonnegative, complete, and additive.

\subsubsection{Deep Dive}\label{deep-dive-120}

\begin{itemize}
\item
  Sample space (Ω): set of all possible outcomes.
\item
  Event: subset of Ω. Example: rolling an even number = \{2,4,6\}.
\item
  Axioms of probability (Kolmogorov):

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item
    Non-negativity: P(A) ≥ 0 for all events A.
  \item
    Normalization: P(Ω) = 1.
  \item
    Additivity: For disjoint events A, B:

    \[
    P(A \cup B) = P(A) + P(B).
    \]
  \end{enumerate}
\end{itemize}

From these axioms, all other probability rules follow, such as
complement, conditional probability, and independence.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1750}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4750}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition / Rule
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sample space Ω & All possible outcomes & Coin toss: \{H, T\} \\
Event & Subset of Ω & Even number on die: \{2,4,6\} \\
Non-negativity & P(A) ≥ 0 & Probability can't be negative \\
Normalization & P(Ω) = 1 & Total probability of all die faces = 1 \\
Additivity & P(A∪B) = P(A)+P(B), if A∩B=∅ & P(odd ∪ even) = 1 \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-120}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Sample space: fair six{-}sided die}
\NormalTok{sample\_space }\OperatorTok{=}\NormalTok{ \{}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{\}}

\CommentTok{\# Uniform probability distribution}
\NormalTok{prob }\OperatorTok{=}\NormalTok{ \{outcome: }\DecValTok{1}\OperatorTok{/}\DecValTok{6} \ControlFlowTok{for}\NormalTok{ outcome }\KeywordTok{in}\NormalTok{ sample\_space\}}

\CommentTok{\# Probability of event A = \{2,4,6\}}
\NormalTok{A }\OperatorTok{=}\NormalTok{ \{}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{\}}
\NormalTok{P\_A }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(prob[x] }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ A)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"P(A):"}\NormalTok{, P\_A)   }\CommentTok{\# 0.5}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Normalization check:"}\NormalTok{, }\BuiltInTok{sum}\NormalTok{(prob.values()))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-18}

AI systems constantly reason under uncertainty: predicting outcomes,
estimating likelihoods, or sampling from models. The axioms guarantee
consistency in these calculations. Without them, probability would
collapse into contradictions, and machine learning models built on
probabilistic foundations would be meaningless.

\subsubsection{Try It Yourself}\label{try-it-yourself-120}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define the sample space for flipping two coins. List all possible
  events.
\item
  If a biased coin has P(H) = 0.7 and P(T) = 0.3, check normalization.
\item
  Roll a die. What is the probability of getting a number divisible by
  3?
\end{enumerate}

\subsection{122. Random Variables and
Distributions}\label{random-variables-and-distributions}

Random variables assign numerical values to outcomes of a random
experiment. They let us translate abstract events into numbers we can
calculate with. The distribution of a random variable tells us how
likely each value is, shaping the behavior of probabilistic models.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-121}

Think of rolling a die. The outcome is a symbol like ``3,'' but the
random variable X maps this to the number 3. Now imagine throwing darts
at a dartboard: the random variable could be the distance from the
center. Distributions describe whether outcomes are spread evenly,
clustered, or skewed.

\subsubsection{Deep Dive}\label{deep-dive-121}

\begin{itemize}
\item
  Random variable (RV): A function X: Ω → ℝ.
\item
  Discrete RV: takes countable values (coin toss, die roll).
\item
  Continuous RV: takes values in intervals of ℝ (height, time).
\item
  Probability Mass Function (PMF):

  \[
  P(X = x) = p(x), \quad \sum_x p(x) = 1.
  \]
\item
  Probability Density Function (PDF):

  \[
  P(a \leq X \leq b) = \int_a^b f(x)\,dx, \quad \int_{-\infty}^\infty f(x)\,dx = 1.
  \]
\item
  Cumulative Distribution Function (CDF):

  \[
  F(x) = P(X \leq x).
  \]
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1449}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2174}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.6377}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Representation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Discrete & PMF p(x) & Word counts, categorical labels \\
Continuous & PDF f(x) & Feature distributions (height, signal value) \\
CDF & F(x) = P(X ≤ x) & Threshold probabilities, quantiles \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-121}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ norm}

\CommentTok{\# Discrete: fair die}
\NormalTok{die\_outcomes }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{]}
\NormalTok{pmf }\OperatorTok{=}\NormalTok{ \{x: }\DecValTok{1}\OperatorTok{/}\DecValTok{6} \ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ die\_outcomes\}}

\CommentTok{\# Continuous: Normal distribution}
\NormalTok{mu, sigma }\OperatorTok{=} \DecValTok{0}\NormalTok{, }\DecValTok{1}
\NormalTok{x }\OperatorTok{=}\NormalTok{ np.linspace(}\OperatorTok{{-}}\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\NormalTok{pdf\_values }\OperatorTok{=}\NormalTok{ norm.pdf(x, mu, sigma)}
\NormalTok{cdf\_values }\OperatorTok{=}\NormalTok{ norm.cdf(x, mu, sigma)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Die PMF:"}\NormalTok{, pmf)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Normal PDF:"}\NormalTok{, pdf\_values)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Normal CDF:"}\NormalTok{, cdf\_values)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-19}

Machine learning depends on modeling data distributions. Random
variables turn uncertainty into analyzable numbers, while distributions
tell us how data is spread. Class probabilities in classifiers, Gaussian
assumptions in regression, and sampling in generative models all rely on
these ideas.

\subsubsection{Try It Yourself}\label{try-it-yourself-121}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define a random variable for tossing a coin twice. What values can it
  take?
\item
  For a fair die, what is the PMF of X = ``die roll''?
\item
  For a continuous variable X ∼ Uniform(0,1), compute P(0.2 ≤ X ≤ 0.5).
\end{enumerate}

\subsection{123. Expectation, Variance, and
Moments}\label{expectation-variance-and-moments}

Expectation measures the average value of a random variable in the long
run. Variance quantifies how spread out the values are around that
average. Higher moments (like skewness and kurtosis) describe asymmetry
and tail heaviness. These statistics summarize distributions into
interpretable quantities.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-122}

Imagine tossing a coin thousands of times and recording 1 for heads, 0
for tails. The expectation is the long-run fraction of heads, the
variance tells how often results deviate from that average, and higher
moments reveal whether the distribution is balanced or skewed. It's like
reducing a noisy dataset to a handful of meaningful descriptors.

\subsubsection{Deep Dive}\label{deep-dive-122}

\begin{itemize}
\item
  Expectation (mean):

  \begin{itemize}
  \item
    Discrete:

    \[
    \mathbb{E}[X] = \sum_x x \, p(x).
    \]
  \item
    Continuous:

    \[
    \mathbb{E}[X] = \int_{-\infty}^\infty x \, f(x) \, dx.
    \]
  \end{itemize}
\item
  Variance:

  \[
  \text{Var}(X) = \mathbb{E}[(X - \mathbb{E}[X])^2] = \mathbb{E}[X^2] - (\mathbb{E}[X])^2.
  \]
\item
  Standard deviation: square root of variance.
\item
  Higher moments:

  \begin{itemize}
  \tightlist
  \item
    Skewness: asymmetry.
  \item
    Kurtosis: heaviness of tails.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Statistic & Formula & Interpretation in AI \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Expectation & E{[}X{]} & Predicted output, mean loss \\
Variance & E{[}(X−μ)²{]} & Uncertainty in predictions \\
Skewness & E{[}((X−μ)/σ)³{]} & Bias toward one side \\
Kurtosis & E{[}((X−μ)/σ)⁴{]} & Outlier sensitivity \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-122}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Sample data: simulated predictions}
\NormalTok{data }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{9}\NormalTok{])}

\CommentTok{\# Expectation}
\NormalTok{mean }\OperatorTok{=}\NormalTok{ np.mean(data)}

\CommentTok{\# Variance and standard deviation}
\NormalTok{var }\OperatorTok{=}\NormalTok{ np.var(data)}
\NormalTok{std }\OperatorTok{=}\NormalTok{ np.std(data)}

\CommentTok{\# Higher moments}
\NormalTok{skew }\OperatorTok{=}\NormalTok{ ((data }\OperatorTok{{-}}\NormalTok{ mean)}\DecValTok{3}\NormalTok{).mean() }\OperatorTok{/}\NormalTok{ (std3)}
\NormalTok{kurt }\OperatorTok{=}\NormalTok{ ((data }\OperatorTok{{-}}\NormalTok{ mean)}\DecValTok{4}\NormalTok{).mean() }\OperatorTok{/}\NormalTok{ (std4)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Mean:"}\NormalTok{, mean)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Variance:"}\NormalTok{, var)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Skewness:"}\NormalTok{, skew)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Kurtosis:"}\NormalTok{, kurt)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-20}

Expectations are used in defining loss functions, variances quantify
uncertainty in probabilistic models, and higher moments detect
distributional shifts. For example, expected risk underlies learning
theory, variance is minimized in ensemble methods, and kurtosis signals
heavy-tailed data often found in real-world datasets.

\subsubsection{Try It Yourself}\label{try-it-yourself-122}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute the expectation of rolling a fair die.
\item
  What is the variance of a Bernoulli random variable with p=0.3?
\item
  Explain why minimizing expected loss (not variance) is the goal in
  training, but variance still matters for model stability.
\end{enumerate}

\subsection{124. Common Distributions (Bernoulli, Binomial,
Gaussian)}\label{common-distributions-bernoulli-binomial-gaussian}

Certain probability distributions occur so often in real-world problems
that they are considered ``canonical.'' The Bernoulli models a single
yes/no event, the Binomial models repeated independent trials, and the
Gaussian (Normal) models continuous data clustered around a mean.
Mastering these is essential for building and interpreting AI models.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-123}

Imagine flipping a single coin: that's Bernoulli. Flip the coin ten
times and count heads: that's Binomial. Measure people's heights: most
cluster near average with some shorter and taller outliers---that's
Gaussian. These three form the basic vocabulary of probability.

\subsubsection{Deep Dive}\label{deep-dive-123}

\begin{itemize}
\item
  Bernoulli(p):

  \begin{itemize}
  \tightlist
  \item
    Values: \{0,1\}, success probability p.
  \item
    PMF: P(X=1)=p, P(X=0)=1−p.
  \item
    Mean: p, Variance: p(1−p).
  \end{itemize}
\item
  Binomial(n,p):

  \begin{itemize}
  \item
    Number of successes in n independent Bernoulli trials.
  \item
    PMF:

    \[
    P(X=k) = \binom{n}{k} p^k (1-p)^{n-k}.
    \]
  \item
    Mean: np, Variance: np(1−p).
  \end{itemize}
\item
  Gaussian(μ,σ²):

  \begin{itemize}
  \item
    Continuous distribution with PDF:

    \[
    f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right).
    \]
  \item
    Mean: μ, Variance: σ².
  \item
    Appears by Central Limit Theorem.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1765}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3382}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4853}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Distribution
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bernoulli & P(X=1)=p, P(X=0)=1−p & Binary labels, dropout masks \\
Binomial & P(X=k)=C(n,k)pᵏ(1−p)ⁿ⁻ᵏ & Number of successes in trials \\
Gaussian & f(x) ∝ exp(−(x−μ)²/2σ²) & Noise models, continuous
features \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-123}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ bernoulli, binom, norm}

\CommentTok{\# Bernoulli trial}
\NormalTok{p }\OperatorTok{=} \FloatTok{0.7}
\NormalTok{sample }\OperatorTok{=}\NormalTok{ bernoulli.rvs(p, size}\OperatorTok{=}\DecValTok{10}\NormalTok{)}

\CommentTok{\# Binomial: 10 trials, p=0.5}
\NormalTok{binom\_samples }\OperatorTok{=}\NormalTok{ binom.rvs(}\DecValTok{10}\NormalTok{, }\FloatTok{0.5}\NormalTok{, size}\OperatorTok{=}\DecValTok{5}\NormalTok{)}

\CommentTok{\# Gaussian: mu=0, sigma=1}
\NormalTok{gauss\_samples }\OperatorTok{=}\NormalTok{ norm.rvs(loc}\OperatorTok{=}\DecValTok{0}\NormalTok{, scale}\OperatorTok{=}\DecValTok{1}\NormalTok{, size}\OperatorTok{=}\DecValTok{5}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Bernoulli samples:"}\NormalTok{, sample)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Binomial samples:"}\NormalTok{, binom\_samples)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Gaussian samples:"}\NormalTok{, gauss\_samples)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-21}

Many machine learning algorithms assume specific distributions: logistic
regression assumes Bernoulli outputs, Naive Bayes uses
Binomial/Multinomial, and Gaussian assumptions appear in linear
regression, PCA, and generative models. Recognizing these distributions
connects statistical modeling to practical AI.

\subsubsection{Try It Yourself}\label{try-it-yourself-123}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What are the mean and variance of a Binomial(20, 0.4) distribution?
\item
  Simulate 1000 Gaussian samples with μ=5, σ=2 and compute their sample
  mean. How close is it to the true mean?
\item
  Explain why the Gaussian is often used to model noise in data.
\end{enumerate}

\subsection{125. Joint, Marginal, and Conditional
Probability}\label{joint-marginal-and-conditional-probability}

When dealing with multiple random variables, probabilities can be
combined (joint), reduced (marginal), or conditioned (conditional).
These operations form the grammar of probabilistic reasoning, allowing
us to express how variables interact and how knowledge of one affects
belief about another.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-124}

Think of two dice rolled together. The joint probability is the full
grid of all 36 outcomes. Marginal probability is like looking only at
one die's values, ignoring the other. Conditional probability is asking:
if the first die shows a 6, what is the probability that the sum is
greater than 10?

\subsubsection{Deep Dive}\label{deep-dive-124}

\begin{itemize}
\item
  Joint probability: probability of events happening together.

  \begin{itemize}
  \tightlist
  \item
    Discrete: P(X=x, Y=y).
  \item
    Continuous: joint density f(x,y).
  \end{itemize}
\item
  Marginal probability: probability of a subset of variables, obtained
  by summing/integrating over others.

  \begin{itemize}
  \tightlist
  \item
    Discrete: P(X=x) = Σ\_y P(X=x, Y=y).
  \item
    Continuous: f\_X(x) = ∫ f(x,y) dy.
  \end{itemize}
\item
  Conditional probability:

  \[
  P(X|Y) = \frac{P(X,Y)}{P(Y)}, \quad P(Y)>0.
  \]
\item
  Chain rule of probability:

  \[
  P(X_1, …, X_n) = \prod_{i=1}^n P(X_i | X_1, …, X_{i-1}).
  \]
\item
  In AI: joint models define distributions over data, marginals appear
  in feature distributions, and conditionals are central to Bayesian
  inference.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1134}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1959}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3402}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3505}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Joint & P(X,Y) & Image pixel + label distribution & \\
Marginal & P(X) = Σ\_y P(X,Y) & Distribution of one feature alone & \\
Conditional & P(X & Y) = P(X,Y)/P(Y) & Class probabilities given
features \\
Chain rule & P(X₁,\ldots,Xₙ) = Π P(Xᵢ & X₁\ldots Xᵢ₋₁) & Generative
sequence models \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-124}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Joint distribution for two binary variables X,Y}
\NormalTok{joint }\OperatorTok{=}\NormalTok{ np.array([[}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.2}\NormalTok{],}
\NormalTok{                  [}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.4}\NormalTok{]])  }\CommentTok{\# rows=X, cols=Y}

\CommentTok{\# Marginals}
\NormalTok{P\_X }\OperatorTok{=}\NormalTok{ joint.}\BuiltInTok{sum}\NormalTok{(axis}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
\NormalTok{P\_Y }\OperatorTok{=}\NormalTok{ joint.}\BuiltInTok{sum}\NormalTok{(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}

\CommentTok{\# Conditional P(X|Y=1)}
\NormalTok{P\_X\_given\_Y1 }\OperatorTok{=}\NormalTok{ joint[:,}\DecValTok{1}\NormalTok{] }\OperatorTok{/}\NormalTok{ P\_Y[}\DecValTok{1}\NormalTok{]}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Joint:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, joint)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Marginal P(X):"}\NormalTok{, P\_X)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Marginal P(Y):"}\NormalTok{, P\_Y)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Conditional P(X|Y=1):"}\NormalTok{, P\_X\_given\_Y1)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-22}

Probabilistic models in AI---from Bayesian networks to hidden Markov
models---are built from joint, marginal, and conditional probabilities.
Classification is essentially conditional probability estimation
(P(label \textbar{} features)). Generative models learn joint
distributions, while inference often involves computing marginals.

\subsubsection{Try It Yourself}\label{try-it-yourself-124}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For a fair die and coin, what is the joint probability of rolling a 3
  and flipping heads?
\item
  From joint distribution P(X,Y), derive P(X) by marginalization.
\item
  Explain why P(A\textbar B) ≠ P(B\textbar A), with an example from
  medical diagnosis.
\end{enumerate}

\subsection{126. Independence and
Correlation}\label{independence-and-correlation}

Independence means two random variables do not influence each other:
knowing one tells you nothing about the other. Correlation measures the
strength and direction of linear dependence. Together, they help us
characterize whether features or events are related, redundant, or
informative.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-125}

Imagine rolling two dice. The result of one die does not affect the
other---this is independence. Now imagine height and weight: they are
not independent, because taller people tend to weigh more. The
correlation quantifies this relationship on a scale from −1 (perfect
negative) to +1 (perfect positive).

\subsubsection{Deep Dive}\label{deep-dive-125}

\begin{itemize}
\item
  Independence:

  \[
  P(X,Y) = P(X)P(Y), \quad \text{or equivalently } P(X|Y)=P(X).
  \]
\item
  Correlation coefficient (Pearson's ρ):

  \[
  \rho(X,Y) = \frac{\text{Cov}(X,Y)}{\sigma_X \sigma_Y}.
  \]
\item
  Covariance:

  \[
  \text{Cov}(X,Y) = \mathbb{E}[(X-\mu_X)(Y-\mu_Y)].
  \]
\item
  Independence ⇒ zero correlation (for uncorrelated distributions), but
  zero correlation does not imply independence in general.
\item
  In AI: independence assumptions simplify models (Naive Bayes).
  Correlation analysis detects redundant features and spurious
  relationships.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1928}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1928}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.6145}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Role
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Independence & P(X,Y)=P(X)P(Y) & Feature independence in Naive Bayes \\
Covariance & E{[}(X−μX)(Y−μY){]} & Relationship strength \\
Correlation ρ & Cov(X,Y)/(σXσY) & Normalized measure (−1 to 1) \\
Zero correlation & ρ=0 & No linear relation, but not necessarily
independent \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-125}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Example data}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{])}
\NormalTok{Y }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{10}\NormalTok{])  }\CommentTok{\# perfectly correlated}

\CommentTok{\# Covariance}
\NormalTok{cov }\OperatorTok{=}\NormalTok{ np.cov(X, Y, bias}\OperatorTok{=}\VariableTok{True}\NormalTok{)[}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{]}

\CommentTok{\# Correlation}
\NormalTok{corr }\OperatorTok{=}\NormalTok{ np.corrcoef(X, Y)[}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{]}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Covariance:"}\NormalTok{, cov)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Correlation:"}\NormalTok{, corr)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-23}

Understanding independence allows us to simplify joint distributions and
design tractable probabilistic models. Correlation helps in feature
engineering---removing redundant features or identifying signals.
Misinterpreting correlation as causation can lead to faulty AI
conclusions, so distinguishing the two is critical.

\subsubsection{Try It Yourself}\label{try-it-yourself-125}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  If X = coin toss, Y = die roll, are X and Y independent? Why?
\item
  Compute the correlation between X = {[}1,2,3{]} and Y = {[}3,2,1{]}.
  What does the sign indicate?
\item
  Give an example where two variables have zero correlation but are not
  independent.
\end{enumerate}

\subsection{127. Law of Large Numbers}\label{law-of-large-numbers}

The Law of Large Numbers (LLN) states that as the number of trials
grows, the average of observed outcomes converges to the expected value.
Randomness dominates in the short run, but averages stabilize in the
long run. This principle explains why empirical data approximates true
probabilities.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-126}

Imagine flipping a fair coin. In 10 flips, you might get 7 heads. In
1000 flips, you'll be close to 500 heads. The noise of chance evens out,
and the proportion of heads converges to 0.5. It's like blurry vision
becoming clearer as more data accumulates.

\subsubsection{Deep Dive}\label{deep-dive-126}

\begin{itemize}
\item
  Weak Law of Large Numbers (WLLN): For i.i.d. random variables
  X₁,\ldots,Xₙ with mean μ,

  \[
  \bar{X}_n = \frac{1}{n}\sum_{i=1}^n X_i \to μ \quad \text{in probability as } n→∞.
  \]
\item
  Strong Law of Large Numbers (SLLN):

  \[
  \bar{X}_n \to μ \quad \text{almost surely as } n→∞.
  \]
\item
  Conditions: finite expectation μ.
\item
  In AI: LLN underlies empirical risk minimization---training loss
  approximates expected loss as dataset size grows.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1351}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2162}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.6486}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Form
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Convergence Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Weak LLN & In probability & Training error ≈ expected error with enough
data \\
Strong LLN & Almost surely & Guarantees convergence on almost every
sequence \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-126}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Simulate coin flips (Bernoulli trials)}
\NormalTok{n\_trials }\OperatorTok{=} \DecValTok{10000}
\NormalTok{coin\_flips }\OperatorTok{=}\NormalTok{ np.random.binomial(}\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{, n\_trials)}

\CommentTok{\# Running averages}
\NormalTok{running\_avg }\OperatorTok{=}\NormalTok{ np.cumsum(coin\_flips) }\OperatorTok{/}\NormalTok{ np.arange(}\DecValTok{1}\NormalTok{, n\_trials}\OperatorTok{+}\DecValTok{1}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Final running average:"}\NormalTok{, running\_avg[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-24}

LLN explains why training on larger datasets improves reliability. It
guarantees that averages of noisy observations approximate true
expectations, making probability-based models feasible. Without LLN,
empirical statistics like mean accuracy or loss would never stabilize.

\subsubsection{Try It Yourself}\label{try-it-yourself-126}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate 100 rolls of a fair die and compute the running average. Does
  it approach 3.5?
\item
  Explain how LLN justifies using validation accuracy to estimate
  generalization.
\item
  If a random variable has infinite variance, does the LLN still hold?
\end{enumerate}

\subsection{128. Central Limit Theorem}\label{central-limit-theorem}

The Central Limit Theorem (CLT) states that the distribution of the sum
(or average) of many independent, identically distributed random
variables tends toward a normal distribution, regardless of the original
distribution. This explains why the Gaussian distribution appears so
frequently in statistics and AI.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-127}

Imagine sampling numbers from any strange distribution---uniform,
skewed, even discrete. If you average enough samples, the histogram of
those averages begins to form the familiar bell curve. It's as if nature
smooths out irregularities when many random effects combine.

\subsubsection{Deep Dive}\label{deep-dive-127}

\begin{itemize}
\item
  Statement (simplified): Let X₁,\ldots,Xₙ be i.i.d. with mean μ and
  variance σ². Then

  \[
  \frac{\bar{X}_n - μ}{σ/\sqrt{n}} \to \mathcal{N}(0,1) \quad \text{as } n \to ∞.
  \]
\item
  Requirements: finite mean and variance.
\item
  Generalizations exist for weaker assumptions.
\item
  In AI: CLT justifies approximating distributions with Gaussians,
  motivates confidence intervals, and explains why stochastic gradients
  behave as noisy normal variables.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2264}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4245}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3491}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Application
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sample mean distribution & (X̄ − μ)/(σ/√n) → N(0,1) & Confidence bounds
on model accuracy \\
Gaussian emergence & Sums/averages of random variables look normal &
Approximation in inference \& learning \\
Variance scaling & Std. error = σ/√n & More data = less uncertainty \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-127}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}

\CommentTok{\# Draw from uniform distribution}
\NormalTok{samples }\OperatorTok{=}\NormalTok{ np.random.uniform(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, (}\DecValTok{10000}\NormalTok{, }\DecValTok{50}\NormalTok{))  }\CommentTok{\# 50 samples each}
\NormalTok{averages }\OperatorTok{=}\NormalTok{ samples.mean(axis}\OperatorTok{=}\DecValTok{1}\NormalTok{)}

\CommentTok{\# Check mean and std}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Sample mean:"}\NormalTok{, np.mean(averages))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Sample std:"}\NormalTok{, np.std(averages))}

\CommentTok{\# Plot histogram}
\NormalTok{plt.hist(averages, bins}\OperatorTok{=}\DecValTok{30}\NormalTok{, density}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{"CLT: Distribution of Averages (Uniform → Gaussian)"}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-25}

The CLT explains why Gaussian assumptions are safe in many models, even
if underlying data is not Gaussian. It powers statistical testing,
confidence intervals, and uncertainty estimation. In machine learning,
it justifies treating stochastic gradient noise as Gaussian and
simplifies analysis of large models.

\subsubsection{Try It Yourself}\label{try-it-yourself-127}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate 1000 averages of 10 coin tosses (Bernoulli p=0.5). What does
  the histogram look like?
\item
  Explain why the CLT makes the Gaussian central to Bayesian inference.
\item
  How does increasing n (sample size) change the standard error of the
  sample mean?
\end{enumerate}

\subsection{129. Bayes' Theorem and Conditional
Inference}\label{bayes-theorem-and-conditional-inference}

Bayes' Theorem provides a way to update beliefs when new evidence
arrives. It relates prior knowledge, likelihood of data, and posterior
beliefs. This simple formula underpins probabilistic reasoning,
classification, and modern Bayesian machine learning.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-128}

Imagine a medical test for a rare disease. Before testing, you know the
disease is rare (prior). If the test comes back positive (evidence),
Bayes' Theorem updates your belief about whether the person is actually
sick (posterior). It's like recalculating odds every time you learn
something new.

\subsubsection{Deep Dive}\label{deep-dive-128}

\begin{itemize}
\item
  Bayes' Theorem:

  \[
  P(A|B) = \frac{P(B|A)P(A)}{P(B)}.
  \]

  \begin{itemize}
  \tightlist
  \item
    P(A): prior probability of event A.
  \item
    P(B\textbar A): likelihood of evidence given A.
  \item
    P(B): normalizing constant = Σ P(B\textbar Ai)P(Ai).
  \item
    P(A\textbar B): posterior probability after seeing B.
  \end{itemize}
\item
  Odds form:

  \[
  \text{Posterior odds} = \text{Prior odds} \times \text{Likelihood ratio}.
  \]
\item
  In AI:

  \begin{itemize}
  \tightlist
  \item
    Naive Bayes classifiers use conditional independence to simplify
    P(X\textbar Y).
  \item
    Bayesian inference updates model parameters.
  \item
    Probabilistic reasoning systems (e.g., spam filtering, diagnostics).
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0794}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2778}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3016}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3413}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Term
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Prior P(A) & Belief before seeing evidence & Spam rate before checking
email & \\
Likelihood & P(B & A): evidence given hypothesis & Probability email
contains ``free'' if spam \\
Posterior & P(A & B): updated belief after evidence & Probability email
is spam given ``free'' word \\
Normalizer & P(B) ensures probabilities sum to 1 & Adjust for total
frequency of evidence & \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-128}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example: Disease testing}
\NormalTok{P\_disease }\OperatorTok{=} \FloatTok{0.01}
\NormalTok{P\_pos\_given\_disease }\OperatorTok{=} \FloatTok{0.95}
\NormalTok{P\_pos\_given\_no }\OperatorTok{=} \FloatTok{0.05}

\CommentTok{\# Total probability of positive test}
\NormalTok{P\_pos }\OperatorTok{=}\NormalTok{ P\_pos\_given\_disease}\OperatorTok{*}\NormalTok{P\_disease }\OperatorTok{+}\NormalTok{ P\_pos\_given\_no}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{{-}}\NormalTok{P\_disease)}

\CommentTok{\# Posterior}
\NormalTok{P\_disease\_given\_pos }\OperatorTok{=}\NormalTok{ (P\_pos\_given\_disease}\OperatorTok{*}\NormalTok{P\_disease) }\OperatorTok{/}\NormalTok{ P\_pos}
\BuiltInTok{print}\NormalTok{(}\StringTok{"P(disease | positive test):"}\NormalTok{, P\_disease\_given\_pos)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-26}

Bayes' Theorem is the foundation of probabilistic AI. It explains how
classifiers infer labels from features, how models incorporate
uncertainty, and how predictions adjust with new evidence. Without
Bayes, probabilistic reasoning in AI would be fragmented and incoherent.

\subsubsection{Try It Yourself}\label{try-it-yourself-128}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A spam filter assigns prior P(spam)=0.2. If
  P(``win''\textbar spam)=0.6 and P(``win''\textbar not spam)=0.05,
  compute P(spam\textbar{}``win'').
\item
  Why is P(A\textbar B) ≠ P(B\textbar A)? Give an everyday example.
\item
  Explain how Naive Bayes simplifies computing P(X\textbar Y) in high
  dimensions.
\end{enumerate}

\subsection{130. Probabilistic Models in
AI}\label{probabilistic-models-in-ai}

Probabilistic models describe data and uncertainty using distributions.
They provide structured ways to capture randomness, model dependencies,
and make predictions with confidence levels. These models are central to
AI, where uncertainty is the norm rather than the exception.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-129}

Think of predicting tomorrow's weather. Instead of saying ``It will
rain,'' a probabilistic model says, ``There's a 70\% chance of rain.''
This uncertainty-aware prediction is more realistic. Probabilistic
models act like maps with probabilities attached to each possible
future.

\subsubsection{Deep Dive}\label{deep-dive-129}

\begin{itemize}
\item
  Generative models: learn joint distributions P(X,Y). Example: Naive
  Bayes, Hidden Markov Models, Variational Autoencoders.
\item
  Discriminative models: focus on conditional probability
  P(Y\textbar X). Example: Logistic Regression, Conditional Random
  Fields.
\item
  Graphical models: represent dependencies with graphs. Example:
  Bayesian Networks, Markov Random Fields.
\item
  Probabilistic inference: computing marginals, posteriors, or MAP
  estimates.
\item
  In AI pipelines:

  \begin{itemize}
  \tightlist
  \item
    Uncertainty estimation in predictions.
  \item
    Decision-making under uncertainty.
  \item
    Data generation and simulation.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1628}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2791}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2674}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2907}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Model Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Focus
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Generative & Joint P(X,Y) & Naive Bayes, VAEs & \\
Discriminative & Conditional P(Y & X) & Logistic regression, CRFs \\
Graphical & Structure + dependencies & HMMs, Bayesian networks & \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-129}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.naive\_bayes }\ImportTok{import}\NormalTok{ GaussianNB}

\CommentTok{\# Example: simple Naive Bayes classifier}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\FloatTok{1.8}\NormalTok{, }\DecValTok{80}\NormalTok{], [}\FloatTok{1.6}\NormalTok{, }\DecValTok{60}\NormalTok{], [}\FloatTok{1.7}\NormalTok{, }\DecValTok{65}\NormalTok{], [}\FloatTok{1.5}\NormalTok{, }\DecValTok{50}\NormalTok{]])  }\CommentTok{\# features: height, weight}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{])  }\CommentTok{\# labels: 1=male, 0=female}

\NormalTok{model }\OperatorTok{=}\NormalTok{ GaussianNB()}
\NormalTok{model.fit(X, y)}

\CommentTok{\# Predict probabilities}
\NormalTok{probs }\OperatorTok{=}\NormalTok{ model.predict\_proba([[}\FloatTok{1.7}\NormalTok{, }\DecValTok{70}\NormalTok{]])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Predicted probabilities:"}\NormalTok{, probs)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-27}

Probabilistic models let AI systems express confidence, combine prior
knowledge with new evidence, and reason about incomplete information.
From spam filters to speech recognition and modern generative AI,
probability provides the mathematical backbone for making reliable
predictions.

\subsubsection{Try It Yourself}\label{try-it-yourself-129}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Explain how Naive Bayes assumes independence among features.
\item
  What is the difference between modeling P(X,Y) vs P(Y\textbar X)?
\item
  Describe how a probabilistic model could handle missing data.
\end{enumerate}

\section{Chapter 14. Statistics and
Estimation}\label{chapter-14.-statistics-and-estimation}

\subsection{131. Descriptive Statistics and
Summaries}\label{descriptive-statistics-and-summaries}

Descriptive statistics condense raw data into interpretable summaries.
Instead of staring at thousands of numbers, we reduce them to measures
like mean, median, variance, and quantiles. These summaries highlight
central tendencies, variability, and patterns, making datasets
comprehensible.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-130}

Think of a classroom's exam scores. Instead of listing every score, you
might say, ``The average was 75, most students scored between 70 and 80,
and the highest was 95.'' These summaries give a clear picture without
overwhelming detail.

\subsubsection{Deep Dive}\label{deep-dive-130}

\begin{itemize}
\tightlist
\item
  Measures of central tendency: mean (average), median (middle), mode
  (most frequent).
\item
  Measures of dispersion: range, variance, standard deviation,
  interquartile range.
\item
  Shape descriptors: skewness (asymmetry), kurtosis (tail heaviness).
\item
  Visualization aids: histograms, box plots, summary tables.
\item
  In AI: descriptive stats guide feature engineering, outlier detection,
  and data preprocessing.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1566}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2892}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5542}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Statistic
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula / Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Mean (μ) & (1/n) Σ xi & Baseline average performance \\
Median & Middle value when sorted & Robust measure against outliers \\
Variance (σ²) & (1/n) Σ (xi−μ)² & Spread of feature distributions \\
IQR & Q3 − Q1 & Detecting outliers \\
Skewness & E{[}((X−μ)/σ)³{]} & Identifying asymmetry in feature
distributions \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-130}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ skew, kurtosis}

\NormalTok{data }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{10}\NormalTok{])}

\NormalTok{mean }\OperatorTok{=}\NormalTok{ np.mean(data)}
\NormalTok{median }\OperatorTok{=}\NormalTok{ np.median(data)}
\NormalTok{var }\OperatorTok{=}\NormalTok{ np.var(data)}
\NormalTok{sk }\OperatorTok{=}\NormalTok{ skew(data)}
\NormalTok{kt }\OperatorTok{=}\NormalTok{ kurtosis(data)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Mean:"}\NormalTok{, mean)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Median:"}\NormalTok{, median)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Variance:"}\NormalTok{, var)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Skewness:"}\NormalTok{, sk)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Kurtosis:"}\NormalTok{, kt)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-28}

Before training a model, understanding your dataset is crucial.
Descriptive statistics reveal biases, anomalies, and trends. They are
the first checkpoint in exploratory data analysis (EDA), helping
practitioners avoid errors caused by misunderstood or skewed data.

\subsubsection{Try It Yourself}\label{try-it-yourself-130}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute the mean, median, and variance of exam scores: {[}60, 65, 70,
  80, 85, 90, 100{]}.
\item
  Which is more robust to outliers: mean or median? Why?
\item
  Plot a histogram of 1000 random Gaussian samples and describe its
  shape.
\end{enumerate}

\subsection{132. Sampling Distributions}\label{sampling-distributions}

A sampling distribution is the probability distribution of a statistic
(like the mean or variance) computed from repeated random samples of the
same population. It explains how statistics vary from sample to sample
and provides the foundation for statistical inference.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-131}

Imagine repeatedly drawing small groups of students from a university
and calculating their average height. Each group will have a slightly
different average. If you plot all these averages, you'll see a new
distribution---the sampling distribution of the mean.

\subsubsection{Deep Dive}\label{deep-dive-131}

\begin{itemize}
\item
  Statistic vs parameter: parameter = fixed property of population,
  statistic = estimate from sample.
\item
  Sampling distribution: distribution of a statistic across repeated
  samples.
\item
  Key result: the sampling distribution of the sample mean has mean μ
  and variance σ²/n.
\item
  Central Limit Theorem: ensures the sampling distribution of the mean
  approaches normality for large n.
\item
  Standard error (SE): standard deviation of the sampling distribution:

  \[
  SE = \frac{\sigma}{\sqrt{n}}.
  \]
\item
  In AI: sampling distributions explain variability in validation
  accuracy, generalization gaps, and performance metrics.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2079}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3465}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4455}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula / Rule
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Connection
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sampling distribution & Distribution of statistics & Variability of
model metrics \\
Standard error (SE) & σ/√n & Confidence in accuracy estimates \\
CLT link & Mean sampling distribution ≈ normal & Justifies Gaussian
assumptions in experiments \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-131}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Population: pretend test scores}
\NormalTok{population }\OperatorTok{=}\NormalTok{ np.random.normal(}\DecValTok{70}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{10000}\NormalTok{)}

\CommentTok{\# Draw repeated samples and compute means}
\NormalTok{sample\_means }\OperatorTok{=}\NormalTok{ [np.mean(np.random.choice(population, }\DecValTok{50}\NormalTok{)) }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1000}\NormalTok{)]}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Mean of sample means:"}\NormalTok{, np.mean(sample\_means))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Std of sample means (SE):"}\NormalTok{, np.std(sample\_means))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-29}

Model evaluation relies on samples of data, not entire populations.
Sampling distributions quantify how much reported metrics (accuracy,
loss) can fluctuate by chance, guiding confidence intervals and
hypothesis tests. They help distinguish true improvements from random
variation.

\subsubsection{Try It Yourself}\label{try-it-yourself-131}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate rolling a die 30 times, compute the sample mean, and repeat
  500 times. Plot the distribution of means.
\item
  Explain why the standard error decreases as sample size increases.
\item
  How does the CLT connect sampling distributions to the normal
  distribution?
\end{enumerate}

\subsection{133. Point Estimation and
Properties}\label{point-estimation-and-properties}

Point estimation provides single-value guesses of population parameters
(like mean or variance) from data. Good estimators should be accurate,
stable, and efficient. Properties such as unbiasedness, consistency, and
efficiency define their quality.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-132}

Imagine trying to guess the average height of all students in a school.
You take a sample and compute the sample mean---it's your ``best
guess.'' Sometimes it's too high, sometimes too low, but with enough
data, it hovers around the true average.

\subsubsection{Deep Dive}\label{deep-dive-132}

\begin{itemize}
\item
  Estimator: a rule (function of data) to estimate a parameter θ.
\item
  Point estimate: realized value of the estimator.
\item
  Desirable properties:

  \begin{itemize}
  \tightlist
  \item
    Unbiasedness: E{[}θ̂{]} = θ.
  \item
    Consistency: θ̂ → θ as n→∞.
  \item
    Efficiency: estimator has the smallest variance among unbiased
    estimators.
  \item
    Sufficiency: θ̂ captures all information about θ in the data.
  \end{itemize}
\item
  Examples:

  \begin{itemize}
  \tightlist
  \item
    Sample mean for μ is unbiased and consistent.
  \item
    Sample variance (with denominator n−1) is unbiased for σ².
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1212}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4242}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4545}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Property
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Unbiasedness & E{[}θ̂{]} = θ & Sample mean as unbiased estimator of true
μ \\
Consistency & θ̂ → θ as n→∞ & Validation accuracy converging with data
size \\
Efficiency & Minimum variance among unbiased estimators & MLE often
efficient in large samples \\
Sufficiency & Captures all information about θ & Sufficient statistics
in probabilistic models \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-132}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# True population}
\NormalTok{population }\OperatorTok{=}\NormalTok{ np.random.normal(}\DecValTok{100}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{100000}\NormalTok{)}

\CommentTok{\# Draw sample}
\NormalTok{sample }\OperatorTok{=}\NormalTok{ np.random.choice(population, }\DecValTok{50}\NormalTok{)}

\CommentTok{\# Point estimators}
\NormalTok{mean\_est }\OperatorTok{=}\NormalTok{ np.mean(sample)}
\NormalTok{var\_est }\OperatorTok{=}\NormalTok{ np.var(sample, ddof}\OperatorTok{=}\DecValTok{1}\NormalTok{)  }\CommentTok{\# unbiased variance}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Sample mean (estimator of μ):"}\NormalTok{, mean\_est)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Sample variance (estimator of σ²):"}\NormalTok{, var\_est)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-30}

Point estimation underlies nearly all machine learning parameter
fitting. From estimating regression weights to learning probabilities in
Naive Bayes, we rely on estimators. Knowing their properties ensures our
models don't just fit data but provide reliable generalizations.

\subsubsection{Try It Yourself}\label{try-it-yourself-132}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Show that the sample mean is an unbiased estimator of the population
  mean.
\item
  Why do we divide by (n−1) instead of n when computing sample variance?
\item
  Explain how maximum likelihood estimation is a general framework for
  point estimation.
\end{enumerate}

\subsection{134. Maximum Likelihood Estimation
(MLE)}\label{maximum-likelihood-estimation-mle}

Maximum Likelihood Estimation is a method for finding parameter values
that make the observed data most probable. It transforms learning into
an optimization problem: choose parameters θ that maximize the
likelihood of data under a model.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-133}

Imagine tuning the parameters of a Gaussian curve to fit a histogram of
data. If the curve is too wide or shifted, the probability of observing
the actual data is low. Adjusting until the curve ``hugs'' the data
maximizes the likelihood---it's like aligning a mold to fit scattered
points.

\subsubsection{Deep Dive}\label{deep-dive-133}

\begin{itemize}
\item
  Likelihood function: For data x₁,\ldots,xₙ from distribution
  P(x\textbar θ):

  \[
  L(θ) = \prod_{i=1}^n P(x_i | θ).
  \]
\item
  Log-likelihood (easier to optimize):

  \[
  \ell(θ) = \sum_{i=1}^n \log P(x_i | θ).
  \]
\item
  MLE estimator:

  \[
  \hat{θ}_{MLE} = \arg\max_θ \ell(θ).
  \]
\item
  Properties:

  \begin{itemize}
  \tightlist
  \item
    Consistent: converges to true θ as n→∞.
  \item
    Asymptotically efficient: achieves minimum variance.
  \item
    Invariant: if θ̂ is MLE of θ, then g(θ̂) is MLE of g(θ).
  \end{itemize}
\item
  Example: For Gaussian(μ,σ²), MLE of μ is sample mean, and of σ² is
  (1/n) Σ(xᵢ−μ)².
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1400}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3600}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3500}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Step
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Connection
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Likelihood & L(θ)=Π P(xᵢ & θ) & Fit parameters to maximize data fit \\
Log-likelihood & ℓ(θ)=Σ log P(xᵢ & θ) & Used in optimization
algorithms \\
Estimator & θ̂=argmax ℓ(θ) & Logistic regression, HMMs, deep nets & \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-133}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ norm}
\ImportTok{from}\NormalTok{ scipy.optimize }\ImportTok{import}\NormalTok{ minimize}

\CommentTok{\# Sample data}
\NormalTok{data }\OperatorTok{=}\NormalTok{ np.array([}\FloatTok{2.3}\NormalTok{, }\FloatTok{2.5}\NormalTok{, }\FloatTok{2.8}\NormalTok{, }\FloatTok{3.0}\NormalTok{, }\FloatTok{3.1}\NormalTok{])}

\CommentTok{\# Negative log{-}likelihood for Gaussian(μ,σ)}
\KeywordTok{def}\NormalTok{ nll(params):}
\NormalTok{    mu, sigma }\OperatorTok{=}\NormalTok{ params}
    \ControlFlowTok{return} \OperatorTok{{-}}\NormalTok{np.}\BuiltInTok{sum}\NormalTok{(norm.logpdf(data, mu, sigma))}

\CommentTok{\# Optimize}
\NormalTok{result }\OperatorTok{=}\NormalTok{ minimize(nll, x0}\OperatorTok{=}\NormalTok{[}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{], bounds}\OperatorTok{=}\NormalTok{[(}\VariableTok{None}\NormalTok{,}\VariableTok{None}\NormalTok{),(}\FloatTok{1e{-}6}\NormalTok{,}\VariableTok{None}\NormalTok{)])}
\NormalTok{mu\_mle, sigma\_mle }\OperatorTok{=}\NormalTok{ result.x}

\BuiltInTok{print}\NormalTok{(}\StringTok{"MLE μ:"}\NormalTok{, mu\_mle)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"MLE σ:"}\NormalTok{, sigma\_mle)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-31}

MLE is the foundation of statistical learning. Logistic regression,
Gaussian Mixture Models, and Hidden Markov Models all rely on MLE. Even
deep learning loss functions (like cross-entropy) can be derived from
MLE principles, framing training as maximizing likelihood of observed
labels.

\subsubsection{Try It Yourself}\label{try-it-yourself-133}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Derive the MLE for the Bernoulli parameter p from n coin flips.
\item
  Show that the MLE for μ in a Gaussian is the sample mean.
\item
  Explain why taking the log of the likelihood simplifies optimization.
\end{enumerate}

\subsection{135. Confidence Intervals}\label{confidence-intervals}

A confidence interval (CI) gives a range of plausible values for a
population parameter, based on sample data. Instead of a single point
estimate, it quantifies uncertainty, reflecting how sample variability
affects inference.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-134}

Imagine shooting arrows at a target. A point estimate is one arrow at
the bullseye. A confidence interval is a band around the bullseye,
acknowledging that you might miss a little, but you're likely to land
within the band most of the time.

\subsubsection{Deep Dive}\label{deep-dive-134}

\begin{itemize}
\item
  Definition: A 95\% confidence interval for θ means that if we repeated
  the sampling process many times, about 95\% of such intervals would
  contain the true θ.
\item
  General form:

  \[
  \hat{θ} \pm z_{\alpha/2} \cdot SE(\hat{θ}),
  \]

  where SE = standard error, and z depends on confidence level.
\item
  For mean with known σ:

  \[
  CI = \bar{x} \pm z_{\alpha/2} \frac{σ}{\sqrt{n}}.
  \]
\item
  For mean with unknown σ: use t-distribution.
\item
  In AI: confidence intervals quantify reliability of reported metrics
  like accuracy, precision, or AUC.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2424}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2424}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5152}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Confidence Level
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
z-score (approx)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning in AI results
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
90\% & 1.64 & Narrower interval, less certain \\
95\% & 1.96 & Standard reporting level \\
99\% & 2.58 & Wider interval, stronger certainty \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-134}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ scipy.stats }\ImportTok{as}\NormalTok{ st}

\CommentTok{\# Sample data}
\NormalTok{data }\OperatorTok{=}\NormalTok{ np.array([}\FloatTok{2.3}\NormalTok{, }\FloatTok{2.5}\NormalTok{, }\FloatTok{2.8}\NormalTok{, }\FloatTok{3.0}\NormalTok{, }\FloatTok{3.1}\NormalTok{])}
\NormalTok{mean }\OperatorTok{=}\NormalTok{ np.mean(data)}
\NormalTok{sem }\OperatorTok{=}\NormalTok{ st.sem(data)  }\CommentTok{\# standard error}

\CommentTok{\# 95\% CI using t{-}distribution}
\NormalTok{ci }\OperatorTok{=}\NormalTok{ st.t.interval(}\FloatTok{0.95}\NormalTok{, }\BuiltInTok{len}\NormalTok{(data)}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, loc}\OperatorTok{=}\NormalTok{mean, scale}\OperatorTok{=}\NormalTok{sem)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Sample mean:"}\NormalTok{, mean)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"95}\SpecialCharTok{\% c}\StringTok{onfidence interval:"}\NormalTok{, ci)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-32}

Point estimates can be misleading if not accompanied by uncertainty.
Confidence intervals prevent overconfidence, enabling better decisions
in model evaluation and comparison. They ensure we know not just what
our estimate is, but how trustworthy it is.

\subsubsection{Try It Yourself}\label{try-it-yourself-134}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute a 95\% confidence interval for the mean of 100 coin tosses
  (with p=0.5).
\item
  Compare intervals at 90\% and 99\% confidence. Which is wider? Why?
\item
  Explain how confidence intervals help interpret differences between
  two classifiers' accuracies.
\end{enumerate}

\subsection{136. Hypothesis Testing}\label{hypothesis-testing}

Hypothesis testing is a formal procedure for deciding whether data
supports a claim about a population. It pits two competing statements
against each other: the null hypothesis (status quo) and the alternative
hypothesis (the effect or difference we are testing for). Statistical
evidence then determines whether to reject the null.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-135}

Imagine a courtroom. The null hypothesis is the presumption of
innocence. The alternative is the claim of guilt. The jury (our data)
doesn't have to prove guilt with certainty, only beyond a reasonable
doubt (statistical significance). Rejecting the null is like delivering
a guilty verdict.

\subsubsection{Deep Dive}\label{deep-dive-135}

\begin{itemize}
\item
  Null hypothesis (H₀): baseline claim, e.g., μ = μ₀.
\item
  Alternative hypothesis (H₁): competing claim, e.g., μ ≠ μ₀.
\item
  Test statistic: summarizes evidence from sample.
\item
  p-value: probability of seeing data as extreme as observed, if H₀ is
  true.
\item
  Decision rule: reject H₀ if p-value \textless{} α (significance level,
  often 0.05).
\item
  Errors:

  \begin{itemize}
  \tightlist
  \item
    Type I error: rejecting H₀ when true (false positive).
  \item
    Type II error: failing to reject H₀ when false (false negative).
  \end{itemize}
\item
  In AI: hypothesis tests validate model improvements, check feature
  effects, and compare algorithms.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1798}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3708}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4494}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Component
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Null (H₀) & Baseline assumption & ``Model A = Model B in accuracy'' \\
Alternative (H₁) & Competing claim & ``Model A \textgreater{} Model
B'' \\
Test statistic & Derived measure (t, z, χ²) & Difference in means
between models \\
p-value & Evidence strength & Probability improvement is due to
chance \\
Type I error & False positive (reject true H₀) & Claiming feature
matters when it doesn't \\
Type II error & False negative (miss true effect) & Overlooking a real
model improvement \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-135}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ scipy }\ImportTok{import}\NormalTok{ stats}

\CommentTok{\# Accuracy of two models on 10 runs}
\NormalTok{model\_a }\OperatorTok{=}\NormalTok{ np.array([}\FloatTok{0.82}\NormalTok{, }\FloatTok{0.81}\NormalTok{, }\FloatTok{0.80}\NormalTok{, }\FloatTok{0.83}\NormalTok{, }\FloatTok{0.82}\NormalTok{, }\FloatTok{0.81}\NormalTok{, }\FloatTok{0.84}\NormalTok{, }\FloatTok{0.83}\NormalTok{, }\FloatTok{0.82}\NormalTok{, }\FloatTok{0.81}\NormalTok{])}
\NormalTok{model\_b }\OperatorTok{=}\NormalTok{ np.array([}\FloatTok{0.79}\NormalTok{, }\FloatTok{0.78}\NormalTok{, }\FloatTok{0.80}\NormalTok{, }\FloatTok{0.77}\NormalTok{, }\FloatTok{0.79}\NormalTok{, }\FloatTok{0.80}\NormalTok{, }\FloatTok{0.78}\NormalTok{, }\FloatTok{0.79}\NormalTok{, }\FloatTok{0.77}\NormalTok{, }\FloatTok{0.78}\NormalTok{])}

\CommentTok{\# Two{-}sample t{-}test}
\NormalTok{t\_stat, p\_val }\OperatorTok{=}\NormalTok{ stats.ttest\_ind(model\_a, model\_b)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"t{-}statistic:"}\NormalTok{, t\_stat, }\StringTok{"p{-}value:"}\NormalTok{, p\_val)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-33}

Hypothesis testing prevents AI practitioners from overclaiming results.
Improvements in accuracy may be due to randomness unless confirmed
statistically. Tests provide a disciplined framework for distinguishing
true effects from noise, ensuring reliable scientific progress.

\subsubsection{Try It Yourself}\label{try-it-yourself-135}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Toss a coin 100 times and test if it's fair (p=0.5).
\item
  Compare two classifiers with accuracies of 0.85 and 0.87 over 20 runs.
  Is the difference significant?
\item
  Explain the difference between Type I and Type II errors in model
  evaluation.
\end{enumerate}

\subsection{137. Bayesian Estimation}\label{bayesian-estimation}

Bayesian estimation updates beliefs about parameters by combining prior
knowledge with observed data. Instead of producing just a single point
estimate, it gives a full posterior distribution, reflecting both what
we assumed before and what the data tells us.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-136}

Imagine guessing the weight of an object. Before weighing, you already
have a prior belief (it's probably around 1 kg). After measuring, you
update that belief to account for the evidence. The result isn't one
number but a refined probability curve centered closer to the truth.

\subsubsection{Deep Dive}\label{deep-dive-136}

\begin{itemize}
\item
  Bayes' theorem for parameters θ:

  \[
  P(θ|D) = \frac{P(D|θ)P(θ)}{P(D)}.
  \]

  \begin{itemize}
  \tightlist
  \item
    Prior P(θ): belief before data.
  \item
    Likelihood P(D\textbar θ): probability of data given θ.
  \item
    Posterior P(θ\textbar D): updated belief after seeing data.
  \end{itemize}
\item
  Point estimates from posterior:

  \begin{itemize}
  \tightlist
  \item
    MAP (Maximum A Posteriori): θ̂ = argmax P(θ\textbar D).
  \item
    Posterior mean: E{[}θ\textbar D{]}.
  \end{itemize}
\item
  Conjugate priors: priors chosen to make posterior distribution same
  family as prior (e.g., Beta prior with Binomial likelihood).
\item
  In AI: Bayesian estimation appears in Naive Bayes, Bayesian neural
  networks, and hierarchical models.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1481}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4691}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3827}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Component
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Role
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Prior & Assumptions before data & Belief in feature importance \\
Likelihood & Data fit & Logistic regression likelihood \\
Posterior & Updated distribution & Updated model weights \\
MAP estimate & Most probable parameter after evidence & Regularized
parameter estimates \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-136}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ beta}

\CommentTok{\# Example: coin flips}
\CommentTok{\# Prior: Beta(2,2) \textasciitilde{} uniformish belief}
\NormalTok{prior\_a, prior\_b }\OperatorTok{=} \DecValTok{2}\NormalTok{, }\DecValTok{2}

\CommentTok{\# Data: 7 heads, 3 tails}
\NormalTok{heads, tails }\OperatorTok{=} \DecValTok{7}\NormalTok{, }\DecValTok{3}

\CommentTok{\# Posterior parameters}
\NormalTok{post\_a }\OperatorTok{=}\NormalTok{ prior\_a }\OperatorTok{+}\NormalTok{ heads}
\NormalTok{post\_b }\OperatorTok{=}\NormalTok{ prior\_b }\OperatorTok{+}\NormalTok{ tails}

\CommentTok{\# Posterior distribution}
\NormalTok{posterior }\OperatorTok{=}\NormalTok{ beta(post\_a, post\_b)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Posterior mean:"}\NormalTok{, posterior.mean())}
\BuiltInTok{print}\NormalTok{(}\StringTok{"MAP estimate:"}\NormalTok{, (post\_a }\OperatorTok{{-}} \DecValTok{1}\NormalTok{) }\OperatorTok{/}\NormalTok{ (post\_a }\OperatorTok{+}\NormalTok{ post\_b }\OperatorTok{{-}} \DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-34}

Bayesian estimation provides a principled way to incorporate prior
knowledge, quantify uncertainty, and avoid overfitting. In machine
learning, it enables robust predictions even with small datasets, while
posterior distributions guide decisions under uncertainty.

\subsubsection{Try It Yourself}\label{try-it-yourself-136}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For 5 coin flips with 4 heads, use a Beta(1,1) prior to compute the
  posterior.
\item
  Compare MAP vs posterior mean estimates---when do they differ?
\item
  Explain how Bayesian estimation could help when training data is
  scarce.
\end{enumerate}

\subsection{138. Resampling Methods (Bootstrap,
Jackknife)}\label{resampling-methods-bootstrap-jackknife}

Resampling methods estimate the variability of a statistic by repeatedly
drawing new samples from the observed data. Instead of relying on strict
formulas, they use computation to approximate confidence intervals,
standard errors, and bias.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-137}

Imagine you only have one class of 30 students and their exam scores. To
estimate the variability of the average score, you can ``resample'' from
those 30 scores with replacement many times, creating many
pseudo-classes. The spread of these averages shows how uncertain your
estimate is.

\subsubsection{Deep Dive}\label{deep-dive-137}

\begin{itemize}
\item
  Bootstrap:

  \begin{itemize}
  \tightlist
  \item
    Resample with replacement from the dataset.
  \item
    Compute statistic for each resample.
  \item
    Approximate distribution of statistic across resamples.
  \end{itemize}
\item
  Jackknife:

  \begin{itemize}
  \tightlist
  \item
    Systematically leave one observation out at a time.
  \item
    Compute statistic for each reduced dataset.
  \item
    Useful for bias and variance estimation.
  \end{itemize}
\item
  Advantages: fewer assumptions, works with complex estimators.
\item
  Limitations: computationally expensive, less effective with very small
  datasets.
\item
  In AI: used for model evaluation, confidence intervals of performance
  metrics, and ensemble methods like bagging.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1071}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4167}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4762}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
How It Works
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bootstrap & Sample with replacement, many times & Confidence intervals
for accuracy or AUC \\
Jackknife & Leave-one-out resampling & Variance estimation for small
datasets \\
Bagging & Bootstrap applied to ML models & Random forests, ensemble
learning \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-137}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{data }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{9}\NormalTok{])}

\CommentTok{\# Bootstrap mean estimates}
\NormalTok{bootstrap\_means }\OperatorTok{=}\NormalTok{ [np.mean(np.random.choice(data, size}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(data), replace}\OperatorTok{=}\VariableTok{True}\NormalTok{))}
                   \ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1000}\NormalTok{)]}

\CommentTok{\# Jackknife mean estimates}
\NormalTok{jackknife\_means }\OperatorTok{=}\NormalTok{ [(np.mean(np.delete(data, i))) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(data))]}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Bootstrap mean (approx):"}\NormalTok{, np.mean(bootstrap\_means))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Jackknife mean (approx):"}\NormalTok{, np.mean(jackknife\_means))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-35}

Resampling frees us from restrictive assumptions about distributions. In
AI, where data may not follow textbook distributions, resampling methods
provide reliable uncertainty estimates. Bootstrap underlies ensemble
learning, while jackknife gives insights into bias and stability of
estimators.

\subsubsection{Try It Yourself}\label{try-it-yourself-137}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute bootstrap confidence intervals for the median of a dataset.
\item
  Apply the jackknife to estimate the variance of the sample mean for a
  dataset of 20 numbers.
\item
  Explain how bagging in random forests is essentially bootstrap applied
  to decision trees.
\end{enumerate}

\subsection{139. Statistical Significance and
p-Values}\label{statistical-significance-and-p-values}

Statistical significance is a way to decide whether an observed effect
is likely real or just due to random chance. The p-value measures how
extreme the data is under the null hypothesis. A small p-value suggests
the null is unlikely, providing evidence for the alternative.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-138}

Imagine tossing a fair coin. If it lands heads 9 out of 10 times, you'd
be suspicious. The p-value answers: ``If the coin were truly fair, how
likely is it to see a result at least this extreme?'' A very small
probability means the fairness assumption (null) may not hold.

\subsubsection{Deep Dive}\label{deep-dive-138}

\begin{itemize}
\item
  p-value:

  \[
  p = P(\text{data or more extreme} | H_0).
  \]
\item
  Decision rule: Reject H₀ if p \textless{} α (commonly α=0.05).
\item
  Significance level (α): threshold chosen before the test.
\item
  Misinterpretations:

  \begin{itemize}
  \tightlist
  \item
    p ≠ probability that H₀ is true.
  \item
    p ≠ strength of effect size.
  \end{itemize}
\item
  In AI: used in A/B testing, comparing algorithms, and evaluating new
  features.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2330}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3495}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4175}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Term
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Null hypothesis & No effect or difference & ``Model A = Model B in
accuracy'' \\
p-value & Likelihood of observed data under H₀ & Probability new feature
effect is by chance \\
α = 0.05 & 5\% tolerance for false positives & Standard cutoff in ML
experiments \\
Statistical significance & Evidence strong enough to reject H₀ & Model
improvement deemed meaningful \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-138}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ scipy }\ImportTok{import}\NormalTok{ stats}

\CommentTok{\# Two models\textquotesingle{} accuracies across 8 runs}
\NormalTok{model\_a }\OperatorTok{=}\NormalTok{ np.array([}\FloatTok{0.82}\NormalTok{, }\FloatTok{0.81}\NormalTok{, }\FloatTok{0.83}\NormalTok{, }\FloatTok{0.84}\NormalTok{, }\FloatTok{0.82}\NormalTok{, }\FloatTok{0.81}\NormalTok{, }\FloatTok{0.83}\NormalTok{, }\FloatTok{0.82}\NormalTok{])}
\NormalTok{model\_b }\OperatorTok{=}\NormalTok{ np.array([}\FloatTok{0.79}\NormalTok{, }\FloatTok{0.78}\NormalTok{, }\FloatTok{0.80}\NormalTok{, }\FloatTok{0.79}\NormalTok{, }\FloatTok{0.78}\NormalTok{, }\FloatTok{0.80}\NormalTok{, }\FloatTok{0.79}\NormalTok{, }\FloatTok{0.78}\NormalTok{])}

\CommentTok{\# Independent t{-}test}
\NormalTok{t\_stat, p\_val }\OperatorTok{=}\NormalTok{ stats.ttest\_ind(model\_a, model\_b)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"t{-}statistic:"}\NormalTok{, t\_stat)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"p{-}value:"}\NormalTok{, p\_val)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-36}

p-values and significance levels prevent us from overclaiming
improvements. In AI research and production, results must be
statistically significant before rollout. They provide a disciplined way
to guard against randomness being mistaken for progress.

\subsubsection{Try It Yourself}\label{try-it-yourself-138}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Flip a coin 20 times, observe 16 heads. Compute the p-value under H₀:
  fair coin.
\item
  Compare two classifiers with 0.80 vs 0.82 accuracy on 100 samples
  each. Is the difference significant?
\item
  Explain why a very small p-value does not always mean a large or
  important effect.
\end{enumerate}

\subsection{140. Applications in Data-Driven
AI}\label{applications-in-data-driven-ai}

Statistical methods turn raw data into actionable insights in AI. From
estimating parameters to testing hypotheses, they provide the tools for
making decisions under uncertainty. Statistics ensures that models are
not only trained but also validated, interpreted, and trusted.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-139}

Think of building a recommendation system. Descriptive stats summarize
user behavior, sampling distributions explain uncertainty, confidence
intervals quantify reliability, and hypothesis testing checks if a new
algorithm truly improves engagement. Each statistical tool plays a part
in the lifecycle.

\subsubsection{Deep Dive}\label{deep-dive-139}

\begin{itemize}
\tightlist
\item
  Exploratory Data Analysis (EDA): descriptive statistics and
  visualization to understand data.
\item
  Parameter Estimation: point and Bayesian estimators for model
  parameters.
\item
  Uncertainty Quantification: confidence intervals and Bayesian
  posteriors.
\item
  Model Evaluation: hypothesis testing and p-values to compare models.
\item
  Resampling: bootstrap methods to assess variability and support
  ensemble methods.
\item
  Decision-Making: statistical significance guides deployment choices.
\end{itemize}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Statistical Tool & AI Application \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Descriptive stats & Detecting skew, anomalies, data preprocessing \\
Estimation & Parameter fitting in regression, Naive Bayes \\
Confidence intervals & Reliable accuracy reports \\
Hypothesis testing & Validating improvements in A/B testing \\
Resampling & Random forests, bagging, model robustness \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-139}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.utils }\ImportTok{import}\NormalTok{ resample}

\CommentTok{\# Example: bootstrap confidence interval for accuracy}
\NormalTok{accuracies }\OperatorTok{=}\NormalTok{ np.array([}\FloatTok{0.81}\NormalTok{, }\FloatTok{0.82}\NormalTok{, }\FloatTok{0.80}\NormalTok{, }\FloatTok{0.83}\NormalTok{, }\FloatTok{0.81}\NormalTok{, }\FloatTok{0.82}\NormalTok{])}

\NormalTok{boot\_means }\OperatorTok{=}\NormalTok{ [np.mean(resample(accuracies)) }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1000}\NormalTok{)]}
\NormalTok{ci\_low, ci\_high }\OperatorTok{=}\NormalTok{ np.percentile(boot\_means, [}\FloatTok{2.5}\NormalTok{, }\FloatTok{97.5}\NormalTok{])}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Mean accuracy:"}\NormalTok{, np.mean(accuracies))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"95\% CI:"}\NormalTok{, (ci\_low, ci\_high))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-37}

Without statistics, AI risks overfitting, overclaiming, or
misinterpreting results. Statistical thinking ensures that conclusions
drawn from data are robust, reproducible, and reliable. It turns machine
learning from heuristic curve-fitting into a scientific discipline.

\subsubsection{Try It Yourself}\label{try-it-yourself-139}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use bootstrap to estimate a 95\% confidence interval for model
  precision.
\item
  Explain how hypothesis testing prevents deploying a worse-performing
  model in A/B testing.
\item
  Give an example where descriptive statistics alone could mislead AI
  evaluation without deeper inference.
\end{enumerate}

\section{Chapter 15. Optimization and convex
analysis}\label{chapter-15.-optimization-and-convex-analysis}

\subsection{141. Optimization Problem
Formulation}\label{optimization-problem-formulation}

Optimization is the process of finding the best solution among many
possibilities, guided by an objective function. Formulating a problem in
optimization terms means defining variables to adjust, constraints to
respect, and an objective to minimize or maximize.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-140}

Imagine packing items into a suitcase. The goal is to maximize how much
value you carry while keeping within the weight limit. The items are
variables, the weight restriction is a constraint, and the total value
is the objective. Optimization frames this decision-making precisely.

\subsubsection{Deep Dive}\label{deep-dive-140}

\begin{itemize}
\item
  General form of optimization problem:

  \[
  \min_{x \in \mathbb{R}^n} f(x) \quad \text{subject to } g_i(x) \leq 0, \; h_j(x)=0.
  \]

  \begin{itemize}
  \item
    Objective function f(x): quantity to minimize or maximize.
  \item
    Decision variables x: parameters to choose.
  \item
    Constraints:

    \begin{itemize}
    \tightlist
    \item
      Inequalities gᵢ(x) ≤ 0.
    \item
      Equalities hⱼ(x) = 0.
    \end{itemize}
  \end{itemize}
\item
  Types of optimization problems:

  \begin{itemize}
  \tightlist
  \item
    Unconstrained: no restrictions, e.g.~minimizing f(x)=‖Ax−b‖².
  \item
    Constrained: restrictions present, e.g.~resource allocation.
  \item
    Convex vs non-convex: convex problems are easier, global solutions
    guaranteed.
  \end{itemize}
\item
  In AI: optimization underlies training (loss minimization),
  hyperparameter tuning, and resource scheduling.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1782}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3069}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5149}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Component
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Role
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Objective function & Defines what is being optimized & Loss function in
neural network training \\
Variables & Parameters to adjust & Model weights, feature weights \\
Constraints & Rules to satisfy & Fairness, resource limits \\
Convexity & Guarantees easier optimization & Logistic regression
(convex), deep nets (non-convex) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-140}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ scipy.optimize }\ImportTok{import}\NormalTok{ minimize}

\CommentTok{\# Example: unconstrained optimization}
\NormalTok{f }\OperatorTok{=} \KeywordTok{lambda}\NormalTok{ x: (x[}\DecValTok{0}\NormalTok{]}\OperatorTok{{-}}\DecValTok{2}\NormalTok{)}\DecValTok{2} \OperatorTok{+}\NormalTok{ (x[}\DecValTok{1}\NormalTok{]}\OperatorTok{+}\DecValTok{3}\NormalTok{)}\DecValTok{2}  \CommentTok{\# objective function}

\NormalTok{result }\OperatorTok{=}\NormalTok{ minimize(f, x0}\OperatorTok{=}\NormalTok{[}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{])  }\CommentTok{\# initial guess}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Optimal solution:"}\NormalTok{, result.x)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Minimum value:"}\NormalTok{, result.fun)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-38}

Every AI model is trained by solving an optimization problem: parameters
are tuned to minimize loss. Understanding how to frame objectives and
constraints transforms vague goals (``make accurate predictions'') into
solvable problems. Without proper formulation, optimization may fail or
produce meaningless results.

\subsubsection{Try It Yourself}\label{try-it-yourself-140}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write the optimization problem for training linear regression with
  squared error loss.
\item
  Formulate logistic regression as a constrained optimization problem.
\item
  Explain why convex optimization problems are more desirable than
  non-convex ones in AI.
\end{enumerate}

\subsection{142. Convex Sets and Convex
Functions}\label{convex-sets-and-convex-functions}

Convexity is the cornerstone of modern optimization. A set is convex if
any line segment between two points in it stays entirely inside. A
function is convex if its epigraph (region above its graph) is convex.
Convex problems are attractive because every local minimum is also a
global minimum.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-141}

Imagine a smooth bowl-shaped surface. Drop a marble anywhere, and it
will roll down to the bottom---the unique global minimum. Contrast this
with a rugged mountain range (non-convex), where marbles can get stuck
in local dips.

\subsubsection{Deep Dive}\label{deep-dive-141}

\begin{itemize}
\item
  Convex set: A set C ⊆ ℝⁿ is convex if ∀ x,y ∈ C and ∀ λ ∈ {[}0,1{]}:

  \[
  λx + (1−λ)y ∈ C.
  \]
\item
  Convex function: f is convex if its domain is convex and ∀ x,y and λ ∈
  {[}0,1{]}:

  \[
  f(λx + (1−λ)y) ≤ λf(x) + (1−λ)f(y).
  \]
\item
  Strict convexity: inequality is strict for x ≠ y.
\item
  Properties:

  \begin{itemize}
  \tightlist
  \item
    Sublevel sets of convex functions are convex.
  \item
    Convex functions have no ``false valleys.''
  \end{itemize}
\item
  In AI: many loss functions (squared error, logistic loss) are convex;
  guarantees on convergence exist for convex optimization.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1798}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4045}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4157}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Convex set & Line segment stays inside & Feasible region in linear
programming \\
Convex function & Weighted average lies above graph & Mean squared error
loss \\
Strict convexity & Unique minimum & Ridge regression objective \\
Non-convex & Many local minima, hard optimization & Deep neural
networks \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-141}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}

\NormalTok{x }\OperatorTok{=}\NormalTok{ np.linspace(}\OperatorTok{{-}}\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{100}\NormalTok{)}
\NormalTok{f\_convex }\OperatorTok{=}\NormalTok{ x2        }\CommentTok{\# convex (bowl)}
\NormalTok{f\_nonconvex }\OperatorTok{=}\NormalTok{ np.sin(x)}\CommentTok{\# non{-}convex (wiggly)}

\NormalTok{plt.plot(x, f\_convex, label}\OperatorTok{=}\StringTok{"Convex: x\^{}2"}\NormalTok{)}
\NormalTok{plt.plot(x, f\_nonconvex, label}\OperatorTok{=}\StringTok{"Non{-}convex: sin(x)"}\NormalTok{)}
\NormalTok{plt.legend()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-39}

Convexity is what makes optimization reliable and efficient. Algorithms
like gradient descent and interior-point methods come with guarantees
for convex problems. Even though deep learning is non-convex, convex
analysis still provides intuition and local approximations that guide
practice.

\subsubsection{Try It Yourself}\label{try-it-yourself-141}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Prove that the set of solutions to Ax ≤ b is convex.
\item
  Show that f(x)=‖x‖² is convex using the definition.
\item
  Give an example of a convex loss function and explain why convexity
  helps optimization.
\end{enumerate}

\subsection{143. Gradient Descent and
Variants}\label{gradient-descent-and-variants}

Gradient descent is an iterative method for minimizing functions. By
following the negative gradient---the direction of steepest descent---we
approach a local (and sometimes global) minimum. Variants improve speed,
stability, and scalability in large-scale machine learning.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-142}

Imagine hiking down a foggy mountain with only a slope detector in your
hand. At each step, you move in the direction that goes downhill the
fastest. If your steps are too small, progress is slow; too big, and you
overshoot the valley. Variants of gradient descent adjust how you step.

\subsubsection{Deep Dive}\label{deep-dive-142}

\begin{itemize}
\item
  Basic gradient descent:

  \[
  x_{k+1} = x_k - η \nabla f(x_k),
  \]

  where η is the learning rate.
\item
  Variants:

  \begin{itemize}
  \tightlist
  \item
    Stochastic Gradient Descent (SGD): uses one sample at a time.
  \item
    Mini-batch GD: compromise between batch and SGD.
  \item
    Momentum: accelerates by remembering past gradients.
  \item
    Adaptive methods (AdaGrad, RMSProp, Adam): scale learning rate per
    parameter.
  \end{itemize}
\item
  Convergence: guaranteed for convex, smooth functions with proper η;
  trickier for non-convex.
\item
  In AI: the default optimizer for training neural networks and many
  statistical models.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1389}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3611}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Update Rule
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Application
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Batch GD & Uses full dataset per step & Small datasets, convex
optimization \\
SGD & One sample per step & Online learning, large-scale ML \\
Mini-batch & Subset of data per step & Neural network training \\
Momentum & Adds velocity term & Faster convergence, less oscillation \\
Adam & Adaptive learning rates & Standard in deep learning \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-142}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Function f(x) = (x{-}3)\^{}2}
\NormalTok{f }\OperatorTok{=} \KeywordTok{lambda}\NormalTok{ x: (x}\OperatorTok{{-}}\DecValTok{3}\NormalTok{)}\DecValTok{2}
\NormalTok{grad }\OperatorTok{=} \KeywordTok{lambda}\NormalTok{ x: }\DecValTok{2}\OperatorTok{*}\NormalTok{(x}\OperatorTok{{-}}\DecValTok{3}\NormalTok{)}

\NormalTok{x }\OperatorTok{=} \FloatTok{0.0}  \CommentTok{\# start point}
\NormalTok{eta }\OperatorTok{=} \FloatTok{0.1}
\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{10}\NormalTok{):}
\NormalTok{    x }\OperatorTok{{-}=}\NormalTok{ eta }\OperatorTok{*}\NormalTok{ grad(x)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"x=}\SpecialCharTok{\{}\NormalTok{x}\SpecialCharTok{:.4f\}}\SpecialStringTok{, f(x)=}\SpecialCharTok{\{}\NormalTok{f(x)}\SpecialCharTok{:.4f\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-40}

Gradient descent is the workhorse of machine learning. Without it,
training models with millions of parameters would be impossible.
Variants like Adam make optimization robust to noisy gradients and poor
scaling, critical in deep learning.

\subsubsection{Try It Yourself}\label{try-it-yourself-142}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Run gradient descent on f(x)=x² starting from x=10 with η=0.1. Does it
  converge to 0?
\item
  Compare SGD and batch GD for logistic regression. What are the
  trade-offs?
\item
  Explain why Adam is often chosen as the default optimizer in deep
  learning.
\end{enumerate}

\subsection{144. Constrained Optimization and Lagrange
Multipliers}\label{constrained-optimization-and-lagrange-multipliers}

Constrained optimization extends standard optimization by adding
conditions that the solution must satisfy. Lagrange multipliers
transform constrained problems into unconstrained ones by incorporating
the constraints into the objective, enabling powerful analytical and
computational methods.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-143}

Imagine trying to find the lowest point in a valley, but you're
restricted to walking along a fence. You can't just follow the valley
downward---you must stay on the fence. Lagrange multipliers act like
weights on the constraints, balancing the pull of the objective and the
restrictions.

\subsubsection{Deep Dive}\label{deep-dive-143}

\begin{itemize}
\item
  Problem form:

  \[
  \min f(x) \quad \text{s.t. } g_i(x)=0, \; h_j(x) \leq 0.
  \]
\item
  Lagrangian function:

  \[
  \mathcal{L}(x,λ,μ) = f(x) + \sum_i λ_i g_i(x) + \sum_j μ_j h_j(x),
  \]

  where λ, μ ≥ 0 are multipliers.
\item
  Karush-Kuhn-Tucker (KKT) conditions: generalization of first-order
  conditions for constrained problems.

  \begin{itemize}
  \tightlist
  \item
    Stationarity: ∇f(x*) + Σ λᵢ∇gᵢ(x*) + Σ μⱼ∇hⱼ(x*) = 0.
  \item
    Primal feasibility: constraints satisfied.
  \item
    Dual feasibility: μ ≥ 0.
  \item
    Complementary slackness: μⱼhⱼ(x*) = 0.
  \end{itemize}
\item
  In AI: constraints enforce fairness, resource limits, or structured
  predictions.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1978}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4286}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3736}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Element
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Application
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Lagrangian & Combines objective + constraints & Training with fairness
constraints \\
Multipliers (λ, μ) & Shadow prices: trade-off between goals & Resource
allocation in ML systems \\
KKT conditions & Optimality conditions under constraints & Support
Vector Machines (SVMs) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-143}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ sympy }\ImportTok{as}\NormalTok{ sp}

\NormalTok{x, y, λ }\OperatorTok{=}\NormalTok{ sp.symbols(}\StringTok{\textquotesingle{}x y λ\textquotesingle{}}\NormalTok{)}
\NormalTok{f }\OperatorTok{=}\NormalTok{ x2 }\OperatorTok{+}\NormalTok{ y2  }\CommentTok{\# objective}
\NormalTok{g }\OperatorTok{=}\NormalTok{ x }\OperatorTok{+}\NormalTok{ y }\OperatorTok{{-}} \DecValTok{1}    \CommentTok{\# constraint}

\CommentTok{\# Lagrangian}
\NormalTok{L }\OperatorTok{=}\NormalTok{ f }\OperatorTok{+}\NormalTok{ λ}\OperatorTok{*}\NormalTok{g}

\CommentTok{\# Solve system: ∂L/∂x = 0, ∂L/∂y = 0, g=0}
\NormalTok{solutions }\OperatorTok{=}\NormalTok{ sp.solve([sp.diff(L, x), sp.diff(L, y), g], [x, y, λ])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Optimal solution:"}\NormalTok{, solutions)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-41}

Most real-world AI problems have constraints: fairness in predictions,
limited memory in deployment, or interpretability requirements. Lagrange
multipliers and KKT conditions give a systematic way to handle such
problems without brute force.

\subsubsection{Try It Yourself}\label{try-it-yourself-143}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Minimize f(x,y) = x² + y² subject to x+y=1. Solve using Lagrange
  multipliers.
\item
  Explain how SVMs use constrained optimization to separate data with a
  margin.
\item
  Give an AI example where inequality constraints are essential.
\end{enumerate}

\subsection{145. Duality in Optimization}\label{duality-in-optimization}

Duality provides an alternative perspective on optimization problems by
transforming them into related ``dual'' problems. The dual often offers
deeper insight, easier computation, or guarantees about the original
(primal) problem. In many cases, solving the dual is equivalent to
solving the primal.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-144}

Think of haggling in a marketplace. The seller wants to maximize profit
(primal problem), while the buyer wants to minimize cost (dual problem).
Their negotiations converge to a price where both objectives
meet---illustrating primal-dual optimality.

\subsubsection{Deep Dive}\label{deep-dive-144}

\begin{itemize}
\item
  Primal problem (general form):

  \[
  \min_x f(x) \quad \text{s.t. } g_i(x) \leq 0, \; h_j(x)=0.
  \]
\item
  Lagrangian:

  \[
  \mathcal{L}(x,λ,μ) = f(x) + \sum_i λ_i g_i(x) + \sum_j μ_j h_j(x).
  \]
\item
  Dual function:

  \[
  q(λ,μ) = \inf_x \mathcal{L}(x,λ,μ).
  \]
\item
  Dual problem:

  \[
  \max_{λ \geq 0, μ} q(λ,μ).
  \]
\item
  Weak duality: dual optimum ≤ primal optimum.
\item
  Strong duality: equality holds under convexity + regularity (Slater's
  condition).
\item
  In AI: duality is central to SVMs, resource allocation, and
  distributed optimization.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1628}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3837}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4535}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Role
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Primal problem & Original optimization goal & Training SVM in feature
space \\
Dual problem & Alternative view with multipliers & Kernel trick applied
in SVM dual form \\
Weak duality & Dual ≤ primal & Bound on objective value \\
Strong duality & Dual = primal (convex problems) & Guarantees optimal
solution equivalence \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-144}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ cvxpy }\ImportTok{as}\NormalTok{ cp}

\CommentTok{\# Primal: minimize x\^{}2 subject to x \textgreater{}= 1}
\NormalTok{x }\OperatorTok{=}\NormalTok{ cp.Variable()}
\NormalTok{objective }\OperatorTok{=}\NormalTok{ cp.Minimize(x2)}
\NormalTok{constraints }\OperatorTok{=}\NormalTok{ [x }\OperatorTok{\textgreater{}=} \DecValTok{1}\NormalTok{]}
\NormalTok{prob }\OperatorTok{=}\NormalTok{ cp.Problem(objective, constraints)}
\NormalTok{primal\_val }\OperatorTok{=}\NormalTok{ prob.solve()}

\CommentTok{\# Dual variables}
\NormalTok{dual\_val }\OperatorTok{=}\NormalTok{ constraints[}\DecValTok{0}\NormalTok{].dual\_value}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Primal optimum:"}\NormalTok{, primal\_val)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Dual variable (λ):"}\NormalTok{, dual\_val)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-42}

Duality gives bounds, simplifies complex problems, and enables
distributed computation. For example, SVM training is usually solved in
the dual because kernels appear naturally there. In large-scale AI, dual
formulations often reduce computational burden.

\subsubsection{Try It Yourself}\label{try-it-yourself-144}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write the dual of the problem: minimize x² subject to x ≥ 1.
\item
  Explain why the kernel trick works naturally in the SVM dual
  formulation.
\item
  Give an example where weak duality holds but strong duality fails.
\end{enumerate}

\subsection{146. Convex Optimization Algorithms (Interior Point,
etc.)}\label{convex-optimization-algorithms-interior-point-etc.}

Convex optimization problems can be solved efficiently with specialized
algorithms that exploit convexity. Unlike generic search, these methods
guarantee convergence to the global optimum. Interior point methods,
gradient-based algorithms, and barrier functions are among the most
powerful tools.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-145}

Imagine navigating a smooth valley bounded by steep cliffs. Instead of
walking along the edge (constraints), interior point methods guide you
smoothly through the interior, avoiding walls but still respecting the
boundaries. Each step moves closer to the lowest point without hitting
constraints head-on.

\subsubsection{Deep Dive}\label{deep-dive-145}

\begin{itemize}
\item
  First-order methods:

  \begin{itemize}
  \tightlist
  \item
    Gradient descent, projected gradient descent.
  \item
    Scalable but may converge slowly.
  \end{itemize}
\item
  Second-order methods:

  \begin{itemize}
  \item
    Newton's method: uses curvature (Hessian).
  \item
    Interior point methods: transform constraints into smooth barrier
    terms.

    \[
    \min f(x) - μ \sum \log(-g_i(x))
    \]

    with μ shrinking → enforces feasibility.
  \end{itemize}
\item
  Complexity: convex optimization can be solved in polynomial time;
  interior point methods are efficient for medium-scale problems.
\item
  Modern solvers: CVX, Gurobi, OSQP.
\item
  In AI: used in SVM training, logistic regression, optimal transport,
  and constrained learning.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1837}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3776}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4388}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Gradient methods & Follow slopes & Large-scale convex problems \\
Newton's method & Use curvature for fast convergence & Logistic
regression \\
Interior point & Barrier functions enforce constraints & Support Vector
Machines, linear programming \\
Projected gradient & Project steps back into feasible set & Constrained
parameter tuning \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-145}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ cvxpy }\ImportTok{as}\NormalTok{ cp}

\CommentTok{\# Example: minimize x\^{}2 + y\^{}2 subject to x+y \textgreater{}= 1}
\NormalTok{x, y }\OperatorTok{=}\NormalTok{ cp.Variable(), cp.Variable()}
\NormalTok{objective }\OperatorTok{=}\NormalTok{ cp.Minimize(x2 }\OperatorTok{+}\NormalTok{ y2)}
\NormalTok{constraints }\OperatorTok{=}\NormalTok{ [x }\OperatorTok{+}\NormalTok{ y }\OperatorTok{\textgreater{}=} \DecValTok{1}\NormalTok{]}
\NormalTok{prob }\OperatorTok{=}\NormalTok{ cp.Problem(objective, constraints)}
\NormalTok{result }\OperatorTok{=}\NormalTok{ prob.solve()}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Optimal x, y:"}\NormalTok{, x.value, y.value)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Optimal value:"}\NormalTok{, result)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-43}

Convex optimization algorithms provide the mathematical backbone of many
classical ML models. They make training provably efficient and
reliable---qualities often lost in non-convex deep learning. Even there,
convex methods appear in components like convex relaxations and
regularized losses.

\subsubsection{Try It Yourself}\label{try-it-yourself-145}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solve min (x−2)²+(y−1)² subject to x+y=2 using CVX or by hand.
\item
  Explain how barrier functions prevent violating inequality
  constraints.
\item
  Compare gradient descent and interior point methods in terms of
  scalability and accuracy.
\end{enumerate}

\subsection{147. Non-Convex Optimization
Challenges}\label{non-convex-optimization-challenges}

Unlike convex problems, non-convex optimization involves rugged
landscapes with many local minima, saddle points, and flat regions.
Finding the global optimum is often intractable, but practical methods
aim for ``good enough'' solutions that generalize well.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-146}

Think of a hiker navigating a mountain range filled with peaks, valleys,
and plateaus. Unlike a simple bowl-shaped valley (convex), here the
hiker might get trapped in a small dip (local minimum) or wander
aimlessly on a flat ridge (saddle point).

\subsubsection{Deep Dive}\label{deep-dive-146}

\begin{itemize}
\item
  Local minima vs global minimum: Non-convex functions may have many
  local minima; algorithms risk getting stuck.
\item
  Saddle points: places where gradient = 0 but not optimal; common in
  high dimensions.
\item
  Plateaus and flat regions: slow convergence due to vanishing
  gradients.
\item
  No guarantees: non-convex optimization is generally NP-hard.
\item
  Heuristics \& strategies:

  \begin{itemize}
  \tightlist
  \item
    Random restarts, stochasticity (SGD helps escape saddles).
  \item
    Momentum-based methods.
  \item
    Regularization and good initialization.
  \item
    Relaxations to convex problems.
  \end{itemize}
\item
  In AI: deep learning is fundamentally non-convex, yet SGD finds
  solutions that generalize.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1566}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4337}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4096}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Challenge
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Explanation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Local minima & Algorithm stuck in suboptimal valley & Training small
neural networks \\
Saddle points & Flat ridges, slow escape & High-dimensional deep nets \\
Flat plateaus & Gradients vanish, slow convergence & Vanishing gradient
problem in RNNs \\
Non-convexity & NP-hard in general & Training deep generative models \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-146}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}

\NormalTok{x }\OperatorTok{=}\NormalTok{ np.linspace(}\OperatorTok{{-}}\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{400}\NormalTok{)}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.linspace(}\OperatorTok{{-}}\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{400}\NormalTok{)}
\NormalTok{X, Y }\OperatorTok{=}\NormalTok{ np.meshgrid(x, y)}
\NormalTok{Z }\OperatorTok{=}\NormalTok{ np.sin(X) }\OperatorTok{*}\NormalTok{ np.cos(Y)  }\CommentTok{\# non{-}convex surface}

\NormalTok{plt.contourf(X, Y, Z, levels}\OperatorTok{=}\DecValTok{20}\NormalTok{, cmap}\OperatorTok{=}\StringTok{"RdBu"}\NormalTok{)}
\NormalTok{plt.colorbar()}
\NormalTok{plt.title(}\StringTok{"Non{-}Convex Optimization Landscape"}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-44}

Most modern AI models---from deep nets to reinforcement learning---are
trained by solving non-convex problems. Understanding the challenges
helps explain why training may be unstable, why initialization matters,
and why methods like SGD succeed despite theoretical hardness.

\subsubsection{Try It Yourself}\label{try-it-yourself-146}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Plot f(x)=sin(x) for x∈{[}−10,10{]}. Identify local minima and the
  global minimum.
\item
  Explain why SGD can escape saddle points more easily than batch
  gradient descent.
\item
  Give an example of a convex relaxation used to approximate a
  non-convex problem.
\end{enumerate}

\subsection{148. Stochastic Optimization}\label{stochastic-optimization}

Stochastic optimization uses randomness to handle large or uncertain
problems where exact computation is impractical. Instead of evaluating
the full objective, it samples parts of the data or uses noisy
approximations, making it scalable for modern machine learning.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-147}

Imagine trying to find the lowest point in a vast landscape. Checking
every inch is impossible. Instead, you take random walks, each giving a
rough sense of direction. With enough steps, the randomness averages
out, guiding you downhill efficiently.

\subsubsection{Deep Dive}\label{deep-dive-147}

\begin{itemize}
\item
  Stochastic Gradient Descent (SGD):

  \[
  x_{k+1} = x_k - η \nabla f_i(x_k),
  \]

  where gradient is estimated from a random sample i.
\item
  Mini-batch SGD: balances variance reduction and efficiency.
\item
  Variance reduction methods: SVRG, SAG, Adam adapt stochastic updates.
\item
  Monte Carlo optimization: approximates expectations with random
  samples.
\item
  Reinforcement learning: stochastic optimization used in policy
  gradient methods.
\item
  Advantages: scalable, handles noisy data.
\item
  Disadvantages: randomness may slow convergence, requires tuning.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2660}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3830}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3511}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Application
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
SGD & Update using random sample & Neural network training \\
Mini-batch SGD & Small batch gradient estimate & Standard deep learning
practice \\
Variance reduction (SVRG) & Reduce noise in stochastic gradients &
Faster convergence in ML training \\
Monte Carlo optimization & Approximate expectation via sampling & RL,
generative models \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-147}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Function f(x) = (x{-}3)\^{}2}
\NormalTok{grad }\OperatorTok{=} \KeywordTok{lambda}\NormalTok{ x, i: }\DecValTok{2}\OperatorTok{*}\NormalTok{(x}\OperatorTok{{-}}\DecValTok{3}\NormalTok{) }\OperatorTok{+}\NormalTok{ np.random.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)  }\CommentTok{\# noisy gradient}

\NormalTok{x }\OperatorTok{=} \FloatTok{0.0}
\NormalTok{eta }\OperatorTok{=} \FloatTok{0.1}
\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{10}\NormalTok{):}
\NormalTok{    x }\OperatorTok{{-}=}\NormalTok{ eta }\OperatorTok{*}\NormalTok{ grad(x, \_)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"x=}\SpecialCharTok{\{}\NormalTok{x}\SpecialCharTok{:.4f\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-45}

AI models are trained on massive datasets where exact optimization is
infeasible. Stochastic optimization makes learning tractable by trading
exactness for scalability. It powers deep learning, reinforcement
learning, and online algorithms.

\subsubsection{Try It Yourself}\label{try-it-yourself-147}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare convergence of batch gradient descent and SGD on a quadratic
  function.
\item
  Explain why adding noise in optimization can help escape local minima.
\item
  Implement mini-batch SGD for logistic regression on a toy dataset.
\end{enumerate}

\subsection{149. Optimization in High
Dimensions}\label{optimization-in-high-dimensions}

High-dimensional optimization is challenging because the geometry of
space changes as dimensions grow. Distances concentrate, gradients may
vanish, and searching the landscape becomes exponentially harder. Yet,
most modern AI models, especially deep neural networks, live in very
high-dimensional spaces.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-148}

Imagine trying to search for a marble in a huge warehouse. In two
dimensions, you can scan rows and columns quickly. In a thousand
dimensions, nearly all points look equally far apart, and the marble
hides in an enormous volume that's impossible to search exhaustively.

\subsubsection{Deep Dive}\label{deep-dive-148}

\begin{itemize}
\item
  Curse of dimensionality: computational cost and data requirements grow
  exponentially with dimension.
\item
  Distance concentration: in high dimensions, distances between points
  become nearly identical, complicating nearest-neighbor methods.
\item
  Gradient issues: gradients can vanish or explode in deep networks.
\item
  Optimization challenges:

  \begin{itemize}
  \tightlist
  \item
    Saddle points become more common than local minima.
  \item
    Flat regions slow convergence.
  \item
    Regularization needed to control overfitting.
  \end{itemize}
\item
  Techniques:

  \begin{itemize}
  \tightlist
  \item
    Dimensionality reduction (PCA, autoencoders).
  \item
    Adaptive learning rates (Adam, RMSProp).
  \item
    Normalization layers (BatchNorm, LayerNorm).
  \item
    Random projections and low-rank approximations.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2421}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3053}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4526}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Challenge
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Effect in High Dimensions
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Connection
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Curse of dimensionality & Requires exponential data & Feature
engineering, embeddings \\
Distance concentration & Points look equally far & Vector similarity
search, nearest neighbors \\
Saddle points dominance & Slows optimization & Deep network training \\
Gradient issues & Vanishing/exploding gradients & RNN training, weight
initialization \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-148}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Distance concentration demo}
\NormalTok{d }\OperatorTok{=} \DecValTok{1000}  \CommentTok{\# dimension}
\NormalTok{points }\OperatorTok{=}\NormalTok{ np.random.randn(}\DecValTok{1000}\NormalTok{, d)}

\CommentTok{\# Pairwise distances}
\ImportTok{from}\NormalTok{ scipy.spatial.distance }\ImportTok{import}\NormalTok{ pdist}
\NormalTok{distances }\OperatorTok{=}\NormalTok{ pdist(points, }\StringTok{\textquotesingle{}euclidean\textquotesingle{}}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Mean distance:"}\NormalTok{, np.mean(distances))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Std of distances:"}\NormalTok{, np.std(distances))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-46}

Most AI problems---from embeddings to deep nets---are inherently
high-dimensional. Understanding how optimization behaves in these spaces
explains why naive algorithms fail, why regularization is essential, and
why specialized techniques like normalization and adaptive methods
succeed.

\subsubsection{Try It Yourself}\label{try-it-yourself-148}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate distances in 10, 100, and 1000 dimensions. How does the
  variance change?
\item
  Explain why PCA can help optimization in high-dimensional feature
  spaces.
\item
  Give an example where high-dimensional embeddings improve AI
  performance despite optimization challenges.
\end{enumerate}

\subsection{150. Applications in ML
Training}\label{applications-in-ml-training}

Optimization is the engine behind machine learning. Training a model
means defining a loss function and using optimization algorithms to
minimize it with respect to the model's parameters. From linear
regression to deep neural networks, optimization turns data into
predictive power.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-149}

Think of sculpting a statue from a block of marble. The raw block is the
initial model with random parameters. Each optimization step chisels
away error, gradually shaping the model to fit the data.

\subsubsection{Deep Dive}\label{deep-dive-149}

\begin{itemize}
\tightlist
\item
  Linear models: closed-form solutions exist (e.g., least squares), but
  gradient descent is often used for scalability.
\item
  Logistic regression: convex optimization with log-loss.
\item
  Support Vector Machines: quadratic programming solved via dual
  optimization.
\item
  Neural networks: non-convex optimization with SGD and adaptive
  methods.
\item
  Regularization: adds penalties (L1, L2) to the objective, improving
  generalization.
\item
  Hyperparameter optimization: grid search, random search, Bayesian
  optimization.
\item
  Distributed optimization: data-parallel SGD, asynchronous updates for
  large-scale training.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2283}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4130}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3587}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Model/Task
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Optimization Formulation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Algorithm
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Linear regression & Minimize squared error & Gradient descent, closed
form \\
Logistic regression & Minimize log-loss & Newton's method, gradient
descent \\
SVM & Maximize margin, quadratic constraints & Interior point, dual
optimization \\
Neural networks & Minimize cross-entropy or MSE & SGD, Adam, RMSProp \\
Hyperparameter tuning & Black-box optimization & Bayesian
optimization \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-149}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}

\CommentTok{\# Simple classification with logistic regression}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{],[}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{],[}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{],[}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{],[}\DecValTok{6}\NormalTok{,}\DecValTok{5}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])}

\NormalTok{model }\OperatorTok{=}\NormalTok{ LogisticRegression()}
\NormalTok{model.fit(X, y)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Optimized coefficients:"}\NormalTok{, model.coef\_)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Intercept:"}\NormalTok{, model.intercept\_)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Accuracy:"}\NormalTok{, model.score(X, y))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-47}

Optimization is what makes learning feasible. Without it, models would
remain abstract definitions with no way to adjust parameters from data.
Every breakthrough in AI---from logistic regression to
transformers---relies on advances in optimization techniques.

\subsubsection{Try It Yourself}\label{try-it-yourself-149}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write the optimization objective for linear regression and solve for
  the closed-form solution.
\item
  Explain why SVM training is solved using a dual formulation.
\item
  Compare training with SGD vs Adam on a small neural network---what
  differences do you observe?
\end{enumerate}

\section{Chapter 16. Numerical methods and
stability}\label{chapter-16.-numerical-methods-and-stability}

\subsection{151. Numerical Representation and Rounding
Errors}\label{numerical-representation-and-rounding-errors}

Computers represent numbers with finite precision, which introduces
rounding errors. While small individually, these errors accumulate in
iterative algorithms, sometimes destabilizing optimization or inference.
Numerical analysis studies how to represent and control such errors.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-150}

Imagine pouring water into a cup but spilling a drop each time. One
spill seems negligible, but after thousands of pours, the missing water
adds up. Similarly, tiny rounding errors in floating-point arithmetic
can snowball into significant inaccuracies.

\subsubsection{Deep Dive}\label{deep-dive-150}

\begin{itemize}
\item
  Floating-point representation (IEEE 754): numbers stored with finite
  bits for sign, exponent, and mantissa.
\item
  Machine epsilon (ε): smallest number such that 1+ε \textgreater{} 1 in
  machine precision.
\item
  Types of errors:

  \begin{itemize}
  \tightlist
  \item
    Rounding error: due to truncation of digits.
  \item
    Cancellation: subtracting nearly equal numbers magnifies error.
  \item
    Overflow/underflow: exceeding representable range.
  \end{itemize}
\item
  Stability concerns: iterative methods (like gradient descent) can
  accumulate error.
\item
  Mitigations: scaling, normalization, higher precision, numerically
  stable algorithms.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1856}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4124}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4021}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Issue
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Rounding error & Truncation of decimals & Summing large feature
vectors \\
Cancellation & Loss of significance in subtraction & Variance
computation with large numbers \\
Overflow/underflow & Exceeding float limits & Softmax with very
large/small logits \\
Machine epsilon & Limit of precision (\textasciitilde1e-16 for float64)
& Convergence thresholds in optimization \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-150}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Machine epsilon}
\NormalTok{eps }\OperatorTok{=}\NormalTok{ np.finfo(}\BuiltInTok{float}\NormalTok{).eps}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Machine epsilon:"}\NormalTok{, eps)}

\CommentTok{\# Cancellation example}
\NormalTok{a, b }\OperatorTok{=} \FloatTok{1e16}\NormalTok{, }\FloatTok{1e16} \OperatorTok{+} \DecValTok{1}
\NormalTok{diff1 }\OperatorTok{=}\NormalTok{ b }\OperatorTok{{-}}\NormalTok{ a         }\CommentTok{\# exact difference should be 1}
\NormalTok{diff2 }\OperatorTok{=}\NormalTok{ (b }\OperatorTok{{-}}\NormalTok{ a) }\OperatorTok{+} \DecValTok{1}   \CommentTok{\# accumulation with error}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Cancellation error example:"}\NormalTok{, diff1, diff2)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-48}

AI systems rely on numerical computation at scale. Floating-point
limitations explain instabilities in training (exploding/vanishing
gradients) and motivate techniques like log-sum-exp for stable
probability calculations. Awareness of rounding errors prevents subtle
but serious bugs.

\subsubsection{Try It Yourself}\label{try-it-yourself-150}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute softmax(1000, 1001) directly and with log-sum-exp. Compare
  results.
\item
  Find machine epsilon for float32 and float64 in Python.
\item
  Explain why subtracting nearly equal probabilities can lead to
  unstable results.
\end{enumerate}

\subsection{152. Root-Finding Methods (Newton-Raphson,
Bisection)}\label{root-finding-methods-newton-raphson-bisection}

Root-finding algorithms locate solutions to equations of the form
f(x)=0. These methods are essential for optimization, solving nonlinear
equations, and iterative methods in AI. Different algorithms trade
speed, stability, and reliance on derivatives.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-151}

Imagine standing at a river, looking for the shallowest crossing. You
test different spots: if the water is too deep, move closer to the bank;
if it's shallow, you're near the crossing. Root-finding works the same
way---adjust guesses until the function value crosses zero.

\subsubsection{Deep Dive}\label{deep-dive-151}

\begin{itemize}
\item
  Bisection method:

  \begin{itemize}
  \tightlist
  \item
    Interval-based, guaranteed convergence if f is continuous and sign
    changes on {[}a,b{]}.
  \item
    Update: repeatedly halve the interval.
  \item
    Converges slowly (linear rate).
  \end{itemize}
\item
  Newton-Raphson method:

  \begin{itemize}
  \item
    Iterative update:

    \[
    x_{k+1} = x_k - \frac{f(x_k)}{f'(x_k)}.
    \]
  \item
    Quadratic convergence if derivative is available and initial guess
    is good.
  \item
    Can diverge if poorly initialized.
  \end{itemize}
\item
  Secant method:

  \begin{itemize}
  \tightlist
  \item
    Approximates derivative numerically.
  \end{itemize}
\item
  In AI: solving logistic regression likelihood equations, computing
  eigenvalues, backpropagation steps.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1647}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1294}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.5059}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Convergence
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Needs derivative?
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bisection & Linear & No & Robust threshold finding \\
Newton-Raphson & Quadratic & Yes & Logistic regression optimization \\
Secant & Superlinear & Approximate & Parameter estimation when
derivative costly \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-151}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Newton{-}Raphson for sqrt(2)}
\NormalTok{f }\OperatorTok{=} \KeywordTok{lambda}\NormalTok{ x: x2 }\OperatorTok{{-}} \DecValTok{2}
\NormalTok{f\_prime }\OperatorTok{=} \KeywordTok{lambda}\NormalTok{ x: }\DecValTok{2}\OperatorTok{*}\NormalTok{x}

\NormalTok{x }\OperatorTok{=} \FloatTok{1.0}
\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{5}\NormalTok{):}
\NormalTok{    x }\OperatorTok{=}\NormalTok{ x }\OperatorTok{{-}}\NormalTok{ f(x)}\OperatorTok{/}\NormalTok{f\_prime(x)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Approximation:"}\NormalTok{, x)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-49}

Root-finding is a building block for optimization and inference.
Newton's method accelerates convergence in training convex models, while
bisection provides safety when robustness is more important than speed.

\subsubsection{Try It Yourself}\label{try-it-yourself-151}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use bisection to find the root of f(x)=cos(x)−x.
\item
  Derive Newton's method for solving log-likelihood equations in
  logistic regression.
\item
  Compare convergence speed of bisection vs Newton on f(x)=x²−2.
\end{enumerate}

\subsection{153. Numerical Linear Algebra (LU, QR
Decomposition)}\label{numerical-linear-algebra-lu-qr-decomposition}

Numerical linear algebra develops stable and efficient ways to solve
systems of linear equations, factorize matrices, and compute
decompositions. These methods form the computational backbone of
optimization, statistics, and machine learning.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-152}

Imagine trying to solve a puzzle by breaking it into smaller, easier
sub-puzzles. Instead of directly inverting a giant matrix,
decompositions split it into triangular or orthogonal pieces that are
simpler to work with.

\subsubsection{Deep Dive}\label{deep-dive-152}

\begin{itemize}
\item
  LU decomposition:

  \begin{itemize}
  \tightlist
  \item
    Factorizes A into L (lower triangular) and U (upper triangular).
  \item
    Solves Ax=b efficiently by forward + backward substitution.
  \end{itemize}
\item
  QR decomposition:

  \begin{itemize}
  \tightlist
  \item
    Factorizes A into Q (orthogonal) and R (upper triangular).
  \item
    Useful for least-squares problems.
  \end{itemize}
\item
  Cholesky decomposition:

  \begin{itemize}
  \tightlist
  \item
    Special case for symmetric positive definite matrices: A=LLᵀ.
  \end{itemize}
\item
  SVD (Singular Value Decomposition): more general, stable but
  expensive.
\item
  Numerical concerns:

  \begin{itemize}
  \tightlist
  \item
    Pivoting improves stability.
  \item
    Condition number indicates sensitivity to perturbations.
  \end{itemize}
\item
  In AI: used in PCA, linear regression, matrix factorization, spectral
  methods.
\end{itemize}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Decomposition & Form & Use Case in AI \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
LU & A = LU & Solving linear systems \\
QR & A = QR & Least squares, orthogonalization \\
Cholesky & A = LLᵀ & Gaussian processes, covariance matrices \\
SVD & A = UΣVᵀ & Dimensionality reduction, embeddings \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-152}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ scipy.linalg }\ImportTok{import}\NormalTok{ lu, qr}

\NormalTok{A }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{], [}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{]])}

\CommentTok{\# LU decomposition}
\NormalTok{P, L, U }\OperatorTok{=}\NormalTok{ lu(A)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"L:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, L)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"U:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, U)}

\CommentTok{\# QR decomposition}
\NormalTok{Q, R }\OperatorTok{=}\NormalTok{ qr(A)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Q:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, Q)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"R:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, R)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-50}

Machine learning workflows rely on efficient linear algebra. From
solving regression equations to training large models, numerical
decompositions provide scalable, stable methods where naive matrix
inversion would fail.

\subsubsection{Try It Yourself}\label{try-it-yourself-152}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solve Ax=b using LU decomposition for A={[}{[}4,2{]},{[}3,1{]}{]},
  b={[}1,2{]}.
\item
  Explain why QR decomposition is more stable than solving normal
  equations directly in least squares.
\item
  Compute the Cholesky decomposition of a covariance matrix and explain
  its role in Gaussian sampling.
\end{enumerate}

\subsection{154. Iterative Methods for Linear
Systems}\label{iterative-methods-for-linear-systems}

Iterative methods solve large systems of linear equations without
directly factorizing the matrix. Instead, they refine an approximate
solution step by step. These methods are essential when matrices are too
large or sparse for direct approaches like LU or QR.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-153}

Imagine adjusting the volume knob on a radio: you start with a guess,
then keep tuning slightly up or down until the signal comes in clearly.
Iterative solvers do the same---gradually refining estimates until the
solution is ``clear enough.''

\subsubsection{Deep Dive}\label{deep-dive-153}

\begin{itemize}
\item
  Problem: Solve Ax = b, where A is large and sparse.
\item
  Basic iterative methods:

  \begin{itemize}
  \tightlist
  \item
    Jacobi method: update each variable using the previous iteration.
  \item
    Gauss-Seidel method: uses latest updated values for faster
    convergence.
  \item
    Successive Over-Relaxation (SOR): accelerates Gauss-Seidel with
    relaxation factor.
  \end{itemize}
\item
  Krylov subspace methods:

  \begin{itemize}
  \tightlist
  \item
    Conjugate Gradient (CG): efficient for symmetric positive definite
    matrices.
  \item
    GMRES (Generalized Minimal Residual): for general nonsymmetric
    matrices.
  \end{itemize}
\item
  Convergence: depends on matrix properties (diagonal dominance,
  conditioning).
\item
  In AI: used in large-scale optimization, graph algorithms, Gaussian
  processes, and PDE-based models.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1978}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3516}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4505}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Requirement
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Jacobi & Diagonal dominance & Approximate inference in graphical
models \\
Gauss-Seidel & Stronger convergence than Jacobi & Sparse system solvers
in ML pipelines \\
Conjugate Gradient & Symmetric positive definite & Kernel methods,
Gaussian processes \\
GMRES & General sparse systems & Large-scale graph embeddings \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-153}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ scipy.sparse.linalg }\ImportTok{import}\NormalTok{ cg}

\CommentTok{\# Example system Ax = b}
\NormalTok{A }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{4}\NormalTok{,}\DecValTok{1}\NormalTok{],[}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{]])}
\NormalTok{b }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{])}

\CommentTok{\# Conjugate Gradient}
\NormalTok{x, info }\OperatorTok{=}\NormalTok{ cg(A, b)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Solution:"}\NormalTok{, x)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-51}

Iterative solvers scale where direct methods fail. In AI, datasets can
involve millions of variables and sparse matrices. Efficient iterative
algorithms enable training kernel machines, performing inference in
probabilistic models, and solving high-dimensional optimization
problems.

\subsubsection{Try It Yourself}\label{try-it-yourself-153}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement the Jacobi method for a 3×3 diagonally dominant system.
\item
  Compare convergence of Jacobi vs Gauss-Seidel on the same system.
\item
  Explain why Conjugate Gradient is preferred for symmetric positive
  definite matrices.
\end{enumerate}

\subsection{155. Numerical Differentiation and
Integration}\label{numerical-differentiation-and-integration}

When analytical solutions are unavailable, numerical methods approximate
derivatives and integrals. Differentiation estimates slopes using nearby
points, while integration approximates areas under curves. These methods
are essential for simulation, optimization, and probabilistic inference.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-154}

Think of measuring the slope of a hill without a formula. You check two
nearby altitudes and estimate the incline. Or, to measure land area, you
cut it into small strips and sum them up. Numerical differentiation and
integration work in the same way.

\subsubsection{Deep Dive}\label{deep-dive-154}

\begin{itemize}
\item
  Numerical differentiation:

  \begin{itemize}
  \item
    Forward difference:

    \[
    f'(x) \approx \frac{f(x+h)-f(x)}{h}.
    \]
  \item
    Central difference (more accurate):

    \[
    f'(x) \approx \frac{f(x+h)-f(x-h)}{2h}.
    \]
  \item
    Trade-off: small h reduces truncation error but increases round-off
    error.
  \end{itemize}
\item
  Numerical integration:

  \begin{itemize}
  \tightlist
  \item
    Rectangle/Trapezoidal rule: approximate area under curve.
  \item
    Simpson's rule: quadratic approximation, higher accuracy.
  \item
    Monte Carlo integration: estimate integral by random sampling,
    useful in high dimensions.
  \end{itemize}
\item
  In AI: used in gradient estimation, reinforcement learning (policy
  gradients), Bayesian inference, and sampling methods.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3152}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4348}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula / Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Application
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Central difference & (f(x+h)-f(x-h))/(2h) & Gradient-free
optimization \\
Trapezoidal rule & Avg height × width & Numerical expectation in small
problems \\
Simpson's rule & Quadratic fit over intervals & Smooth density
integration \\
Monte Carlo integration & Random sampling approximation & Probabilistic
models, Bayesian inference \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-154}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Function}
\NormalTok{f }\OperatorTok{=} \KeywordTok{lambda}\NormalTok{ x: np.sin(x)}

\CommentTok{\# Numerical derivative at x=1}
\NormalTok{h }\OperatorTok{=} \FloatTok{1e{-}5}
\NormalTok{derivative }\OperatorTok{=}\NormalTok{ (f(}\DecValTok{1}\OperatorTok{+}\NormalTok{h) }\OperatorTok{{-}}\NormalTok{ f(}\DecValTok{1}\OperatorTok{{-}}\NormalTok{h)) }\OperatorTok{/}\NormalTok{ (}\DecValTok{2}\OperatorTok{*}\NormalTok{h)}

\CommentTok{\# Numerical integration of sin(x) from 0 to pi}
\NormalTok{xs }\OperatorTok{=}\NormalTok{ np.linspace(}\DecValTok{0}\NormalTok{, np.pi, }\DecValTok{1000}\NormalTok{)}
\NormalTok{trapezoid }\OperatorTok{=}\NormalTok{ np.trapz(np.sin(xs), xs)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Derivative of sin at x=1 ≈"}\NormalTok{, derivative)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Integral of sin from 0 to pi ≈"}\NormalTok{, trapezoid)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-52}

Many AI models rely on gradients and expectations where closed forms
don't exist. Numerical differentiation provides approximate gradients,
while Monte Carlo integration handles high-dimensional expectations
central to probabilistic inference and generative modeling.

\subsubsection{Try It Yourself}\label{try-it-yourself-154}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Estimate derivative of f(x)=exp(x) at x=0 using central difference.
\item
  Compute ∫₀¹ x² dx numerically with trapezoidal and Simpson's
  rule---compare accuracy.
\item
  Use Monte Carlo to approximate π by integrating the unit circle area.
\end{enumerate}

\subsection{156. Stability and Conditioning of
Problems}\label{stability-and-conditioning-of-problems}

Stability and conditioning describe how sensitive a numerical problem is
to small changes. Conditioning is a property of the problem itself,
while stability concerns the algorithm used to solve it. Together, they
determine whether numerical answers can be trusted.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-155}

Imagine balancing a pencil on its tip. The system (problem) is
ill-conditioned---tiny nudges cause big changes. Now imagine the floor
is also shaky (algorithm instability). Even with a well-posed problem,
an unstable method could still topple your pencil.

\subsubsection{Deep Dive}\label{deep-dive-155}

\begin{itemize}
\item
  Conditioning:

  \begin{itemize}
  \item
    A problem is well-conditioned if small input changes cause small
    output changes.
  \item
    Ill-conditioned if small errors in input cause large deviations in
    output.
  \item
    Condition number (κ):

    \[
    κ(A) = \|A\|\|A^{-1}\|.
    \]

    Large κ ⇒ ill-conditioned.
  \end{itemize}
\item
  Stability:

  \begin{itemize}
  \tightlist
  \item
    An algorithm is stable if it produces nearly correct results for
    nearly correct data.
  \item
    Example: Gaussian elimination with partial pivoting is more stable
    than without pivoting.
  \end{itemize}
\item
  Well-posedness (Hadamard): a problem must have existence, uniqueness,
  and continuous dependence on data.
\item
  In AI: conditioning affects gradient-based training, covariance
  estimation, and inversion of kernel matrices.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1633}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4082}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4286}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Well-conditioned & Small errors → small output change & PCA on
normalized data \\
Ill-conditioned & Small errors → large output change & Inverting
covariance in Gaussian processes \\
Stable algorithm & Doesn't magnify rounding errors & Pivoted LU for
regression problems \\
Unstable algo & Propagates or amplifies numerical errors & Naive
Gaussian elimination \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-155}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Ill{-}conditioned matrix}
\NormalTok{A }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{1}\NormalTok{, }\FloatTok{1.001}\NormalTok{], [}\FloatTok{1.001}\NormalTok{, }\FloatTok{1.002}\NormalTok{]])}
\NormalTok{cond }\OperatorTok{=}\NormalTok{ np.linalg.cond(A)}

\NormalTok{b }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{])}
\NormalTok{x }\OperatorTok{=}\NormalTok{ np.linalg.solve(A, b)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Condition number:"}\NormalTok{, cond)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Solution:"}\NormalTok{, x)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-53}

AI systems often rely on solving large linear systems or optimizing
high-dimensional objectives. Poor conditioning leads to unstable
training (exploding/vanishing gradients). Stable algorithms and
preconditioning improve reliability.

\subsubsection{Try It Yourself}\label{try-it-yourself-155}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute condition numbers of random matrices of size 5×5. Which are
  ill-conditioned?
\item
  Explain why normalization improves conditioning in linear regression.
\item
  Give an AI example where unstable algorithms could cause misleading
  results.
\end{enumerate}

\subsection{157. Floating-Point Arithmetic and
Precision}\label{floating-point-arithmetic-and-precision}

Floating-point arithmetic allows computers to represent real numbers
approximately using a finite number of bits. While flexible, it
introduces rounding and precision issues that can accumulate, affecting
the reliability of numerical algorithms.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-156}

Think of measuring with a ruler that only has centimeter markings. If
you measure something 10 times and add the results, each small rounding
error adds up. Floating-point numbers work similarly---precise enough
for most tasks, but never exact.

\subsubsection{Deep Dive}\label{deep-dive-156}

\begin{itemize}
\item
  IEEE 754 format:

  \begin{itemize}
  \tightlist
  \item
    Single precision (float32): 1 sign bit, 8 exponent bits, 23 fraction
    bits (\textasciitilde7 decimal digits).
  \item
    Double precision (float64): 1 sign bit, 11 exponent bits, 52
    fraction bits (\textasciitilde16 decimal digits).
  \end{itemize}
\item
  Precision limits: machine epsilon ε ≈ 1.19×10⁻⁷ (float32), ≈
  2.22×10⁻¹⁶ (float64).
\item
  Common pitfalls:

  \begin{itemize}
  \tightlist
  \item
    Rounding error in sums/products.
  \item
    Cancellation when subtracting close numbers.
  \item
    Overflow/underflow for very large/small numbers.
  \end{itemize}
\item
  Workarounds:

  \begin{itemize}
  \tightlist
  \item
    Use higher precision if needed.
  \item
    Reorder operations for numerical stability.
  \item
    Apply log transformations for probabilities (log-sum-exp trick).
  \end{itemize}
\item
  In AI: float32 dominates training neural networks; float16 and
  bfloat16 reduce memory and speed up training with some precision
  trade-offs.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1972}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0845}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2113}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.5070}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Precision Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Digits
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Range Approx.
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Usage
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
float16 & \textasciitilde3-4 & 10⁻⁵ to 10⁵ & Mixed precision deep
learning \\
float32 & \textasciitilde7 & 10⁻³⁸ to 10³⁸ & Standard for training \\
float64 & \textasciitilde16 & 10⁻³⁰⁸ to 10³⁰⁸ & Scientific computing,
kernel methods \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-156}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Precision comparison}
\NormalTok{x32 }\OperatorTok{=}\NormalTok{ np.float32(}\FloatTok{1.0}\NormalTok{) }\OperatorTok{+}\NormalTok{ np.float32(}\FloatTok{1e{-}8}\NormalTok{)}
\NormalTok{x64 }\OperatorTok{=}\NormalTok{ np.float64(}\FloatTok{1.0}\NormalTok{) }\OperatorTok{+}\NormalTok{ np.float64(}\FloatTok{1e{-}8}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Float32 result:"}\NormalTok{, x32)  }\CommentTok{\# rounds away}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Float64 result:"}\NormalTok{, x64)  }\CommentTok{\# keeps precision}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-54}

Precision trade-offs influence speed, memory, and stability. Deep
learning thrives on float32/float16 for efficiency, but numerical
algorithms (like kernel methods or Gaussian processes) often require
float64 to avoid instability.

\subsubsection{Try It Yourself}\label{try-it-yourself-156}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add 1e-8 to 1.0 using float32 and float64. What happens?
\item
  Compute softmax({[}1000,1001{]}) with and without log-sum-exp. Compare
  results.
\item
  Explain why mixed precision training works despite reduced numerical
  accuracy.
\end{enumerate}

\subsection{158. Monte Carlo Methods}\label{monte-carlo-methods}

Monte Carlo methods use random sampling to approximate quantities that
are hard to compute exactly. By averaging many random trials, they
estimate integrals, expectations, or probabilities, making them
invaluable in high-dimensional and complex AI problems.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-157}

Imagine trying to measure the area of an irregular pond. Instead of
using formulas, you throw pebbles randomly in a bounding box. The
proportion that lands in the pond estimates its area. Monte Carlo
methods do the same with randomness and computation.

\subsubsection{Deep Dive}\label{deep-dive-157}

\begin{itemize}
\item
  Monte Carlo integration:

  \[
  \int f(x) dx \approx \frac{1}{N}\sum_{i=1}^N f(x_i), \quad x_i \sim p(x).
  \]
\item
  Law of Large Numbers: guarantees convergence as N→∞.
\item
  Variance reduction techniques: importance sampling, stratified
  sampling, control variates.
\item
  Markov Chain Monte Carlo (MCMC): generates samples from complex
  distributions (e.g., Metropolis-Hastings, Gibbs sampling).
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Bayesian inference.
  \item
    Policy evaluation in reinforcement learning.
  \item
    Probabilistic graphical models.
  \item
    Simulation for uncertainty quantification.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1959}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4124}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3918}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Plain Monte Carlo & Random uniform sampling & Estimating π or
integrals \\
Importance sampling & Bias sampling toward important regions & Rare
event probability in risk models \\
Stratified sampling & Divide space into strata for efficiency & Variance
reduction in simulation \\
MCMC & Construct Markov chain with target dist. & Bayesian neural
networks, topic models \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-157}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Monte Carlo estimate of pi}
\NormalTok{N }\OperatorTok{=} \DecValTok{100000}
\NormalTok{points }\OperatorTok{=}\NormalTok{ np.random.rand(N, }\DecValTok{2}\NormalTok{)}
\NormalTok{inside }\OperatorTok{=}\NormalTok{ np.}\BuiltInTok{sum}\NormalTok{(points[:,}\DecValTok{0}\NormalTok{]}\DecValTok{2} \OperatorTok{+}\NormalTok{ points[:,}\DecValTok{1}\NormalTok{]}\DecValTok{2} \OperatorTok{\textless{}=} \DecValTok{1}\NormalTok{)}
\NormalTok{pi\_est }\OperatorTok{=} \DecValTok{4} \OperatorTok{*}\NormalTok{ inside }\OperatorTok{/}\NormalTok{ N}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Monte Carlo estimate of pi:"}\NormalTok{, pi\_est)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-55}

Monte Carlo makes the intractable tractable. High-dimensional integrals
appear in Bayesian models, reinforcement learning, and generative AI;
Monte Carlo is often the only feasible tool. It trades exactness for
scalability, a cornerstone of modern probabilistic AI.

\subsubsection{Try It Yourself}\label{try-it-yourself-157}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use Monte Carlo to estimate the integral of f(x)=exp(−x²) from −2 to
  2.
\item
  Implement importance sampling for rare-event probability estimation.
\item
  Run Gibbs sampling for a simple two-variable Gaussian distribution.
\end{enumerate}

\subsection{159. Error Propagation and
Analysis}\label{error-propagation-and-analysis}

Error propagation studies how small inaccuracies in inputs---whether
from measurement, rounding, or approximation---affect outputs of
computations. In numerical methods, understanding how errors accumulate
is essential for ensuring trustworthy results.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-158}

Imagine passing a message along a chain of people. Each person whispers
it slightly differently. By the time it reaches the end, the message may
have drifted far from the original. Computational pipelines behave the
same way---small errors compound through successive operations.

\subsubsection{Deep Dive}\label{deep-dive-158}

\begin{itemize}
\item
  Sources of error:

  \begin{itemize}
  \tightlist
  \item
    Input error: noisy data or imprecise measurements.
  \item
    Truncation error: approximating infinite processes (e.g., Taylor
    series).
  \item
    Rounding error: finite precision arithmetic.
  \end{itemize}
\item
  Error propagation formula (first-order): For y = f(x₁,\ldots,xₙ):

  \[
  \Delta y \approx \sum_{i=1}^n \frac{\partial f}{\partial x_i} \Delta x_i.
  \]
\item
  Condition number link: higher sensitivity ⇒ greater error
  amplification.
\item
  Monte Carlo error analysis: simulate error distributions via sampling.
\item
  In AI: affects stability of optimization, uncertainty in predictions,
  and reliability of simulations.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1739}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3696}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4565}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Error Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Input error & Noisy or approximate measurements & Sensor data for
robotics \\
Truncation error & Approximation cutoff & Numerical gradient
estimation \\
Rounding error & Finite precision representation & Softmax probabilities
in deep learning \\
Propagation & Errors amplify through computation & Long training
pipelines, iterative solvers \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-158}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Function sensitive to input errors}
\NormalTok{f }\OperatorTok{=} \KeywordTok{lambda}\NormalTok{ x: np.exp(x) }\OperatorTok{{-}}\NormalTok{ np.exp(x}\OperatorTok{{-}}\FloatTok{0.00001}\NormalTok{)}

\NormalTok{x\_true }\OperatorTok{=} \DecValTok{10}
\NormalTok{perturbations }\OperatorTok{=}\NormalTok{ np.linspace(}\OperatorTok{{-}}\FloatTok{1e{-}5}\NormalTok{, }\FloatTok{1e{-}5}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ dx }\KeywordTok{in}\NormalTok{ perturbations:}
\NormalTok{    y }\OperatorTok{=}\NormalTok{ f(x\_true }\OperatorTok{+}\NormalTok{ dx)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"x=}\SpecialCharTok{\{}\NormalTok{x\_true}\OperatorTok{+}\NormalTok{dx}\SpecialCharTok{:.8f\}}\SpecialStringTok{, f(x)=}\SpecialCharTok{\{}\NormalTok{y}\SpecialCharTok{:.8e\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-56}

Error propagation explains why some algorithms are stable while others
collapse under noise. In AI, where models rely on massive computations,
unchecked error growth can lead to unreliable predictions, exploding
gradients, or divergence in training.

\subsubsection{Try It Yourself}\label{try-it-yourself-158}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use the propagation formula to estimate error in y = x² when x=1000
  with Δx=0.01.
\item
  Compare numerical and symbolic differentiation for small step
  sizes---observe truncation error.
\item
  Simulate how float32 rounding affects the cumulative sum of 1 million
  random numbers.
\end{enumerate}

\subsection{160. Numerical Methods in AI
Systems}\label{numerical-methods-in-ai-systems}

Numerical methods are the hidden engines inside AI systems, enabling
efficient optimization, stable learning, and scalable inference. From
solving linear systems to approximating integrals, they bridge the gap
between mathematical models and practical computation.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-159}

Think of AI as a skyscraper. The visible structure is the model---neural
networks, decision trees, probabilistic graphs. But the unseen
foundation is numerical methods: without solid algorithms for
computation, the skyscraper would collapse.

\subsubsection{Deep Dive}\label{deep-dive-159}

\begin{itemize}
\tightlist
\item
  Linear algebra methods: matrix factorizations (LU, QR, SVD) for
  regression, PCA, embeddings.
\item
  Optimization algorithms: gradient descent, interior point, stochastic
  optimization for model training.
\item
  Probability and statistics tools: Monte Carlo integration, resampling,
  numerical differentiation for uncertainty estimation.
\item
  Stability and conditioning: ensuring models remain reliable when data
  or computations are noisy.
\item
  Precision management: choosing float16, float32, or float64 depending
  on trade-offs between efficiency and accuracy.
\item
  Scalability: iterative solvers and distributed numerical methods allow
  AI to handle massive datasets.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.3529}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.6471}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Numerical Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Role in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Linear solvers & Regression, covariance estimation \\
Optimization routines & Training neural networks, tuning hyperparams \\
Monte Carlo methods & Bayesian inference, RL simulations \\
Error/stability analysis & Reliable model evaluation \\
Mixed precision & Faster deep learning training \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-159}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.decomposition }\ImportTok{import}\NormalTok{ PCA}

\CommentTok{\# PCA using SVD under the hood (numerical linear algebra)}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.random.randn(}\DecValTok{100}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\NormalTok{pca }\OperatorTok{=}\NormalTok{ PCA(n\_components}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{X\_reduced }\OperatorTok{=}\NormalTok{ pca.fit\_transform(X)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Original shape:"}\NormalTok{, X.shape)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Reduced shape:"}\NormalTok{, X\_reduced.shape)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-57}

Without robust numerical methods, AI would be brittle, slow, and
unreliable. Training transformers, running reinforcement learning
simulations, or doing large-scale probabilistic inference all depend on
efficient numerical algorithms that tame complexity.

\subsubsection{Try It Yourself}\label{try-it-yourself-159}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement PCA manually using SVD and compare with sklearn's PCA.
\item
  Train a small neural network using float16 and float32---compare speed
  and stability.
\item
  Explain how Monte Carlo integration enables probabilistic inference in
  Bayesian models.
\end{enumerate}

\section{Chapter 17. Information
Theory}\label{chapter-17.-information-theory}

\subsection{161. Entropy and Information
Content}\label{entropy-and-information-content}

Entropy measures the average uncertainty or surprise in a random
variable. Information content quantifies how much ``news'' an event
provides: rare events carry more information than common ones. Together,
they form the foundation of information theory.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-160}

Imagine guessing a number someone is thinking of. If they choose
uniformly between 1 and 1000, each answer feels surprising and
informative. If they always pick 7, there's no surprise---and no
information gained.

\subsubsection{Deep Dive}\label{deep-dive-160}

\begin{itemize}
\item
  Information content (self-information): For event \(x\) with
  probability \(p(x)\),

  \[
  I(x) = -\log p(x)
  \]

  Rare events (low \(p(x)\)) yield higher \(I(x)\).
\item
  Entropy (Shannon entropy): Average information of random variable
  \(X\):

  \[
  H(X) = -\sum_x p(x)\log p(x)
  \]

  \begin{itemize}
  \tightlist
  \item
    Maximum when all outcomes are equally likely.
  \item
    Minimum (0) when outcome is certain.
  \end{itemize}
\item
  Interpretations:

  \begin{itemize}
  \tightlist
  \item
    Average uncertainty.
  \item
    Expected code length in optimal compression.
  \item
    Measure of unpredictability in systems.
  \end{itemize}
\item
  Properties:

  \begin{itemize}
  \tightlist
  \item
    \(H(X) \geq 0\).
  \item
    \(H(X)\) is maximized for uniform distribution.
  \item
    Units: bits (log base 2), nats (log base \(e\)).
  \end{itemize}
\item
  In AI: used in decision trees (information gain), language modeling,
  reinforcement learning, and uncertainty quantification.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2468}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3896}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3636}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Distribution
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Entropy Value
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Interpretation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Certain outcome & \(H=0\) & No uncertainty \\
Fair coin toss & \(H=1\) bit & One bit needed per toss \\
Fair 6-sided die & \(H=\log_2 6 \approx 2.58\) bits & Average surprise
per roll \\
Biased coin (p=0.9) & \(H \approx 0.47\) bits & Less surprise than fair
coin \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-160}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\KeywordTok{def}\NormalTok{ entropy(probs):}
    \ControlFlowTok{return} \OperatorTok{{-}}\NormalTok{np.}\BuiltInTok{sum}\NormalTok{([p}\OperatorTok{*}\NormalTok{np.log2(p) }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ probs }\ControlFlowTok{if}\NormalTok{ p }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{])}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Entropy fair coin:"}\NormalTok{, entropy([}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{]))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Entropy biased coin:"}\NormalTok{, entropy([}\FloatTok{0.9}\NormalTok{, }\FloatTok{0.1}\NormalTok{]))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Entropy fair die:"}\NormalTok{, entropy([}\DecValTok{1}\OperatorTok{/}\DecValTok{6}\NormalTok{]}\OperatorTok{*}\DecValTok{6}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-58}

Entropy provides a universal measure of uncertainty and compressibility.
In AI, it quantifies uncertainty in predictions, guides model training,
and connects probability with coding and decision-making. Without
entropy, concepts like information gain, cross-entropy loss, and
probabilistic learning would lack foundation.

\subsubsection{Try It Yourself}\label{try-it-yourself-160}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute entropy for a dataset where 80\% of labels are ``A'' and 20\%
  are ``B.''
\item
  Compare entropy of a uniform distribution vs a highly skewed one.
\item
  Explain why entropy measures the lower bound of lossless data
  compression.
\end{enumerate}

\subsection{162. Joint and Conditional
Entropy}\label{joint-and-conditional-entropy}

Joint entropy measures the uncertainty of two random variables
considered together. Conditional entropy refines this by asking: given
knowledge of one variable, how much uncertainty remains about the other?
These concepts extend entropy to relationships between variables.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-161}

Imagine rolling two dice. The joint entropy reflects the total
unpredictability of the pair. Now, suppose you already know the result
of the first die---how uncertain are you about the second? That
remaining uncertainty is the conditional entropy.

\subsubsection{Deep Dive}\label{deep-dive-161}

\begin{itemize}
\item
  Joint entropy: For random variables \(X, Y\):

  \[
  H(X, Y) = -\sum_{x,y} p(x,y) \log p(x,y)
  \]

  \begin{itemize}
  \tightlist
  \item
    Captures combined uncertainty of both variables.
  \end{itemize}
\item
  Conditional entropy: Uncertainty in \(Y\) given \(X\):

  \[
  H(Y \mid X) = -\sum_{x,y} p(x,y) \log p(y \mid x)
  \]

  \begin{itemize}
  \tightlist
  \item
    Measures average uncertainty left in \(Y\) once \(X\) is known.
  \end{itemize}
\item
  Relationships:

  \begin{itemize}
  \tightlist
  \item
    Chain rule: \(H(X, Y) = H(X) + H(Y \mid X)\).
  \item
    Symmetry: \(H(X, Y) = H(Y, X)\).
  \end{itemize}
\item
  Properties:

  \begin{itemize}
  \tightlist
  \item
    \(H(Y \mid X) \leq H(Y)\).
  \item
    Equality if \(X\) and \(Y\) are independent.
  \end{itemize}
\item
  In AI:

  \begin{itemize}
  \tightlist
  \item
    Joint entropy: modeling uncertainty across features.
  \item
    Conditional entropy: decision trees (information gain),
    communication efficiency, Bayesian networks.
  \end{itemize}
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-161}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Example joint distribution for X,Y (binary variables)}
\NormalTok{p }\OperatorTok{=}\NormalTok{ np.array([[}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.25}\NormalTok{],}
\NormalTok{              [}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.25}\NormalTok{]])  }\CommentTok{\# independent uniform}

\KeywordTok{def}\NormalTok{ entropy(probs):}
    \ControlFlowTok{return} \OperatorTok{{-}}\NormalTok{np.}\BuiltInTok{sum}\NormalTok{([p}\OperatorTok{*}\NormalTok{np.log2(p) }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ probs.flatten() }\ControlFlowTok{if}\NormalTok{ p }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{])}

\KeywordTok{def}\NormalTok{ joint\_entropy(p):}
    \ControlFlowTok{return}\NormalTok{ entropy(p)}

\KeywordTok{def}\NormalTok{ conditional\_entropy(p):}
\NormalTok{    H }\OperatorTok{=} \DecValTok{0}
\NormalTok{    row\_sums }\OperatorTok{=}\NormalTok{ p.}\BuiltInTok{sum}\NormalTok{(axis}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(row\_sums)):}
        \ControlFlowTok{if}\NormalTok{ row\_sums[i] }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{:}
\NormalTok{            cond\_probs }\OperatorTok{=}\NormalTok{ p[i]}\OperatorTok{/}\NormalTok{row\_sums[i]}
\NormalTok{            H }\OperatorTok{+=}\NormalTok{ row\_sums[i] }\OperatorTok{*}\NormalTok{ entropy(cond\_probs)}
    \ControlFlowTok{return}\NormalTok{ H}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Joint entropy:"}\NormalTok{, joint\_entropy(p))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Conditional entropy H(Y|X):"}\NormalTok{, conditional\_entropy(p))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-59}

Joint and conditional entropy extend uncertainty beyond single
variables, capturing relationships and dependencies. They underpin
information gain in machine learning, compression schemes, and
probabilistic reasoning frameworks like Bayesian networks.

\subsubsection{Try It Yourself}\label{try-it-yourself-161}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Calculate joint entropy for two independent coin tosses.
\item
  Compute conditional entropy for a biased coin where you're told
  whether the outcome is heads.
\item
  Explain why \(H(Y|X)=0\) when \(Y\) is a deterministic function of
  \(X\).
\end{enumerate}

\subsection{163. Mutual Information}\label{mutual-information}

Mutual information (MI) quantifies how much knowing one random variable
reduces uncertainty about another. It measures dependence: if two
variables are independent, their mutual information is zero; if
perfectly correlated, MI is maximized.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-162}

Think of two overlapping circles representing uncertainty about
variables \(X\) and \(Y\). The overlap region is the mutual
information---it's the shared knowledge between the two.

\subsubsection{Deep Dive}\label{deep-dive-162}

\begin{itemize}
\item
  Definition:

  \[
  I(X;Y) = \sum_{x,y} p(x,y) \log \frac{p(x,y)}{p(x)p(y)}
  \]
\item
  Equivalent forms:

  \[
  I(X;Y) = H(X) + H(Y) - H(X,Y)
  \]

  \[
  I(X;Y) = H(X) - H(X|Y) = H(Y) - H(Y|X)
  \]
\item
  Properties:

  \begin{itemize}
  \tightlist
  \item
    Always nonnegative.
  \item
    Symmetric: \(I(X;Y) = I(Y;X)\).
  \item
    Zero iff \(X\) and \(Y\) are independent.
  \end{itemize}
\item
  Interpretation:

  \begin{itemize}
  \tightlist
  \item
    Reduction in uncertainty about one variable given the other.
  \item
    Shared information content.
  \end{itemize}
\item
  In AI:

  \begin{itemize}
  \tightlist
  \item
    Feature selection: pick features with high MI with labels.
  \item
    Clustering: measure similarity between variables.
  \item
    Representation learning: InfoNCE loss, variational bounds on MI.
  \item
    Communication: efficiency of transmitting signals.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Expression & Interpretation \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(I(X;Y)=0\) & X and Y are independent \\
Large \(I(X;Y)\) & Strong dependence between X and Y \\
\(I(X;Y)=H(X)\) & X completely determined by Y \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-162}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ mutual\_info\_score}

\CommentTok{\# Example joint distribution: correlated binary variables}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.random.binomial(}\DecValTok{1}\NormalTok{, }\FloatTok{0.7}\NormalTok{, size}\OperatorTok{=}\DecValTok{1000}\NormalTok{)}
\NormalTok{Y }\OperatorTok{=}\NormalTok{ X }\OperatorTok{\^{}}\NormalTok{ np.random.binomial(}\DecValTok{1}\NormalTok{, }\FloatTok{0.1}\NormalTok{, size}\OperatorTok{=}\DecValTok{1000}\NormalTok{)  }\CommentTok{\# noisy copy of X}

\NormalTok{mi }\OperatorTok{=}\NormalTok{ mutual\_info\_score(X, Y)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Mutual Information:"}\NormalTok{, mi)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-60}

Mutual information generalizes correlation to capture both linear and
nonlinear dependencies. In AI, it guides feature selection, helps design
efficient encodings, and powers modern unsupervised and self-supervised
learning methods.

\subsubsection{Try It Yourself}\label{try-it-yourself-162}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute MI between two independent coin tosses---why is it zero?
\item
  Compute MI between a variable and its noisy copy---how does noise
  affect the value?
\item
  Explain how maximizing mutual information can improve learned
  representations.
\end{enumerate}

\subsection{164. Kullback--Leibler
Divergence}\label{kullbackleibler-divergence}

Kullback--Leibler (KL) divergence measures how one probability
distribution diverges from another. It quantifies the inefficiency of
assuming distribution \(Q\) when the true distribution is \(P\).

\subsubsection{Picture in Your Head}\label{picture-in-your-head-163}

Imagine packing luggage with the wrong-sized suitcases. If you assume
people pack small items (distribution \(Q\)), but in reality, they bring
bulky clothes (distribution \(P\)), you'll waste space or run out of
room. KL divergence measures that mismatch.

\subsubsection{Deep Dive}\label{deep-dive-163}

\begin{itemize}
\item
  Definition: For discrete distributions \(P\) and \(Q\):

  \[
  D_{KL}(P \parallel Q) = \sum_x P(x) \log \frac{P(x)}{Q(x)}
  \]

  For continuous:

  \[
  D_{KL}(P \parallel Q) = \int p(x) \log \frac{p(x)}{q(x)} dx
  \]
\item
  Properties:

  \begin{itemize}
  \tightlist
  \item
    \(D_{KL}(P \parallel Q) \geq 0\) (Gibbs inequality).
  \item
    Asymmetric: \(D_{KL}(P \parallel Q) \neq D_{KL}(Q \parallel P)\).
  \item
    Zero iff \(P=Q\) almost everywhere.
  \end{itemize}
\item
  Interpretations:

  \begin{itemize}
  \tightlist
  \item
    Extra bits required when coding samples from \(P\) using code
    optimized for \(Q\).
  \item
    Measure of distance (though not a true metric).
  \end{itemize}
\item
  In AI:

  \begin{itemize}
  \tightlist
  \item
    Variational inference (ELBO minimization).
  \item
    Regularizer in VAEs (match approximate posterior to prior).
  \item
    Policy optimization in RL (trust region methods).
  \item
    Comparing probability models.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.3718}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.6282}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Expression
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(D_{KL}(P \parallel Q)=0\) & Perfect match between P and Q \\
Large \(D_{KL}(P \parallel Q)\) & Q is a poor approximation of P \\
Asymmetry & Forward vs reverse KL lead to different behaviors \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-163}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ entropy}

\NormalTok{P }\OperatorTok{=}\NormalTok{ np.array([}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{])       }\CommentTok{\# True distribution}
\NormalTok{Q }\OperatorTok{=}\NormalTok{ np.array([}\FloatTok{0.9}\NormalTok{, }\FloatTok{0.1}\NormalTok{])       }\CommentTok{\# Approximate distribution}

\NormalTok{kl }\OperatorTok{=}\NormalTok{ entropy(P, Q)  }\CommentTok{\# KL(P||Q)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"KL Divergence:"}\NormalTok{, kl)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-61}

KL divergence underpins much of probabilistic AI, from Bayesian
inference to deep generative models. It provides a bridge between
probability theory, coding theory, and optimization. Understanding it is
key to modern machine learning.

\subsubsection{Try It Yourself}\label{try-it-yourself-163}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute KL divergence between two biased coins (e.g., P={[}0.6,0.4{]},
  Q={[}0.5,0.5{]}).
\item
  Compare forward KL (P\textbar\textbar Q) and reverse KL
  (Q\textbar\textbar P). Which penalizes mode-covering vs mode-seeking?
\item
  Explain how KL divergence is used in training variational
  autoencoders.
\end{enumerate}

\subsection{165. Cross-Entropy and
Likelihood}\label{cross-entropy-and-likelihood}

Cross-entropy measures the average number of bits needed to encode
events from a true distribution \(P\) using a model distribution \(Q\).
It is directly related to likelihood: minimizing cross-entropy is
equivalent to maximizing the likelihood of the model given the data.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-164}

Imagine trying to compress text with a code designed for English, but
your text is actually in French. The mismatch wastes space.
Cross-entropy quantifies that inefficiency, and likelihood measures how
well your model explains the observed text.

\subsubsection{Deep Dive}\label{deep-dive-164}

\begin{itemize}
\item
  Cross-entropy definition:

  \[
  H(P, Q) = - \sum_x P(x) \log Q(x)
  \]

  \begin{itemize}
  \item
    Equals entropy \(H(P)\) plus KL divergence:

    \[
    H(P, Q) = H(P) + D_{KL}(P \parallel Q)
    \]
  \end{itemize}
\item
  Maximum likelihood connection:

  \begin{itemize}
  \item
    Given samples \(\{x_i\}\), maximizing likelihood

    \[
    \hat{\theta} = \arg\max_\theta \prod_i Q(x_i;\theta)
    \]

    is equivalent to minimizing cross-entropy between empirical
    distribution and model.
  \end{itemize}
\item
  Loss functions in AI:

  \begin{itemize}
  \item
    Binary cross-entropy:

    \[
    L = -[y \log \hat{y} + (1-y)\log(1-\hat{y})]
    \]
  \item
    Categorical cross-entropy:

    \[
    L = -\sum_{k} y_k \log \hat{y}_k
    \]
  \end{itemize}
\item
  Applications:

  \begin{itemize}
  \tightlist
  \item
    Classification tasks (logistic regression, neural networks).
  \item
    Language modeling (predicting next token).
  \item
    Probabilistic forecasting.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2178}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3762}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4059}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Cross-entropy \(H(P,Q)\) & \(-\sum P(x)\log Q(x)\) & Model evaluation
and training \\
Relation to KL & \(H(P,Q) = H(P) + D_{KL}(P\parallel Q)\) & Shows
inefficiency when using wrong model \\
Likelihood & Product of probabilities under model & Basis of parameter
estimation \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-164}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ log\_loss}

\CommentTok{\# True labels and predicted probabilities}
\NormalTok{y\_true }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{]}
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ [}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.9}\NormalTok{, }\FloatTok{0.8}\NormalTok{, }\FloatTok{0.2}\NormalTok{]}

\CommentTok{\# Binary cross{-}entropy}
\NormalTok{loss }\OperatorTok{=}\NormalTok{ log\_loss(y\_true, y\_pred)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Cross{-}Entropy Loss:"}\NormalTok{, loss)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-62}

Cross-entropy ties together coding theory and statistical learning. It
is the standard loss function for classification because minimizing it
maximizes likelihood, ensuring the model aligns as closely as possible
with the true data distribution.

\subsubsection{Try It Yourself}\label{try-it-yourself-164}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute cross-entropy for a biased coin with true p=0.7 but model
  q=0.5.
\item
  Show how minimizing cross-entropy improves a classifier's predictions.
\item
  Explain why cross-entropy is preferred over mean squared error for
  probability outputs.
\end{enumerate}

\subsection{166. Channel Capacity and Coding
Theorems}\label{channel-capacity-and-coding-theorems}

Channel capacity is the maximum rate at which information can be
reliably transmitted over a noisy communication channel. Coding theorems
guarantee that, with clever encoding, we can approach this limit while
keeping the error probability arbitrarily small.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-165}

Imagine trying to talk to a friend across a noisy café. If you speak too
fast, they'll miss words. But if you speak at or below a certain
pace---the channel capacity---they'll catch everything with the right
decoding strategy.

\subsubsection{Deep Dive}\label{deep-dive-165}

\begin{itemize}
\item
  Channel capacity:

  \begin{itemize}
  \item
    Defined as the maximum mutual information between input \(X\) and
    output \(Y\):

    \[
    C = \max_{p(x)} I(X;Y)
    \]
  \item
    Represents highest achievable communication rate (bits per channel
    use).
  \end{itemize}
\item
  Shannon's Channel Coding Theorem:

  \begin{itemize}
  \tightlist
  \item
    If rate \(R < C\), there exist coding schemes with error probability
    → 0 as block length grows.
  \item
    If \(R > C\), reliable communication is impossible.
  \end{itemize}
\item
  Types of channels:

  \begin{itemize}
  \tightlist
  \item
    Binary symmetric channel (BSC): flips bits with probability \(p\).
  \item
    Binary erasure channel (BEC): deletes bits with probability \(p\).
  \item
    Gaussian channel: continuous noise added to signal.
  \end{itemize}
\item
  Coding schemes:

  \begin{itemize}
  \tightlist
  \item
    Error-correcting codes: Hamming codes, Reed--Solomon, LDPC, Turbo,
    Polar codes.
  \item
    Trade-off between redundancy, efficiency, and error correction.
  \end{itemize}
\item
  In AI:

  \begin{itemize}
  \tightlist
  \item
    Inspiration for regularization (information bottleneck).
  \item
    Understanding data transmission in distributed learning.
  \item
    Analogies for generalization and noise robustness.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2895}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4079}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3026}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Channel Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Capacity Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Use
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Binary Symmetric (BSC) & \(C = 1 - H(p)\) & Noisy bit transmission \\
Binary Erasure (BEC) & \(C = 1 - p\) & Packet loss in networks \\
Gaussian & \(C = \tfrac{1}{2}\log_2(1+SNR)\) & Wireless
communications \\
\end{longtable}

Tiny Code Sample (Python, simulate BSC capacity)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ math }\ImportTok{import}\NormalTok{ log2}

\KeywordTok{def}\NormalTok{ binary\_entropy(p):}
    \ControlFlowTok{if}\NormalTok{ p }\OperatorTok{==} \DecValTok{0} \KeywordTok{or}\NormalTok{ p }\OperatorTok{==} \DecValTok{1}\NormalTok{: }\ControlFlowTok{return} \DecValTok{0}
    \ControlFlowTok{return} \OperatorTok{{-}}\NormalTok{p}\OperatorTok{*}\NormalTok{log2(p) }\OperatorTok{{-}}\NormalTok{ (}\DecValTok{1}\OperatorTok{{-}}\NormalTok{p)}\OperatorTok{*}\NormalTok{log2(}\DecValTok{1}\OperatorTok{{-}}\NormalTok{p)}

\CommentTok{\# Capacity of Binary Symmetric Channel}
\NormalTok{p }\OperatorTok{=} \FloatTok{0.1}  \CommentTok{\# bit flip probability}
\NormalTok{C }\OperatorTok{=} \DecValTok{1} \OperatorTok{{-}}\NormalTok{ binary\_entropy(p)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"BSC Capacity:"}\NormalTok{, C, }\StringTok{"bits per channel use"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-63}

Channel capacity sets a fundamental limit: no algorithm can surpass it.
The coding theorems show how close we can get, forming the backbone of
digital communication. In AI, these ideas echo in information
bottlenecks, compression, and error-tolerant learning systems.

\subsubsection{Try It Yourself}\label{try-it-yourself-165}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute capacity of a BSC with error probability \(p=0.2\).
\item
  Compare capacity of a Gaussian channel with SNR = 10 dB and 20 dB.
\item
  Explain how redundancy in coding relates to regularization in machine
  learning.
\end{enumerate}

\subsection{167. Rate--Distortion Theory}\label{ratedistortion-theory}

Rate--distortion theory studies the trade-off between compression rate
(how many bits you use) and distortion (how much information is lost).
It answers: what is the minimum number of bits per symbol required to
represent data within a given tolerance of error?

\subsubsection{Picture in Your Head}\label{picture-in-your-head-166}

Imagine saving a photo. If you compress it heavily, the file is small
but blurry. If you save it losslessly, the file is large but perfect.
Rate--distortion theory formalizes this compromise between size and
quality.

\subsubsection{Deep Dive}\label{deep-dive-166}

\begin{itemize}
\item
  Distortion measure: Quantifies error between original \(x\) and
  reconstruction \(\hat{x}\). Example: mean squared error (MSE), Hamming
  distance.
\item
  Rate--distortion function: Minimum rate needed for distortion \(D\):

  \[
  R(D) = \min_{p(\hat{x}|x): E[d(x,\hat{x})] \leq D} I(X;\hat{X})
  \]
\item
  Interpretations:

  \begin{itemize}
  \tightlist
  \item
    At \(D=0\): \(R(D)=H(X)\) (lossless compression).
  \item
    As \(D\) increases, fewer bits are needed.
  \end{itemize}
\item
  Shannon's Rate--Distortion Theorem:

  \begin{itemize}
  \tightlist
  \item
    Provides theoretical lower bound on compression efficiency.
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Image/audio compression (JPEG, MP3).
  \item
    Variational autoencoders (ELBO resembles rate--distortion
    trade-off).
  \item
    Information bottleneck method (trade-off between relevance and
    compression).
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2286}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3143}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4571}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Distortion Level
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Bits per Symbol (Rate)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in Practice
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 (perfect) & \(H(X)\) & Lossless compression (PNG, FLAC) \\
Low & Slightly \textless{} \(H(X)\) & High-quality JPEG \\
High & Much smaller & Aggressive lossy compression \\
\end{longtable}

Tiny Code Sample (Python, toy rate--distortion curve)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}

\NormalTok{D }\OperatorTok{=}\NormalTok{ np.linspace(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{50}\NormalTok{)  }\CommentTok{\# distortion}
\NormalTok{R }\OperatorTok{=}\NormalTok{ np.maximum(}\DecValTok{0}\NormalTok{, }\DecValTok{1} \OperatorTok{{-}}\NormalTok{ D)   }\CommentTok{\# toy linear approx for illustration}

\NormalTok{plt.plot(D, R)}
\NormalTok{plt.xlabel(}\StringTok{"Distortion"}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{"Rate (bits/symbol)"}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{"Toy Rate–Distortion Trade{-}off"}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-64}

Rate--distortion theory reveals the limits of lossy compression: how
much data can be removed without exceeding a distortion threshold. In
AI, it inspires representation learning methods that balance
expressiveness with efficiency.

\subsubsection{Try It Yourself}\label{try-it-yourself-166}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute the rate--distortion function for a binary source with Hamming
  distortion.
\item
  Compare distortion tolerance in JPEG vs PNG for the same image.
\item
  Explain how rate--distortion ideas appear in the variational
  autoencoder objective.
\end{enumerate}

\subsection{168. Information Bottleneck
Principle}\label{information-bottleneck-principle}

The Information Bottleneck (IB) principle describes how to extract the
most relevant information from an input while compressing away
irrelevant details. It formalizes learning as balancing two goals:
retain information about the target variable while discarding noise.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-167}

Imagine squeezing water through a filter. The wide stream of input data
passes through a narrow bottleneck that only lets essential drops
through---enough to reconstruct what matters, but not every detail.

\subsubsection{Deep Dive}\label{deep-dive-167}

\begin{itemize}
\item
  Formal objective: Given input \(X\) and target \(Y\), find compressed
  representation \(T\):

  \[
  \min I(X;T) - \beta I(T;Y)
  \]

  \begin{itemize}
  \tightlist
  \item
    \(I(X;T)\): how much input information is kept.
  \item
    \(I(T;Y)\): how useful the representation is for predicting \(Y\).
  \item
    \(\beta\): trade-off parameter between compression and relevance.
  \end{itemize}
\item
  Connections:

  \begin{itemize}
  \tightlist
  \item
    At \(\beta=0\): keep all information (\(T=X\)).
  \item
    Large \(\beta\): compress aggressively, retain only predictive
    parts.
  \item
    Related to rate--distortion theory with ``distortion'' defined by
    prediction error.
  \end{itemize}
\item
  In AI:

  \begin{itemize}
  \tightlist
  \item
    Neural networks: hidden layers act as information bottlenecks.
  \item
    Variational Information Bottleneck (VIB): practical approximation
    for deep learning.
  \item
    Regularization: prevents overfitting by discarding irrelevant
    detail.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1910}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3483}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4607}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Term
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(I(X;T)\) & Info retained from input & Latent representation
complexity \\
\(I(T;Y)\) & Info relevant for prediction & Accuracy of classifier \\
\(\beta\) trade-off & Compression vs predictive power & Tuning
representation learning objectives \\
\end{longtable}

Tiny Code Sample (Python, sketch of VIB loss)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ torch}
\ImportTok{import}\NormalTok{ torch.nn.functional }\ImportTok{as}\NormalTok{ F}

\KeywordTok{def}\NormalTok{ vib\_loss(p\_y\_given\_t, q\_t\_given\_x, p\_t, y, beta}\OperatorTok{=}\FloatTok{1e{-}3}\NormalTok{):}
    \CommentTok{\# Prediction loss (cross{-}entropy)}
\NormalTok{    pred\_loss }\OperatorTok{=}\NormalTok{ F.nll\_loss(p\_y\_given\_t, y)}
    \CommentTok{\# KL divergence term for compression}
\NormalTok{    kl }\OperatorTok{=}\NormalTok{ torch.distributions.kl.kl\_divergence(q\_t\_given\_x, p\_t).mean()}
    \ControlFlowTok{return}\NormalTok{ pred\_loss }\OperatorTok{+}\NormalTok{ beta }\OperatorTok{*}\NormalTok{ kl}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-65}

The IB principle provides a unifying view of representation learning:
good models should compress inputs while preserving what matters for
outputs. It bridges coding theory, statistics, and deep learning, and
explains why deep networks generalize well despite huge capacity.

\subsubsection{Try It Yourself}\label{try-it-yourself-167}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Explain why the hidden representation of a neural net can be seen as a
  bottleneck.
\item
  Modify \(\beta\) in the VIB objective---what happens to compression vs
  accuracy?
\item
  Compare IB to rate--distortion theory: how do they differ in purpose?
\end{enumerate}

\subsection{169. Minimum Description Length
(MDL)}\label{minimum-description-length-mdl}

The Minimum Description Length principle views learning as compression:
the best model is the one that provides the shortest description of the
data plus the model itself. MDL formalizes Occam's razor---prefer
simpler models unless complexity is justified by better fit.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-168}

Imagine trying to explain a dataset to a friend. If you just read out
all the numbers, that's long. If you fit a simple pattern (``all numbers
are even up to 100''), your explanation is shorter. MDL says the best
explanation is the one that minimizes total description length.

\subsubsection{Deep Dive}\label{deep-dive-168}

\begin{itemize}
\item
  Formal principle: Total description length = model complexity + data
  encoding under model.

  \[
  L(M, D) = L(M) + L(D \mid M)
  \]

  \begin{itemize}
  \tightlist
  \item
    \(L(M)\): bits to describe the model.
  \item
    \(L(D|M)\): bits to encode the data given the model.
  \end{itemize}
\item
  Connections:

  \begin{itemize}
  \tightlist
  \item
    Equivalent to maximizing posterior probability in Bayesian
    inference.
  \item
    Related to Kolmogorov complexity (shortest program producing the
    data).
  \item
    Generalizes to stochastic models: choose the one with minimal
    codelength.
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Model selection (balancing bias--variance).
  \item
    Avoiding overfitting in machine learning.
  \item
    Feature selection via compressibility.
  \item
    Information-theoretic foundations of regularization.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1204}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3056}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2407}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Term
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(L(M)\) & Complexity cost of the model & Number of parameters in neural
net & \\
(L(D & M)) & Encoding cost of data given model & Log-likelihood under
model \\
MDL principle & Minimize total description length & Trade-off between
fit and simplicity & \\
\end{longtable}

Tiny Code Sample (Python, toy MDL for polynomial fit)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ PolynomialFeatures}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LinearRegression}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ mean\_squared\_error}
\ImportTok{import}\NormalTok{ math}

\CommentTok{\# Generate noisy quadratic data}
\NormalTok{np.random.seed(}\DecValTok{0}\NormalTok{)}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.linspace(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{20}\NormalTok{).reshape(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\NormalTok{y }\OperatorTok{=} \DecValTok{2}\OperatorTok{*}\NormalTok{X[:,}\DecValTok{0}\NormalTok{]}\DecValTok{2} \OperatorTok{+} \FloatTok{0.1}\OperatorTok{*}\NormalTok{np.random.randn(}\DecValTok{20}\NormalTok{)}

\KeywordTok{def}\NormalTok{ mdl\_cost(degree):}
\NormalTok{    poly }\OperatorTok{=}\NormalTok{ PolynomialFeatures(degree)}
\NormalTok{    X\_poly }\OperatorTok{=}\NormalTok{ poly.fit\_transform(X)}
\NormalTok{    model }\OperatorTok{=}\NormalTok{ LinearRegression().fit(X\_poly, y)}
\NormalTok{    y\_pred }\OperatorTok{=}\NormalTok{ model.predict(X\_poly)}
\NormalTok{    mse }\OperatorTok{=}\NormalTok{ mean\_squared\_error(y, y\_pred)}
\NormalTok{    L\_D\_given\_M }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(y)}\OperatorTok{*}\NormalTok{math.log(mse}\OperatorTok{+}\FloatTok{1e{-}6}\NormalTok{)   }\CommentTok{\# data fit cost}
\NormalTok{    L\_M }\OperatorTok{=}\NormalTok{ degree                              }\CommentTok{\# model complexity proxy}
    \ControlFlowTok{return}\NormalTok{ L\_M }\OperatorTok{+}\NormalTok{ L\_D\_given\_M}

\ControlFlowTok{for}\NormalTok{ d }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{6}\NormalTok{):}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Degree }\SpecialCharTok{\{}\NormalTok{d}\SpecialCharTok{\}}\SpecialStringTok{, MDL cost: }\SpecialCharTok{\{}\NormalTok{mdl\_cost(d)}\SpecialCharTok{:.2f\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-66}

MDL offers a principled, universal way to balance model complexity with
data fit. It justifies why simpler models generalize better, and
underlies practical methods like AIC, BIC, and regularization penalties
in modern machine learning.

\subsubsection{Try It Yourself}\label{try-it-yourself-168}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare MDL costs for fitting linear vs quadratic models to data.
\item
  Explain how MDL prevents overfitting in decision trees.
\item
  Relate MDL to deep learning regularization: how do weight penalties
  mimic description length?
\end{enumerate}

\subsection{170. Applications in Machine
Learning}\label{applications-in-machine-learning}

Information theory provides the language and tools to quantify
uncertainty, dependence, and efficiency. In machine learning, these
concepts directly translate into loss functions, regularization, and
representation learning.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-169}

Imagine teaching a child new words. You want to give them enough
examples to reduce uncertainty (entropy), focus on the most relevant
clues (mutual information), and avoid wasting effort on noise. Machine
learning systems operate under the same principles.

\subsubsection{Deep Dive}\label{deep-dive-169}

\begin{itemize}
\item
  Entropy \& Cross-Entropy:

  \begin{itemize}
  \tightlist
  \item
    Classification uses cross-entropy loss to align predicted and true
    distributions.
  \item
    Entropy measures model uncertainty, guiding exploration in
    reinforcement learning.
  \end{itemize}
\item
  Mutual Information:

  \begin{itemize}
  \tightlist
  \item
    Feature selection: choose variables with high MI with labels.
  \item
    Representation learning: InfoNCE and contrastive learning maximize
    MI between views.
  \end{itemize}
\item
  KL Divergence:

  \begin{itemize}
  \tightlist
  \item
    Core of variational inference and VAEs.
  \item
    Regularizes approximate posteriors toward priors.
  \end{itemize}
\item
  Channel Capacity:

  \begin{itemize}
  \tightlist
  \item
    Analogy for limits of model generalization.
  \item
    Bottleneck layers in deep nets function like constrained channels.
  \end{itemize}
\item
  Rate--Distortion \& Bottleneck:

  \begin{itemize}
  \tightlist
  \item
    Variational Information Bottleneck (VIB) balances compression and
    relevance.
  \item
    Applied in disentangled representation learning.
  \end{itemize}
\item
  MDL Principle:

  \begin{itemize}
  \tightlist
  \item
    Guides model selection by trading complexity for fit.
  \item
    Explains regularization penalties (L1, L2) as description length
    constraints.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2381}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3690}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3929}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Information Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Machine Learning Role
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Entropy & Quantify uncertainty & Exploration in RL \\
Cross-Entropy & Training objective & Classification, language
modeling \\
Mutual Information & Feature/repr. relevance & Contrastive learning,
clustering \\
KL Divergence & Approximate inference & VAEs, Bayesian deep learning \\
Channel Capacity & Limit of reliable info transfer & Neural bottlenecks,
compression \\
Rate--Distortion / IB & Compress yet preserve relevance & Representation
learning, VAEs \\
MDL & Model selection, generalization & Regularization, pruning \\
\end{longtable}

Tiny Code Sample (Python, InfoNCE Loss)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ torch}
\ImportTok{import}\NormalTok{ torch.nn.functional }\ImportTok{as}\NormalTok{ F}

\KeywordTok{def}\NormalTok{ info\_nce\_loss(z\_i, z\_j, temperature}\OperatorTok{=}\FloatTok{0.1}\NormalTok{):}
    \CommentTok{\# z\_i, z\_j are embeddings from two augmented views}
\NormalTok{    batch\_size }\OperatorTok{=}\NormalTok{ z\_i.shape[}\DecValTok{0}\NormalTok{]}
\NormalTok{    z }\OperatorTok{=}\NormalTok{ torch.cat([z\_i, z\_j], dim}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\NormalTok{    sim }\OperatorTok{=}\NormalTok{ F.cosine\_similarity(z.unsqueeze(}\DecValTok{1}\NormalTok{), z.unsqueeze(}\DecValTok{0}\NormalTok{), dim}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{    sim }\OperatorTok{/=}\NormalTok{ temperature}
\NormalTok{    labels }\OperatorTok{=}\NormalTok{ torch.arange(batch\_size, device}\OperatorTok{=}\NormalTok{z.device)}
\NormalTok{    labels }\OperatorTok{=}\NormalTok{ torch.cat([labels, labels], dim}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ F.cross\_entropy(sim, labels)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-67}

Information theory explains \emph{why} machine learning works. It
unifies compression, prediction, and generalization, showing that
learning is fundamentally about extracting, transmitting, and
representing information efficiently.

\subsubsection{Try It Yourself}\label{try-it-yourself-169}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Train a classifier with cross-entropy loss and measure entropy of
  predictions on uncertain data.
\item
  Use mutual information to rank features in a dataset.
\item
  Relate the concept of channel capacity to overfitting in deep
  networks.
\end{enumerate}

\section{Chapter 18. Graphs, Matrices and Special
Methods}\label{chapter-18.-graphs-matrices-and-special-methods}

\subsection{171. Graphs: Nodes, Edges, and
Paths}\label{graphs-nodes-edges-and-paths}

Graphs are mathematical structures that capture relationships between
entities. A graph consists of nodes (vertices) and edges (links). They
can be directed or undirected, weighted or unweighted, and form the
foundation for reasoning about connectivity, flow, and structure.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-170}

Imagine a social network. Each person is a node, and each friendship is
an edge connecting two people. A path is just a chain of
friendships---how you get from one person to another through mutual
friends.

\subsubsection{Deep Dive}\label{deep-dive-170}

\begin{itemize}
\item
  Graph definition: \(G = (V, E)\) with vertex set \(V\) and edge set
  \(E\).
\item
  Nodes (vertices): fundamental units (people, cities, states).
\item
  Edges (links): represent relationships, can be:

  \begin{itemize}
  \tightlist
  \item
    Directed: (u,v) ≠ (v,u) → Twitter follow.
  \item
    Undirected: (u,v) = (v,u) → Facebook friendship.
  \end{itemize}
\item
  Weighted graphs: edges have values (distance, cost, similarity).
\item
  Paths and connectivity:

  \begin{itemize}
  \tightlist
  \item
    Path = sequence of edges between nodes.
  \item
    Cycle = path that starts and ends at same node.
  \item
    Connected graph = path exists between any two nodes.
  \end{itemize}
\item
  Special graphs: trees, bipartite graphs, complete graphs.
\item
  In AI: graphs model knowledge bases, molecules, neural nets,
  logistics, and interactions in multi-agent systems.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1548}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3452}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Element
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Node (vertex) & Entity & User in social network, word in NLP \\
Edge (link) & Relationship between entities & Friendship, co-occurrence,
road connection \\
Weighted edge & Strength or cost of relation & Distance between cities,
attention score \\
Path & Sequence of nodes/edges & Inference chain in knowledge graph \\
Cycle & Path that returns to start & Feedback loop in causal models \\
\end{longtable}

Tiny Code Sample (Python, using NetworkX)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ networkx }\ImportTok{as}\NormalTok{ nx}

\CommentTok{\# Create graph}
\NormalTok{G }\OperatorTok{=}\NormalTok{ nx.Graph()}
\NormalTok{G.add\_edges\_from([(}\StringTok{"Alice"}\NormalTok{,}\StringTok{"Bob"}\NormalTok{), (}\StringTok{"Bob"}\NormalTok{,}\StringTok{"Carol"}\NormalTok{), (}\StringTok{"Alice"}\NormalTok{,}\StringTok{"Dan"}\NormalTok{)])}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Nodes:"}\NormalTok{, G.nodes())}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Edges:"}\NormalTok{, G.edges())}

\CommentTok{\# Check paths}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Path Alice {-}\textgreater{} Carol:"}\NormalTok{, nx.shortest\_path(G, }\StringTok{"Alice"}\NormalTok{, }\StringTok{"Carol"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-68}

Graphs are the universal language of structure and relationships. In AI,
they support reasoning (knowledge graphs), learning (graph neural
networks), and optimization (routing, scheduling). Without graphs, many
AI systems would lack the ability to represent and reason about complex
connections.

\subsubsection{Try It Yourself}\label{try-it-yourself-170}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Construct a graph of five cities and connect them with distances as
  edge weights. Find the shortest path between two cities.
\item
  Build a bipartite graph of users and movies. What does a path from
  user A to user B mean?
\item
  Give an example where cycles in a graph model feedback in a real
  system (e.g., economy, ecology).
\end{enumerate}

\subsection{172. Adjacency and Incidence
Matrices}\label{adjacency-and-incidence-matrices}

Graphs can be represented algebraically using matrices. The adjacency
matrix encodes which nodes are connected, while the incidence matrix
captures relationships between nodes and edges. These matrix forms
enable powerful linear algebra techniques for analyzing graphs.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-171}

Think of a city map. You could describe it with a list of roads (edges)
connecting intersections (nodes), or you could build a big table. Each
row and column of the table represents intersections, and you mark a
``1'' whenever a road connects two intersections. That table is the
adjacency matrix.

\subsubsection{Deep Dive}\label{deep-dive-171}

\begin{itemize}
\item
  Adjacency matrix (A):

  \begin{itemize}
  \item
    For graph \(G=(V,E)\) with \(|V|=n\):

    \[
    A_{ij} = \begin{cases} 
      1 & \text{if edge } (i,j) \in E, \\
      0 & \text{otherwise.}
    \end{cases}
    \]
  \item
    For weighted graphs, entries contain weights instead of 1s.
  \item
    Properties: symmetric for undirected graphs; row sums give node
    degrees.
  \end{itemize}
\item
  Incidence matrix (B):

  \begin{itemize}
  \item
    Rows = nodes, columns = edges.
  \item
    For edge \(e=(i,j)\):

    \begin{itemize}
    \tightlist
    \item
      \(B_{i,e} = +1\), \(B_{j,e} = -1\), all others 0 (for directed
      graphs).
    \end{itemize}
  \item
    Captures how edges connect vertices.
  \end{itemize}
\item
  Linear algebra links:

  \begin{itemize}
  \tightlist
  \item
    Degree matrix: \(D_{ii} = \sum_j A_{ij}\).
  \item
    Graph Laplacian: \(L = D - A\).
  \end{itemize}
\item
  In AI: used in spectral clustering, graph convolutional networks,
  knowledge graph embeddings.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2069}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3563}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4368}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Matrix
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Adjacency (A) & Node-to-node connectivity & Graph neural networks, node
embeddings \\
Weighted adjacency & Edge weights as entries & Shortest paths,
recommender systems \\
Incidence (B) & Node-to-edge mapping & Flow problems, electrical
circuits \\
Laplacian (L=D−A) & Derived from adjacency + degree & Spectral methods,
clustering, GNNs \\
\end{longtable}

Tiny Code Sample (Python, using NetworkX \& NumPy)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ networkx }\ImportTok{as}\NormalTok{ nx}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Build graph}
\NormalTok{G }\OperatorTok{=}\NormalTok{ nx.Graph()}
\NormalTok{G.add\_edges\_from([(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{),(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{),(}\DecValTok{2}\NormalTok{,}\DecValTok{0}\NormalTok{),(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{)])}

\CommentTok{\# Adjacency matrix}
\NormalTok{A }\OperatorTok{=}\NormalTok{ nx.to\_numpy\_array(G)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Adjacency matrix:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, A)}

\CommentTok{\# Incidence matrix}
\NormalTok{B }\OperatorTok{=}\NormalTok{ nx.incidence\_matrix(G, oriented}\OperatorTok{=}\VariableTok{True}\NormalTok{).toarray()}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Incidence matrix:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, B)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-69}

Matrix representations let us apply linear algebra to graphs, unlocking
tools for clustering, spectral analysis, and graph neural networks. This
algebraic viewpoint turns structural problems into numerical ones,
making them solvable with efficient algorithms.

\subsubsection{Try It Yourself}\label{try-it-yourself-171}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Construct the adjacency matrix for a triangle graph (3 nodes, fully
  connected). What are its eigenvalues?
\item
  Build the incidence matrix for a 4-node chain graph. How do its
  columns reflect edge connections?
\item
  Use the Laplacian \(L=D-A\) of a small graph to compute its connected
  components.
\end{enumerate}

\subsection{173. Graph Traversals (DFS,
BFS)}\label{graph-traversals-dfs-bfs}

Graph traversal algorithms systematically explore nodes and edges.
Depth-First Search (DFS) goes as far as possible along one path before
backtracking, while Breadth-First Search (BFS) explores neighbors layer
by layer. These two strategies underpin many higher-level graph
algorithms.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-172}

Imagine searching a maze. DFS is like always taking the next hallway
until you hit a dead end, then backtracking. BFS is like exploring all
hallways one step at a time, ensuring you find the shortest way out.

\subsubsection{Deep Dive}\label{deep-dive-172}

\begin{itemize}
\item
  DFS (Depth-First Search):

  \begin{itemize}
  \tightlist
  \item
    Explores deep into a branch before backtracking.
  \item
    Implemented recursively or with a stack.
  \item
    Useful for detecting cycles, topological sorting, connected
    components.
  \end{itemize}
\item
  BFS (Breadth-First Search):

  \begin{itemize}
  \tightlist
  \item
    Explores all neighbors of current node before moving deeper.
  \item
    Uses a queue.
  \item
    Finds shortest paths in unweighted graphs.
  \end{itemize}
\item
  Complexity: \(O(|V| + |E|)\) for both.
\item
  In AI: used in search (state spaces, planning), social network
  analysis, knowledge graph queries.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0833}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3704}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3796}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Traversal
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Mechanism
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strengths
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
DFS & Stack/recursion & Memory-efficient, explores deeply & Topological
sort, constraint satisfaction \\
BFS & Queue, level-order & Finds shortest path in unweighted graphs &
Shortest queries in knowledge graphs \\
\end{longtable}

Tiny Code Sample (Python, DFS \& BFS with NetworkX)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ networkx }\ImportTok{as}\NormalTok{ nx}
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ deque}

\NormalTok{G }\OperatorTok{=}\NormalTok{ nx.Graph()}
\NormalTok{G.add\_edges\_from([(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{),(}\DecValTok{0}\NormalTok{,}\DecValTok{2}\NormalTok{),(}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{),(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{),(}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{)])}

\CommentTok{\# DFS}
\KeywordTok{def}\NormalTok{ dfs(graph, start, visited}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
    \ControlFlowTok{if}\NormalTok{ visited }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{        visited }\OperatorTok{=} \BuiltInTok{set}\NormalTok{()}
\NormalTok{    visited.add(start)}
    \ControlFlowTok{for}\NormalTok{ neighbor }\KeywordTok{in}\NormalTok{ graph.neighbors(start):}
        \ControlFlowTok{if}\NormalTok{ neighbor }\KeywordTok{not} \KeywordTok{in}\NormalTok{ visited:}
\NormalTok{            dfs(graph, neighbor, visited)}
    \ControlFlowTok{return}\NormalTok{ visited}

\BuiltInTok{print}\NormalTok{(}\StringTok{"DFS from 0:"}\NormalTok{, dfs(G, }\DecValTok{0}\NormalTok{))}

\CommentTok{\# BFS}
\KeywordTok{def}\NormalTok{ bfs(graph, start):}
\NormalTok{    visited, queue }\OperatorTok{=} \BuiltInTok{set}\NormalTok{([start]), deque([start])}
\NormalTok{    order }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{while}\NormalTok{ queue:}
\NormalTok{        node }\OperatorTok{=}\NormalTok{ queue.popleft()}
\NormalTok{        order.append(node)}
        \ControlFlowTok{for}\NormalTok{ neighbor }\KeywordTok{in}\NormalTok{ graph.neighbors(node):}
            \ControlFlowTok{if}\NormalTok{ neighbor }\KeywordTok{not} \KeywordTok{in}\NormalTok{ visited:}
\NormalTok{                visited.add(neighbor)}
\NormalTok{                queue.append(neighbor)}
    \ControlFlowTok{return}\NormalTok{ order}

\BuiltInTok{print}\NormalTok{(}\StringTok{"BFS from 0:"}\NormalTok{, bfs(G, }\DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-70}

Traversal is the backbone of graph algorithms. Whether navigating a
state space in AI search, analyzing social networks, or querying
knowledge graphs, DFS and BFS provide the exploration strategies on
which more complex reasoning is built.

\subsubsection{Try It Yourself}\label{try-it-yourself-172}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use BFS to find the shortest path between two nodes in an unweighted
  graph.
\item
  Modify DFS to detect cycles in a directed graph.
\item
  Compare the traversal order of BFS vs DFS on a binary tree---what
  insights do you gain?
\end{enumerate}

\subsection{174. Connectivity and
Components}\label{connectivity-and-components}

Connectivity describes whether nodes in a graph are reachable from one
another. A connected component is a maximal set of nodes where each pair
has a path between them. In directed graphs, we distinguish between
strongly and weakly connected components.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-173}

Think of islands connected by bridges. Each island cluster where you can
walk from any town to any other without leaving the cluster is a
connected component. If some islands are cut off, they form separate
components.

\subsubsection{Deep Dive}\label{deep-dive-173}

\begin{itemize}
\item
  Undirected graphs:

  \begin{itemize}
  \tightlist
  \item
    A graph is connected if every pair of nodes has a path.
  \item
    Otherwise, it splits into multiple connected components.
  \end{itemize}
\item
  Directed graphs:

  \begin{itemize}
  \tightlist
  \item
    Strongly connected component (SCC): every node reachable from every
    other node.
  \item
    Weakly connected component: connectivity holds if edge directions
    are ignored.
  \end{itemize}
\item
  Algorithms:

  \begin{itemize}
  \tightlist
  \item
    BFS/DFS to find connected components in undirected graphs.
  \item
    Kosaraju's, Tarjan's, or Gabow's algorithm for SCCs in directed
    graphs.
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Social network analysis (friendship clusters).
  \item
    Knowledge graphs (isolated subgraphs).
  \item
    Computer vision (connected pixel regions).
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2353}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4118}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3529}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Connected graph & All nodes reachable & Communication networks \\
Connected component & Maximal subset of mutually reachable nodes &
Community detection in social graphs \\
Strongly connected comp. & Directed paths in both directions exist & Web
graph link cycles \\
Weakly connected comp. & Paths exist if direction is ignored & Isolated
knowledge graph partitions \\
\end{longtable}

Tiny Code Sample (Python, NetworkX)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ networkx }\ImportTok{as}\NormalTok{ nx}

\CommentTok{\# Undirected graph with two components}
\NormalTok{G }\OperatorTok{=}\NormalTok{ nx.Graph()}
\NormalTok{G.add\_edges\_from([(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{),(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{),(}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{)])}

\NormalTok{components }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(nx.connected\_components(G))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Connected components:"}\NormalTok{, components)}

\CommentTok{\# Directed graph SCCs}
\NormalTok{DG }\OperatorTok{=}\NormalTok{ nx.DiGraph()}
\NormalTok{DG.add\_edges\_from([(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{),(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{),(}\DecValTok{2}\NormalTok{,}\DecValTok{0}\NormalTok{),(}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{)])}
\NormalTok{sccs }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(nx.strongly\_connected\_components(DG))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Strongly connected components:"}\NormalTok{, sccs)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-71}

Understanding connectivity helps identify whether a system is unified or
fragmented. In AI, it reveals isolated data clusters, ensures graph
search completeness, and supports robustness analysis in networks and
multi-agent systems.

\subsubsection{Try It Yourself}\label{try-it-yourself-173}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a graph with three disconnected subgraphs and identify its
  connected components.
\item
  Create a directed cycle (A→B→C→A). Is it strongly connected? Weakly
  connected?
\item
  Explain how identifying SCCs might help in optimizing web crawlers or
  knowledge graph queries.
\end{enumerate}

\subsection{175. Graph Laplacians}\label{graph-laplacians}

The graph Laplacian is a matrix that encodes both connectivity and
structure of a graph. It is central to spectral graph theory, linking
graph properties with eigenvalues and eigenvectors. Laplacians underpin
clustering, graph embeddings, and diffusion processes in AI.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-174}

Imagine pouring dye on one node of a network of pipes. The way the dye
diffuses over time depends on how the pipes connect. The Laplacian
matrix mathematically describes that diffusion across the graph.

\subsubsection{Deep Dive}\label{deep-dive-174}

\begin{itemize}
\item
  Definition: For graph \(G=(V,E)\) with adjacency matrix \(A\) and
  degree matrix \(D\):

  \[
  L = D - A
  \]
\item
  Normalized forms:

  \begin{itemize}
  \tightlist
  \item
    Symmetric: \(L_{sym} = D^{-1/2} L D^{-1/2}\).
  \item
    Random-walk: \(L_{rw} = D^{-1} L\).
  \end{itemize}
\item
  Key properties:

  \begin{itemize}
  \tightlist
  \item
    \(L\) is symmetric and positive semi-definite.
  \item
    The smallest eigenvalue is always 0, with multiplicity equal to the
    number of connected components.
  \end{itemize}
\item
  Applications:

  \begin{itemize}
  \tightlist
  \item
    Spectral clustering: uses eigenvectors of Laplacian to partition
    graphs.
  \item
    Graph embeddings: Laplacian Eigenmaps for dimensionality reduction.
  \item
    Physics: models heat diffusion and random walks.
  \end{itemize}
\item
  In AI: community detection, semi-supervised learning, manifold
  learning, graph neural networks.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2740}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2603}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4658}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Variant
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Application in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Unnormalized L & \(D - A\) & General graph analysis \\
Normalized \(L_{sym}\) & \(D^{-1/2}LD^{-1/2}\) & Spectral clustering \\
Random-walk \(L_{rw}\) & \(D^{-1}L\) & Markov processes, diffusion
models \\
\end{longtable}

Tiny Code Sample (Python, NumPy + NetworkX)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ networkx }\ImportTok{as}\NormalTok{ nx}

\CommentTok{\# Build simple graph}
\NormalTok{G }\OperatorTok{=}\NormalTok{ nx.Graph()}
\NormalTok{G.add\_edges\_from([(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{),(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{),(}\DecValTok{2}\NormalTok{,}\DecValTok{0}\NormalTok{),(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{)])}

\CommentTok{\# Degree and adjacency matrices}
\NormalTok{A }\OperatorTok{=}\NormalTok{ nx.to\_numpy\_array(G)}
\NormalTok{D }\OperatorTok{=}\NormalTok{ np.diag(A.}\BuiltInTok{sum}\NormalTok{(axis}\OperatorTok{=}\DecValTok{1}\NormalTok{))}

\CommentTok{\# Laplacian}
\NormalTok{L }\OperatorTok{=}\NormalTok{ D }\OperatorTok{{-}}\NormalTok{ A}
\NormalTok{eigs, vecs }\OperatorTok{=}\NormalTok{ np.linalg.eigh(L)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Laplacian:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, L)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Eigenvalues:"}\NormalTok{, eigs)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-72}

The Laplacian turns graph problems into linear algebra problems. Its
spectral properties reveal clusters, connectivity, and diffusion
dynamics. This makes it indispensable in AI methods that rely on graph
structure, from GNNs to semi-supervised learning.

\subsubsection{Try It Yourself}\label{try-it-yourself-174}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Construct the Laplacian of a chain of 4 nodes and compute its
  eigenvalues.
\item
  Use the Fiedler vector (second-smallest eigenvector) to partition a
  graph into two clusters.
\item
  Explain how the Laplacian relates to random walks and Markov chains.
\end{enumerate}

\subsection{176. Spectral Decomposition of
Graphs}\label{spectral-decomposition-of-graphs}

Spectral graph theory studies the eigenvalues and eigenvectors of
matrices associated with graphs, especially the Laplacian and adjacency
matrices. These spectral properties reveal structure, connectivity, and
clustering in graphs.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-175}

Imagine plucking a guitar string. The vibration frequencies are
determined by the string's structure. Similarly, the ``frequencies''
(eigenvalues) of a graph come from its Laplacian, and the ``modes''
(eigenvectors) reveal how the graph naturally partitions.

\subsubsection{Deep Dive}\label{deep-dive-175}

\begin{itemize}
\item
  Adjacency spectrum: eigenvalues of adjacency matrix \(A\).

  \begin{itemize}
  \tightlist
  \item
    Capture connectivity patterns.
  \end{itemize}
\item
  Laplacian spectrum: eigenvalues of \(L=D-A\).

  \begin{itemize}
  \tightlist
  \item
    Smallest eigenvalue is always 0.
  \item
    Multiplicity of 0 equals number of connected components.
  \item
    Second-smallest eigenvalue (Fiedler value) measures graph
    connectivity.
  \end{itemize}
\item
  Eigenvectors:

  \begin{itemize}
  \tightlist
  \item
    Fiedler vector used to partition graphs (spectral clustering).
  \item
    Eigenvectors represent smooth variations across nodes.
  \end{itemize}
\item
  Applications:

  \begin{itemize}
  \tightlist
  \item
    Graph partitioning, community detection.
  \item
    Embeddings (Laplacian eigenmaps).
  \item
    Analyzing diffusion and random walks.
  \item
    Designing Graph Neural Networks with spectral filters.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3778}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3889}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Spectrum Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Information Provided
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Adjacency eigenvalues & Density, degree distribution & Social network
analysis \\
Laplacian eigenvalues & Connectivity, clustering structure & Spectral
clustering in ML \\
Eigenvectors & Node embeddings, smooth functions & Semi-supervised node
classification \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-165}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ networkx }\ImportTok{as}\NormalTok{ nx}

\CommentTok{\# Build simple graph}
\NormalTok{G }\OperatorTok{=}\NormalTok{ nx.path\_graph(}\DecValTok{5}\NormalTok{)  }\CommentTok{\# 5 nodes in a chain}

\CommentTok{\# Laplacian}
\NormalTok{L }\OperatorTok{=}\NormalTok{ nx.laplacian\_matrix(G).toarray()}

\CommentTok{\# Eigen{-}decomposition}
\NormalTok{eigs, vecs }\OperatorTok{=}\NormalTok{ np.linalg.eigh(L)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Eigenvalues:"}\NormalTok{, eigs)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Fiedler vector (2nd eigenvector):"}\NormalTok{, vecs[:,}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-73}

Spectral methods provide a bridge between graph theory and linear
algebra. In AI, they enable powerful techniques for clustering,
embeddings, and GNN architectures. Understanding the spectral view of
graphs is key to analyzing structure beyond simple connectivity.

\subsubsection{Try It Yourself}\label{try-it-yourself-175}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute Laplacian eigenvalues of a complete graph with 4 nodes. How
  many zeros appear?
\item
  Use the Fiedler vector to split a graph into two communities.
\item
  Explain how eigenvalues can indicate robustness of networks to
  node/edge removal.
\end{enumerate}

\subsection{177. Eigenvalues and Graph
Partitioning}\label{eigenvalues-and-graph-partitioning}

Graph partitioning divides a graph into groups of nodes while minimizing
connections between groups. Eigenvalues and eigenvectors of the
Laplacian provide a principled way to achieve this, forming the basis of
spectral clustering.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-176}

Imagine a city split by a river. People within each side interact more
with each other than across the river. The graph Laplacian's eigenvalues
reveal this ``natural cut,'' and the corresponding eigenvector helps
assign nodes to their side.

\subsubsection{Deep Dive}\label{deep-dive-176}

\begin{itemize}
\item
  Fiedler value (λ₂):

  \begin{itemize}
  \tightlist
  \item
    Second-smallest eigenvalue of Laplacian.
  \item
    Measures algebraic connectivity: small λ₂ means graph is loosely
    connected.
  \end{itemize}
\item
  Fiedler vector:

  \begin{itemize}
  \tightlist
  \item
    Corresponding eigenvector partitions nodes into two sets based on
    sign (or value threshold).
  \item
    Defines a ``spectral cut'' of the graph.
  \end{itemize}
\item
  Graph partitioning problem:

  \begin{itemize}
  \tightlist
  \item
    Minimize edge cuts between partitions while balancing group sizes.
  \item
    NP-hard in general, but spectral relaxation makes it tractable.
  \end{itemize}
\item
  Spectral clustering:

  \begin{itemize}
  \tightlist
  \item
    Use top k eigenvectors of normalized Laplacian as features.
  \item
    Apply k-means to cluster nodes.
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Community detection in social networks.
  \item
    Document clustering in NLP.
  \item
    Image segmentation (pixels as graph nodes).
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1881}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4455}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3663}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Role in Partitioning
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Fiedler value λ₂ & Strength of connectivity & Detecting weakly linked
communities \\
Fiedler vector & Partition nodes into two sets & Splitting social
networks into groups \\
Spectral clustering & Uses eigenvectors of Laplacian for clustering &
Image segmentation, topic modeling \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-166}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ networkx }\ImportTok{as}\NormalTok{ nx}
\ImportTok{from}\NormalTok{ sklearn.cluster }\ImportTok{import}\NormalTok{ KMeans}

\CommentTok{\# Build graph}
\NormalTok{G }\OperatorTok{=}\NormalTok{ nx.karate\_club\_graph()}
\NormalTok{L }\OperatorTok{=}\NormalTok{ nx.normalized\_laplacian\_matrix(G).toarray()}

\CommentTok{\# Eigen{-}decomposition}
\NormalTok{eigs, vecs }\OperatorTok{=}\NormalTok{ np.linalg.eigh(L)}

\CommentTok{\# Use second eigenvector for 2{-}way partition}
\NormalTok{fiedler\_vector }\OperatorTok{=}\NormalTok{ vecs[:,}\DecValTok{1}\NormalTok{]}
\NormalTok{partition }\OperatorTok{=}\NormalTok{ fiedler\_vector }\OperatorTok{\textgreater{}} \DecValTok{0}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Partition groups:"}\NormalTok{, partition.astype(}\BuiltInTok{int}\NormalTok{))}

\CommentTok{\# k{-}means spectral clustering (k=2)}
\NormalTok{features }\OperatorTok{=}\NormalTok{ vecs[:,}\DecValTok{1}\NormalTok{:}\DecValTok{3}\NormalTok{]}
\NormalTok{labels }\OperatorTok{=}\NormalTok{ KMeans(n\_clusters}\OperatorTok{=}\DecValTok{2}\NormalTok{, n\_init}\OperatorTok{=}\DecValTok{10}\NormalTok{).fit\_predict(features)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Spectral clustering labels:"}\NormalTok{, labels)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-74}

Graph partitioning via eigenvalues is more robust than naive heuristics.
It reveals hidden communities and patterns, enabling AI systems to learn
structure in complex data. Without spectral methods, clustering
high-dimensional relational data would often be intractable.

\subsubsection{Try It Yourself}\label{try-it-yourself-176}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute λ₂ for a chain of 5 nodes and explain its meaning.
\item
  Use the Fiedler vector to partition a graph with two weakly connected
  clusters.
\item
  Apply spectral clustering to a pixel graph of an image---what
  structures emerge?
\end{enumerate}

\subsection{178. Random Walks and Markov Chains on
Graphs}\label{random-walks-and-markov-chains-on-graphs}

A random walk is a process of moving through a graph by randomly
choosing edges. When repeated indefinitely, it forms a Markov chain---a
stochastic process where the next state depends only on the current one.
Random walks connect graph structure with probability, enabling ranking,
clustering, and learning.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-177}

Imagine a tourist wandering a city. At every intersection (node), they
pick a random road (edge) to walk down. Over time, the frequency with
which they visit each place reflects the structure of the city.

\subsubsection{Deep Dive}\label{deep-dive-177}

\begin{itemize}
\item
  Random walk definition:

  \begin{itemize}
  \tightlist
  \item
    From node \(i\), move to neighbor \(j\) with probability
    \(1/\deg(i)\) (uniform case).
  \item
    Transition matrix: \(P = D^{-1}A\).
  \end{itemize}
\item
  Stationary distribution:

  \begin{itemize}
  \tightlist
  \item
    Probability distribution \(\pi\) where \(\pi = \pi P\).
  \item
    In undirected graphs, \(\pi_i \propto \deg(i)\).
  \end{itemize}
\item
  Markov chains:

  \begin{itemize}
  \tightlist
  \item
    Irreducible: all nodes reachable.
  \item
    Aperiodic: no fixed cycle.
  \item
    Converges to stationary distribution under these conditions.
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    PageRank (random surfer model).
  \item
    Semi-supervised learning on graphs.
  \item
    Node embeddings (DeepWalk, node2vec).
  \item
    Sampling for large-scale graph analysis.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2300}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3800}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3900}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition/Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Transition matrix (P) & \(P=D^{-1}A\) & Defines step probabilities \\
Stationary distribution & \(\pi = \pi P\) & Long-run importance of nodes
(PageRank) \\
Mixing time & Steps to reach near-stationarity & Efficiency of
random-walk sampling \\
Biased random walk & Probabilities adjusted by weights/bias & node2vec
embeddings \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-167}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ networkx }\ImportTok{as}\NormalTok{ nx}

\CommentTok{\# Simple graph}
\NormalTok{G }\OperatorTok{=}\NormalTok{ nx.path\_graph(}\DecValTok{4}\NormalTok{)}
\NormalTok{A }\OperatorTok{=}\NormalTok{ nx.to\_numpy\_array(G)}
\NormalTok{D }\OperatorTok{=}\NormalTok{ np.diag(A.}\BuiltInTok{sum}\NormalTok{(axis}\OperatorTok{=}\DecValTok{1}\NormalTok{))}
\NormalTok{P }\OperatorTok{=}\NormalTok{ np.linalg.inv(D) }\OperatorTok{@}\NormalTok{ A}

\CommentTok{\# Random walk simulation}
\NormalTok{n\_steps }\OperatorTok{=} \DecValTok{10}
\NormalTok{state }\OperatorTok{=} \DecValTok{0}
\NormalTok{trajectory }\OperatorTok{=}\NormalTok{ [state]}
\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n\_steps):}
\NormalTok{    state }\OperatorTok{=}\NormalTok{ np.random.choice(}\BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(G)), p}\OperatorTok{=}\NormalTok{P[state])}
\NormalTok{    trajectory.append(state)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Transition matrix:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, P)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Random walk trajectory:"}\NormalTok{, trajectory)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-75}

Random walks connect probabilistic reasoning with graph structure. They
enable scalable algorithms for ranking, clustering, and representation
learning, powering search engines, recommendation systems, and
graph-based AI.

\subsubsection{Try It Yourself}\label{try-it-yourself-177}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate a random walk on a triangle graph. Does the stationary
  distribution match degree proportions?
\item
  Compute PageRank scores on a small directed graph using the random
  walk model.
\item
  Explain how biased random walks in node2vec capture both local and
  global graph structure.
\end{enumerate}

\subsection{179. Spectral Clustering}\label{spectral-clustering}

Spectral clustering partitions a graph using the eigenvalues and
eigenvectors of its Laplacian. Instead of clustering directly in the raw
feature space, it embeds nodes into a low-dimensional spectral space
where structure is easier to separate.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-178}

Think of shining light through a prism. The light splits into clear,
separated colors. Similarly, spectral clustering transforms graph data
into a space where groups become naturally separable.

\subsubsection{Deep Dive}\label{deep-dive-178}

\begin{itemize}
\item
  Steps of spectral clustering:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Construct similarity graph and adjacency matrix \(A\).
  \item
    Compute Laplacian \(L = D - A\) (or normalized versions).
  \item
    Find eigenvectors corresponding to the smallest nonzero eigenvalues.
  \item
    Use these eigenvectors as features in k-means clustering.
  \end{enumerate}
\item
  Why it works:

  \begin{itemize}
  \tightlist
  \item
    Eigenvectors encode smooth variations across the graph.
  \item
    Fiedler vector separates weakly connected groups.
  \end{itemize}
\item
  Normalized variants:

  \begin{itemize}
  \tightlist
  \item
    Shi--Malik (normalized cut): uses random-walk Laplacian.
  \item
    Ng--Jordan--Weiss: uses symmetric Laplacian.
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Image segmentation (pixels as graph nodes).
  \item
    Social/community detection.
  \item
    Document clustering.
  \item
    Semi-supervised learning.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2414}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4253}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Variant
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Laplacian Used
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Typical Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Unnormalized spectral & \(L = D - A\) & Small, balanced graphs \\
Shi--Malik (Ncut) & \(L_{rw} = D^{-1}L\) & Image segmentation,
partitioning \\
Ng--Jordan--Weiss & \(L_{sym} = D^{-1/2}LD^{-1/2}\) & General clustering
with normalization \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-168}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ networkx }\ImportTok{as}\NormalTok{ nx}
\ImportTok{from}\NormalTok{ sklearn.cluster }\ImportTok{import}\NormalTok{ KMeans}

\CommentTok{\# Build simple graph}
\NormalTok{G }\OperatorTok{=}\NormalTok{ nx.karate\_club\_graph()}
\NormalTok{L }\OperatorTok{=}\NormalTok{ nx.normalized\_laplacian\_matrix(G).toarray()}

\CommentTok{\# Eigen{-}decomposition}
\NormalTok{eigs, vecs }\OperatorTok{=}\NormalTok{ np.linalg.eigh(L)}

\CommentTok{\# Use k=2 smallest nonzero eigenvectors}
\NormalTok{X }\OperatorTok{=}\NormalTok{ vecs[:,}\DecValTok{1}\NormalTok{:}\DecValTok{3}\NormalTok{]}
\NormalTok{labels }\OperatorTok{=}\NormalTok{ KMeans(n\_clusters}\OperatorTok{=}\DecValTok{2}\NormalTok{, n\_init}\OperatorTok{=}\DecValTok{10}\NormalTok{).fit\_predict(X)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Spectral clustering labels:"}\NormalTok{, labels[:}\DecValTok{10}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-76}

Spectral clustering harnesses graph structure hidden in data,
outperforming traditional clustering in non-Euclidean or highly
structured datasets. It is a cornerstone method linking graph theory
with machine learning.

\subsubsection{Try It Yourself}\label{try-it-yourself-178}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Perform spectral clustering on a graph with two loosely connected
  clusters. Does the Fiedler vector split them?
\item
  Compare spectral clustering with k-means directly on raw
  coordinates---what differences emerge?
\item
  Apply spectral clustering to an image (treating pixels as nodes). How
  do the clusters map to regions?
\end{enumerate}

\subsection{180. Graph-Based AI
Applications}\label{graph-based-ai-applications}

Graphs naturally capture relationships, making them a central structure
for AI. From social networks to molecules, many domains are best modeled
as nodes and edges. Graph-based AI leverages algorithms and neural
architectures to reason, predict, and learn from such structured data.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-179}

Imagine a detective's board with people, places, and events connected by
strings. Graph-based AI is like training an assistant who not only
remembers all the connections but can also infer missing links and
predict what might happen next.

\subsubsection{Deep Dive}\label{deep-dive-179}

\begin{itemize}
\item
  Knowledge graphs: structured representations of entities and
  relations.

  \begin{itemize}
  \tightlist
  \item
    Used in search engines, question answering, and recommender systems.
  \end{itemize}
\item
  Graph Neural Networks (GNNs): extend deep learning to graphs.

  \begin{itemize}
  \tightlist
  \item
    Message-passing framework: nodes update embeddings based on
    neighbors.
  \item
    Variants: GCN, GAT, GraphSAGE.
  \end{itemize}
\item
  Graph embeddings: map nodes/edges/subgraphs into continuous space.

  \begin{itemize}
  \tightlist
  \item
    Enable link prediction, clustering, classification.
  \end{itemize}
\item
  Graph-based algorithms:

  \begin{itemize}
  \tightlist
  \item
    PageRank: ranking nodes by importance.
  \item
    Community detection: finding clusters of related nodes.
  \item
    Random walks: for node embeddings and sampling.
  \end{itemize}
\item
  Applications across AI:

  \begin{itemize}
  \tightlist
  \item
    NLP: semantic parsing, knowledge graphs.
  \item
    Vision: scene graphs, object relationships.
  \item
    Science: molecular property prediction, drug discovery.
  \item
    Robotics: planning with state-space graphs.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1702}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3830}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4468}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Domain
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Graph Representation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Application
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Social networks & Users as nodes, friendships as edges & Influence
prediction, community detection \\
Knowledge graphs & Entities + relations & Question answering, semantic
search \\
Molecules & Atoms as nodes, bonds as edges & Drug discovery, materials
science \\
Scenes & Objects and their relationships & Visual question answering,
scene reasoning \\
Planning & States as nodes, actions as edges & Robotics, reinforcement
learning \\
\end{longtable}

Tiny Code Sample (Python, Graph Neural Network with PyTorch Geometric)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ torch}
\ImportTok{from}\NormalTok{ torch\_geometric.data }\ImportTok{import}\NormalTok{ Data}
\ImportTok{from}\NormalTok{ torch\_geometric.nn }\ImportTok{import}\NormalTok{ GCNConv}

\CommentTok{\# Simple graph with 3 nodes and 2 edges}
\NormalTok{edge\_index }\OperatorTok{=}\NormalTok{ torch.tensor([[}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{],}
\NormalTok{                           [}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{]], dtype}\OperatorTok{=}\NormalTok{torch.}\BuiltInTok{long}\NormalTok{)}
\NormalTok{x }\OperatorTok{=}\NormalTok{ torch.tensor([[}\DecValTok{1}\NormalTok{], [}\DecValTok{2}\NormalTok{], [}\DecValTok{3}\NormalTok{]], dtype}\OperatorTok{=}\NormalTok{torch.}\BuiltInTok{float}\NormalTok{)}

\NormalTok{data }\OperatorTok{=}\NormalTok{ Data(x}\OperatorTok{=}\NormalTok{x, edge\_index}\OperatorTok{=}\NormalTok{edge\_index)}

\KeywordTok{class}\NormalTok{ GCN(torch.nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \VariableTok{self}\NormalTok{.conv1 }\OperatorTok{=}\NormalTok{ GCNConv(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, data):}
        \ControlFlowTok{return} \VariableTok{self}\NormalTok{.conv1(data.x, data.edge\_index)}

\NormalTok{model }\OperatorTok{=}\NormalTok{ GCN()}
\NormalTok{out }\OperatorTok{=}\NormalTok{ model(data)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Node embeddings:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, out)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-77}

Graphs bridge symbolic reasoning and statistical learning, making them a
powerful tool for AI. They enable AI systems to capture structure,
context, and relationships---crucial for understanding language, vision,
and complex real-world systems.

\subsubsection{Try It Yourself}\label{try-it-yourself-179}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a small knowledge graph of three entities and use it to answer
  simple queries.
\item
  Train a GNN on a citation graph dataset and compare with logistic
  regression on node features.
\item
  Explain why graphs are a more natural representation than tables for
  molecules or social networks.
\end{enumerate}

\section{Chapter 19. Logic, Sets and Proof
Techniques}\label{chapter-19.-logic-sets-and-proof-techniques}

\subsection{181. Set Theory Fundamentals}\label{set-theory-fundamentals}

Set theory provides the foundation for modern mathematics, describing
collections of objects and the rules for manipulating them. In AI, sets
underlie probability, logic, databases, and knowledge representation.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-180}

Think of a basket of fruit. The basket is the set, and the fruits are
its elements. You can combine baskets (union), find fruits in both
baskets (intersection), or look at fruits missing from one basket
(difference).

\subsubsection{Deep Dive}\label{deep-dive-180}

\begin{itemize}
\item
  Basic definitions:

  \begin{itemize}
  \tightlist
  \item
    Set = collection of distinct elements.
  \item
    Notation: \(A = \{a, b, c\}\).
  \item
    Empty set: \(\varnothing\).
  \end{itemize}
\item
  Operations:

  \begin{itemize}
  \tightlist
  \item
    Union: \(A \cup B\).
  \item
    Intersection: \(A \cap B\).
  \item
    Difference: \(A \setminus B\).
  \item
    Complement: \(\overline{A}\).
  \end{itemize}
\item
  Special sets:

  \begin{itemize}
  \tightlist
  \item
    Universal set \(U\).
  \item
    Subsets: \(A \subseteq B\).
  \item
    Power set: set of all subsets of \(A\).
  \end{itemize}
\item
  Properties:

  \begin{itemize}
  \tightlist
  \item
    Commutativity, associativity, distributivity.
  \item
    De Morgan's laws:
    \(\overline{A \cup B} = \overline{A} \cap \overline{B}\).
  \end{itemize}
\item
  In AI: forming knowledge bases, defining probability events,
  representing state spaces.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1714}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2143}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.6143}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Operation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Union & \(A \cup B\) & Merging candidate features from two sources \\
Intersection & \(A \cap B\) & Common tokens in NLP vocabulary \\
Difference & \(A \setminus B\) & Features unique to one dataset \\
Power set & \(2^A\) & All possible feature subsets \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-169}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ \{}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{\}}
\NormalTok{B }\OperatorTok{=}\NormalTok{ \{}\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{\}}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Union:"}\NormalTok{, A }\OperatorTok{|}\NormalTok{ B)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Intersection:"}\NormalTok{, A }\OperatorTok{\&}\NormalTok{ B)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Difference:"}\NormalTok{, A }\OperatorTok{{-}}\NormalTok{ B)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Power set:"}\NormalTok{, [\{x }\ControlFlowTok{for}\NormalTok{ i,x }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(A) }\ControlFlowTok{if}\NormalTok{ (mask}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{i)}\OperatorTok{\&}\DecValTok{1}\NormalTok{\} }
                     \ControlFlowTok{for}\NormalTok{ mask }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\BuiltInTok{len}\NormalTok{(A))])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-78}

Set theory provides the language for probability, logic, and data
representation in AI. From defining event spaces in machine learning to
structuring knowledge graphs, sets offer a precise way to reason about
collections.

\subsubsection{Try It Yourself}\label{try-it-yourself-180}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write down two sets of words (e.g., \{cat, dog, fish\}, \{dog,
  bird\}). Compute their union and intersection.
\item
  List the power set of \{a, b\}.
\item
  Use De Morgan's law to simplify \(\overline{(A \cup B)}\) when
  \(A={1,2}\), \(B={2,3}\), \(U={1,2,3,4}\).
\end{enumerate}

\subsection{182. Relations and Functions}\label{relations-and-functions}

Relations describe connections between elements of sets, while functions
are special relations that assign exactly one output to each input.
These ideas underpin mappings, transformations, and dependencies across
mathematics and AI.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-181}

Imagine a school roster. A relation could pair each student with every
course they take. A function is stricter: each student gets exactly one
unique ID number.

\subsubsection{Deep Dive}\label{deep-dive-181}

\begin{itemize}
\item
  Relations:

  \begin{itemize}
  \tightlist
  \item
    A relation \(R\) between sets \(A\) and \(B\) is a subset of
    \(A \times B\).
  \item
    Examples: ``is a friend of,'' ``is greater than.''
  \item
    Properties: reflexive, symmetric, transitive, antisymmetric.
  \end{itemize}
\item
  Equivalence relations: reflexive, symmetric, transitive → partition
  set into equivalence classes.
\item
  Partial orders: reflexive, antisymmetric, transitive → define
  hierarchies.
\item
  Functions:

  \begin{itemize}
  \tightlist
  \item
    Special relation: \(f: A \to B\).
  \item
    Each \(a \in A\) has exactly one \(b \in B\).
  \item
    Surjective (onto), injective (one-to-one), bijective (both).
  \end{itemize}
\item
  In AI:

  \begin{itemize}
  \tightlist
  \item
    Relations: knowledge graphs (entities + relations).
  \item
    Functions: mappings from input features to predictions.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1980}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3564}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4455}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Relation & Subset of \(A \times B\) & User--item rating pairs in
recommender systems \\
Equivalence relation & Reflexive, symmetric, transitive & Grouping
synonyms in NLP \\
Partial order & Reflexive, antisymmetric, transitive & Task dependency
graph in scheduling \\
Function & Maps input to single output & Neural network mapping x → y \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-170}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Relation: list of pairs}
\NormalTok{students }\OperatorTok{=}\NormalTok{ \{}\StringTok{"Alice"}\NormalTok{, }\StringTok{"Bob"}\NormalTok{\}}
\NormalTok{courses }\OperatorTok{=}\NormalTok{ \{}\StringTok{"Math"}\NormalTok{, }\StringTok{"CS"}\NormalTok{\}}
\NormalTok{relation }\OperatorTok{=}\NormalTok{ \{(}\StringTok{"Alice"}\NormalTok{, }\StringTok{"Math"}\NormalTok{), (}\StringTok{"Bob"}\NormalTok{, }\StringTok{"CS"}\NormalTok{), (}\StringTok{"Alice"}\NormalTok{, }\StringTok{"CS"}\NormalTok{)\}}

\CommentTok{\# Function: mapping}
\NormalTok{f }\OperatorTok{=}\NormalTok{ \{}\StringTok{"Alice"}\NormalTok{: }\StringTok{"ID001"}\NormalTok{, }\StringTok{"Bob"}\NormalTok{: }\StringTok{"ID002"}\NormalTok{\}}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Relation:"}\NormalTok{, relation)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Function mapping:"}\NormalTok{, f)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-79}

Relations give AI systems the ability to represent structured
connections like ``works at'' or ``is similar to.'' Functions guarantee
consistent mappings, essential in deterministic prediction tasks. This
distinction underlies both symbolic and statistical approaches to AI.

\subsubsection{Try It Yourself}\label{try-it-yourself-181}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Give an example of a relation that is symmetric but not transitive.
\item
  Define a function \(f: \{1,2,3\} \to \{a,b\}\). Is it surjective?
  Injective?
\item
  Explain why equivalence relations are useful for clustering in AI.
\end{enumerate}

\subsection{183. Propositional Logic}\label{propositional-logic}

Propositional logic formalizes reasoning with statements that can be
true or false. It uses logical operators to build complex expressions
and determine truth systematically.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-182}

Imagine a set of switches that can be either ON (true) or OFF (false).
Combining them with rules like ``AND,'' ``OR,'' and ``NOT'' lets you
create more complex circuits. Propositional logic works like that:
simple truths combine into structured reasoning.

\subsubsection{Deep Dive}\label{deep-dive-182}

\begin{itemize}
\item
  Propositions: declarative statements with truth values (e.g., ``It is
  raining'').
\item
  Logical connectives:

  \begin{itemize}
  \tightlist
  \item
    NOT (¬p): true if p is false.
  \item
    AND (p ∧ q): true if both are true.
  \item
    OR (p ∨ q): true if at least one is true.
  \item
    IMPLIES (p → q): false only if p is true and q is false.
  \item
    IFF (p ↔ q): true if p and q have same truth value.
  \end{itemize}
\item
  Truth tables: define behavior of operators.
\item
  Normal forms:

  \begin{itemize}
  \tightlist
  \item
    CNF (conjunctive normal form): AND of ORs.
  \item
    DNF (disjunctive normal form): OR of ANDs.
  \end{itemize}
\item
  Inference: rules like modus ponens (p → q, p ⇒ q).
\item
  In AI: SAT solvers, planning, rule-based expert systems.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2097}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0968}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2742}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4194}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Operator
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Symbol
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example (p=Rain, q=Cloudy)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Negation & ¬p & Opposite truth & ¬p = ``Not raining'' \\
Conjunction & p ∧ q & Both true & ``Raining AND Cloudy'' \\
Disjunction & p ∨ q & At least one true & ``Raining OR Cloudy'' \\
Implication & p → q & If p then q & ``If raining then cloudy'' \\
Biconditional & p ↔ q & Both same truth & ``Raining iff cloudy'' \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-171}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Truth table for implication}
\ImportTok{import}\NormalTok{ itertools}

\KeywordTok{def}\NormalTok{ implies(p, q):}
    \ControlFlowTok{return}\NormalTok{ (}\KeywordTok{not}\NormalTok{ p) }\KeywordTok{or}\NormalTok{ q}

\BuiltInTok{print}\NormalTok{(}\StringTok{"p q | p→q"}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ p, q }\KeywordTok{in}\NormalTok{ itertools.product([}\VariableTok{False}\NormalTok{, }\VariableTok{True}\NormalTok{], repeat}\OperatorTok{=}\DecValTok{2}\NormalTok{):}
    \BuiltInTok{print}\NormalTok{(p, q, }\StringTok{"|"}\NormalTok{, implies(p,q))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-80}

Propositional logic is the simplest formal system of reasoning and the
foundation for more expressive logics. In AI, it powers SAT solvers,
which in turn drive verification, planning, and optimization engines at
scale.

\subsubsection{Try It Yourself}\label{try-it-yourself-182}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a truth table for (p ∧ q) → r.
\item
  Convert (¬p ∨ q) into CNF and DNF.
\item
  Explain how propositional logic could represent constraints in a
  scheduling problem.
\end{enumerate}

\subsection{184. Predicate Logic and
Quantifiers}\label{predicate-logic-and-quantifiers}

Predicate logic (first-order logic) extends propositional logic by
allowing statements about objects and their properties, using
quantifiers to express generality. It can capture more complex
relationships and forms the backbone of formal reasoning in AI.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-183}

Think of propositional logic as reasoning with whole sentences: ``It is
raining.'' Predicate logic opens them up: ``For every city, if it is
cloudy, then it rains.'' Quantifiers let us say ``for all'' or ``there
exists,'' making reasoning far richer.

\subsubsection{Deep Dive}\label{deep-dive-183}

\begin{itemize}
\item
  Predicates: functions that return true/false depending on input.

  \begin{itemize}
  \tightlist
  \item
    Example: Likes(Alice, IceCream).
  \end{itemize}
\item
  Quantifiers:

  \begin{itemize}
  \tightlist
  \item
    Universal (∀x P(x)): P(x) holds for all x.
  \item
    Existential (∃x P(x)): P(x) holds for at least one x.
  \end{itemize}
\item
  Syntax examples:

  \begin{itemize}
  \tightlist
  \item
    ∀x (Human(x) → Mortal(x))
  \item
    ∃y (Student(y) ∧ Studies(y, AI))
  \end{itemize}
\item
  Semantics: defined over domains of discourse.
\item
  Inference rules:

  \begin{itemize}
  \tightlist
  \item
    Universal instantiation: from ∀x P(x), infer P(a).
  \item
    Existential generalization: from P(a), infer ∃x P(x).
  \end{itemize}
\item
  In AI: knowledge representation, natural language understanding,
  automated reasoning.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2278}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0759}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4051}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2911}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Element
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Symbol
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Predicate & P(x) & Property or relation of object x & Human(Socrates) \\
Universal quant. & ∀x & For all x & ∀x Human(x) → Mortal(x) \\
Existential quant. & ∃x & There exists x & ∃x Loves(x, IceCream) \\
Nested quantifiers & ∀x∃y & For each x, there is a y & ∀x ∃y
Parent(y,x) \\
\end{longtable}

Tiny Code Sample (Python, simple predicate logic)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Domain of people and properties}
\NormalTok{people }\OperatorTok{=}\NormalTok{ [}\StringTok{"Alice"}\NormalTok{, }\StringTok{"Bob"}\NormalTok{, }\StringTok{"Charlie"}\NormalTok{]}
\NormalTok{likes\_icecream }\OperatorTok{=}\NormalTok{ \{}\StringTok{"Alice"}\NormalTok{, }\StringTok{"Charlie"}\NormalTok{\}}

\CommentTok{\# Predicate}
\KeywordTok{def}\NormalTok{ LikesIcecream(x):}
    \ControlFlowTok{return}\NormalTok{ x }\KeywordTok{in}\NormalTok{ likes\_icecream}

\CommentTok{\# Universal quantifier}
\NormalTok{all\_like }\OperatorTok{=} \BuiltInTok{all}\NormalTok{(LikesIcecream(p) }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ people)}

\CommentTok{\# Existential quantifier}
\NormalTok{exists\_like }\OperatorTok{=} \BuiltInTok{any}\NormalTok{(LikesIcecream(p) }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ people)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"∀x LikesIcecream(x):"}\NormalTok{, all\_like)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"∃x LikesIcecream(x):"}\NormalTok{, exists\_like)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-81}

Predicate logic allows AI systems to represent structured knowledge and
reason with it. Unlike propositional logic, it scales to domains with
many objects and relationships, making it essential for semantic
parsing, theorem proving, and symbolic AI.

\subsubsection{Try It Yourself}\label{try-it-yourself-183}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Express ``All cats are mammals, some mammals are pets'' in predicate
  logic.
\item
  Translate ``Every student studies some course'' into formal notation.
\item
  Explain why predicate logic is more powerful than propositional logic
  for knowledge graphs.
\end{enumerate}

\subsection{185. Logical Inference and
Deduction}\label{logical-inference-and-deduction}

Logical inference is the process of deriving new truths from known ones
using formal rules of deduction. Deduction ensures that if the premises
are true, the conclusion must also be true, providing a foundation for
automated reasoning in AI.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-184}

Think of a chain of dominoes. Each piece represents a logical statement.
If the first falls (premise is true), the rules ensure that the next
falls, and eventually the conclusion is reached without contradiction.

\subsubsection{Deep Dive}\label{deep-dive-184}

\begin{itemize}
\item
  Inference rules:

  \begin{itemize}
  \tightlist
  \item
    Modus Ponens: from \(p → q\) and \(p\), infer \(q\).
  \item
    Modus Tollens: from \(p → q\) and ¬q, infer ¬p.
  \item
    Hypothetical Syllogism: from \(p → q\), \(q → r\), infer \(p → r\).
  \item
    Universal Instantiation: from ∀x P(x), infer P(a).
  \end{itemize}
\item
  Deduction systems:

  \begin{itemize}
  \tightlist
  \item
    Natural deduction (step-by-step reasoning).
  \item
    Resolution (refutation-based).
  \item
    Sequent calculus.
  \end{itemize}
\item
  Soundness: if a conclusion can be derived, it must be true in all
  models.
\item
  Completeness: all truths in the system can, in principle, be derived.
\item
  In AI: SAT solvers, expert systems, theorem proving, program
  verification.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2340}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2553}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5106}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Rule
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formulation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Modus Ponens & \(p, p → q ⟹ q\) & If it rains, the ground gets wet. It
rains ⇒ wet \\
Modus Tollens & \(p → q, ¬q ⟹ ¬p\) & If rain ⇒ wet. Ground not wet ⇒ no
rain \\
Hypothetical Syllogism & \(p → q, q → r ⟹ p → r\) & If A is human ⇒
mortal, mortal ⇒ dies ⇒ A dies \\
Resolution & Eliminate contradictions & Used in SAT solving \\
\end{longtable}

Tiny Code Sample (Python: Modus Ponens)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ modus\_ponens(p, implication):}
    \CommentTok{\# implication in form (p, q)}
\NormalTok{    antecedent, consequent }\OperatorTok{=}\NormalTok{ implication}
    \ControlFlowTok{if}\NormalTok{ p }\OperatorTok{==}\NormalTok{ antecedent:}
        \ControlFlowTok{return}\NormalTok{ consequent}
    \ControlFlowTok{return} \VariableTok{None}

\BuiltInTok{print}\NormalTok{(}\StringTok{"From (p → q) and p, infer q:"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(modus\_ponens(}\StringTok{"It rains"}\NormalTok{, (}\StringTok{"It rains"}\NormalTok{, }\StringTok{"Ground is wet"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-82}

Inference and deduction provide the reasoning backbone for symbolic AI.
They allow systems not just to store knowledge but to derive
consequences, verify consistency, and explain their reasoning
steps---critical for trustworthy AI.

\subsubsection{Try It Yourself}\label{try-it-yourself-184}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use Modus Ponens to infer: ``If AI learns, it improves. AI learns.''
\item
  Show why resolution is powerful for proving contradictions in
  propositional logic.
\item
  Explain how completeness guarantees that no valid inference is left
  unreachable.
\end{enumerate}

\subsection{186. Proof Techniques: Direct, Contradiction,
Induction}\label{proof-techniques-direct-contradiction-induction}

Proof techniques provide structured methods for demonstrating that
statements are true. Direct proofs build step-by-step arguments, proof
by contradiction shows that denying the claim leads to impossibility,
and induction proves statements for all natural numbers by building on
simpler cases.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-185}

Imagine climbing a staircase. Direct proof is like walking up the steps
in order. Proof by contradiction is like assuming the staircase ends
suddenly and discovering that would make the entire building collapse.
Induction is like proving you can step onto the first stair, and if you
can move from one stair to the next, you can reach any stair.

\subsubsection{Deep Dive}\label{deep-dive-185}

\begin{itemize}
\item
  Direct proof:

  \begin{itemize}
  \tightlist
  \item
    Assume premises and apply logical rules until the conclusion is
    reached.
  \item
    Example: prove that the sum of two even numbers is even.
  \end{itemize}
\item
  Proof by contradiction:

  \begin{itemize}
  \tightlist
  \item
    Assume the negation of the statement.
  \item
    Show this assumption leads to inconsistency.
  \item
    Example: proof that √2 is irrational.
  \end{itemize}
\item
  Proof by induction:

  \begin{itemize}
  \tightlist
  \item
    Base case: show statement holds for n=1.
  \item
    Inductive step: assume it holds for n=k, prove it for n=k+1.
  \item
    Example: sum of first n integers = n(n+1)/2.
  \end{itemize}
\item
  Applications in AI: formal verification of algorithms, correctness
  proofs, mathematical foundations of learning theory.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1340}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3505}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5155}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI/Math
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Direct proof & Build argument step by step & Prove gradient descent
converges under assumptions \\
Contradiction & Assume false, derive impossibility & Show no smaller
counterexample exists \\
Induction & Base case + inductive step & Proof of recursive algorithm
correctness \\
\end{longtable}

Tiny Code Sample (Python: Induction Idea)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Verify induction hypothesis for sum of integers}
\KeywordTok{def}\NormalTok{ formula(n):}
    \ControlFlowTok{return}\NormalTok{ n}\OperatorTok{*}\NormalTok{(n}\OperatorTok{+}\DecValTok{1}\NormalTok{)}\OperatorTok{//}\DecValTok{2}

\CommentTok{\# Check base case and a few steps}
\ControlFlowTok{for}\NormalTok{ n }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{6}\NormalTok{):}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"n=}\SpecialCharTok{\{}\NormalTok{n}\SpecialCharTok{\}}\SpecialStringTok{, sum=}\SpecialCharTok{\{}\BuiltInTok{sum}\NormalTok{(}\BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{,n}\OperatorTok{+}\DecValTok{1}\NormalTok{))}\SpecialCharTok{\}}\SpecialStringTok{, formula=}\SpecialCharTok{\{}\NormalTok{formula(n)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-83}

Proof techniques give rigor to reasoning in AI and computer science.
They ensure algorithms behave as expected, prevent hidden
contradictions, and provide guarantees---especially important in
safety-critical AI systems.

\subsubsection{Try It Yourself}\label{try-it-yourself-185}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a direct proof that the product of two odd numbers is odd.
\item
  Use contradiction to prove there is no largest prime number.
\item
  Apply induction to show that a binary tree with n nodes has exactly
  n−1 edges.
\end{enumerate}

\subsection{187. Mathematical Induction in
Depth}\label{mathematical-induction-in-depth}

Mathematical induction is a proof technique tailored to statements about
integers or recursively defined structures. It shows that if a property
holds for a base case and persists from \(n\) to \(n+1\), then it holds
universally. Strong induction and structural induction extend the idea
further.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-186}

Think of a row of dominoes. Knocking down the first (base case) and
proving each one pushes the next (inductive step) ensures the whole line
falls. Induction guarantees the truth of infinitely many cases with just
two steps.

\subsubsection{Deep Dive}\label{deep-dive-186}

\begin{itemize}
\item
  Ordinary induction:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Base case: prove statement for \(n=1\).
  \item
    Inductive hypothesis: assume statement holds for \(n=k\).
  \item
    Inductive step: prove statement for \(n=k+1\).
  \end{enumerate}
\item
  Strong induction:

  \begin{itemize}
  \tightlist
  \item
    Assume statement holds for all cases up to \(k\), then prove for
    \(k+1\).
  \item
    Useful when the \(k+1\) case depends on multiple earlier cases.
  \end{itemize}
\item
  Structural induction:

  \begin{itemize}
  \tightlist
  \item
    Extends induction to trees, graphs, or recursively defined data.
  \item
    Base case: prove for simplest structure.
  \item
    Inductive step: assume for substructures, prove for larger ones.
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Proving algorithm correctness (e.g., recursive sorting).
  \item
    Verifying properties of data structures.
  \item
    Formal reasoning about grammars and logical systems.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1800}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2100}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4100}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type of Induction
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Base Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Inductive Step
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI/CS
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Ordinary induction & \(n=1\) & From \(n=k\) ⇒ \(n=k+1\) & Proof of
arithmetic formulas \\
Strong induction & \(n=1\) & From all ≤k ⇒ \(n=k+1\) & Proving
correctness of divide-and-conquer \\
Structural induction & Smallest structure & From parts ⇒ whole & Proof
of correctness for syntax trees \\
\end{longtable}

Tiny Code Sample (Python, checking induction idea)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Verify sum of first n squares formula by brute force}
\KeywordTok{def}\NormalTok{ sum\_squares(n): }\ControlFlowTok{return} \BuiltInTok{sum}\NormalTok{(i}\OperatorTok{*}\NormalTok{i }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{,n}\OperatorTok{+}\DecValTok{1}\NormalTok{))}
\KeywordTok{def}\NormalTok{ formula(n): }\ControlFlowTok{return}\NormalTok{ n}\OperatorTok{*}\NormalTok{(n}\OperatorTok{+}\DecValTok{1}\NormalTok{)}\OperatorTok{*}\NormalTok{(}\DecValTok{2}\OperatorTok{*}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\NormalTok{)}\OperatorTok{//}\DecValTok{6}

\ControlFlowTok{for}\NormalTok{ n }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{6}\NormalTok{):}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"n=}\SpecialCharTok{\{}\NormalTok{n}\SpecialCharTok{\}}\SpecialStringTok{, sum=}\SpecialCharTok{\{}\NormalTok{sum\_squares(n)}\SpecialCharTok{\}}\SpecialStringTok{, formula=}\SpecialCharTok{\{}\NormalTok{formula(n)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-84}

Induction provides a rigorous way to prove correctness of AI algorithms
and recursive models. It ensures trust in results across infinite cases,
making it essential in theory, programming, and verification.

\subsubsection{Try It Yourself}\label{try-it-yourself-186}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Prove by induction that \(1+2+...+n = n(n+1)/2\).
\item
  Use strong induction to prove that every integer ≥2 is a product of
  primes.
\item
  Apply structural induction to show that a binary tree with n nodes has
  n−1 edges.
\end{enumerate}

\subsection{188. Recursion and
Well-Foundedness}\label{recursion-and-well-foundedness}

Recursion defines objects or processes in terms of themselves, with a
base case anchoring the definition. Well-foundedness ensures recursion
doesn't loop forever: every recursive call must move closer to a base
case. Together, they guarantee termination and correctness.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-187}

Imagine Russian nesting dolls. Each doll contains a smaller one, until
you reach the smallest. Recursion works the same way---problems are
broken into smaller pieces until the simplest case is reached.

\subsubsection{Deep Dive}\label{deep-dive-187}

\begin{itemize}
\item
  Recursive definitions:

  \begin{itemize}
  \tightlist
  \item
    Factorial: \(n! = n \times (n-1)!\), with \(0! = 1\).
  \item
    Fibonacci: \(F(n) = F(n-1) + F(n-2)\), with \(F(0)=0, F(1)=1\).
  \end{itemize}
\item
  Well-foundedness:

  \begin{itemize}
  \tightlist
  \item
    Requires a measure (like size of n) that decreases at every step.
  \item
    Prevents infinite descent.
  \end{itemize}
\item
  Structural recursion:

  \begin{itemize}
  \tightlist
  \item
    Defined on data structures like lists or trees.
  \item
    Example: sum of list = head + sum(tail).
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Recursive search (DFS, minimax in games).
  \item
    Recursive neural networks for structured data.
  \item
    Inductive definitions in knowledge representation.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2353}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3882}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3765}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Base case & Anchor for recursion & \(F(0)=0\), \(F(1)=1\) in
Fibonacci \\
Recursive case & Define larger in terms of smaller & DFS visits
neighbors recursively \\
Well-foundedness & Guarantees termination & Depth decreases in search \\
Structural recursion & Recursion on data structures & Parsing trees in
NLP \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-172}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ factorial(n):}
    \ControlFlowTok{if}\NormalTok{ n }\OperatorTok{==} \DecValTok{0}\NormalTok{:   }\CommentTok{\# base case}
        \ControlFlowTok{return} \DecValTok{1}
    \ControlFlowTok{return}\NormalTok{ n }\OperatorTok{*}\NormalTok{ factorial(n}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)  }\CommentTok{\# recursive case}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Factorial 5:"}\NormalTok{, factorial(}\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-85}

Recursion is fundamental to algorithms, data structures, and AI
reasoning. Ensuring well-foundedness avoids infinite loops and
guarantees correctness---critical for search algorithms, symbolic
reasoning, and recursive neural models.

\subsubsection{Try It Yourself}\label{try-it-yourself-187}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a recursive function to compute the nth Fibonacci number. Prove
  it terminates.
\item
  Define a recursive function to count nodes in a binary tree.
\item
  Explain how minimax recursion in game AI relies on well-foundedness.
\end{enumerate}

\subsection{189. Formal Systems and
Completeness}\label{formal-systems-and-completeness}

A formal system is a framework consisting of symbols, rules for forming
expressions, and rules for deriving theorems. Completeness describes
whether the system can express and prove all truths within its intended
scope. Together, they define the boundaries of formal reasoning in
mathematics and AI.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-188}

Imagine a game with pieces (symbols), rules for valid moves (syntax),
and strategies to reach checkmate (proofs). A formal system is like such
a game---but instead of chess, it encodes mathematics or logic.
Completeness asks: ``Can every winning position be reached using the
rules?''

\subsubsection{Deep Dive}\label{deep-dive-188}

\begin{itemize}
\item
  Components of a formal system:

  \begin{itemize}
  \tightlist
  \item
    Alphabet: finite set of symbols.
  \item
    Grammar: rules to build well-formed formulas.
  \item
    Axioms: starting truths.
  \item
    Inference rules: how to derive theorems.
  \end{itemize}
\item
  Soundness: everything derivable is true.
\item
  Completeness: everything true is derivable.
\item
  Gödel's completeness theorem (first-order logic): every logically
  valid formula can be proven.
\item
  Gödel's incompleteness theorem: in arithmetic, no consistent formal
  system can be both complete and decidable.
\item
  In AI:

  \begin{itemize}
  \tightlist
  \item
    Used in theorem provers, logic programming (Prolog).
  \item
    Defines limits of symbolic reasoning.
  \item
    Influences design of verification tools and knowledge
    representation.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1429}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4388}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4184}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI/Logic
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Formal system & Symbols + rules for expressions + inference &
Propositional calculus, first-order logic \\
Soundness & Derivations ⊆ truths & No false theorem provable \\
Completeness & Truths ⊆ derivations & All valid statements can be
proved \\
Incompleteness & Some truths unprovable in system & Gödel's theorem for
arithmetic \\
\end{longtable}

Tiny Code Sample (Prolog Example)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\% Simple formal system in Prolog}
\NormalTok{parent(alice}\KeywordTok{,}\NormalTok{ bob)}\KeywordTok{.}
\NormalTok{parent(bob}\KeywordTok{,}\NormalTok{ carol)}\KeywordTok{.}

\NormalTok{ancestor(}\DataTypeTok{X}\KeywordTok{,}\DataTypeTok{Y}\NormalTok{) }\KeywordTok{:{-}}\NormalTok{ parent(}\DataTypeTok{X}\KeywordTok{,}\DataTypeTok{Y}\NormalTok{)}\KeywordTok{.}
\NormalTok{ancestor(}\DataTypeTok{X}\KeywordTok{,}\DataTypeTok{Y}\NormalTok{) }\KeywordTok{:{-}}\NormalTok{ parent(}\DataTypeTok{X}\KeywordTok{,}\DataTypeTok{Z}\NormalTok{)}\KeywordTok{,}\NormalTok{ ancestor(}\DataTypeTok{Z}\KeywordTok{,}\DataTypeTok{Y}\NormalTok{)}\KeywordTok{.}

\CommentTok{\% Query: ?{-} ancestor(alice, carol).}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-86}

Formal systems and completeness define the power and limits of
logic-based AI. They ensure reasoning is rigorous but also highlight
boundaries---no single system can capture all mathematical truths. This
awareness shapes how AI blends symbolic and statistical approaches.

\subsubsection{Try It Yourself}\label{try-it-yourself-188}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define axioms and inference rules for propositional logic as a formal
  system.
\item
  Explain the difference between soundness and completeness using an
  example.
\item
  Reflect on why Gödel's incompleteness is important for AI safety and
  reasoning.
\end{enumerate}

\subsection{190. Logic in AI Reasoning
Systems}\label{logic-in-ai-reasoning-systems}

Logic provides a structured way for AI systems to represent knowledge
and reason with it. From rule-based systems to modern neuro-symbolic AI,
logical reasoning enables deduction, consistency checking, and
explanation.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-189}

Think of an AI as a detective. It gathers facts (``Alice is Bob's
parent''), applies rules (``All parents are ancestors''), and deduces
new conclusions (``Alice is Carol's ancestor''). Logic gives the
detective both the notebook (representation) and the reasoning rules
(inference).

\subsubsection{Deep Dive}\label{deep-dive-189}

\begin{itemize}
\item
  Rule-based reasoning:

  \begin{itemize}
  \tightlist
  \item
    Expert systems represent knowledge as IF--THEN rules.
  \item
    Inference engines apply forward or backward chaining.
  \end{itemize}
\item
  Knowledge representation:

  \begin{itemize}
  \tightlist
  \item
    Ontologies and semantic networks structure logical relationships.
  \item
    Description logics form the basis of the Semantic Web.
  \end{itemize}
\item
  Uncertainty in logic:

  \begin{itemize}
  \tightlist
  \item
    Probabilistic logics combine probability with deductive reasoning.
  \item
    Useful for noisy, real-world AI.
  \end{itemize}
\item
  Neuro-symbolic integration:

  \begin{itemize}
  \tightlist
  \item
    Combines neural networks with logical reasoning.
  \item
    Example: neural models extract facts, logic enforces consistency.
  \end{itemize}
\item
  Applications:

  \begin{itemize}
  \tightlist
  \item
    Automated planning and scheduling.
  \item
    Natural language understanding.
  \item
    Verification of AI models.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2381}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3714}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3905}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Mechanism
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Rule-based expert systems & Forward/backward chaining & Medical
diagnosis (MYCIN) \\
Description logics & Formal semantics for ontologies & Semantic Web,
knowledge graphs \\
Probabilistic logics & Add uncertainty to logical frameworks & AI for
robotics in uncertain environments \\
Neuro-symbolic AI & Neural + symbolic reasoning integration &
Knowledge-grounded NLP \\
\end{longtable}

Tiny Code Sample (Prolog)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\% Facts}
\NormalTok{parent(alice}\KeywordTok{,}\NormalTok{ bob)}\KeywordTok{.}
\NormalTok{parent(bob}\KeywordTok{,}\NormalTok{ carol)}\KeywordTok{.}

\CommentTok{\% Rule}
\NormalTok{ancestor(}\DataTypeTok{X}\KeywordTok{,}\DataTypeTok{Y}\NormalTok{) }\KeywordTok{:{-}}\NormalTok{ parent(}\DataTypeTok{X}\KeywordTok{,}\DataTypeTok{Y}\NormalTok{)}\KeywordTok{.}
\NormalTok{ancestor(}\DataTypeTok{X}\KeywordTok{,}\DataTypeTok{Y}\NormalTok{) }\KeywordTok{:{-}}\NormalTok{ parent(}\DataTypeTok{X}\KeywordTok{,}\DataTypeTok{Z}\NormalTok{)}\KeywordTok{,}\NormalTok{ ancestor(}\DataTypeTok{Z}\KeywordTok{,}\DataTypeTok{Y}\NormalTok{)}\KeywordTok{.}

\CommentTok{\% Query: ?{-} ancestor(alice, carol).}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-87}

Logic brings transparency, interpretability, and rigor to AI. While deep
learning excels at pattern recognition, logic ensures decisions are
consistent and explainable---critical for safety, fairness, and
accountability.

\subsubsection{Try It Yourself}\label{try-it-yourself-189}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write three facts about family relationships and a rule to infer
  grandparents.
\item
  Show how forward chaining can derive new knowledge from initial facts.
\item
  Explain how logic could complement deep learning in natural language
  question answering.
\end{enumerate}

\section{Chapter 20. Stochastic Process and Markov
chains}\label{chapter-20.-stochastic-process-and-markov-chains}

\subsection{191. Random Processes and
Sequences}\label{random-processes-and-sequences}

A random process is a collection of random variables indexed by time or
space, describing how uncertainty evolves. Sequences like coin tosses,
signals, or sensor readings can be modeled as realizations of such
processes, forming the basis for stochastic modeling in AI.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-190}

Think of flipping a coin repeatedly. Each toss is uncertain, but
together they form a sequence with a well-defined structure. Over time,
patterns emerge---like the proportion of heads approaching 0.5.

\subsubsection{Deep Dive}\label{deep-dive-190}

\begin{itemize}
\item
  Random sequences: ordered collections of random variables
  \(\{X_t\}_{t=1}^\infty\).
\item
  Random processes: map from index set (time, space) to outcomes.

  \begin{itemize}
  \tightlist
  \item
    Discrete-time vs continuous-time.
  \item
    Discrete-state vs continuous-state.
  \end{itemize}
\item
  Key properties:

  \begin{itemize}
  \tightlist
  \item
    Mean function: \(m(t) = E[X_t]\).
  \item
    Autocorrelation: \(R(s,t) = E[X_s X_t]\).
  \item
    Stationarity: statistical properties invariant over time.
  \end{itemize}
\item
  Examples:

  \begin{itemize}
  \tightlist
  \item
    IID sequence: independent identically distributed.
  \item
    Random walk: sum of IID noise terms.
  \item
    Gaussian process: every finite subset has multivariate normal
    distribution.
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Time-series prediction.
  \item
    Bayesian optimization (Gaussian processes).
  \item
    Modeling sensor noise in robotics.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1818}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3977}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4205}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Process Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
IID sequence & Independent, identical distribution & Shuffling training
data \\
Random walk & Incremental sum of noise & Stock price models \\
Gaussian process & Distribution over functions & Bayesian regression \\
Poisson process & Random events over time & Queueing systems, rare event
modeling \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-173}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}

\CommentTok{\# Simulate random walk}
\NormalTok{np.random.seed(}\DecValTok{0}\NormalTok{)}
\NormalTok{steps }\OperatorTok{=}\NormalTok{ np.random.choice([}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{], size}\OperatorTok{=}\DecValTok{100}\NormalTok{)}
\NormalTok{random\_walk }\OperatorTok{=}\NormalTok{ np.cumsum(steps)}

\NormalTok{plt.plot(random\_walk)}
\NormalTok{plt.title(}\StringTok{"Random Walk"}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-88}

Random processes provide the mathematical foundation for uncertainty
over time. In AI, they power predictive models, reinforcement learning,
Bayesian inference, and uncertainty quantification. Without them,
modeling dynamic, noisy environments would be impossible.

\subsubsection{Try It Yourself}\label{try-it-yourself-190}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate 100 coin tosses and compute the empirical frequency of heads.
\item
  Generate a Gaussian process with mean 0 and RBF kernel, and sample 3
  functions.
\item
  Explain how a random walk could model user behavior in recommendation
  systems.
\end{enumerate}

\subsection{192. Stationarity and
Ergodicity}\label{stationarity-and-ergodicity}

Stationarity describes when the statistical properties of a random
process do not change over time. Ergodicity ensures that long-run
averages from a single sequence equal expectations over the entire
process. Together, they provide the foundations for making reliable
inferences from time series.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-191}

Imagine watching waves at the beach. If the overall pattern of wave
height doesn't change day to day, the process is stationary. If one long
afternoon of observation gives you the same average as many afternoons
combined, the process is ergodic.

\subsubsection{Deep Dive}\label{deep-dive-191}

\begin{itemize}
\item
  Stationarity:

  \begin{itemize}
  \tightlist
  \item
    \emph{Strict-sense}: all joint distributions are time-invariant.
  \item
    \emph{Weak-sense}: mean and autocovariance depend only on lag, not
    absolute time.
  \item
    Examples: white noise (stationary), stock prices (non-stationary).
  \end{itemize}
\item
  Ergodicity:

  \begin{itemize}
  \tightlist
  \item
    Ensures time averages ≈ ensemble averages.
  \item
    Needed when we only have one sequence (common in practice).
  \end{itemize}
\item
  Testing stationarity:

  \begin{itemize}
  \tightlist
  \item
    Visual inspection (mean, variance drift).
  \item
    Unit root tests (ADF, KPSS).
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Reliable training on time-series data.
  \item
    Reinforcement learning policies assume ergodicity of environment
    states.
  \item
    Signal processing in robotics and speech.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2088}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4396}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3516}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Strict stationarity & Full distribution time-invariant & White noise
process \\
Weak stationarity & Mean, variance stable; covariance by lag & ARMA
models in forecasting \\
Ergodicity & Time average = expectation & Long-run reward estimation in
RL \\
\end{longtable}

Tiny Code Sample (Python, checking weak stationarity)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{from}\NormalTok{ statsmodels.tsa.stattools }\ImportTok{import}\NormalTok{ adfuller}

\CommentTok{\# Generate AR(1) process: X\_t = 0.7 X\_\{t{-}1\} + noise}
\NormalTok{np.random.seed(}\DecValTok{0}\NormalTok{)}
\NormalTok{n }\OperatorTok{=} \DecValTok{200}
\NormalTok{x }\OperatorTok{=}\NormalTok{ np.zeros(n)}
\ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, n):}
\NormalTok{    x[t] }\OperatorTok{=} \FloatTok{0.7} \OperatorTok{*}\NormalTok{ x[t}\OperatorTok{{-}}\DecValTok{1}\NormalTok{] }\OperatorTok{+}\NormalTok{ np.random.randn()}

\NormalTok{plt.plot(x)}
\NormalTok{plt.title(}\StringTok{"AR(1) Process"}\NormalTok{)}
\NormalTok{plt.show()}

\CommentTok{\# Augmented Dickey{-}Fuller test for stationarity}
\NormalTok{result }\OperatorTok{=}\NormalTok{ adfuller(x)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"ADF p{-}value:"}\NormalTok{, result[}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-89}

AI systems often rely on single observed sequences (like user logs or
sensor readings). Stationarity and ergodicity justify treating those
samples as representative of the whole process, enabling robust
forecasting, learning, and decision-making.

\subsubsection{Try It Yourself}\label{try-it-yourself-191}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate a random walk and test if it is stationary.
\item
  Compare the sample mean of one long trajectory to averages across many
  simulations.
\item
  Explain why non-stationarity (e.g., concept drift) is a major
  challenge for deployed AI models.
\end{enumerate}

\subsection{193. Discrete-Time Markov
Chains}\label{discrete-time-markov-chains}

A discrete-time Markov chain (DTMC) is a stochastic process where the
next state depends only on the current state, not the past history. This
memoryless property makes Markov chains a cornerstone of probabilistic
modeling in AI.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-192}

Think of a board game where each move depends only on the square you're
currently on and the dice roll---not on how you got there. That's how a
Markov chain works: the present fully determines the future.

\subsubsection{Deep Dive}\label{deep-dive-192}

\begin{itemize}
\item
  Definition:

  \begin{itemize}
  \item
    Sequence of random variables \(\{X_t\}\).
  \item
    Markov property:

    \[
    P(X_{t+1} \mid X_t, X_{t-1}, \dots, X_0) = P(X_{t+1} \mid X_t).
    \]
  \end{itemize}
\item
  Transition matrix \(P\):

  \begin{itemize}
  \tightlist
  \item
    \(P_{ij} = P(X_{t+1}=j \mid X_t=i)\).
  \item
    Rows sum to 1.
  \end{itemize}
\item
  Key properties:

  \begin{itemize}
  \tightlist
  \item
    Irreducibility: all states reachable.
  \item
    Periodicity: cycles of fixed length.
  \item
    Stationary distribution: \(\pi = \pi P\).
  \item
    Convergence: under mild conditions, DTMC converges to stationary
    distribution.
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Web search (PageRank).
  \item
    Hidden Markov Models (HMMs) in NLP.
  \item
    Reinforcement learning state transitions.
  \item
    Stochastic simulations.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2584}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4045}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3371}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Term
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Transition matrix & Probability of moving between states & PageRank
random surfer \\
Stationary distribution & Long-run probabilities & Importance ranking in
networks \\
Irreducible chain & Every state reachable & Exploration in RL
environments \\
Periodicity & Fixed cycles of states & Oscillatory processes \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-174}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Transition matrix for 3 states}
\NormalTok{P }\OperatorTok{=}\NormalTok{ np.array([[}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.6}\NormalTok{, }\FloatTok{0.3}\NormalTok{],}
\NormalTok{              [}\FloatTok{0.4}\NormalTok{, }\FloatTok{0.4}\NormalTok{, }\FloatTok{0.2}\NormalTok{],}
\NormalTok{              [}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FloatTok{0.5}\NormalTok{]])}

\CommentTok{\# Simulate Markov chain}
\NormalTok{n\_steps }\OperatorTok{=} \DecValTok{10}
\NormalTok{state }\OperatorTok{=} \DecValTok{0}
\NormalTok{trajectory }\OperatorTok{=}\NormalTok{ [state]}
\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n\_steps):}
\NormalTok{    state }\OperatorTok{=}\NormalTok{ np.random.choice([}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{], p}\OperatorTok{=}\NormalTok{P[state])}
\NormalTok{    trajectory.append(state)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Trajectory:"}\NormalTok{, trajectory)}

\CommentTok{\# Approximate stationary distribution}
\NormalTok{dist }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{]) }\OperatorTok{@}\NormalTok{ np.linalg.matrix\_power(P, }\DecValTok{50}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Stationary distribution:"}\NormalTok{, dist)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-90}

DTMCs strike a balance between simplicity and expressive power. They
model dynamic systems where history matters only through the current
state---perfect for many AI domains like sequence prediction, decision
processes, and probabilistic planning.

\subsubsection{Try It Yourself}\label{try-it-yourself-192}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Construct a 2-state weather model (sunny, rainy). Simulate 20 days.
\item
  Compute the stationary distribution of your model. What does it mean?
\item
  Explain why the Markov property simplifies reinforcement learning
  algorithms.
\end{enumerate}

\subsection{194. Continuous-Time Markov
Processes}\label{continuous-time-markov-processes}

Continuous-Time Markov Processes (CTMPs) extend the Markov property to
continuous time. Instead of stepping forward in discrete ticks, the
system evolves with random waiting times between transitions, often
modeled with exponential distributions.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-193}

Imagine customers arriving at a bank. The arrivals don't happen exactly
every 5 minutes, but randomly---sometimes quickly, sometimes after a
long gap. The ``clock'' is continuous, and the process is still
memoryless: the future depends only on the current state, not how long
you've been waiting.

\subsubsection{Deep Dive}\label{deep-dive-193}

\begin{itemize}
\item
  Definition:

  \begin{itemize}
  \item
    A stochastic process \(\{X(t)\}_{t \geq 0}\) with state space \(S\).
  \item
    Markov property:

    \[
    P(X(t+\Delta t)=j \mid X(t)=i, \text{history}) = P(X(t+\Delta t)=j \mid X(t)=i).
    \]
  \end{itemize}
\item
  Transition rates (generator matrix \(Q\)):

  \begin{itemize}
  \tightlist
  \item
    \(Q_{ij} \geq 0\) for \(i \neq j\).
  \item
    \(Q_{ii} = -\sum_{j \neq i} Q_{ij}\).
  \item
    Probability of leaving state \(i\) in small interval \(\Delta t\):
    \(-Q_{ii}\Delta t\).
  \end{itemize}
\item
  Waiting times:

  \begin{itemize}
  \tightlist
  \item
    Time spent in a state is exponentially distributed.
  \end{itemize}
\item
  Stationary distribution:

  \begin{itemize}
  \tightlist
  \item
    Solve \(\pi Q = 0\), with \(\sum_i \pi_i = 1\).
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Queueing models in computer systems.
  \item
    Continuous-time reinforcement learning.
  \item
    Reliability modeling for robotics and networks.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2421}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3579}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula / Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Generator matrix \(Q\) & Rates of transition between states & System
reliability analysis \\
Exponential waiting & \(P(T>t)=e^{-\lambda t}\) & Customer arrivals in
queueing models \\
Stationary distribution & \(\pi Q = 0\) & Long-run uptime vs downtime of
systems \\
\end{longtable}

Tiny Code Sample (Python, simulating CTMC)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Generator matrix Q for 2{-}state system}
\NormalTok{Q }\OperatorTok{=}\NormalTok{ np.array([[}\OperatorTok{{-}}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{],}
\NormalTok{              [}\FloatTok{0.2}\NormalTok{, }\OperatorTok{{-}}\FloatTok{0.2}\NormalTok{]])}

\NormalTok{n\_steps }\OperatorTok{=} \DecValTok{5}
\NormalTok{state }\OperatorTok{=} \DecValTok{0}
\NormalTok{times }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{]}
\NormalTok{trajectory }\OperatorTok{=}\NormalTok{ [state]}

\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n\_steps):}
\NormalTok{    rate }\OperatorTok{=} \OperatorTok{{-}}\NormalTok{Q[state,state]}
\NormalTok{    wait }\OperatorTok{=}\NormalTok{ np.random.exponential(}\DecValTok{1}\OperatorTok{/}\NormalTok{rate)  }\CommentTok{\# exponential waiting time}
\NormalTok{    next\_state }\OperatorTok{=}\NormalTok{ np.random.choice([}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{], p}\OperatorTok{=}\NormalTok{[}\FloatTok{0.0} \ControlFlowTok{if}\NormalTok{ i}\OperatorTok{==}\NormalTok{state }\ControlFlowTok{else}\NormalTok{ Q[state,i]}\OperatorTok{/}\NormalTok{rate }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in}\NormalTok{ [}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{]])}
\NormalTok{    times.append(times[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}\OperatorTok{+}\NormalTok{wait)}
\NormalTok{    trajectory.append(next\_state)}
\NormalTok{    state }\OperatorTok{=}\NormalTok{ next\_state}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Times:"}\NormalTok{, times)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Trajectory:"}\NormalTok{, trajectory)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-91}

Many AI systems operate in real time where events occur
irregularly---like network failures, user interactions, or biological
processes. Continuous-time Markov processes capture these dynamics,
bridging probability theory and practical system modeling.

\subsubsection{Try It Yourself}\label{try-it-yourself-193}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Model a machine that alternates between \emph{working} and
  \emph{failed} with exponential waiting times.
\item
  Compute the stationary distribution for the machine's uptime.
\item
  Explain why CTMPs are better suited than DTMCs for modeling network
  traffic.
\end{enumerate}

\subsection{195. Transition Matrices and
Probabilities}\label{transition-matrices-and-probabilities}

Transition matrices describe how probabilities shift between states in a
Markov process. Each row encodes the probability distribution of moving
from one state to all others. They provide a compact and powerful way to
analyze dynamics and long-term behavior.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-194}

Think of a subway map where each station is a state. The transition
matrix is like the schedule: from each station, it lists the
probabilities of ending up at the others after one ride.

\subsubsection{Deep Dive}\label{deep-dive-194}

\begin{itemize}
\item
  Transition matrix (discrete-time Markov chain):

  \begin{itemize}
  \tightlist
  \item
    \(P_{ij} = P(X_{t+1}=j \mid X_t=i)\).
  \item
    Rows sum to 1.
  \end{itemize}
\item
  n-step transitions:

  \begin{itemize}
  \tightlist
  \item
    \(P^n\) gives probability of moving between states in n steps.
  \end{itemize}
\item
  Stationary distribution:

  \begin{itemize}
  \tightlist
  \item
    Vector \(\pi\) with \(\pi P = \pi\).
  \end{itemize}
\item
  Continuous-time case (generator matrix Q):

  \begin{itemize}
  \item
    Transition probabilities obtained via matrix exponential:

    \[
    P(t) = e^{Qt}.
    \]
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    PageRank and ranking algorithms.
  \item
    Hidden Markov Models for NLP and speech.
  \item
    Modeling policies in reinforcement learning.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3108}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1757}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5135}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
One-step probability & \(P_{ij}\) & Next word prediction in HMM \\
n-step probability & \(P^n_{ij}\) & Multi-step planning in RL \\
Stationary distribution & \(\pi P = \pi\) & Long-run importance in
PageRank \\
Continuous-time & \(P(t)=e^{Qt}\) & Reliability modeling, queueing
systems \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-175}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Transition matrix for 3{-}state chain}
\NormalTok{P }\OperatorTok{=}\NormalTok{ np.array([[}\FloatTok{0.7}\NormalTok{, }\FloatTok{0.2}\NormalTok{, }\FloatTok{0.1}\NormalTok{],}
\NormalTok{              [}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.6}\NormalTok{, }\FloatTok{0.3}\NormalTok{],}
\NormalTok{              [}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FloatTok{0.5}\NormalTok{]])}

\CommentTok{\# Two{-}step transition probabilities}
\NormalTok{P2 }\OperatorTok{=}\NormalTok{ np.linalg.matrix\_power(P, }\DecValTok{2}\NormalTok{)}

\CommentTok{\# Stationary distribution (approximate via power method)}
\NormalTok{pi }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{]) }\OperatorTok{@}\NormalTok{ np.linalg.matrix\_power(P, }\DecValTok{50}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"P\^{}2:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, P2)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Stationary distribution:"}\NormalTok{, pi)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-92}

Transition matrices turn probabilistic dynamics into linear algebra,
enabling efficient computation of future states, long-run distributions,
and stability analysis. This bridges stochastic processes with numerical
methods, making them core to AI reasoning under uncertainty.

\subsubsection{Try It Yourself}\label{try-it-yourself-194}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Construct a 2-state transition matrix for weather (sunny, rainy).
  Compute probabilities after 3 days.
\item
  Find the stationary distribution of a 3-state Markov chain by solving
  \(\pi P = \pi\).
\item
  Explain why transition matrices are key to reinforcement learning
  policy evaluation.
\end{enumerate}

\subsection{196. Markov Property and
Memorylessness}\label{markov-property-and-memorylessness}

The Markov property states that the future of a process depends only on
its present state, not its past history. This ``memorylessness''
simplifies modeling dynamic systems, allowing them to be described with
transition probabilities instead of full histories.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-195}

Imagine standing at a crossroads. To decide where you'll go next, you
only need to know where you are now---not the exact path you took to get
there.

\subsubsection{Deep Dive}\label{deep-dive-195}

\begin{itemize}
\item
  Formal definition: A stochastic process \(\{X_t\}\) has the Markov
  property if

  \[
  P(X_{t+1} \mid X_t, X_{t-1}, \ldots, X_0) = P(X_{t+1} \mid X_t).
  \]
\item
  Memorylessness:

  \begin{itemize}
  \tightlist
  \item
    In discrete-time Markov chains, the next state depends only on the
    current state.
  \item
    In continuous-time Markov processes, the waiting time in each state
    is exponentially distributed, which is also memoryless.
  \end{itemize}
\item
  Consequences:

  \begin{itemize}
  \tightlist
  \item
    Simplifies analysis of stochastic systems.
  \item
    Enables recursive computation of probabilities.
  \item
    Forms basis for dynamic programming.
  \end{itemize}
\item
  Limitations:

  \begin{itemize}
  \tightlist
  \item
    Not all processes are Markovian (e.g., stock markets with long-term
    dependencies).
  \item
    Extensions: higher-order Markov models, hidden Markov models.
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Reinforcement learning environments.
  \item
    Hidden Markov Models in NLP and speech recognition.
  \item
    State-space models for robotics and planning.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1613}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3978}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4409}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Markov property & Future depends only on present & Reinforcement
learning policies \\
Memorylessness & No dependency on elapsed time/history & Exponential
waiting times in CTMCs \\
Extension & Higher-order or hidden Markov models & Part-of-speech
tagging, sequence labeling \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-176}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Simple 2{-}state Markov chain: Sunny (0), Rainy (1)}
\NormalTok{P }\OperatorTok{=}\NormalTok{ np.array([[}\FloatTok{0.8}\NormalTok{, }\FloatTok{0.2}\NormalTok{],}
\NormalTok{              [}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{]])}

\NormalTok{state }\OperatorTok{=} \DecValTok{0}  \CommentTok{\# start Sunny}
\NormalTok{trajectory }\OperatorTok{=}\NormalTok{ [state]}
\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{10}\NormalTok{):}
\NormalTok{    state }\OperatorTok{=}\NormalTok{ np.random.choice([}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{], p}\OperatorTok{=}\NormalTok{P[state])}
\NormalTok{    trajectory.append(state)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Weather trajectory:"}\NormalTok{, trajectory)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-93}

The Markov property reduces complexity by removing dependence on the
full past, making dynamic systems tractable for analysis and learning.
Without it, reinforcement learning and probabilistic planning would be
computationally intractable.

\subsubsection{Try It Yourself}\label{try-it-yourself-195}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write down a simple 3-state Markov chain and verify the Markov
  property holds.
\item
  Explain how the exponential distribution's memorylessness supports
  continuous-time Markov processes.
\item
  Discuss a real-world process that violates the Markov
  property---what's missing?
\end{enumerate}

\subsection{197. Martingales and
Applications}\label{martingales-and-applications}

A martingale is a stochastic process where the conditional expectation
of the next value equals the current value, given all past information.
In other words, martingales are ``fair game'' processes with no
predictable trend up or down.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-196}

Think of repeatedly betting on a fair coin toss. Your expected fortune
after the next toss is exactly your current fortune, regardless of how
many wins or losses you've had before.

\subsubsection{Deep Dive}\label{deep-dive-196}

\begin{itemize}
\item
  Formal definition: A process \(\{X_t\}\) is a martingale with respect
  to a filtration \(\mathcal{F}_t\) if:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    \(E[|X_t|] < \infty\).
  \item
    \(E[X_{t+1} \mid \mathcal{F}_t] = X_t\).
  \end{enumerate}
\item
  Submartingale: expectation increases
  (\(E[X_{t+1}\mid \mathcal{F}_t] \geq X_t\)).
\item
  Supermartingale: expectation decreases.
\item
  Key properties:

  \begin{itemize}
  \tightlist
  \item
    Martingale convergence theorem: under conditions, martingales
    converge almost surely.
  \item
    Optional stopping theorem: stopping a martingale at a fair time
    preserves expectation.
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Analysis of randomized algorithms.
  \item
    Reinforcement learning (value estimates as martingales).
  \item
    Finance models (asset prices under no-arbitrage).
  \item
    Bandit problems and regret analysis.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1848}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3696}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4457}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Martingale & Fair game, expected next = current & RL value updates under
unbiased estimates \\
Submartingale & Expected value grows & Regret bounds in online
learning \\
Supermartingale & Expected value shrinks & Discounted reward models \\
Optional stopping & Fairness persists under stopping & Termination in
stochastic simulations \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-177}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{np.random.seed(}\DecValTok{0}\NormalTok{)}
\NormalTok{n }\OperatorTok{=} \DecValTok{20}
\NormalTok{steps }\OperatorTok{=}\NormalTok{ np.random.choice([}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{], size}\OperatorTok{=}\NormalTok{n)  }\CommentTok{\# fair coin tosses}
\NormalTok{martingale }\OperatorTok{=}\NormalTok{ np.cumsum(steps)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Martingale sequence:"}\NormalTok{, martingale)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Expectation \textasciitilde{} 0:"}\NormalTok{, martingale.mean())}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-94}

Martingales provide the mathematical language for fairness, stability,
and unpredictability in stochastic systems. They allow AI researchers to
prove convergence guarantees, analyze uncertainty, and ensure robustness
in algorithms.

\subsubsection{Try It Yourself}\label{try-it-yourself-196}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate a random walk and check if it is a martingale.
\item
  Give an example of a process that is a submartingale but not a
  martingale.
\item
  Explain why martingale analysis is important in proving reinforcement
  learning convergence.
\end{enumerate}

\subsection{198. Hidden Markov Models}\label{hidden-markov-models}

A Hidden Markov Model (HMM) is a probabilistic model where the system
evolves through hidden states according to a Markov chain, but we only
observe outputs generated probabilistically from those states. HMMs
bridge unobservable dynamics and observable data.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-197}

Imagine trying to infer the weather based only on whether people carry
umbrellas. The actual weather (hidden state) follows a Markov chain,
while the umbrellas you see (observations) are noisy signals of it.

\subsubsection{Deep Dive}\label{deep-dive-197}

\begin{itemize}
\item
  Model structure:

  \begin{itemize}
  \tightlist
  \item
    Hidden states: \(S = \{s_1, s_2, \dots, s_N\}\).
  \item
    Transition probabilities: \(A = [a_{ij}]\).
  \item
    Emission probabilities: \(B = [b_j(o)]\), likelihood of observation
    given state.
  \item
    Initial distribution: \(\pi\).
  \end{itemize}
\item
  Key algorithms:

  \begin{itemize}
  \tightlist
  \item
    Forward algorithm: compute likelihood of observation sequence.
  \item
    Viterbi algorithm: most likely hidden state sequence.
  \item
    Baum-Welch (EM): learn parameters from data.
  \end{itemize}
\item
  Assumptions:

  \begin{itemize}
  \tightlist
  \item
    Markov property: next state depends only on current state.
  \item
    Observations independent given hidden states.
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Speech recognition (phonemes as states, audio as observations).
  \item
    NLP (part-of-speech tagging, named entity recognition).
  \item
    Bioinformatics (gene sequence modeling).
  \item
    Finance (regime-switching models).
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2200}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4100}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3700}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Component
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Hidden states & Latent variables evolving by Markov chain & Phonemes,
POS tags, weather \\
Emission probabilities & Distribution over observations & Acoustic
signals, words, user actions \\
Forward algorithm & Sequence likelihood & Speech recognition scoring \\
Viterbi algorithm & Most probable hidden sequence & Decoding phoneme or
tag sequences \\
\end{longtable}

Tiny Code Sample (Python, hmmlearn)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ hmmlearn }\ImportTok{import}\NormalTok{ hmm}

\CommentTok{\# Define HMM with 2 hidden states}
\NormalTok{model }\OperatorTok{=}\NormalTok{ hmm.MultinomialHMM(n\_components}\OperatorTok{=}\DecValTok{2}\NormalTok{, random\_state}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\NormalTok{model.startprob\_ }\OperatorTok{=}\NormalTok{ np.array([}\FloatTok{0.6}\NormalTok{, }\FloatTok{0.4}\NormalTok{])}
\NormalTok{model.transmat\_ }\OperatorTok{=}\NormalTok{ np.array([[}\FloatTok{0.7}\NormalTok{, }\FloatTok{0.3}\NormalTok{],}
\NormalTok{                            [}\FloatTok{0.4}\NormalTok{, }\FloatTok{0.6}\NormalTok{]])}
\NormalTok{model.emissionprob\_ }\OperatorTok{=}\NormalTok{ np.array([[}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{],}
\NormalTok{                                [}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.9}\NormalTok{]])}

\CommentTok{\# Observations: 0,1}
\NormalTok{obs }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{]])}
\NormalTok{logprob, states }\OperatorTok{=}\NormalTok{ model.decode(obs, algorithm}\OperatorTok{=}\StringTok{"viterbi"}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Most likely states:"}\NormalTok{, states)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-95}

HMMs are a foundational model for reasoning under uncertainty with
sequential data. They remain essential in speech, language, and
biological sequence analysis, and their principles inspire more advanced
deep sequence models like RNNs and Transformers.

\subsubsection{Try It Yourself}\label{try-it-yourself-197}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define a 2-state HMM for ``Rainy'' vs ``Sunny'' with umbrella
  observations. Simulate a sequence.
\item
  Use the Viterbi algorithm to decode the most likely weather given
  observations.
\item
  Compare HMMs to modern sequence models---what advantages remain for
  HMMs?
\end{enumerate}

\subsection{199. Stochastic Differential
Equations}\label{stochastic-differential-equations}

Stochastic Differential Equations (SDEs) extend ordinary differential
equations by adding random noise terms, typically modeled with Brownian
motion. They capture dynamics where systems evolve continuously but with
uncertainty at every step.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-198}

Imagine watching pollen floating in water. Its overall drift follows
physical laws, but random collisions with water molecules push it
unpredictably. An SDE models both the smooth drift and the jittery
randomness together.

\subsubsection{Deep Dive}\label{deep-dive-198}

\begin{itemize}
\item
  General form:

  \[
  dX_t = \mu(X_t, t)dt + \sigma(X_t, t)dW_t
  \]

  \begin{itemize}
  \tightlist
  \item
    Drift term \(\mu\): deterministic trend.
  \item
    Diffusion term \(\sigma\): random fluctuations.
  \item
    \(W_t\): Wiener process (Brownian motion).
  \end{itemize}
\item
  Solutions:

  \begin{itemize}
  \tightlist
  \item
    Interpreted via Itô or Stratonovich calculus.
  \item
    Numerical: Euler--Maruyama, Milstein methods.
  \end{itemize}
\item
  Examples:

  \begin{itemize}
  \tightlist
  \item
    Geometric Brownian motion: \(dS_t = \mu S_t dt + \sigma S_t dW_t\).
  \item
    Ornstein--Uhlenbeck process: mean-reverting dynamics.
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Stochastic gradient Langevin dynamics (SGLD) for Bayesian learning.
  \item
    Diffusion models in generative AI.
  \item
    Continuous-time reinforcement learning.
  \item
    Modeling uncertainty in robotics and finance.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2336}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3925}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3738}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Process Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Equation Form
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Geometric Brownian Motion & \(dS_t = \mu S_t dt + \sigma S_t dW_t\) &
Asset pricing, probabilistic forecasting \\
Ornstein--Uhlenbeck & \(dX_t = \theta(\mu - X_t)dt + \sigma dW_t\) &
Exploration in RL, noise in control \\
Langevin dynamics & Gradient + noise dynamics & Bayesian deep learning,
diffusion models \\
\end{longtable}

Tiny Code Sample (Python, Euler--Maruyama Simulation)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}

\NormalTok{np.random.seed(}\DecValTok{0}\NormalTok{)}
\NormalTok{T, N }\OperatorTok{=} \FloatTok{1.0}\NormalTok{, }\DecValTok{1000}
\NormalTok{dt }\OperatorTok{=}\NormalTok{ T}\OperatorTok{/}\NormalTok{N}
\NormalTok{mu, sigma }\OperatorTok{=} \FloatTok{1.0}\NormalTok{, }\FloatTok{0.3}

\CommentTok{\# Simulate geometric Brownian motion}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.zeros(N)}
\NormalTok{X[}\DecValTok{0}\NormalTok{] }\OperatorTok{=} \DecValTok{1}
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, N):}
\NormalTok{    dW }\OperatorTok{=}\NormalTok{ np.sqrt(dt) }\OperatorTok{*}\NormalTok{ np.random.randn()}
\NormalTok{    X[i] }\OperatorTok{=}\NormalTok{ X[i}\OperatorTok{{-}}\DecValTok{1}\NormalTok{] }\OperatorTok{+}\NormalTok{ mu}\OperatorTok{*}\NormalTok{X[i}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}\OperatorTok{*}\NormalTok{dt }\OperatorTok{+}\NormalTok{ sigma}\OperatorTok{*}\NormalTok{X[i}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}\OperatorTok{*}\NormalTok{dW}

\NormalTok{plt.plot(np.linspace(}\DecValTok{0}\NormalTok{, T, N), X)}
\NormalTok{plt.title(}\StringTok{"Geometric Brownian Motion"}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-96}

SDEs let AI systems model continuous uncertainty and randomness in
dynamic environments. They are the mathematical foundation of
diffusion-based generative models and stochastic optimization techniques
that dominate modern machine learning.

\subsubsection{Try It Yourself}\label{try-it-yourself-198}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate an Ornstein--Uhlenbeck process and observe its mean-reverting
  behavior.
\item
  Explain how SDEs relate to diffusion models for image generation.
\item
  Use SGLD to train a simple regression model with Bayesian uncertainty.
\end{enumerate}

\subsection{200. Monte Carlo Methods}\label{monte-carlo-methods-1}

Monte Carlo methods use randomness to approximate solutions to
mathematical and computational problems. By simulating many random
samples, they estimate expectations, probabilities, and integrals that
are otherwise intractable.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-199}

Imagine trying to measure the area of an irregularly shaped pond.
Instead of calculating exactly, you throw random pebbles into a square
containing the pond. The fraction that lands inside gives an estimate of
its area.

\subsubsection{Deep Dive}\label{deep-dive-199}

\begin{itemize}
\item
  Core idea: approximate \(\mathbb{E}[f(X)]\) by averaging over random
  draws of \(X\).

  \[
  \mathbb{E}[f(X)] \approx \frac{1}{N}\sum_{i=1}^N f(x_i), \quad x_i \sim p(x)
  \]
\item
  Variance reduction:

  \begin{itemize}
  \tightlist
  \item
    Importance sampling, control variates, stratified sampling.
  \end{itemize}
\item
  Monte Carlo integration:

  \begin{itemize}
  \tightlist
  \item
    Estimate integrals over high-dimensional spaces.
  \end{itemize}
\item
  Markov Chain Monte Carlo (MCMC):

  \begin{itemize}
  \tightlist
  \item
    Use dependent samples from a Markov chain to approximate
    distributions (Metropolis-Hastings, Gibbs sampling).
  \end{itemize}
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Bayesian inference (posterior estimation).
  \item
    Reinforcement learning (policy evaluation with rollouts).
  \item
    Probabilistic programming.
  \item
    Simulation for planning under uncertainty.
  \end{itemize}
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2323}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4444}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3232}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Technique
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Basic Monte Carlo & Average over random samples & Estimating expected
reward in RL \\
Importance sampling & Reweight samples from different distribution &
Off-policy evaluation \\
MCMC & Generate dependent samples via Markov chain & Bayesian neural
networks \\
Variational Monte Carlo & Combine sampling with optimization &
Approximate posterior inference \\
\end{longtable}

Tiny Code Sample (Python, Monte Carlo for π)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{N }\OperatorTok{=} \DecValTok{100000}
\NormalTok{points }\OperatorTok{=}\NormalTok{ np.random.rand(N,}\DecValTok{2}\NormalTok{)}
\NormalTok{inside\_circle }\OperatorTok{=}\NormalTok{ np.}\BuiltInTok{sum}\NormalTok{(points[:,}\DecValTok{0}\NormalTok{]}\DecValTok{2} \OperatorTok{+}\NormalTok{ points[:,}\DecValTok{1}\NormalTok{]}\DecValTok{2} \OperatorTok{\textless{}=} \DecValTok{1}\NormalTok{)}
\NormalTok{pi\_estimate }\OperatorTok{=} \DecValTok{4} \OperatorTok{*}\NormalTok{ inside\_circle }\OperatorTok{/}\NormalTok{ N}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Monte Carlo estimate of π:"}\NormalTok{, pi\_estimate)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-97}

Monte Carlo methods make the intractable tractable. They allow AI
systems to approximate probabilities, expectations, and integrals in
high dimensions, powering Bayesian inference, probabilistic models, and
modern generative approaches.

\subsubsection{Try It Yourself}\label{try-it-yourself-199}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use Monte Carlo to estimate the integral of \(f(x)=e^{-x^2}\) over
  \([0,1]\).
\item
  Implement importance sampling for a skewed distribution.
\item
  Explain how MCMC can approximate the posterior of a Bayesian linear
  regression model.
\end{enumerate}




\end{document}
