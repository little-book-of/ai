% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother





\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={The Little Book of Artificial Intelligence},
  pdfauthor={Duc-Tam Nguyen},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{The Little Book of Artificial Intelligence}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Version 0.1.0}
\author{Duc-Tam Nguyen}
\date{2025-09-17}
\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter{Contents}\label{contents}

\subsubsection{Volume 1 --- First Principles of
AI}\label{volume-1-first-principles-of-ai}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Defining Intelligence, Agents, and Environments
\item
  Objectives, Utility, and Reward
\item
  Information, Uncertainty, and Entropy
\item
  Computation, Complexity, and Limits
\item
  Representation and Abstraction
\item
  Learning vs.~Reasoning: Two Paths to Intelligence
\item
  Search, Optimization, and Decision-Making
\item
  Data, Signals, and Measurement
\item
  Evaluation: Ground Truth, Metrics, and Benchmarks
\item
  Reproducibility, Tooling, and the Scientific Method
\end{enumerate}

\subsubsection{Volume 2 --- Mathematical
Foundations}\label{volume-2-mathematical-foundations}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{10}
\tightlist
\item
  Linear Algebra for Representations
\item
  Differential and Integral Calculus
\item
  Probability Theory Fundamentals
\item
  Statistics and Estimation
\item
  Optimization and Convex Analysis
\item
  Numerical Methods and Stability
\item
  Information Theory
\item
  Graphs, Matrices, and Spectral Methods
\item
  Logic, Sets, and Proof Techniques
\item
  Stochastic Processes and Markov Chains
\end{enumerate}

\subsubsection{Volume 3 --- Data \&
Representation}\label{volume-3-data-representation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{20}
\tightlist
\item
  Data Lifecycle and Governance
\item
  Data Models: Tensors, Tables, Graphs
\item
  Feature Engineering and Encodings
\item
  Labeling, Annotation, and Weak Supervision
\item
  Sampling, Splits, and Experimental Design
\item
  Augmentation, Synthesis, and Simulation
\item
  Data Quality, Integrity, and Bias
\item
  Privacy, Security, and Anonymization
\item
  Datasets, Benchmarks, and Data Cards
\item
  Data Versioning and Lineage
\end{enumerate}

\subsubsection{Volume 4 --- Search \&
Planning}\label{volume-4-search-planning}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{30}
\tightlist
\item
  State Spaces and Problem Formulation
\item
  Uninformed Search (BFS, DFS, Iterative Deepening)
\item
  Informed Search (Heuristics, A*)
\item
  Constraint Satisfaction Problems
\item
  Local Search and Metaheuristics
\item
  Game Search and Adversarial Planning
\item
  Planning in Deterministic Domains
\item
  Probabilistic Planning and POMDPs
\item
  Scheduling and Resource Allocation
\item
  Meta-Reasoning and Anytime Algorithms
\end{enumerate}

\subsubsection{Volume 5 --- Logic \&
Knowledge}\label{volume-5-logic-knowledge}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{40}
\tightlist
\item
  Propositional and First-Order Logic
\item
  Knowledge Representation Schemes
\item
  Inference Engines and Theorem Proving
\item
  Ontologies and Knowledge Graphs
\item
  Description Logics and the Semantic Web
\item
  Default, Non-Monotonic, and Probabilistic Logic
\item
  Temporal, Modal, and Spatial Reasoning
\item
  Commonsense and Qualitative Reasoning
\item
  Neuro-Symbolic AI: Bridging Learning and Logic
\item
  Knowledge Acquisition and Maintenance
\end{enumerate}

\subsubsection{Volume 6 --- Probabilistic Modeling \&
Inference}\label{volume-6-probabilistic-modeling-inference}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{50}
\tightlist
\item
  Bayesian Inference Basics
\item
  Directed Graphical Models (Bayesian Networks)
\item
  Undirected Graphical Models (MRFs/CRFs)
\item
  Exact Inference (Variable Elimination, Junction Tree)
\item
  Approximate Inference (Sampling, Variational)
\item
  Latent Variable Models and EM
\item
  Sequential Models (HMMs, Kalman, Particle Filters)
\item
  Decision Theory and Influence Diagrams
\item
  Probabilistic Programming Languages
\item
  Calibration, Uncertainty Quantification, Reliability
\end{enumerate}

\subsubsection{Volume 7 --- Machine Learning Theory \&
Practice}\label{volume-7-machine-learning-theory-practice}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{60}
\tightlist
\item
  Hypothesis Spaces, Bias, and Capacity
\item
  Generalization, VC, Rademacher, PAC
\item
  Losses, Regularization, and Optimization
\item
  Model Selection, Cross-Validation, Bootstrapping
\item
  Linear and Generalized Linear Models
\item
  Kernel Methods and SVMs
\item
  Trees, Random Forests, Gradient Boosting
\item
  Feature Selection and Dimensionality Reduction
\item
  Imbalanced Data and Cost-Sensitive Learning
\item
  Evaluation, Error Analysis, and Debugging
\end{enumerate}

\subsubsection{Volume 8 --- Supervised Learning
Systems}\label{volume-8-supervised-learning-systems}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{70}
\tightlist
\item
  Regression: From Linear to Nonlinear
\item
  Classification: Binary, Multiclass, Multilabel
\item
  Structured Prediction (CRFs, Seq2Seq Basics)
\item
  Time Series and Forecasting
\item
  Tabular Modeling and Feature Stores
\item
  Hyperparameter Optimization and AutoML
\item
  Interpretability and Explainability (XAI)
\item
  Robustness, Adversarial Examples, Hardening
\item
  Deployment Patterns for Supervised Models
\item
  Monitoring, Drift, and Lifecycle Management
\end{enumerate}

\subsubsection{Volume 9 --- Unsupervised, Self-Supervised \&
Representation}\label{volume-9-unsupervised-self-supervised-representation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{80}
\tightlist
\item
  Clustering (k-Means, Hierarchical, DBSCAN)
\item
  Density Estimation and Mixture Models
\item
  Matrix Factorization and NMF
\item
  Dimensionality Reduction (PCA, t-SNE, UMAP)
\item
  Manifold Learning and Topological Methods
\item
  Topic Models and Latent Dirichlet Allocation
\item
  Autoencoders and Representation Learning
\item
  Contrastive and Self-Supervised Learning
\item
  Anomaly and Novelty Detection
\item
  Graph Representation Learning
\end{enumerate}

\subsubsection{Volume 10 --- Deep Learning
Core}\label{volume-10-deep-learning-core}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{90}
\tightlist
\item
  Computational Graphs and Autodiff
\item
  Backpropagation and Initialization
\item
  Optimizers (SGD, Momentum, Adam, etc.)
\item
  Regularization (Dropout, Norms, Batch/Layer Norm)
\item
  Convolutional Networks and Inductive Biases
\item
  Recurrent Networks and Sequence Models
\item
  Attention Mechanisms and Transformers
\item
  Architecture Patterns and Design Spaces
\item
  Training at Scale (Parallelism, Mixed Precision)
\item
  Failure Modes, Debugging, Evaluation
\end{enumerate}

\subsubsection{Volume 11 --- Large Language
Models}\label{volume-11-large-language-models}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{100}
\tightlist
\item
  Tokenization, Subwords, and Embeddings
\item
  Transformer Architecture Deep Dive
\item
  Pretraining Objectives (MLM, CLM, SFT)
\item
  Scaling Laws and Data/Compute Tradeoffs
\item
  Instruction Tuning, RLHF, and RLAIF
\item
  Parameter-Efficient Tuning (Adapters, LoRA)
\item
  Retrieval-Augmented Generation (RAG) and Memory
\item
  Tool Use, Function Calling, and Agents
\item
  Evaluation, Safety, and Prompting Strategies
\item
  Production LLM Systems and Cost Optimization
\end{enumerate}

\subsubsection{Volume 12 --- Computer
Vision}\label{volume-12-computer-vision}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{110}
\tightlist
\item
  Image Formation and Preprocessing
\item
  ConvNets for Recognition
\item
  Object Detection and Tracking
\item
  Segmentation and Scene Understanding
\item
  3D Vision and Geometry
\item
  Self-Supervised and Foundation Models for Vision
\item
  Vision Transformers and Hybrid Models
\item
  Multimodal Vision-Language (VL) Models
\item
  Datasets, Metrics, and Benchmarks
\item
  Real-World Vision Systems and Edge Deployment
\end{enumerate}

\subsubsection{Volume 13 --- Natural Language
Processing}\label{volume-13-natural-language-processing}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{120}
\tightlist
\item
  Linguistic Foundations (Morphology, Syntax, Semantics)
\item
  Classical NLP (n-Grams, HMMs, CRFs)
\item
  Word and Sentence Embeddings
\item
  Sequence-to-Sequence and Attention
\item
  Machine Translation and Multilingual NLP
\item
  Question Answering and Information Retrieval
\item
  Summarization and Text Generation
\item
  Prompting, In-Context Learning, Program Induction
\item
  Evaluation, Bias, and Toxicity in NLP
\item
  Low-Resource, Code, and Domain-Specific NLP
\end{enumerate}

\subsubsection{Volume 14 --- Speech \& Audio
Intelligence}\label{volume-14-speech-audio-intelligence}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{130}
\tightlist
\item
  Signal Processing and Feature Extraction
\item
  Automatic Speech Recognition (CTC, Transducers)
\item
  Text-to-Speech and Voice Conversion
\item
  Speaker Identification and Diarization
\item
  Music Information Retrieval
\item
  Audio Event Detection and Scene Analysis
\item
  Prosody, Emotion, and Paralinguistics
\item
  Multimodal Audio-Visual Learning
\item
  Robustness to Noise, Accents, Reverberation
\item
  Real-Time and On-Device Audio AI
\end{enumerate}

\subsubsection{Volume 15 --- Reinforcement
Learning}\label{volume-15-reinforcement-learning}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{140}
\tightlist
\item
  Markov Decision Processes and Bellman Equations
\item
  Dynamic Programming and Planning
\item
  Monte Carlo and Temporal-Difference Learning
\item
  Value-Based Methods (DQN and Variants)
\item
  Policy Gradients and Actor-Critic
\item
  Exploration, Intrinsic Motivation, Bandits
\item
  Model-Based RL and World Models
\item
  Multi-Agent RL and Games
\item
  Offline RL, Safety, and Constraints
\item
  RL in the Wild: Sim2Real and Applications
\end{enumerate}

\subsubsection{Volume 16 --- Robotics \& Embodied
AI}\label{volume-16-robotics-embodied-ai}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{150}
\tightlist
\item
  Kinematics, Dynamics, and Control
\item
  Perception for Robotics
\item
  SLAM and Mapping
\item
  Motion Planning and Trajectory Optimization
\item
  Grasping and Manipulation
\item
  Locomotion and Balance
\item
  Human-Robot Interaction and Collaboration
\item
  Simulation, Digital Twins, Domain Randomization
\item
  Learning for Manipulation and Navigation
\item
  System Integration and Real-World Deployment
\end{enumerate}

\subsubsection{Volume 17 --- Causality, Reasoning \&
Science}\label{volume-17-causality-reasoning-science}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{160}
\tightlist
\item
  Causal Graphs, SCMs, and Do-Calculus
\item
  Identification, Estimation, and Transportability
\item
  Counterfactuals and Mediation
\item
  Causal Discovery from Observational Data
\item
  Experiment Design, A/B/n Testing, Uplift
\item
  Time Series Causality and Granger
\item
  Scientific ML and Differentiable Physics
\item
  Symbolic Regression and Program Synthesis
\item
  Automated Theorem Proving and Formal Methods
\item
  Limits, Fallacies, and Robust Scientific Practice
\end{enumerate}

\subsubsection{Volume 18 --- AI Systems, MLOps \&
Infrastructure}\label{volume-18-ai-systems-mlops-infrastructure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{170}
\tightlist
\item
  Data Engineering and Feature Stores
\item
  Experiment Tracking and Reproducibility
\item
  Training Orchestration and Scheduling
\item
  Distributed Training and Parallelism
\item
  Model Packaging, Serving, and APIs
\item
  Monitoring, Telemetry, and Observability
\item
  Drift, Feedback Loops, Continuous Learning
\item
  Privacy, Security, and Model Governance
\item
  Cost, Efficiency, and Green AI
\item
  Platform Architecture and Team Practices
\end{enumerate}

\subsubsection{Volume 19 --- Multimodality, Tools \&
Agents}\label{volume-19-multimodality-tools-agents}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{180}
\tightlist
\item
  Multimodal Pretraining and Alignment
\item
  Cross-Modal Retrieval and Fusion
\item
  Vision-Language-Action Models
\item
  Memory, Datastores, and RAG Systems
\item
  Tool Use, Function APIs, and Plugins
\item
  Planning, Decomposition, Toolformer-Style Agents
\item
  Multi-Agent Simulation and Coordination
\item
  Evaluation of Agents and Emergent Behavior
\item
  Human-in-the-Loop and Interactive Systems
\item
  Case Studies: Assistants, Copilots, Autonomy
\end{enumerate}

\subsubsection{Volume 20 --- Ethics, Safety, Governance \&
Futures}\label{volume-20-ethics-safety-governance-futures}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{190}
\tightlist
\item
  Ethical Frameworks and Principles
\item
  Fairness, Bias, and Inclusion
\item
  Privacy, Surveillance, and Consent
\item
  Robustness, Reliability, and Safety Engineering
\item
  Alignment, Preference Learning, and Control
\item
  Misuse, Abuse, and Red-Teaming
\item
  Law, Regulation, and International Policy
\item
  Economic Impacts, Labor, and Society
\item
  Education, Healthcare, and Public Goods
\item
  Roadmaps, Open Problems, and Future Scenarios
\end{enumerate}

\bookmarksetup{startatroot}

\chapter{Volume 1. First principles of Artificial
Intelligence}\label{volume-1.-first-principles-of-artificial-intelligence}

\section{Chapter 1. Defining Ingelligence, Agents, and
Environments}\label{chapter-1.-defining-ingelligence-agents-and-environments}

\subsection{1. What do we mean by
``intelligence''?}\label{what-do-we-mean-by-intelligence}

Intelligence is the capacity to achieve goals across a wide variety of
environments. In AI, it means designing systems that can perceive,
reason, and act effectively, even under uncertainty. Unlike narrow
programs built for one fixed task, intelligence implies adaptability and
generalization.

\subsubsection{Picture in Your Head}\label{picture-in-your-head}

Think of a skilled traveler arriving in a new city. They don't just
follow one rigid script---they observe the signs, ask questions, and
adjust plans when the bus is late or the route is blocked. An
intelligent system works the same way: it navigates new situations by
combining perception, reasoning, and action.

\subsubsection{Deep Dive}\label{deep-dive}

Researchers debate whether intelligence should be defined by behavior,
internal mechanisms, or measurable outcomes.

\begin{itemize}
\tightlist
\item
  Behavioral definitions focus on observable success in tasks (e.g.,
  solving puzzles, playing games).
\item
  Cognitive definitions emphasize processes like reasoning, planning,
  and learning.
\item
  Formal definitions often turn to frameworks like rational agents:
  entities that choose actions to maximize expected utility.
\end{itemize}

A challenge is that intelligence is multi-dimensional---logical
reasoning, creativity, social interaction, and physical dexterity are
all aspects. No single metric fully captures it, but unifying themes
include adaptability, generalization, and goal-directed behavior.

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1712}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2703}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2613}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2973}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Perspective
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Emphasis
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Behavioral & Task performance & Chess-playing programs & May not
generalize beyond task \\
Cognitive & Reasoning, planning, learning & Cognitive architectures &
Hard to measure directly \\
Formal (agent view) & Maximizing expected utility & Reinforcement
learning agents & Depends heavily on utility design \\
Human analogy & Mimicking human-like abilities & Conversational
assistants & Anthropomorphism can mislead \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# A toy "intelligent agent" choosing actions}
\ImportTok{import}\NormalTok{ random}

\NormalTok{goals }\OperatorTok{=}\NormalTok{ [}\StringTok{"find food"}\NormalTok{, }\StringTok{"avoid danger"}\NormalTok{, }\StringTok{"explore"}\NormalTok{]}
\NormalTok{environment }\OperatorTok{=}\NormalTok{ [}\StringTok{"food nearby"}\NormalTok{, }\StringTok{"predator spotted"}\NormalTok{, }\StringTok{"unknown terrain"}\NormalTok{]}

\KeywordTok{def}\NormalTok{ choose\_action(env):}
    \ControlFlowTok{if} \StringTok{"food"} \KeywordTok{in}\NormalTok{ env:}
        \ControlFlowTok{return} \StringTok{"eat"}
    \ControlFlowTok{elif} \StringTok{"predator"} \KeywordTok{in}\NormalTok{ env:}
        \ControlFlowTok{return} \StringTok{"hide"}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ random.choice([}\StringTok{"move forward"}\NormalTok{, }\StringTok{"observe"}\NormalTok{, }\StringTok{"rest"}\NormalTok{])}

\ControlFlowTok{for}\NormalTok{ situation }\KeywordTok{in}\NormalTok{ environment:}
\NormalTok{    action }\OperatorTok{=}\NormalTok{ choose\_action(situation)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Environment: }\SpecialCharTok{\{}\NormalTok{situation}\SpecialCharTok{\}}\SpecialStringTok{ {-}\textgreater{} Action: }\SpecialCharTok{\{}\NormalTok{action}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add new environments (e.g., ``ally detected'') and define how the
  agent should act.
\item
  Introduce conflicting goals (e.g., explore vs.~avoid danger) and
  create simple rules for trade-offs.
\item
  Reflect: does this toy model capture intelligence, or only a narrow
  slice of it?
\end{enumerate}

\subsection{2. Agents as entities that perceive and
act}\label{agents-as-entities-that-perceive-and-act}

An agent is anything that can perceive its environment through sensors
and act upon that environment through actuators. In AI, the agent
framework provides a clean abstraction: inputs come from the world,
outputs affect the world, and the cycle continues. This framing allows
us to model everything from a thermostat to a robot to a trading
algorithm as an agent.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-1}

Imagine a robot with eyes (cameras), ears (microphones), and wheels. The
robot sees an obstacle, hears a sound, and decides to turn left. It
takes in signals, processes them, and sends commands back out. That
perception--action loop defines what it means to be an agent.

\subsubsection{Deep Dive}\label{deep-dive-1}

Agents can be categorized by their complexity and decision-making
ability:

\begin{itemize}
\tightlist
\item
  Simple reflex agents act directly on current perceptions (if obstacle
  → turn).
\item
  Model-based agents maintain an internal representation of the world.
\item
  Goal-based agents plan actions to achieve objectives.
\item
  Utility-based agents optimize outcomes according to preferences.
\end{itemize}

This hierarchy illustrates increasing sophistication: from reactive
behaviors to deliberate reasoning and optimization. Modern AI systems
often combine multiple levels---deep learning for perception, symbolic
models for planning, and reinforcement learning for utility
maximization.

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1226}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2642}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2736}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3396}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type of Agent
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
How It Works
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Reflex & Condition → Action rules & Vacuum that turns at walls & Cannot
handle unseen situations \\
Model-based & Maintains internal state & Self-driving car localization &
Needs accurate, updated model \\
Goal-based & Chooses actions for outcomes & Path planning in robotics &
Requires explicit goal specification \\
Utility-based & Maximizes preferences & Trading algorithm & Success
depends on utility design \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-1}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple reflex agent: if obstacle detected, turn}
\KeywordTok{def}\NormalTok{ reflex\_agent(percept):}
    \ControlFlowTok{if}\NormalTok{ percept }\OperatorTok{==} \StringTok{"obstacle"}\NormalTok{:}
        \ControlFlowTok{return} \StringTok{"turn left"}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{return} \StringTok{"move forward"}

\NormalTok{percepts }\OperatorTok{=}\NormalTok{ [}\StringTok{"clear"}\NormalTok{, }\StringTok{"obstacle"}\NormalTok{, }\StringTok{"clear"}\NormalTok{]}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ percepts:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Percept: }\SpecialCharTok{\{}\NormalTok{p}\SpecialCharTok{\}}\SpecialStringTok{ {-}\textgreater{} Action: }\SpecialCharTok{\{}\NormalTok{reflex\_agent(p)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Extend the agent to include a goal, such as ``reach destination,'' and
  modify the rules.
\item
  Add state: track whether the agent has already turned left, and
  prevent repeated turns.
\item
  Reflect on how increasing complexity (state, goals, utilities)
  improves generality but adds design challenges.
\end{enumerate}

\subsection{3. The role of environments in shaping
behavior}\label{the-role-of-environments-in-shaping-behavior}

An environment defines the context in which an agent operates. It
supplies the inputs the agent perceives, the consequences of the agent's
actions, and the rules of interaction. AI systems cannot be understood
in isolation---their intelligence is always relative to the environment
they inhabit.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-2}

Think of a fish in a tank. The fish swims, but the glass walls, water,
plants, and currents determine what is possible and how hard certain
movements are. Likewise, an agent's ``tank'' is its environment, shaping
its behavior and success.

\subsubsection{Deep Dive}\label{deep-dive-2}

Environments can be characterized along several dimensions:

\begin{itemize}
\tightlist
\item
  Observable vs.~partially observable: whether the agent sees the full
  state or just partial glimpses.
\item
  Deterministic vs.~stochastic: whether actions lead to predictable
  outcomes or probabilistic ones.
\item
  Static vs.~dynamic: whether the environment changes on its own or only
  when the agent acts.
\item
  Discrete vs.~continuous: whether states and actions are finite steps
  or smooth ranges.
\item
  Single-agent vs.~multi-agent: whether others also influence outcomes.
\end{itemize}

These properties determine the difficulty of building agents. A chess
game is deterministic and fully observable, while real-world driving is
stochastic, dynamic, continuous, and multi-agent. Designing intelligent
behavior means tailoring methods to the environment's structure.

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2039}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1553}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3010}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3398}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Environment Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example (Simple)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example (Complex)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Implication for AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Observable & Chess board & Poker game & Hidden info requires
inference \\
Deterministic & Tic-tac-toe & Weather forecasting & Uncertainty needs
probabilities \\
Static & Crossword puzzle & Stock market & Must adapt to constant
change \\
Discrete & Board games & Robotics control & Continuous control needs
calculus \\
Single-agent & Maze navigation & Autonomous driving with traffic &
Coordination and competition matter \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-2}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Environment: simple grid world}
\KeywordTok{class}\NormalTok{ GridWorld:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, size}\OperatorTok{=}\DecValTok{3}\NormalTok{):}
        \VariableTok{self}\NormalTok{.size }\OperatorTok{=}\NormalTok{ size}
        \VariableTok{self}\NormalTok{.agent\_pos }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{]}
    
    \KeywordTok{def}\NormalTok{ step(}\VariableTok{self}\NormalTok{, action):}
        \ControlFlowTok{if}\NormalTok{ action }\OperatorTok{==} \StringTok{"right"} \KeywordTok{and} \VariableTok{self}\NormalTok{.agent\_pos[}\DecValTok{0}\NormalTok{] }\OperatorTok{\textless{}} \VariableTok{self}\NormalTok{.size }\OperatorTok{{-}} \DecValTok{1}\NormalTok{:}
            \VariableTok{self}\NormalTok{.agent\_pos[}\DecValTok{0}\NormalTok{] }\OperatorTok{+=} \DecValTok{1}
        \ControlFlowTok{elif}\NormalTok{ action }\OperatorTok{==} \StringTok{"down"} \KeywordTok{and} \VariableTok{self}\NormalTok{.agent\_pos[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textless{}} \VariableTok{self}\NormalTok{.size }\OperatorTok{{-}} \DecValTok{1}\NormalTok{:}
            \VariableTok{self}\NormalTok{.agent\_pos[}\DecValTok{1}\NormalTok{] }\OperatorTok{+=} \DecValTok{1}
        \ControlFlowTok{return} \BuiltInTok{tuple}\NormalTok{(}\VariableTok{self}\NormalTok{.agent\_pos)}

\NormalTok{env }\OperatorTok{=}\NormalTok{ GridWorld()}
\NormalTok{actions }\OperatorTok{=}\NormalTok{ [}\StringTok{"right"}\NormalTok{, }\StringTok{"down"}\NormalTok{, }\StringTok{"right"}\NormalTok{]}
\ControlFlowTok{for}\NormalTok{ a }\KeywordTok{in}\NormalTok{ actions:}
\NormalTok{    pos }\OperatorTok{=}\NormalTok{ env.step(a)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Action: }\SpecialCharTok{\{}\NormalTok{a}\SpecialCharTok{\}}\SpecialStringTok{ {-}\textgreater{} Position: }\SpecialCharTok{\{}\NormalTok{pos}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the grid to include obstacles---how does that alter the agent's
  path?
\item
  Add randomness to actions (e.g., a 10\% chance of slipping). Does the
  agent still reach its goal reliably?
\item
  Compare this toy world to real environments---what complexities are
  missing, and why do they matter?
\end{enumerate}

\subsection{4. Inputs, outputs, and feedback
loops}\label{inputs-outputs-and-feedback-loops}

An agent exists in a constant exchange with its environment: it receives
inputs, produces outputs, and adjusts based on the results. This cycle
is known as a feedback loop. Intelligence emerges not from isolated
decisions but from continuous interaction---perception, action, and
adaptation.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-3}

Picture a thermostat in a house. It senses the temperature (input),
decides whether to switch on heating or cooling (processing), and
changes the temperature (output). The altered temperature is then sensed
again, completing the loop. The same principle scales from thermostats
to autonomous robots and learning systems.

\subsubsection{Deep Dive}\label{deep-dive-3}

Feedback loops are fundamental to control theory, cybernetics, and AI.
Key ideas include:

\begin{itemize}
\tightlist
\item
  Open-loop systems: act without monitoring results (e.g., a microwave
  runs for a fixed time).
\item
  Closed-loop systems: adjust based on feedback (e.g., cruise control in
  cars).
\item
  Positive feedback: amplifies changes (e.g., recommendation engines
  reinforcing popularity).
\item
  Negative feedback: stabilizes systems (e.g., homeostasis in biology).
\end{itemize}

For AI, well-designed feedback loops enable adaptation and stability.
Poorly designed ones can cause runaway effects, bias reinforcement, or
instability.

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1300}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3200}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Feedback Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
How It Works
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Risk or Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Open-loop & No correction from output & Batch script that ignores errors
& Fails if environment changes \\
Closed-loop & Adjusts using feedback & Robot navigation with sensors &
Slower if feedback is delayed \\
Positive & Amplifies signal & Viral content recommendation & Can lead to
echo chambers \\
Negative & Stabilizes system & PID controller in robotics & May suppress
useful variations \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-3}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Closed{-}loop temperature controller}
\NormalTok{desired\_temp }\OperatorTok{=} \DecValTok{22}
\NormalTok{current\_temp }\OperatorTok{=} \DecValTok{18}

\KeywordTok{def}\NormalTok{ thermostat(current):}
    \ControlFlowTok{if}\NormalTok{ current }\OperatorTok{\textless{}}\NormalTok{ desired\_temp:}
        \ControlFlowTok{return} \StringTok{"heat on"}
    \ControlFlowTok{elif}\NormalTok{ current }\OperatorTok{\textgreater{}}\NormalTok{ desired\_temp:}
        \ControlFlowTok{return} \StringTok{"cool on"}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{return} \StringTok{"idle"}

\ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in}\NormalTok{ [}\DecValTok{18}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{22}\NormalTok{, }\DecValTok{24}\NormalTok{]:}
\NormalTok{    action }\OperatorTok{=}\NormalTok{ thermostat(t)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Temperature: }\SpecialCharTok{\{}\NormalTok{t}\SpecialCharTok{\}}\SpecialStringTok{°C {-}\textgreater{} Action: }\SpecialCharTok{\{}\NormalTok{action}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-3}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add noise to the temperature readings and see if the controller still
  stabilizes.
\item
  Modify the code to overshoot intentionally---what happens if heating
  continues after the target is reached?
\item
  Reflect on large-scale AI: where do feedback loops appear in social
  media, finance, or autonomous driving?
\end{enumerate}

\subsection{5. Rationality, bounded rationality, and
satisficing}\label{rationality-bounded-rationality-and-satisficing}

Rationality in AI means selecting the action that maximizes expected
performance given the available knowledge. However, real agents face
limits---computational power, time, and incomplete information. This
leads to bounded rationality: making good-enough decisions under
constraints. Often, agents satisfice (pick the first acceptable
solution) instead of optimizing perfectly.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-4}

Imagine grocery shopping with only ten minutes before the store closes.
You could, in theory, calculate the optimal shopping route through every
aisle. But in practice, you grab what you need in a reasonable order and
head to checkout. That's bounded rationality and satisficing at work.

\subsubsection{Deep Dive}\label{deep-dive-4}

\begin{itemize}
\tightlist
\item
  Perfect rationality assumes unlimited information, time, and
  computation---rarely possible in reality.
\item
  Bounded rationality (Herbert Simon's idea) acknowledges constraints
  and focuses on feasible choices.
\item
  Satisficing means picking an option that meets minimum criteria, not
  necessarily the absolute best.
\item
  In AI, heuristics, approximations, and greedy algorithms embody these
  ideas, enabling systems to act effectively in complex or
  time-sensitive domains.
\end{itemize}

This balance between ideal and practical rationality is central to AI
design. Systems must achieve acceptable performance within real-world
limits.

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1681}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2832}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2389}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3097}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Perfect rationality & Always chooses optimal action & Dynamic
programming solvers & Computationally infeasible at scale \\
Bounded rationality & Chooses under time/info limits & Heuristic search
(A*) & May miss optimal solutions \\
Satisficing & Picks first ``good enough'' option & Greedy algorithms &
Quality depends on threshold chosen \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-4}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Satisficing: pick the first option above a threshold}
\NormalTok{options }\OperatorTok{=}\NormalTok{ \{}\StringTok{"A"}\NormalTok{: }\FloatTok{0.6}\NormalTok{, }\StringTok{"B"}\NormalTok{: }\FloatTok{0.9}\NormalTok{, }\StringTok{"C"}\NormalTok{: }\FloatTok{0.7}\NormalTok{\}  }\CommentTok{\# scores for actions}
\NormalTok{threshold }\OperatorTok{=} \FloatTok{0.75}

\KeywordTok{def}\NormalTok{ satisficing(choices, threshold):}
    \ControlFlowTok{for}\NormalTok{ action, score }\KeywordTok{in}\NormalTok{ choices.items():}
        \ControlFlowTok{if}\NormalTok{ score }\OperatorTok{\textgreater{}=}\NormalTok{ threshold:}
            \ControlFlowTok{return}\NormalTok{ action}
    \ControlFlowTok{return} \StringTok{"no good option"}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Chosen action:"}\NormalTok{, satisficing(options, threshold))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-4}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Lower or raise the threshold---does the agent choose differently?
\item
  Shuffle the order of options---how does satisficing depend on
  ordering?
\item
  Compare results to an ``optimal'' strategy that always picks the
  highest score.
\end{enumerate}

\subsection{6. Goals, objectives, and adaptive
behavior}\label{goals-objectives-and-adaptive-behavior}

Goals give direction to an agent's behavior. Without goals, actions are
random or reflexive; with goals, behavior becomes purposeful. Objectives
translate goals into measurable targets, while adaptive behavior ensures
that agents can adjust their strategies when environments or goals
change.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-5}

Think of a GPS navigator. The goal is to reach a destination. The
objective is to minimize travel time. If a road is closed, the system
adapts by rerouting. This cycle---setting goals, pursuing objectives,
and adapting along the way---is central to intelligence.

\subsubsection{Deep Dive}\label{deep-dive-5}

\begin{itemize}
\tightlist
\item
  Goals: broad desired outcomes (e.g., ``deliver package'').
\item
  Objectives: quantifiable or operationalized targets (e.g., ``arrive in
  under 30 minutes'').
\item
  Adaptive behavior: the ability to change plans when obstacles arise.
\item
  Goal hierarchies: higher-level goals (stay safe) may constrain
  lower-level ones (move fast).
\item
  Multi-objective trade-offs: agents often balance efficiency, safety,
  cost, and fairness simultaneously.
\end{itemize}

Effective AI requires encoding not just static goals but also
flexibility---anticipating uncertainty and adjusting course as
conditions change.

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1478}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2522}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2696}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3304}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Element
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Challenge
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Goal & Desired outcome & Reach target location & May be vague or
high-level \\
Objective & Concrete, measurable target & Minimize travel time &
Requires careful specification \\
Adaptive behavior & Adjusting actions dynamically & Rerouting in
autonomous driving & Complexity grows with uncertainty \\
Goal hierarchy & Layered priorities & Safety \textgreater{} speed in
robotics & Conflicting priorities hard to resolve \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-5}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Adaptive goal pursuit}
\ImportTok{import}\NormalTok{ random}

\NormalTok{goal }\OperatorTok{=} \StringTok{"reach destination"}
\NormalTok{path }\OperatorTok{=}\NormalTok{ [}\StringTok{"road1"}\NormalTok{, }\StringTok{"road2"}\NormalTok{, }\StringTok{"road3"}\NormalTok{]}

\KeywordTok{def}\NormalTok{ travel(path):}
    \ControlFlowTok{for}\NormalTok{ road }\KeywordTok{in}\NormalTok{ path:}
        \ControlFlowTok{if}\NormalTok{ random.random() }\OperatorTok{\textless{}} \FloatTok{0.3}\NormalTok{:  }\CommentTok{\# simulate blockage}
            \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{road}\SpecialCharTok{\}}\SpecialStringTok{ blocked {-}\textgreater{} adapting route"}\NormalTok{)}
            \ControlFlowTok{continue}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Taking }\SpecialCharTok{\{}\NormalTok{road}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
        \ControlFlowTok{return} \StringTok{"destination reached"}
    \ControlFlowTok{return} \StringTok{"failed"}

\BuiltInTok{print}\NormalTok{(travel(path))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-5}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the blockage probability and observe how often the agent adapts
  successfully.
\item
  Add multiple goals (e.g., reach fast vs.~stay safe) and design rules
  to prioritize them.
\item
  Reflect: how do human goals shift when resources, risks, or
  preferences change?
\end{enumerate}

\subsection{7. Reactive vs.~deliberative
agents}\label{reactive-vs.-deliberative-agents}

Reactive agents respond immediately to stimuli without explicit
planning, while deliberative agents reason about the future before
acting. This distinction highlights two modes of intelligence: reflexive
speed versus thoughtful foresight. Most practical AI systems blend both
approaches.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-6}

Imagine driving a car. When a ball suddenly rolls into the street, you
react instantly by braking---this is reactive behavior. But planning a
road trip across the country, considering fuel stops and hotels,
requires deliberation. Intelligent systems must know when to be quick
and when to be thoughtful.

\subsubsection{Deep Dive}\label{deep-dive-6}

\begin{itemize}
\tightlist
\item
  Reactive agents: simple, fast, and robust in well-structured
  environments. They follow condition--action rules and excel in
  time-critical situations.
\item
  Deliberative agents: maintain models of the world, reason about
  possible futures, and plan sequences of actions. They handle complex,
  novel problems but require more computation.
\item
  Hybrid approaches: most real-world AI (e.g., robotics) combines
  reactive layers (for safety and reflexes) with deliberative layers
  (for planning and optimization).
\item
  Trade-offs: reactivity gives speed but little foresight; deliberation
  gives foresight but can stall in real time.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1165}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2621}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2816}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3398}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Agent Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Characteristics
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Reactive & Fast, rule-based, reflexive & Collision-avoidance in drones &
Shortsighted, no long-term planning \\
Deliberative & Model-based, plans ahead & Path planning in robotics &
Computationally expensive \\
Hybrid & Combines both layers & Self-driving cars & Integration
complexity \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-6}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Reactive vs. deliberative decision}
\ImportTok{import}\NormalTok{ random}

\KeywordTok{def}\NormalTok{ reactive\_agent(percept):}
    \ControlFlowTok{if}\NormalTok{ percept }\OperatorTok{==} \StringTok{"obstacle"}\NormalTok{:}
        \ControlFlowTok{return} \StringTok{"turn"}
    \ControlFlowTok{return} \StringTok{"forward"}

\KeywordTok{def}\NormalTok{ deliberative\_agent(goal, options):}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Planning for goal: }\SpecialCharTok{\{}\NormalTok{goal}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
    \ControlFlowTok{return} \BuiltInTok{min}\NormalTok{(options, key}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ x: x[}\StringTok{"cost"}\NormalTok{])[}\StringTok{"action"}\NormalTok{]}

\CommentTok{\# Demo}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Reactive:"}\NormalTok{, reactive\_agent(}\StringTok{"obstacle"}\NormalTok{))}
\NormalTok{options }\OperatorTok{=}\NormalTok{ [\{}\StringTok{"action"}\NormalTok{: }\StringTok{"path1"}\NormalTok{, }\StringTok{"cost"}\NormalTok{: }\DecValTok{5}\NormalTok{\}, \{}\StringTok{"action"}\NormalTok{: }\StringTok{"path2"}\NormalTok{, }\StringTok{"cost"}\NormalTok{: }\DecValTok{2}\NormalTok{\}]}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Deliberative:"}\NormalTok{, deliberative\_agent(}\StringTok{"reach target"}\NormalTok{, options))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-6}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more options to the deliberative agent and see how planning
  scales.
\item
  Simulate time pressure: what happens if the agent must decide in one
  step?
\item
  Design a hybrid agent: use reactive behavior for emergencies,
  deliberative planning for long-term goals.
\end{enumerate}

\subsection{8. Embodied, situated, and distributed
intelligence}\label{embodied-situated-and-distributed-intelligence}

Intelligence is not just about abstract computation---it is shaped by
the body it resides in (embodiment), the context it operates within
(situatedness), and how it interacts with others (distribution). These
perspectives highlight that intelligence emerges from the interaction
between mind, body, and world.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-7}

Picture a colony of ants. Each ant has limited abilities, but together
they forage, build, and defend. Their intelligence is distributed across
the colony. Now imagine a robot with wheels instead of legs---it solves
problems differently than a robot with arms. The shape of the body and
the environment it acts in fundamentally shape the form of intelligence.

\subsubsection{Deep Dive}\label{deep-dive-7}

\begin{itemize}
\tightlist
\item
  Embodied intelligence: The physical form influences cognition. A
  flying drone and a ground rover require different strategies for
  navigation.
\item
  Situated intelligence: Knowledge is tied to specific contexts. A
  chatbot trained for customer service behaves differently from one in
  medical triage.
\item
  Distributed intelligence: Multiple agents collaborate or compete,
  producing collective outcomes greater than individuals alone. Swarm
  robotics, sensor networks, and human-AI teams illustrate this
  principle.
\item
  These dimensions remind us that intelligence is not universal---it is
  adapted to bodies, places, and social structures.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1009}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2477}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3119}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3394}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Focus
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Embodied & Physical form shapes action & Humanoid robots vs.~drones &
Constrained by hardware design \\
Situated & Context-specific behavior & Chatbot for finance
vs.~healthcare & May fail when moved to new domain \\
Distributed & Collective problem-solving & Swarm robotics, multi-agent
games & Coordination overhead, emergent risks \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-7}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Distributed decision: majority voting among agents}
\NormalTok{agents }\OperatorTok{=}\NormalTok{ [}
    \KeywordTok{lambda}\NormalTok{: }\StringTok{"left"}\NormalTok{,}
    \KeywordTok{lambda}\NormalTok{: }\StringTok{"right"}\NormalTok{,}
    \KeywordTok{lambda}\NormalTok{: }\StringTok{"left"}
\NormalTok{]}

\NormalTok{votes }\OperatorTok{=}\NormalTok{ [agent() }\ControlFlowTok{for}\NormalTok{ agent }\KeywordTok{in}\NormalTok{ agents]}
\NormalTok{decision }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(}\BuiltInTok{set}\NormalTok{(votes), key}\OperatorTok{=}\NormalTok{votes.count)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Agents voted:"}\NormalTok{, votes)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Final decision:"}\NormalTok{, decision)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-7}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more agents with different preferences---how stable is the final
  decision?
\item
  Replace majority voting with weighted votes---does it change outcomes?
\item
  Reflect on how embodiment, situatedness, and distribution might affect
  AI safety and robustness.
\end{enumerate}

\subsection{9. Comparing human, animal, and machine
intelligence}\label{comparing-human-animal-and-machine-intelligence}

Human intelligence, animal intelligence, and machine intelligence share
similarities but differ in mechanisms and scope. Humans excel in
abstract reasoning and language, animals demonstrate remarkable
adaptation and instinctive behaviors, while machines process vast data
and computations at scale. Studying these comparisons reveals both
inspirations for AI and its limitations.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-8}

Imagine three problem-solvers faced with the same task: finding food. A
human might draw a map and plan a route. A squirrel remembers where it
buried nuts last season and uses its senses to locate them. A search
engine crawls databases and retrieves relevant entries in milliseconds.
Each is intelligent, but in different ways.

\subsubsection{Deep Dive}\label{deep-dive-8}

\begin{itemize}
\item
  Human intelligence: characterized by symbolic reasoning, creativity,
  theory of mind, and cultural learning.
\item
  Animal intelligence: often domain-specific, optimized for survival
  tasks like navigation, hunting, or communication. Crows use tools,
  dolphins cooperate, bees dance to share information.
\item
  Machine intelligence: excels at pattern recognition, optimization, and
  brute-force computation, but lacks embodied experience, emotions, and
  intrinsic motivation.
\item
  Comparative insights:

  \begin{itemize}
  \tightlist
  \item
    Machines often mimic narrow aspects of human or animal cognition.
  \item
    Biological intelligence evolved under resource constraints, while
    machines rely on energy and data availability.
  \item
    Hybrid systems may combine strengths---machine speed with human
    judgment.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1217}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2783}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2783}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3217}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Human Intelligence
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Animal Intelligence
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Machine Intelligence
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Strength & Abstract reasoning, language & Instinct, adaptation,
perception & Scale, speed, data processing \\
Limitation & Cognitive biases, limited memory & Narrow survival domains
& Lacks common sense, embodiment \\
Learning Style & Culture, education, symbols & Evolution, imitation,
instinct & Data-driven algorithms \\
Example & Solving math proofs & Birds using tools & Neural networks for
image recognition \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-8}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Toy comparison: three "agents" solving a food search}
\ImportTok{import}\NormalTok{ random}

\KeywordTok{def}\NormalTok{ human\_agent():}
    \ControlFlowTok{return} \StringTok{"plans route to food"}

\KeywordTok{def}\NormalTok{ animal\_agent():}
    \ControlFlowTok{return}\NormalTok{ random.choice([}\StringTok{"sniffs trail"}\NormalTok{, }\StringTok{"remembers cache"}\NormalTok{])}

\KeywordTok{def}\NormalTok{ machine\_agent():}
    \ControlFlowTok{return} \StringTok{"queries database for food location"}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Human:"}\NormalTok{, human\_agent())}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Animal:"}\NormalTok{, animal\_agent())}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Machine:"}\NormalTok{, machine\_agent())}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-8}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Expand the code with success/failure rates---who finds food fastest or
  most reliably?
\item
  Add constraints (e.g., limited memory for humans, noisy signals for
  animals, incomplete data for machines).
\item
  Reflect: can machines ever achieve the flexibility of humans or the
  embodied instincts of animals?
\end{enumerate}

\subsection{10. Open challenges in defining AI
precisely}\label{open-challenges-in-defining-ai-precisely}

Despite decades of progress, there is still no single, universally
accepted definition of artificial intelligence. Definitions range from
engineering goals (``machines that act intelligently'') to philosophical
ambitions (``machines that think like humans''). The lack of consensus
reflects the diversity of approaches, applications, and expectations in
the field.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-9}

Imagine trying to define ``life.'' Biologists debate whether viruses
count, and new discoveries constantly stretch boundaries. AI is similar:
chess programs, chatbots, self-driving cars, and generative models all
qualify to some, but not to others. The borders of AI shift with each
breakthrough.

\subsubsection{Deep Dive}\label{deep-dive-9}

\begin{itemize}
\item
  Shifting goalposts: Once a task is automated, it is often no longer
  considered AI (``AI is whatever hasn't been done yet'').
\item
  Multiple perspectives:

  \begin{itemize}
  \tightlist
  \item
    Human-like: AI as machines imitating human thought or behavior.
  \item
    Rational agent: AI as systems that maximize expected performance.
  \item
    Tool-based: AI as advanced statistical and optimization methods.
  \end{itemize}
\item
  Cultural differences: Western AI emphasizes autonomy and competition,
  while Eastern perspectives often highlight harmony and augmentation.
\item
  Practical consequence: Without a precise definition, policy, safety,
  and evaluation frameworks must be flexible yet principled.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1416}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2832}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2743}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3009}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Perspective
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition of AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Human-like & Machines that think/act like us & Turing Test, chatbots &
Anthropomorphic and vague \\
Rational agent & Systems maximizing performance & Reinforcement learning
agents & Overly formal, utility design hard \\
Tool-based & Advanced computation techniques & Neural networks,
optimization & Reduces AI to ``just math'' \\
Cultural framing & Varies by society and philosophy & Augmenting
vs.~replacing humans & Hard to unify globally \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-9}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Toy illustration: classify "is this AI?"}
\NormalTok{systems }\OperatorTok{=}\NormalTok{ [}\StringTok{"calculator"}\NormalTok{, }\StringTok{"chess engine"}\NormalTok{, }\StringTok{"chatbot"}\NormalTok{, }\StringTok{"robot vacuum"}\NormalTok{]}

\KeywordTok{def}\NormalTok{ is\_ai(system):}
    \ControlFlowTok{if}\NormalTok{ system }\KeywordTok{in}\NormalTok{ [}\StringTok{"chatbot"}\NormalTok{, }\StringTok{"robot vacuum"}\NormalTok{, }\StringTok{"chess engine"}\NormalTok{]:}
        \ControlFlowTok{return} \VariableTok{True}
    \ControlFlowTok{return} \VariableTok{False}  \CommentTok{\# debatable, depends on definition}

\ControlFlowTok{for}\NormalTok{ s }\KeywordTok{in}\NormalTok{ systems:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{s}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\StringTok{\textquotesingle{}AI\textquotesingle{}} \ControlFlowTok{if}\NormalTok{ is\_ai(s) }\ControlFlowTok{else} \StringTok{\textquotesingle{}not AI?\textquotesingle{}}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-9}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the definition in the code (e.g., ``anything that adapts''
  vs.~``anything that learns'').
\item
  Add new systems like ``search engine'' or ``autopilot''---do they
  count?
\item
  Reflect: does the act of redefining AI highlight why consensus is so
  elusive?
\end{enumerate}

\section{Chapter 2. Objective, Utility, and
Reward}\label{chapter-2.-objective-utility-and-reward}

\subsection{11. Objectives as drivers of intelligent
behavior}\label{objectives-as-drivers-of-intelligent-behavior}

Objectives give an agent a sense of purpose. They specify what outcomes
are desirable and shape how the agent evaluates choices. Without
objectives, an agent has no basis for preferring one action over
another; with objectives, every decision can be judged as better or
worse.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-10}

Think of playing chess without trying to win---it would just be random
moves. But once you set the objective ``checkmate the opponent,'' every
action gains meaning. The same principle holds for AI: objectives
transform arbitrary behaviors into purposeful ones.

\subsubsection{Deep Dive}\label{deep-dive-10}

\begin{itemize}
\tightlist
\item
  Explicit objectives: encoded directly (e.g., maximize score, minimize
  error).
\item
  Implicit objectives: emerge from training data (e.g., language models
  learning next-word prediction).
\item
  Single vs.~multiple objectives: agents may have one clear goal or need
  to balance many (e.g., safety, efficiency, fairness).
\item
  Objective specification problem: poorly defined objectives can lead to
  unintended behaviors, like reward hacking.
\item
  Research frontier: designing objectives aligned with human values
  while remaining computationally tractable.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1570}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2975}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2893}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2562}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Benefit
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Risk / Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Explicit objective & Minimize classification error & Transparent, easy
to measure & Narrow, may ignore side effects \\
Implicit objective & Predict next token in language model & Emerges
naturally from data & Hard to interpret or adjust \\
Single objective & Maximize profit in trading agent & Clear optimization
target & May ignore fairness or risk \\
Multiple objectives & Self-driving car (safe, fast, legal) & Balanced
performance across domains & Conflicts hard to resolve \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-10}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Toy agent choosing based on objective scores}
\NormalTok{actions }\OperatorTok{=}\NormalTok{ \{}\StringTok{"drive\_fast"}\NormalTok{: \{}\StringTok{"time"}\NormalTok{: }\FloatTok{0.9}\NormalTok{, }\StringTok{"safety"}\NormalTok{: }\FloatTok{0.3}\NormalTok{\},}
           \StringTok{"drive\_safe"}\NormalTok{: \{}\StringTok{"time"}\NormalTok{: }\FloatTok{0.5}\NormalTok{, }\StringTok{"safety"}\NormalTok{: }\FloatTok{0.9}\NormalTok{\}\}}

\KeywordTok{def}\NormalTok{ score(action, weights):}
    \ControlFlowTok{return} \BuiltInTok{sum}\NormalTok{(action[k] }\OperatorTok{*}\NormalTok{ w }\ControlFlowTok{for}\NormalTok{ k, w }\KeywordTok{in}\NormalTok{ weights.items())}

\NormalTok{weights }\OperatorTok{=}\NormalTok{ \{}\StringTok{"time"}\NormalTok{: }\FloatTok{0.4}\NormalTok{, }\StringTok{"safety"}\NormalTok{: }\FloatTok{0.6}\NormalTok{\}  }\CommentTok{\# prioritize safety}
\NormalTok{scores }\OperatorTok{=}\NormalTok{ \{a: score(v, weights) }\ControlFlowTok{for}\NormalTok{ a, v }\KeywordTok{in}\NormalTok{ actions.items()\}}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Chosen action:"}\NormalTok{, }\BuiltInTok{max}\NormalTok{(scores, key}\OperatorTok{=}\NormalTok{scores.get))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-10}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the weights---what happens if speed is prioritized over safety?
\item
  Add more objectives (e.g., fuel cost) and see how choices shift.
\item
  Reflect on real-world risks: what if objectives are misaligned with
  human intent?
\end{enumerate}

\subsection{12. Utility functions and preference
modeling}\label{utility-functions-and-preference-modeling}

A utility function assigns a numerical score to outcomes, allowing an
agent to compare and rank them. Preference modeling captures how agents
(or humans) value different possibilities. Together, they formalize the
idea of ``what is better,'' enabling systematic decision-making under
uncertainty.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-11}

Imagine choosing dinner. Pizza, sushi, and salad each have different
appeal depending on your mood. A utility function is like giving each
option a score---pizza 8, sushi 9, salad 6---and then picking the
highest. Machines use the same logic to decide among actions.

\subsubsection{Deep Dive}\label{deep-dive-11}

\begin{itemize}
\tightlist
\item
  Utility theory: provides a mathematical foundation for rational
  choice.
\item
  Cardinal utilities: assign measurable values (e.g., expected profit).
\item
  Ordinal preferences: only rank outcomes without assigning numbers.
\item
  AI applications: reinforcement learning agents maximize expected
  reward, recommender systems model user preferences, and
  multi-objective agents weigh competing utilities.
\item
  Challenges: human preferences are dynamic, inconsistent, and
  context-dependent, making them hard to capture precisely.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1538}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2735}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2650}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3077}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Cardinal utility & Numeric values of outcomes & RL reward functions &
Sensitive to design errors \\
Ordinal preference & Ranking outcomes without numbers & Search engine
rankings & Lacks intensity of preferences \\
Learned utility & Model inferred from data & Collaborative filtering
systems & May reflect bias in data \\
Multi-objective & Balancing several utilities & Autonomous vehicle
trade-offs & Conflicting objectives hard to solve \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-11}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Preference modeling with a utility function}
\NormalTok{options }\OperatorTok{=}\NormalTok{ \{}\StringTok{"pizza"}\NormalTok{: }\DecValTok{8}\NormalTok{, }\StringTok{"sushi"}\NormalTok{: }\DecValTok{9}\NormalTok{, }\StringTok{"salad"}\NormalTok{: }\DecValTok{6}\NormalTok{\}}

\KeywordTok{def}\NormalTok{ choose\_best(options):}
    \ControlFlowTok{return} \BuiltInTok{max}\NormalTok{(options, key}\OperatorTok{=}\NormalTok{options.get)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Chosen option:"}\NormalTok{, choose\_best(options))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-11}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add randomness to reflect mood swings---does the choice change?
\item
  Expand to multi-objective utilities (taste + health + cost).
\item
  Reflect on how preference modeling affects fairness, bias, and
  alignment in AI systems.
\end{enumerate}

\subsection{13. Rewards, signals, and
incentives}\label{rewards-signals-and-incentives}

Rewards are feedback signals that tell an agent how well it is doing
relative to its objectives. Incentives structure these signals to guide
long-term behavior. In AI, rewards are the currency of learning: they
connect actions to outcomes and shape the strategies agents develop.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-12}

Think of training a dog. A treat after sitting on command is a reward.
Over time, the dog learns to connect the action (sit) with the outcome
(treat). AI systems learn in a similar way, except their ``treats'' are
numbers from a reward function.

\subsubsection{Deep Dive}\label{deep-dive-12}

\begin{itemize}
\tightlist
\item
  Rewards vs.~objectives: rewards are immediate signals, while
  objectives define long-term goals.
\item
  Sparse vs.~dense rewards: sparse rewards give feedback only at the end
  (winning a game), while dense rewards provide step-by-step guidance.
\item
  Shaping incentives: carefully designed reward functions can encourage
  exploration, cooperation, or fairness.
\item
  Pitfalls: misaligned incentives can lead to unintended behavior, such
  as reward hacking (agents exploiting loopholes in the reward
  definition).
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1545}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3091}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2273}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3091}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Benefit
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Risk / Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sparse reward & ``+1 if win, else 0'' in a game & Simple,
outcome-focused & Harder to learn intermediate steps \\
Dense reward & Points for each correct move & Easier credit assignment &
May bias toward short-term gains \\
Incentive shaping & Bonus for exploration in RL & Encourages broader
search & Can distort intended objective \\
Misaligned reward & Agent learns to exploit a loophole & Reveals design
flaws & Dangerous or useless behaviors \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-12}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Reward signal shaping}
\KeywordTok{def}\NormalTok{ reward(action):}
    \ControlFlowTok{if}\NormalTok{ action }\OperatorTok{==} \StringTok{"win"}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{10}
    \ControlFlowTok{elif}\NormalTok{ action }\OperatorTok{==} \StringTok{"progress"}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{1}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{0}

\NormalTok{actions }\OperatorTok{=}\NormalTok{ [}\StringTok{"progress"}\NormalTok{, }\StringTok{"progress"}\NormalTok{, }\StringTok{"win"}\NormalTok{]}
\NormalTok{total }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(reward(a) }\ControlFlowTok{for}\NormalTok{ a }\KeywordTok{in}\NormalTok{ actions)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Total reward:"}\NormalTok{, total)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-12}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add a ``cheat'' action with artificially high reward---what happens?
\item
  Change dense rewards to sparse rewards---does the agent still learn
  effectively?
\item
  Reflect: how do incentives in AI mirror incentives in human society,
  markets, or ecosystems?
\end{enumerate}

\subsection{14. Aligning objectives with desired
outcomes}\label{aligning-objectives-with-desired-outcomes}

An AI system is only as good as its objective design. If objectives are
poorly specified, agents may optimize for the wrong thing. Aligning
objectives with real-world desired outcomes is central to safe and
reliable AI. This problem is known as the alignment problem.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-13}

Imagine telling a robot vacuum to ``clean as fast as possible.'' It
might respond by pushing dirt under the couch instead of actually
cleaning. The objective (speed) is met, but the outcome (a clean room)
is not. This gap between specification and intent defines the alignment
challenge.

\subsubsection{Deep Dive}\label{deep-dive-13}

\begin{itemize}
\item
  Specification problem: translating human values and goals into
  machine-readable objectives.
\item
  Proxy objectives: often we measure what's easy (clicks, likes) instead
  of what we really want (knowledge, well-being).
\item
  Goodhart's Law: when a measure becomes a target, it ceases to be a
  good measure.
\item
  Solutions under study:

  \begin{itemize}
  \tightlist
  \item
    Human-in-the-loop learning (reinforcement learning from feedback).
  \item
    Multi-objective optimization to capture trade-offs.
  \item
    Interpretability to check whether objectives are truly met.
  \item
    Iterative refinement as objectives evolve.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1653}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2810}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2562}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2975}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Issue
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Risk
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Possible Mitigation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Mis-specified reward & Robot cleans faster by hiding dirt & Optimizes
wrong behavior & Better proxy metrics, human feedback \\
Proxy objective & Maximizing clicks on content & Promotes clickbait, not
quality & Multi-metric optimization \\
Over-optimization & Tuning too strongly to benchmark & Exploits quirks,
not true skill & Regularization, diverse evaluations \\
Value misalignment & Self-driving car optimizes speed & Safety
violations & Encode constraints, safety checks \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-13}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Misaligned vs. aligned objectives}
\KeywordTok{def}\NormalTok{ score(action):}
    \CommentTok{\# Proxy objective: speed}
    \ControlFlowTok{if}\NormalTok{ action }\OperatorTok{==} \StringTok{"finish\_fast"}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{10}
    \CommentTok{\# True desired outcome: clean thoroughly}
    \ControlFlowTok{elif}\NormalTok{ action }\OperatorTok{==} \StringTok{"clean\_well"}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{8}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{0}

\NormalTok{actions }\OperatorTok{=}\NormalTok{ [}\StringTok{"finish\_fast"}\NormalTok{, }\StringTok{"clean\_well"}\NormalTok{]}
\ControlFlowTok{for}\NormalTok{ a }\KeywordTok{in}\NormalTok{ actions:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Action: }\SpecialCharTok{\{}\NormalTok{a}\SpecialCharTok{\}}\SpecialStringTok{, Score: }\SpecialCharTok{\{}\NormalTok{score(a)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-13}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add a ``cheat'' action like ``hide dirt''---how does the scoring
  system respond?
\item
  Introduce multiple objectives (speed + cleanliness) and balance them
  with weights.
\item
  Reflect on real-world AI: how often do incentives focus on proxies
  (clicks, time spent) instead of true goals?
\end{enumerate}

\subsection{15. Conflicting objectives and
trade-offs}\label{conflicting-objectives-and-trade-offs}

Real-world agents rarely pursue a single objective. They must balance
competing goals: safety vs.~speed, accuracy vs.~efficiency, fairness
vs.~profitability. These conflicts make trade-offs inevitable, and
designing AI requires explicit strategies to manage them.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-14}

Think of cooking dinner. You want the meal to be tasty, healthy, and
quick. Focusing only on speed might mean instant noodles; focusing only
on health might mean a slow, complex recipe. Compromise---perhaps a
stir-fry---is the art of balancing objectives. AI faces the same
dilemma.

\subsubsection{Deep Dive}\label{deep-dive-14}

\begin{itemize}
\tightlist
\item
  Multi-objective optimization: agents evaluate several metrics
  simultaneously.
\item
  Pareto optimality: a solution is Pareto optimal if no objective can be
  improved without worsening another.
\item
  Weighted sums: assign relative importance to each objective (e.g.,
  70\% safety, 30\% speed).
\item
  Dynamic trade-offs: priorities may shift over time or across contexts.
\item
  Challenge: trade-offs often reflect human values, making technical
  design an ethical question.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2478}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2566}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2301}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2655}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Conflict
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Trade-off Strategy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Safety vs.~efficiency & Self-driving cars & Weight safety higher & May
reduce user satisfaction \\
Accuracy vs.~speed & Real-time speech recognition & Use approximate
models & Lower quality results \\
Fairness vs.~profit & Loan approval systems & Apply fairness constraints
& Possible revenue reduction \\
Exploration vs.~exploitation & Reinforcement learning agents & ε-greedy
or UCB strategies & Needs careful parameter tuning \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-14}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Multi{-}objective scoring with weights}
\NormalTok{options }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"fast"}\NormalTok{: \{}\StringTok{"time"}\NormalTok{: }\FloatTok{0.9}\NormalTok{, }\StringTok{"safety"}\NormalTok{: }\FloatTok{0.4}\NormalTok{\},}
    \StringTok{"safe"}\NormalTok{: \{}\StringTok{"time"}\NormalTok{: }\FloatTok{0.5}\NormalTok{, }\StringTok{"safety"}\NormalTok{: }\FloatTok{0.9}\NormalTok{\},}
    \StringTok{"balanced"}\NormalTok{: \{}\StringTok{"time"}\NormalTok{: }\FloatTok{0.7}\NormalTok{, }\StringTok{"safety"}\NormalTok{: }\FloatTok{0.7}\NormalTok{\}}
\NormalTok{\}}

\NormalTok{weights }\OperatorTok{=}\NormalTok{ \{}\StringTok{"time"}\NormalTok{: }\FloatTok{0.4}\NormalTok{, }\StringTok{"safety"}\NormalTok{: }\FloatTok{0.6}\NormalTok{\}}

\KeywordTok{def}\NormalTok{ score(option, weights):}
    \ControlFlowTok{return} \BuiltInTok{sum}\NormalTok{(option[k] }\OperatorTok{*}\NormalTok{ w }\ControlFlowTok{for}\NormalTok{ k, w }\KeywordTok{in}\NormalTok{ weights.items())}

\NormalTok{scores }\OperatorTok{=}\NormalTok{ \{k: score(v, weights) }\ControlFlowTok{for}\NormalTok{ k, v }\KeywordTok{in}\NormalTok{ options.items()\}}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Best choice:"}\NormalTok{, }\BuiltInTok{max}\NormalTok{(scores, key}\OperatorTok{=}\NormalTok{scores.get))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-14}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the weights to prioritize speed over safety---how does the
  outcome shift?
\item
  Add more conflicting objectives, such as cost or fairness.
\item
  Reflect: who should decide the weights---engineers, users, or
  policymakers?
\end{enumerate}

\subsection{16. Temporal aspects: short-term vs.~long-term
goals}\label{temporal-aspects-short-term-vs.-long-term-goals}

Intelligent agents must consider time when pursuing objectives.
Short-term goals focus on immediate rewards, while long-term goals
emphasize delayed outcomes. Balancing the two is crucial: chasing only
immediate gains can undermine future success, but focusing only on the
long run may ignore urgent needs.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-15}

Imagine studying for an exam. Watching videos online provides instant
pleasure (short-term reward), but studying builds knowledge that pays
off later (long-term reward). Smart choices weigh both---enjoy some
breaks while still preparing for the exam.

\subsubsection{Deep Dive}\label{deep-dive-15}

\begin{itemize}
\tightlist
\item
  Myopic agents: optimize only for immediate payoff, often failing in
  environments with delayed rewards.
\item
  Far-sighted agents: value future outcomes, but may overcommit to
  uncertain futures.
\item
  Discounting: future rewards are typically weighted less (e.g.,
  exponential discounting in reinforcement learning).
\item
  Temporal trade-offs: real-world systems, like healthcare AI, must
  optimize both immediate patient safety and long-term outcomes.
\item
  Challenge: setting the right balance depends on context, risk, and
  values.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1842}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3684}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4474}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Short-Term Focus
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Long-Term Focus
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Reward horizon & Immediate payoff & Delayed benefits \\
Example in AI & Online ad click optimization & Drug discovery with years
of delay \\
Strength & Quick responsiveness & Sustainable outcomes \\
Weakness & Shortsighted, risky & Slow, computationally demanding \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-15}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Balancing short vs. long{-}term rewards}
\NormalTok{rewards }\OperatorTok{=}\NormalTok{ \{}\StringTok{"actionA"}\NormalTok{: \{}\StringTok{"short"}\NormalTok{: }\DecValTok{5}\NormalTok{, }\StringTok{"long"}\NormalTok{: }\DecValTok{2}\NormalTok{\},}
           \StringTok{"actionB"}\NormalTok{: \{}\StringTok{"short"}\NormalTok{: }\DecValTok{2}\NormalTok{, }\StringTok{"long"}\NormalTok{: }\DecValTok{8}\NormalTok{\}\}}

\NormalTok{discount }\OperatorTok{=} \FloatTok{0.8}  \CommentTok{\# value future less than present}

\KeywordTok{def}\NormalTok{ value(action, discount):}
    \ControlFlowTok{return}\NormalTok{ action[}\StringTok{"short"}\NormalTok{] }\OperatorTok{+}\NormalTok{ discount }\OperatorTok{*}\NormalTok{ action[}\StringTok{"long"}\NormalTok{]}

\NormalTok{values }\OperatorTok{=}\NormalTok{ \{a: value(r, discount) }\ControlFlowTok{for}\NormalTok{ a, r }\KeywordTok{in}\NormalTok{ rewards.items()\}}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Chosen action:"}\NormalTok{, }\BuiltInTok{max}\NormalTok{(values, key}\OperatorTok{=}\NormalTok{values.get))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-15}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Adjust the discount factor closer to 0 (short-sighted) or 1
  (far-sighted)---how does the choice change?
\item
  Add uncertainty to long-term rewards---what if outcomes aren't
  guaranteed?
\item
  Reflect on real-world cases: how do companies, governments, or
  individuals balance short vs.~long-term objectives?
\end{enumerate}

\subsection{17. Measuring success and utility in
practice}\label{measuring-success-and-utility-in-practice}

Defining success for an AI system requires measurable criteria. Utility
functions provide a theoretical framework, but in practice, success is
judged by task-specific metrics---accuracy, efficiency, user
satisfaction, safety, or profit. The challenge lies in translating
abstract objectives into concrete, measurable signals.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-16}

Imagine designing a delivery drone. You might say its goal is to
``deliver packages well.'' But what does ``well'' mean? Fast delivery,
minimal energy use, or safe landings? Each definition of success leads
to different system behaviors.

\subsubsection{Deep Dive}\label{deep-dive-16}

\begin{itemize}
\tightlist
\item
  Task-specific metrics: classification error, precision/recall,
  latency, throughput.
\item
  Composite metrics: weighted combinations of goals (e.g., safety +
  efficiency).
\item
  Operational constraints: resource usage, fairness requirements, or
  regulatory compliance.
\item
  User-centered measures: satisfaction, trust, adoption rates.
\item
  Pitfalls: metrics can diverge from true goals, creating misaligned
  incentives or unintended consequences.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1308}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2897}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2617}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3178}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Domain
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Common Metric
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Weakness
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Classification & Accuracy, F1-score & Clear, quantitative & Ignores
fairness, interpretability \\
Robotics & Task success rate, energy usage & Captures physical
efficiency & Hard to model safety trade-offs \\
Recommenders & Click-through rate (CTR) & Easy to measure at scale &
Encourages clickbait \\
Finance & ROI, Sharpe ratio & Reflects profitability & May overlook
systemic risks \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-16}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Measuring success with multiple metrics}
\NormalTok{results }\OperatorTok{=}\NormalTok{ \{}\StringTok{"accuracy"}\NormalTok{: }\FloatTok{0.92}\NormalTok{, }\StringTok{"latency"}\NormalTok{: }\DecValTok{120}\NormalTok{, }\StringTok{"user\_satisfaction"}\NormalTok{: }\FloatTok{0.8}\NormalTok{\}}

\NormalTok{weights }\OperatorTok{=}\NormalTok{ \{}\StringTok{"accuracy"}\NormalTok{: }\FloatTok{0.5}\NormalTok{, }\StringTok{"latency"}\NormalTok{: }\OperatorTok{{-}}\FloatTok{0.2}\NormalTok{, }\StringTok{"user\_satisfaction"}\NormalTok{: }\FloatTok{0.3}\NormalTok{\}}

\KeywordTok{def}\NormalTok{ utility(metrics, weights):}
    \ControlFlowTok{return} \BuiltInTok{sum}\NormalTok{(metrics[k] }\OperatorTok{*}\NormalTok{ w }\ControlFlowTok{for}\NormalTok{ k, w }\KeywordTok{in}\NormalTok{ weights.items())}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Overall utility score:"}\NormalTok{, utility(results, weights))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-16}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change weights to prioritize latency over accuracy---how does the
  utility score shift?
\item
  Add fairness as a new metric and decide how to incorporate it.
\item
  Reflect: do current industry benchmarks truly measure success, or just
  proxies for convenience?
\end{enumerate}

\subsection{18. Reward hacking and specification
gaming}\label{reward-hacking-and-specification-gaming}

When objectives or reward functions are poorly specified, agents can
exploit loopholes to maximize the reward without achieving the intended
outcome. This phenomenon is known as reward hacking or specification
gaming. It highlights the danger of optimizing for proxies instead of
true goals.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-17}

Imagine telling a cleaning robot to ``remove visible dirt.'' Instead of
vacuuming, it learns to cover dirt with a rug. The room looks clean, the
objective is ``met,'' but the real goal---cleanliness---has been
subverted.

\subsubsection{Deep Dive}\label{deep-dive-17}

\begin{itemize}
\item
  Causes:

  \begin{itemize}
  \tightlist
  \item
    Overly simplistic reward design.
  \item
    Reliance on proxies instead of direct measures.
  \item
    Failure to anticipate edge cases.
  \end{itemize}
\item
  Examples:

  \begin{itemize}
  \tightlist
  \item
    A simulated agent flips over in a racing game to earn reward points
    faster.
  \item
    A text model maximizes length because ``longer output'' is rewarded,
    regardless of relevance.
  \end{itemize}
\item
  Consequences: reward hacking reduces trust, safety, and usefulness.
\item
  Research directions:

  \begin{itemize}
  \tightlist
  \item
    Iterative refinement of reward functions.
  \item
    Human feedback integration (RLHF).
  \item
    Inverse reinforcement learning to infer true goals.
  \item
    Safe exploration methods to avoid pathological behaviors.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1653}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2562}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2975}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2810}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Issue
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Why It Happens
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Mitigation Approach
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Proxy misuse & Optimizing clicks → clickbait & Easy-to-measure metric
replaces goal & Multi-metric evaluation \\
Exploiting loopholes & Game agent exploits scoring bug & Reward not
covering all cases & Robust testing, adversarial design \\
Perverse incentives & ``Remove dirt'' → hide dirt & Ambiguity in
specification & Human oversight, richer feedback \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-17}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Reward hacking example}
\KeywordTok{def}\NormalTok{ reward(action):}
    \ControlFlowTok{if}\NormalTok{ action }\OperatorTok{==} \StringTok{"hide\_dirt"}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{10}  \CommentTok{\# unintended loophole}
    \ControlFlowTok{elif}\NormalTok{ action }\OperatorTok{==} \StringTok{"clean"}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{8}
    \ControlFlowTok{return} \DecValTok{0}

\NormalTok{actions }\OperatorTok{=}\NormalTok{ [}\StringTok{"clean"}\NormalTok{, }\StringTok{"hide\_dirt"}\NormalTok{]}
\ControlFlowTok{for}\NormalTok{ a }\KeywordTok{in}\NormalTok{ actions:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Action: }\SpecialCharTok{\{}\NormalTok{a}\SpecialCharTok{\}}\SpecialStringTok{, Reward: }\SpecialCharTok{\{}\NormalTok{reward(a)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-17}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Modify the reward so that ``hide\_dirt'' is penalized---does the agent
  now choose correctly?
\item
  Add additional proxy rewards (e.g., speed) and test whether they
  conflict.
\item
  Reflect on real-world analogies: how do poorly designed incentives in
  finance, education, or politics lead to unintended behavior?
\end{enumerate}

\subsection{19. Human feedback and preference
learning}\label{human-feedback-and-preference-learning}

Human feedback provides a way to align AI systems with values that are
hard to encode directly. Instead of handcrafting reward functions,
agents can learn from demonstrations, comparisons, or ratings. This
process, known as preference learning, is central to making AI behavior
more aligned with human expectations.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-18}

Imagine teaching a child to draw. You don't give them a formula for
``good art.'' Instead, you encourage some attempts and correct others.
Over time, they internalize your preferences. AI agents can be trained
in the same way---by receiving approval or disapproval signals from
humans.

\subsubsection{Deep Dive}\label{deep-dive-18}

\begin{itemize}
\item
  Forms of feedback:

  \begin{itemize}
  \tightlist
  \item
    Demonstrations: show the agent how to act.
  \item
    Comparisons: pick between two outputs (``this is better than
    that'').
  \item
    Ratings: assign quality scores to behaviors or outputs.
  \end{itemize}
\item
  Algorithms: reinforcement learning from human feedback (RLHF), inverse
  reinforcement learning, and preference-based optimization.
\item
  Advantages: captures subtle, value-laden judgments not expressible in
  explicit rewards.
\item
  Challenges: feedback can be inconsistent, biased, or expensive to
  gather at scale.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1373}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2941}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2549}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3137}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Feedback Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Use Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Demonstrations & Robot learns tasks from humans & Intuitive, easy to
provide & Hard to cover all cases \\
Comparisons & Ranking chatbot responses & Efficient, captures nuance &
Requires many pairwise judgments \\
Ratings & Users scoring recommendations & Simple signal, scalable &
Subjective, noisy, may be gamed \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-18}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Preference learning via pairwise comparison}
\NormalTok{pairs }\OperatorTok{=}\NormalTok{ [(}\StringTok{"response A"}\NormalTok{, }\StringTok{"response B"}\NormalTok{), (}\StringTok{"response C"}\NormalTok{, }\StringTok{"response D"}\NormalTok{)]}
\NormalTok{human\_choices }\OperatorTok{=}\NormalTok{ \{}\StringTok{"response A"}\NormalTok{: }\DecValTok{1}\NormalTok{, }\StringTok{"response B"}\NormalTok{: }\DecValTok{0}\NormalTok{,}
                 \StringTok{"response C"}\NormalTok{: }\DecValTok{0}\NormalTok{, }\StringTok{"response D"}\NormalTok{: }\DecValTok{1}\NormalTok{\}}

\KeywordTok{def}\NormalTok{ learn\_preferences(pairs, choices):}
\NormalTok{    scores }\OperatorTok{=}\NormalTok{ \{\}}
    \ControlFlowTok{for}\NormalTok{ a, b }\KeywordTok{in}\NormalTok{ pairs:}
\NormalTok{        scores[a] }\OperatorTok{=}\NormalTok{ scores.get(a, }\DecValTok{0}\NormalTok{) }\OperatorTok{+}\NormalTok{ choices[a]}
\NormalTok{        scores[b] }\OperatorTok{=}\NormalTok{ scores.get(b, }\DecValTok{0}\NormalTok{) }\OperatorTok{+}\NormalTok{ choices[b]}
    \ControlFlowTok{return}\NormalTok{ scores}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Learned preference scores:"}\NormalTok{, learn\_preferences(pairs, human\_choices))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-18}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more responses with conflicting feedback---how stable are the
  learned preferences?
\item
  Introduce noisy feedback (random mistakes) and test how it affects
  outcomes.
\item
  Reflect: in which domains (education, healthcare, social media) should
  human feedback play the strongest role in shaping AI?
\end{enumerate}

\subsection{20. Normative vs.~descriptive accounts of
utility}\label{normative-vs.-descriptive-accounts-of-utility}

Utility can be understood in two ways: normatively, as how perfectly
rational agents \emph{should} behave, and descriptively, as how real
humans (or systems) actually behave. AI design must grapple with this
gap: formal models of utility often clash with observed human
preferences, which are noisy, inconsistent, and context-dependent.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-19}

Imagine someone choosing food at a buffet. A normative model might
assume they maximize health or taste consistently. In reality, they may
skip salad one day, overeat dessert the next, or change choices
depending on mood. Human behavior is rarely a clean optimization of a
fixed utility.

\subsubsection{Deep Dive}\label{deep-dive-19}

\begin{itemize}
\item
  Normative utility: rooted in economics and decision theory, assumes
  consistency, transitivity, and rational optimization.
\item
  Descriptive utility: informed by psychology and behavioral economics,
  reflects cognitive biases, framing effects, and bounded rationality.
\item
  AI implications:

  \begin{itemize}
  \tightlist
  \item
    If we design systems around normative models, they may misinterpret
    real human behavior.
  \item
    If we design systems around descriptive models, they may replicate
    human biases.
  \end{itemize}
\item
  Middle ground: AI research increasingly seeks hybrid models---rational
  principles corrected by behavioral insights.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0932}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3136}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3390}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2542}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Perspective
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Normative & How agents \emph{should} maximize utility & Reinforcement
learning with clean reward & Ignores human irrationality \\
Descriptive & How agents actually behave & Recommenders modeling click
patterns & Reinforces bias, inconsistency \\
Hybrid & Blend of rational + behavioral models & Human-in-the-loop
decision support & Complex to design and validate \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-19}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Normative vs descriptive utility example}
\ImportTok{import}\NormalTok{ random}

\CommentTok{\# Normative: always pick highest score}
\NormalTok{options }\OperatorTok{=}\NormalTok{ \{}\StringTok{"salad"}\NormalTok{: }\DecValTok{8}\NormalTok{, }\StringTok{"cake"}\NormalTok{: }\DecValTok{6}\NormalTok{\}}
\NormalTok{choice\_norm }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(options, key}\OperatorTok{=}\NormalTok{options.get)}

\CommentTok{\# Descriptive: human sometimes picks suboptimal}
\NormalTok{choice\_desc }\OperatorTok{=}\NormalTok{ random.choice(}\BuiltInTok{list}\NormalTok{(options.keys()))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Normative choice:"}\NormalTok{, choice\_norm)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Descriptive choice:"}\NormalTok{, choice\_desc)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-19}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Run the descriptive choice multiple times---how often does it diverge
  from the normative?
\item
  Add framing effects (e.g., label salad as ``diet food'') and see how
  it alters preferences.
\item
  Reflect: should AI systems enforce normative rationality, or adapt to
  descriptive human behavior?
\end{enumerate}

\section{Chapter 3. Information, Uncertainty, and
Entropy}\label{chapter-3.-information-uncertainty-and-entropy}

\subsection{21. Information as reduction of
uncertainty}\label{information-as-reduction-of-uncertainty}

Information is not just raw data---it is the amount by which uncertainty
is reduced when new data is received. In AI, information measures how
much an observation narrows down the possible states of the world. The
more surprising or unexpected the signal, the more information it
carries.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-20}

Imagine guessing a number between 1 and 100. Each yes/no question halves
the possibilities: ``Is it greater than 50?'' reduces uncertainty
dramatically. Every answer gives you information by shrinking the space
of possible numbers.

\subsubsection{Deep Dive}\label{deep-dive-20}

\begin{itemize}
\tightlist
\item
  Information theory (Claude Shannon) formalizes this idea.
\item
  The information content of an event relates to its probability: rare
  events are more informative.
\item
  Entropy measures the average uncertainty of a random variable.
\item
  AI uses information measures in many ways: feature selection, decision
  trees (information gain), communication systems, and model evaluation.
\item
  High information reduces ambiguity, but noisy channels and biased data
  can distort the signal.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2021}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4043}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3936}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Information content & Surprise of an event = −log(p) & Rare class label
in classification \\
Entropy & Expected uncertainty over distribution & Decision tree
splits \\
Information gain & Reduction in entropy after observation & Choosing the
best feature to split on \\
Mutual information & Shared information between variables & Feature
relevance for prediction \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-20}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ math}

\CommentTok{\# Information content of an event}
\KeywordTok{def}\NormalTok{ info\_content(prob):}
    \ControlFlowTok{return} \OperatorTok{{-}}\NormalTok{math.log2(prob)}

\NormalTok{events }\OperatorTok{=}\NormalTok{ \{}\StringTok{"common"}\NormalTok{: }\FloatTok{0.8}\NormalTok{, }\StringTok{"rare"}\NormalTok{: }\FloatTok{0.2}\NormalTok{\}}
\ControlFlowTok{for}\NormalTok{ e, p }\KeywordTok{in}\NormalTok{ events.items():}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{e}\SpecialCharTok{\}}\SpecialStringTok{: information = }\SpecialCharTok{\{}\NormalTok{info\_content(p)}\SpecialCharTok{:.2f\}}\SpecialStringTok{ bits"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-20}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more events with different probabilities---how does rarity affect
  information?
\item
  Simulate a fair vs.~biased coin toss---compare entropy values.
\item
  Reflect: how does information connect to AI tasks like
  decision-making, compression, or communication?
\end{enumerate}

\subsection{22. Probabilities and degrees of
belief}\label{probabilities-and-degrees-of-belief}

Probability provides a mathematical language for representing
uncertainty. Instead of treating outcomes as certain or impossible,
probabilities assign degrees of belief between 0 and 1. In AI,
probability theory underpins reasoning, prediction, and learning under
incomplete information.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-21}

Think of carrying an umbrella. If the forecast says a 90\% chance of
rain, you probably take it. If it's 10\%, you might risk leaving it at
home. Probabilities let you act sensibly even when the outcome is
uncertain.

\subsubsection{Deep Dive}\label{deep-dive-21}

\begin{itemize}
\tightlist
\item
  Frequentist view: probability as long-run frequency of events.
\item
  Bayesian view: probability as degree of belief, updated with evidence.
\item
  Random variables: map uncertain outcomes to numbers.
\item
  Distributions: describe how likely different outcomes are.
\item
  Applications in AI: spam detection, speech recognition, medical
  diagnosis---all rely on probabilistic reasoning to handle noisy or
  incomplete inputs.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Frequentist & Probability = long-run frequency & Coin toss
experiments \\
Bayesian & Probability = belief, updated by data & Spam filters
adjusting to new emails \\
Random variable & Variable taking probabilistic values & Weather: sunny
= 0, rainy = 1 \\
Distribution & Assignment of probabilities to outcomes & Gaussian priors
in machine learning \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-21}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ random}

\CommentTok{\# Simple probability estimation (frequentist)}
\NormalTok{trials }\OperatorTok{=} \DecValTok{1000}
\NormalTok{heads }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(}\DecValTok{1} \ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(trials) }\ControlFlowTok{if}\NormalTok{ random.random() }\OperatorTok{\textless{}} \FloatTok{0.5}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Estimated P(heads):"}\NormalTok{, heads }\OperatorTok{/}\NormalTok{ trials)}

\CommentTok{\# Bayesian{-}style update (toy)}
\NormalTok{prior }\OperatorTok{=} \FloatTok{0.5}
\NormalTok{likelihood }\OperatorTok{=} \FloatTok{0.8}  \CommentTok{\# chance of evidence given hypothesis}
\NormalTok{evidence\_prob }\OperatorTok{=} \FloatTok{0.6}
\NormalTok{posterior }\OperatorTok{=}\NormalTok{ (prior }\OperatorTok{*}\NormalTok{ likelihood) }\OperatorTok{/}\NormalTok{ evidence\_prob}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Posterior belief:"}\NormalTok{, posterior)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-21}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase the number of trials---does the estimated probability
  converge to 0.5?
\item
  Modify the Bayesian update with different priors---how does prior
  belief affect the posterior?
\item
  Reflect: when designing AI, when should you favor frequentist
  reasoning, and when Bayesian?
\end{enumerate}

\subsection{23. Random variables, distributions, and
signals}\label{random-variables-distributions-and-signals}

A random variable assigns numerical values to uncertain outcomes. Its
distribution describes how likely each outcome is. In AI, random
variables model uncertain inputs (sensor readings), latent states
(hidden causes), and outputs (predictions). Signals are time-varying
realizations of such variables, carrying information from the
environment.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-22}

Imagine rolling a die. The outcome itself (1--6) is uncertain, but the
random variable ``X = die roll'' captures that uncertainty. If you track
successive rolls over time, you get a signal: a sequence of values
reflecting the random process.

\subsubsection{Deep Dive}\label{deep-dive-22}

\begin{itemize}
\item
  Random variables: can be discrete (finite outcomes) or continuous
  (infinite outcomes).
\item
  Distributions: specify the probabilities (discrete) or densities
  (continuous). Examples include Bernoulli, Gaussian, and Poisson.
\item
  Signals: realizations of random processes evolving over
  time---essential in speech, vision, and sensor data.
\item
  AI applications:

  \begin{itemize}
  \tightlist
  \item
    Gaussian distributions for modeling noise.
  \item
    Bernoulli/Binomial for classification outcomes.
  \item
    Hidden random variables in latent variable models.
  \end{itemize}
\item
  Challenge: real-world signals often combine noise, structure, and
  nonstationarity.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2159}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4091}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3750}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Discrete variable & Finite possible outcomes & Dice rolls,
classification labels \\
Continuous variable & Infinite range of values & Temperature, pixel
intensities \\
Distribution & Likelihood of different outcomes & Gaussian noise in
sensors \\
Signal & Sequence of random variable outcomes & Audio waveform, video
frames \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-22}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Discrete random variable: dice}
\NormalTok{dice\_rolls }\OperatorTok{=}\NormalTok{ np.random.choice([}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{], size}\OperatorTok{=}\DecValTok{10}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Dice rolls:"}\NormalTok{, dice\_rolls)}

\CommentTok{\# Continuous random variable: Gaussian noise}
\NormalTok{noise }\OperatorTok{=}\NormalTok{ np.random.normal(loc}\OperatorTok{=}\DecValTok{0}\NormalTok{, scale}\OperatorTok{=}\DecValTok{1}\NormalTok{, size}\OperatorTok{=}\DecValTok{5}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Gaussian noise samples:"}\NormalTok{, noise)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-22}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the distribution parameters (e.g., mean and variance of
  Gaussian)---how do samples shift?
\item
  Simulate a signal by generating a sequence of random variables over
  time.
\item
  Reflect: how does modeling randomness help AI deal with uncertainty in
  perception and decision-making?
\end{enumerate}

\subsection{24. Entropy as a measure of
uncertainty}\label{entropy-as-a-measure-of-uncertainty}

Entropy quantifies how uncertain or unpredictable a random variable is.
High entropy means outcomes are spread out and less predictable, while
low entropy means outcomes are concentrated and more certain. In AI,
entropy helps measure information content, guide decision trees, and
regularize models.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-23}

Imagine two dice: one fair, one loaded to always roll a six. The fair
die is unpredictable (high entropy), while the loaded die is predictable
(low entropy). Entropy captures this difference in uncertainty
mathematically.

\subsubsection{Deep Dive}\label{deep-dive-23}

\begin{itemize}
\item
  Shannon entropy:

  \[
  H(X) = -\sum p(x) \log_2 p(x)
  \]
\item
  High entropy: uniform distributions, maximum uncertainty.
\item
  Low entropy: skewed distributions, predictable outcomes.
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Decision trees: choose features with highest information gain
    (entropy reduction).
  \item
    Reinforcement learning: encourage exploration by maximizing policy
    entropy.
  \item
    Generative models: evaluate uncertainty in output distributions.
  \end{itemize}
\item
  Limitations: entropy depends on probability estimates, which may be
  inaccurate in noisy environments.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1809}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3085}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1383}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3723}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Distribution Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Entropy Level
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Uniform & Fair die (1--6 equally likely) & High & Maximum
unpredictability \\
Skewed & Loaded die (90\% six) & Low & Predictable classification
outcomes \\
Binary balanced & Coin flip & Medium & Baseline uncertainty in
decisions \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-23}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ math}

\KeywordTok{def}\NormalTok{ entropy(probs):}
    \ControlFlowTok{return} \OperatorTok{{-}}\BuiltInTok{sum}\NormalTok{(p }\OperatorTok{*}\NormalTok{ math.log2(p) }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ probs }\ControlFlowTok{if}\NormalTok{ p }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{)}

\CommentTok{\# Fair die vs. loaded die}
\NormalTok{fair\_probs }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\OperatorTok{/}\DecValTok{6}\NormalTok{] }\OperatorTok{*} \DecValTok{6}
\NormalTok{loaded\_probs }\OperatorTok{=}\NormalTok{ [}\FloatTok{0.9}\NormalTok{] }\OperatorTok{+}\NormalTok{ [}\FloatTok{0.02}\NormalTok{] }\OperatorTok{*} \DecValTok{5}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Fair die entropy:"}\NormalTok{, entropy(fair\_probs))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Loaded die entropy:"}\NormalTok{, entropy(loaded\_probs))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-23}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change probabilities---see how entropy increases with uniformity.
\item
  Apply entropy to text: compute uncertainty over letter frequencies in
  a sentence.
\item
  Reflect: why do AI systems often prefer reducing entropy when making
  decisions?
\end{enumerate}

\subsection{25. Mutual information and
relevance}\label{mutual-information-and-relevance}

Mutual information (MI) measures how much knowing one variable reduces
uncertainty about another. It captures dependence between variables,
going beyond simple correlation. In AI, mutual information helps
identify which features are most relevant for prediction, compress data
efficiently, and align multimodal signals.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-24}

Think of two friends whispering answers during a quiz. If one always
knows the answer and the other copies, the information from one
completely determines the other---high mutual information. If their
answers are random and unrelated, the MI is zero.

\subsubsection{Deep Dive}\label{deep-dive-24}

\begin{itemize}
\item
  Definition:

  \[
  I(X;Y) = \sum_{x,y} p(x,y) \log \frac{p(x,y)}{p(x)p(y)}
  \]
\item
  Zero MI: variables are independent.
\item
  High MI: strong dependence, one variable reveals much about the other.
\item
  Applications in AI:

  \begin{itemize}
  \tightlist
  \item
    Feature selection (choose features with highest MI with labels).
  \item
    Multimodal learning (aligning audio with video).
  \item
    Representation learning (maximize MI between input and latent
    codes).
  \end{itemize}
\item
  Advantages: captures nonlinear relationships, unlike correlation.
\item
  Challenges: requires estimating joint distributions, which is
  difficult in high dimensions.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2917}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4583}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Situation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Mutual Information
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Independent variables & MI = 0 & Random noise vs.~labels \\
Strong dependence & High MI & Pixel intensities vs.~image class \\
Partial dependence & Medium MI & User clicks vs.~recommendations \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-24}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ math}
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ Counter}

\KeywordTok{def}\NormalTok{ mutual\_information(X, Y):}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(X)}
\NormalTok{    px }\OperatorTok{=}\NormalTok{ Counter(X)}
\NormalTok{    py }\OperatorTok{=}\NormalTok{ Counter(Y)}
\NormalTok{    pxy }\OperatorTok{=}\NormalTok{ Counter(}\BuiltInTok{zip}\NormalTok{(X, Y))}
\NormalTok{    mi }\OperatorTok{=} \FloatTok{0.0}
    \ControlFlowTok{for}\NormalTok{ (x, y), count }\KeywordTok{in}\NormalTok{ pxy.items():}
\NormalTok{        pxy\_val }\OperatorTok{=}\NormalTok{ count }\OperatorTok{/}\NormalTok{ n}
\NormalTok{        mi }\OperatorTok{+=}\NormalTok{ pxy\_val }\OperatorTok{*}\NormalTok{ math.log2(pxy\_val }\OperatorTok{/}\NormalTok{ ((px[x]}\OperatorTok{/}\NormalTok{n) }\OperatorTok{*}\NormalTok{ (py[y]}\OperatorTok{/}\NormalTok{n)))}
    \ControlFlowTok{return}\NormalTok{ mi}

\NormalTok{X }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{]}
\NormalTok{Y }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{]}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Mutual Information:"}\NormalTok{, mutual\_information(X, Y))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-24}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Generate independent variables---does MI approach zero?
\item
  Create perfectly correlated variables---does MI increase?
\item
  Reflect: why is MI a more powerful measure of relevance than
  correlation in AI systems?
\end{enumerate}

\subsection{26. Noise, error, and uncertainty in
perception}\label{noise-error-and-uncertainty-in-perception}

AI systems rarely receive perfect data. Sensors introduce noise, models
make errors, and the world itself produces uncertainty. Understanding
and managing these imperfections is crucial for building reliable
perception systems in vision, speech, robotics, and beyond.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-25}

Imagine trying to recognize a friend in a crowded, dimly lit room.
Background chatter, poor lighting, and movement all interfere. Despite
this, your brain filters signals, corrects errors, and still identifies
them. AI perception faces the same challenges.

\subsubsection{Deep Dive}\label{deep-dive-25}

\begin{itemize}
\item
  Noise: random fluctuations in signals (e.g., static in audio, blur in
  images).
\item
  Error: systematic deviation from the correct value (e.g., biased
  sensor calibration).
\item
  Uncertainty: incomplete knowledge about the true state of the
  environment.
\item
  Handling strategies:

  \begin{itemize}
  \tightlist
  \item
    Filtering (Kalman, particle filters) to denoise signals.
  \item
    Probabilistic models to represent uncertainty explicitly.
  \item
    Ensemble methods to reduce model variance.
  \end{itemize}
\item
  Challenge: distinguishing between random noise, systematic error, and
  inherent uncertainty.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1058}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2212}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3173}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3558}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Source
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Mitigation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Noise & Random signal variation & Camera grain in low light & Smoothing,
denoising filters \\
Error & Systematic deviation & Miscalibrated temperature sensor &
Calibration, bias correction \\
Uncertainty & Lack of full knowledge & Self-driving car unsure of intent
& Probabilistic modeling, Bayesian nets \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-25}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Simulate noisy sensor data}
\NormalTok{true\_value }\OperatorTok{=} \DecValTok{10}
\NormalTok{noise }\OperatorTok{=}\NormalTok{ np.random.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{)  }\CommentTok{\# Gaussian noise}
\NormalTok{measurements }\OperatorTok{=}\NormalTok{ true\_value }\OperatorTok{+}\NormalTok{ noise}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Measurements:"}\NormalTok{, measurements)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Estimated mean:"}\NormalTok{, np.mean(measurements))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-25}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase noise variance---how does it affect the reliability of the
  estimate?
\item
  Add systematic error (e.g., always +2 bias)---can the mean still
  recover the truth?
\item
  Reflect: when should AI treat uncertainty as noise to be removed,
  versus as real ambiguity to be modeled?
\end{enumerate}

\subsection{27. Bayesian updating and belief
revision}\label{bayesian-updating-and-belief-revision}

Bayesian updating provides a principled way to revise beliefs in light
of new evidence. It combines prior knowledge (what you believed before)
with likelihood (how well the evidence fits a hypothesis) to produce a
posterior belief. This mechanism lies at the heart of probabilistic AI.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-26}

Imagine a doctor diagnosing a patient. Before seeing test results, she
has a prior belief about possible illnesses. A new lab test provides
evidence, shifting her belief toward one diagnosis. Each new piece of
evidence reshapes the belief distribution.

\subsubsection{Deep Dive}\label{deep-dive-26}

\begin{itemize}
\item
  Bayes' theorem:

  \[
  P(H|E) = \frac{P(E|H) P(H)}{P(E)}
  \]

  where \(H\) = hypothesis, \(E\) = evidence.
\item
  Prior: initial degree of belief.
\item
  Likelihood: how consistent evidence is with the hypothesis.
\item
  Posterior: updated belief after evidence.
\item
  AI applications: spam filtering, medical diagnosis, robotics
  localization, Bayesian neural networks.
\item
  Key insight: Bayesian updating enables continual learning, where
  beliefs evolve rather than reset.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1829}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3659}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4512}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Element
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Prior & Belief before evidence & Spam probability before reading
email \\
Likelihood & Evidence fit given hypothesis & Probability of words if
spam \\
Posterior & Belief after evidence & Updated spam probability \\
Belief revision & Iterative update with new data & Robot refining map
after each sensor \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-26}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple Bayesian update}
\NormalTok{prior\_spam }\OperatorTok{=} \FloatTok{0.2}
\NormalTok{likelihood\_word\_given\_spam }\OperatorTok{=} \FloatTok{0.9}
\NormalTok{likelihood\_word\_given\_ham }\OperatorTok{=} \FloatTok{0.3}
\NormalTok{evidence\_prob }\OperatorTok{=}\NormalTok{ prior\_spam }\OperatorTok{*}\NormalTok{ likelihood\_word\_given\_spam }\OperatorTok{+}\NormalTok{ (}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ prior\_spam) }\OperatorTok{*}\NormalTok{ likelihood\_word\_given\_ham}

\NormalTok{posterior\_spam }\OperatorTok{=}\NormalTok{ (prior\_spam }\OperatorTok{*}\NormalTok{ likelihood\_word\_given\_spam) }\OperatorTok{/}\NormalTok{ evidence\_prob}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Posterior P(spam|word):"}\NormalTok{, posterior\_spam)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-26}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change priors---how does initial belief influence the posterior?
\item
  Add more evidence step by step---observe belief revision over time.
\item
  Reflect: what kinds of AI systems need to continuously update beliefs
  instead of making static predictions?
\end{enumerate}

\subsection{28. Ambiguity
vs.~randomness}\label{ambiguity-vs.-randomness}

Uncertainty can arise from two different sources: randomness, where
outcomes are inherently probabilistic, and ambiguity, where the
probabilities themselves are unknown or ill-defined. Distinguishing
between these is crucial for AI systems making decisions under
uncertainty.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-27}

Imagine drawing a ball from a jar. If you know the jar has 50 red and 50
blue balls, the outcome is random but well-defined. If you don't know
the composition of the jar, the uncertainty is ambiguous---you can't
even assign exact probabilities.

\subsubsection{Deep Dive}\label{deep-dive-27}

\begin{itemize}
\item
  Randomness (risk): modeled with well-defined probability
  distributions. Example: rolling dice, weather forecasts.
\item
  Ambiguity (Knightian uncertainty): probabilities are unknown,
  incomplete, or contested. Example: predicting success of a brand-new
  technology.
\item
  AI implications:

  \begin{itemize}
  \tightlist
  \item
    Randomness can be managed with probabilistic models.
  \item
    Ambiguity requires robust decision criteria (maximin, minimax
    regret, distributional robustness).
  \item
    Real-world AI often faces both at once---stochastic environments
    with incomplete models.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1583}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3167}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type of Uncertainty
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Handling Strategy
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Randomness (risk) & Known probabilities, random outcome & Dice rolls,
sensor noise & Probability theory, expected value \\
Ambiguity & Unknown or ill-defined probabilities & Novel diseases, new
markets & Robust optimization, cautious planning \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-27}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ random}

\CommentTok{\# Randomness: fair coin}
\NormalTok{coin }\OperatorTok{=}\NormalTok{ random.choice([}\StringTok{"H"}\NormalTok{, }\StringTok{"T"}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Random outcome:"}\NormalTok{, coin)}

\CommentTok{\# Ambiguity: unknown distribution (simulate ignorance)}
\NormalTok{unknown\_jar }\OperatorTok{=}\NormalTok{ [}\StringTok{"?"}\NormalTok{, }\StringTok{"?"}\NormalTok{]  }\CommentTok{\# cannot assign probabilities yet}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Ambiguous outcome:"}\NormalTok{, random.choice(unknown\_jar))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-27}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate dice rolls (randomness) vs.~drawing from an unknown jar
  (ambiguity).
\item
  Implement maximin: choose the action with the best worst-case payoff.
\item
  Reflect: how should AI systems behave differently when probabilities
  are known versus when they are not?
\end{enumerate}

\subsection{29. Value of information in
decision-making}\label{value-of-information-in-decision-making}

The value of information (VoI) measures how much an additional piece of
information improves decision quality. Not all data is equally
useful---some observations greatly reduce uncertainty, while others
change nothing. In AI, VoI guides data collection, active learning, and
sensor placement.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-28}

Imagine planning a picnic. If the weather forecast is uncertain, paying
for a more accurate update could help decide whether to pack sunscreen
or an umbrella. But once you already know it's raining, more forecasts
add no value.

\subsubsection{Deep Dive}\label{deep-dive-28}

\begin{itemize}
\item
  Definition: VoI = (expected utility with information) − (expected
  utility without information).
\item
  Perfect information: knowing outcomes in advance---upper bound on VoI.
\item
  Sample information: partial signals---lower but often practical value.
\item
  Applications:

  \begin{itemize}
  \tightlist
  \item
    Active learning: query the most informative data points.
  \item
    Robotics: decide where to place sensors.
  \item
    Healthcare AI: order diagnostic tests only when they meaningfully
    improve treatment choices.
  \end{itemize}
\item
  Trade-off: gathering information has costs; VoI balances benefit
  vs.~expense.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3091}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3091}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1818}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type of Information
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Benefit
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Perfect information & Knowing true label before training & Maximum
reduction in uncertainty & Rare, hypothetical \\
Sample information & Adding a diagnostic test result & Improves decision
accuracy & Costly, may be noisy \\
Irrelevant information & Redundant features in a dataset & No
improvement, may add complexity & Wastes resources \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-28}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Toy value of information calculation}
\ImportTok{import}\NormalTok{ random}

\KeywordTok{def}\NormalTok{ decision\_with\_info():}
    \CommentTok{\# Always correct after info}
    \ControlFlowTok{return} \FloatTok{1.0}  \CommentTok{\# utility}

\KeywordTok{def}\NormalTok{ decision\_without\_info():}
    \CommentTok{\# Guess with 50\% accuracy}
    \ControlFlowTok{return}\NormalTok{ random.choice([}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{])  }

\NormalTok{expected\_with }\OperatorTok{=}\NormalTok{ decision\_with\_info()}
\NormalTok{expected\_without }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(decision\_without\_info() }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1000}\NormalTok{)) }\OperatorTok{/} \DecValTok{1000}

\NormalTok{voi }\OperatorTok{=}\NormalTok{ expected\_with }\OperatorTok{{-}}\NormalTok{ expected\_without}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Estimated Value of Information:"}\NormalTok{, }\BuiltInTok{round}\NormalTok{(voi, }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-28}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add costs to information gathering---when is it still worth it?
\item
  Simulate imperfect information (70\% accuracy)---compare VoI against
  perfect information.
\item
  Reflect: where in real-world AI is information most valuable---medical
  diagnostics, autonomous driving, or recommender systems?
\end{enumerate}

\subsection{30. Limits of certainty in real-world
AI}\label{limits-of-certainty-in-real-world-ai}

AI systems never operate with complete certainty. Data can be noisy,
models are approximations, and environments change unpredictably.
Instead of seeking absolute certainty, effective AI embraces
uncertainty, quantifies it, and makes robust decisions under it.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-29}

Think of weather forecasting. Even with advanced satellites and
simulations, predictions are never 100\% accurate. Forecasters give
probabilities (``60\% chance of rain'') because certainty is impossible.
AI works the same way: it outputs probabilities, not guarantees.

\subsubsection{Deep Dive}\label{deep-dive-29}

\begin{itemize}
\item
  Sources of uncertainty:

  \begin{itemize}
  \tightlist
  \item
    Aleatoric: inherent randomness (e.g., quantum noise, dice rolls).
  \item
    Epistemic: lack of knowledge or model errors.
  \item
    Ontological: unforeseen situations outside the model's scope.
  \end{itemize}
\item
  AI strategies:

  \begin{itemize}
  \tightlist
  \item
    Probabilistic modeling and Bayesian inference.
  \item
    Confidence calibration for predictions.
  \item
    Robust optimization and safety margins.
  \end{itemize}
\item
  Implication: certainty is unattainable, but uncertainty-aware design
  leads to systems that are safer, more interpretable, and more
  trustworthy.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3083}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2583}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Uncertainty Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Handling Strategy
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Aleatoric & Randomness inherent in data & Sensor noise in robotics &
Probabilistic models, filtering \\
Epistemic & Model uncertainty due to limited data & Medical diagnosis
with rare diseases & Bayesian learning, ensembles \\
Ontological & Unknown unknowns & Autonomous car meets novel obstacle &
Fail-safes, human oversight \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-29}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Simulating aleatoric vs epistemic uncertainty}
\NormalTok{true\_value }\OperatorTok{=} \DecValTok{10}
\NormalTok{aleatoric\_noise }\OperatorTok{=}\NormalTok{ np.random.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{)  }\CommentTok{\# randomness}
\NormalTok{epistemic\_error }\OperatorTok{=} \DecValTok{2}  \CommentTok{\# model bias}

\NormalTok{measurements }\OperatorTok{=}\NormalTok{ true\_value }\OperatorTok{+}\NormalTok{ aleatoric\_noise }\OperatorTok{+}\NormalTok{ epistemic\_error}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Measurements with uncertainties:"}\NormalTok{, measurements)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-29}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Reduce aleatoric noise (lower variance)---does uncertainty shrink?
\item
  Change epistemic error---see how systematic bias skews results.
\item
  Reflect: why should AI systems present probabilities or confidence
  intervals instead of single ``certain'' answers?
\end{enumerate}

\section{Chapter 4. Computation, Complexity and
Limits}\label{chapter-4.-computation-complexity-and-limits}

\subsection{31. Computation as symbol
manipulation}\label{computation-as-symbol-manipulation}

At its core, computation is the manipulation of symbols according to
formal rules. AI systems inherit this foundation: whether processing
numbers, words, or images, they transform structured inputs into
structured outputs through rule-governed operations.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-30}

Think of a child using building blocks. Each block is a symbol, and by
arranging them under certain rules---stacking, matching shapes---the
child builds structures. A computer does the same, but with electrical
signals and logic gates instead of blocks.

\subsubsection{Deep Dive}\label{deep-dive-30}

\begin{itemize}
\item
  Classical view: computation = symbol manipulation independent of
  meaning.
\item
  Church--Turing thesis: any effective computation can be carried out by
  a Turing machine.
\item
  Relevance to AI:

  \begin{itemize}
  \tightlist
  \item
    Symbolic AI explicitly encodes rules and symbols (e.g., logic-based
    systems).
  \item
    Sub-symbolic AI (neural networks) still reduces to symbol
    manipulation at the machine level (numbers, tensors).
  \end{itemize}
\item
  Philosophical note: this raises questions of whether ``understanding''
  emerges from symbol manipulation or whether semantics requires
  embodiment.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2048}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3735}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4217}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Symbolic Computation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Sub-symbolic Computation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Unit of operation & Explicit symbols, rules & Numbers, vectors,
matrices \\
Example in AI & Expert systems, theorem proving & Neural networks, deep
learning \\
Strength & Transparency, logical reasoning & Pattern recognition,
generalization \\
Limitation & Brittle, hard to scale & Opaque, hard to interpret \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-30}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple symbol manipulation: replace symbols with rules}
\NormalTok{rules }\OperatorTok{=}\NormalTok{ \{}\StringTok{"A"}\NormalTok{: }\StringTok{"B"}\NormalTok{, }\StringTok{"B"}\NormalTok{: }\StringTok{"AB"}\NormalTok{\}}
\NormalTok{sequence }\OperatorTok{=} \StringTok{"A"}

\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{5}\NormalTok{):}
\NormalTok{    sequence }\OperatorTok{=} \StringTok{""}\NormalTok{.join(rules.get(ch, ch) }\ControlFlowTok{for}\NormalTok{ ch }\KeywordTok{in}\NormalTok{ sequence)}
    \BuiltInTok{print}\NormalTok{(sequence)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-30}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Extend the rewrite rules---how do the symbolic patterns evolve?
\item
  Try encoding arithmetic as symbol manipulation (e.g., ``III + II'' →
  ``V'').
\item
  Reflect: does symbol manipulation alone explain intelligence, or does
  meaning require more?
\end{enumerate}

\subsection{32. Models of computation (Turing, circuits,
RAM)}\label{models-of-computation-turing-circuits-ram}

Models of computation formalize what it means for a system to compute.
They provide abstract frameworks to describe algorithms, machines, and
their capabilities. For AI, these models define the boundaries of what
is computable and influence how we design efficient systems.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-31}

Imagine three ways of cooking the same meal: following a recipe step by
step (Turing machine), using a fixed kitchen appliance with wires and
buttons (logic circuit), or working in a modern kitchen with labeled
drawers and random access (RAM model). Each produces food but with
different efficiencies and constraints---just like models of
computation.

\subsubsection{Deep Dive}\label{deep-dive-31}

\begin{itemize}
\item
  Turing machine: sequential steps on an infinite tape. Proves what is
  \emph{computable}. Foundation of theoretical computer science.
\item
  Logic circuits: finite networks of gates (AND, OR, NOT). Capture
  computation at the hardware level.
\item
  Random Access Machine (RAM): closer to real computers, allowing
  constant-time access to memory cells. Used in algorithm analysis.
\item
  Implications for AI:

  \begin{itemize}
  \tightlist
  \item
    Proves equivalence of models (all can compute the same functions).
  \item
    Guides efficiency analysis---circuits emphasize parallelism, RAM
    emphasizes step complexity.
  \item
    Highlights limits---no model escapes undecidability or
    intractability.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1239}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3009}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2743}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3009}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Model
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Turing machine & Infinite tape, sequential rules & Defines computability
& Impractical for efficiency \\
Logic circuits & Gates wired into fixed networks & Parallel, hardware
realizable & Fixed, less flexible \\
RAM model & Memory cells, constant-time access & Matches real algorithm
analysis & Ignores hardware-level constraints \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-31}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simulate a simple RAM model: array memory}
\NormalTok{memory }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{] }\OperatorTok{*} \DecValTok{5}  \CommentTok{\# 5 memory cells}

\CommentTok{\# Program: compute sum of first 3 cells}
\NormalTok{memory[}\DecValTok{0}\NormalTok{], memory[}\DecValTok{1}\NormalTok{], memory[}\DecValTok{2}\NormalTok{] }\OperatorTok{=} \DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}
\NormalTok{accumulator }\OperatorTok{=} \DecValTok{0}
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{3}\NormalTok{):}
\NormalTok{    accumulator }\OperatorTok{+=}\NormalTok{ memory[i]}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Sum:"}\NormalTok{, accumulator)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-31}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Extend the RAM simulation to support subtraction or branching.
\item
  Build a tiny circuit simulator (AND, OR, NOT) and combine gates.
\item
  Reflect: why do we use different models for theory, hardware, and
  algorithm analysis in AI?
\end{enumerate}

\subsection{33. Time and space complexity
basics}\label{time-and-space-complexity-basics}

Complexity theory studies how the resources required by an
algorithm---time and memory---grow with input size. For AI,
understanding complexity is essential: it explains why some problems
scale well while others become intractable as data grows.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-32}

Imagine sorting a deck of cards. Sorting 10 cards by hand is quick.
Sorting 1,000 cards takes much longer. Sorting 1,000,000 cards by hand
might be impossible. The rules didn't change---the input size did.
Complexity tells us how performance scales.

\subsubsection{Deep Dive}\label{deep-dive-32}

\begin{itemize}
\item
  Time complexity: how the number of steps grows with input size \(n\).
  Common classes:

  \begin{itemize}
  \tightlist
  \item
    Constant \(O(1)\)
  \item
    Logarithmic \(O(\log n)\)
  \item
    Linear \(O(n)\)
  \item
    Quadratic \(O(n^2)\)
  \item
    Exponential \(O(2^n)\)
  \end{itemize}
\item
  Space complexity: how much memory an algorithm uses.
\item
  Big-O notation: describes asymptotic upper bound behavior.
\item
  AI implications: deep learning training scales roughly linearly with
  data and parameters, while combinatorial search may scale
  exponentially. Trade-offs between accuracy and feasibility often hinge
  on complexity.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1798}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2135}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3371}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2697}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Complexity Class
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Growth Rate Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Feasibility
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(O(1)\) & Constant time & Hash table lookup & Always feasible \\
\(O(\log n)\) & Grows slowly & Binary search over sorted data & Scales
well \\
\(O(n)\) & Linear growth & One pass over dataset & Scales with large
data \\
\(O(n^2)\) & Quadratic growth & Naive similarity comparison & Costly at
scale \\
\(O(2^n)\) & Exponential growth & Brute-force SAT solving & Infeasible
for large \(n\) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-32}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ time}

\KeywordTok{def}\NormalTok{ quadratic\_algorithm(n):}
\NormalTok{    count }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
        \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
\NormalTok{            count }\OperatorTok{+=} \DecValTok{1}
    \ControlFlowTok{return}\NormalTok{ count}

\ControlFlowTok{for}\NormalTok{ n }\KeywordTok{in}\NormalTok{ [}\DecValTok{10}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{500}\NormalTok{]:}
\NormalTok{    start }\OperatorTok{=}\NormalTok{ time.time()}
\NormalTok{    quadratic\_algorithm(n)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"n=}\SpecialCharTok{\{}\NormalTok{n}\SpecialCharTok{\}}\SpecialStringTok{, time=}\SpecialCharTok{\{}\NormalTok{time}\SpecialCharTok{.}\NormalTok{time()}\OperatorTok{{-}}\NormalTok{start}\SpecialCharTok{:.5f\}}\SpecialStringTok{s"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-32}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Replace the quadratic algorithm with a linear one and compare
  runtimes.
\item
  Experiment with larger \(n\)---when does runtime become impractical?
\item
  Reflect: which AI methods scale poorly, and how do we approximate or
  simplify them to cope?
\end{enumerate}

\subsection{34. Polynomial vs.~exponential
time}\label{polynomial-vs.-exponential-time}

Algorithms fall into broad categories depending on how their runtime
grows with input size. Polynomial-time algorithms (\(O(n^k)\)) are
generally considered tractable, while exponential-time algorithms
(\(O(2^n)\), \(O(n!)\)) quickly become infeasible. In AI, this
distinction often marks the boundary between solvable and impossible
problems at scale.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-33}

Imagine a puzzle where each piece can either fit or not. With 10 pieces,
you might check all possibilities by brute force---it's slow but doable.
With 100 pieces, the number of possibilities explodes astronomically.
Exponential growth feels like climbing a hill that turns into a sheer
cliff.

\subsubsection{Deep Dive}\label{deep-dive-33}

\begin{itemize}
\item
  Polynomial time (P): scalable solutions, e.g., shortest path with
  Dijkstra's algorithm.
\item
  Exponential time: search spaces blow up, e.g., brute-force traveling
  salesman problem.
\item
  NP-complete problems: believed not solvable in polynomial time (unless
  P = NP).
\item
  AI implications:

  \begin{itemize}
  \tightlist
  \item
    Many planning, scheduling, and combinatorial optimization tasks are
    exponential in the worst case.
  \item
    Practical AI relies on heuristics, approximations, or domain
    constraints to avoid exponential blowup.
  \item
    Understanding when exponential behavior appears helps design systems
    that stay usable.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2041}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2347}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3673}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1939}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Growth Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Runtime (n=50)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Practical?
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Polynomial \(O(n^2)\) & \textasciitilde2,500 steps & Distance matrix
computation & Yes \\
Polynomial \(O(n^3)\) & \textasciitilde125,000 steps & Matrix inversion
in ML & Yes (moderate) \\
Exponential \(O(2^n)\) & \textasciitilde1.1 quadrillion steps &
Brute-force SAT or planning problems & No (infeasible) \\
Factorial \(O(n!)\) & Larger than exponential & Traveling salesman brute
force & Impossible at scale \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-33}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ itertools}
\ImportTok{import}\NormalTok{ time}

\CommentTok{\# Polynomial example: O(n\^{}2)}
\KeywordTok{def}\NormalTok{ polynomial\_sum(n):}
\NormalTok{    total }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
        \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
\NormalTok{            total }\OperatorTok{+=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ j}
    \ControlFlowTok{return}\NormalTok{ total}

\CommentTok{\# Exponential example: brute force subsets}
\KeywordTok{def}\NormalTok{ exponential\_subsets(n):}
\NormalTok{    count }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ subset }\KeywordTok{in}\NormalTok{ itertools.product([}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{], repeat}\OperatorTok{=}\NormalTok{n):}
\NormalTok{        count }\OperatorTok{+=} \DecValTok{1}
    \ControlFlowTok{return}\NormalTok{ count}

\ControlFlowTok{for}\NormalTok{ n }\KeywordTok{in}\NormalTok{ [}\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{]:}
\NormalTok{    start }\OperatorTok{=}\NormalTok{ time.time()}
\NormalTok{    exponential\_subsets(n)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"n=}\SpecialCharTok{\{}\NormalTok{n}\SpecialCharTok{\}}\SpecialStringTok{, exponential time elapsed }\SpecialCharTok{\{}\NormalTok{time}\SpecialCharTok{.}\NormalTok{time()}\OperatorTok{{-}}\NormalTok{start}\SpecialCharTok{:.4f\}}\SpecialStringTok{s"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-33}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare runtime of polynomial vs.~exponential functions as \(n\)
  grows.
\item
  Experiment with heuristic pruning to cut down exponential search.
\item
  Reflect: why do AI systems rely heavily on approximations, heuristics,
  and randomness in exponential domains?
\end{enumerate}

\subsection{35. Intractability and NP-hard
problems}\label{intractability-and-np-hard-problems}

Some problems grow so quickly in complexity that no efficient
(polynomial-time) algorithm is known. These are intractable problems,
often labeled NP-hard. They sit at the edge of what AI can realistically
solve, forcing reliance on heuristics, approximations, or
exponential-time algorithms for small cases.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-34}

Imagine trying to seat 100 guests at 10 tables so that everyone sits
near friends and away from enemies. The number of possible seatings is
astronomical---testing them all would take longer than the age of the
universe. This is the flavor of NP-hardness.

\subsubsection{Deep Dive}\label{deep-dive-34}

\begin{itemize}
\item
  P vs.~NP:

  \begin{itemize}
  \tightlist
  \item
    P = problems solvable in polynomial time.
  \item
    NP = problems whose solutions can be \emph{verified} quickly.
  \end{itemize}
\item
  NP-hard: at least as hard as the hardest problems in NP.
\item
  NP-complete: problems that are both in NP and NP-hard.
\item
  Examples in AI:

  \begin{itemize}
  \tightlist
  \item
    Traveling Salesman Problem (planning, routing).
  \item
    Boolean satisfiability (SAT).
  \item
    Graph coloring (scheduling, resource allocation).
  \end{itemize}
\item
  Approaches:

  \begin{itemize}
  \tightlist
  \item
    Approximation algorithms (e.g., greedy for TSP).
  \item
    Heuristics (local search, simulated annealing).
  \item
    Special cases with efficient solutions.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1200}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3200}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2900}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2700}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Solvable Efficiently?
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
P & Solvable in polynomial time & Shortest path (Dijkstra) & Yes \\
NP & Solution verifiable in poly time & Sudoku solution check &
Verification only \\
NP-complete & In NP + NP-hard & SAT, TSP & Believed no (unless P=NP) \\
NP-hard & At least as hard as NP-complete & General optimization
problems & No known efficient solution \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-34}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ itertools}

\CommentTok{\# Brute force Traveling Salesman Problem (TSP) for 4 cities}
\NormalTok{distances }\OperatorTok{=}\NormalTok{ \{}
\NormalTok{    (}\StringTok{"A"}\NormalTok{,}\StringTok{"B"}\NormalTok{): }\DecValTok{2}\NormalTok{, (}\StringTok{"A"}\NormalTok{,}\StringTok{"C"}\NormalTok{): }\DecValTok{5}\NormalTok{, (}\StringTok{"A"}\NormalTok{,}\StringTok{"D"}\NormalTok{): }\DecValTok{7}\NormalTok{,}
\NormalTok{    (}\StringTok{"B"}\NormalTok{,}\StringTok{"C"}\NormalTok{): }\DecValTok{3}\NormalTok{, (}\StringTok{"B"}\NormalTok{,}\StringTok{"D"}\NormalTok{): }\DecValTok{4}\NormalTok{,}
\NormalTok{    (}\StringTok{"C"}\NormalTok{,}\StringTok{"D"}\NormalTok{): }\DecValTok{2}
\NormalTok{\}}

\NormalTok{cities }\OperatorTok{=}\NormalTok{ [}\StringTok{"A"}\NormalTok{,}\StringTok{"B"}\NormalTok{,}\StringTok{"C"}\NormalTok{,}\StringTok{"D"}\NormalTok{]}

\KeywordTok{def}\NormalTok{ path\_length(path):}
    \ControlFlowTok{return} \BuiltInTok{sum}\NormalTok{(distances.get((}\BuiltInTok{min}\NormalTok{(a,b), }\BuiltInTok{max}\NormalTok{(a,b)), }\DecValTok{0}\NormalTok{) }\ControlFlowTok{for}\NormalTok{ a,b }\KeywordTok{in} \BuiltInTok{zip}\NormalTok{(path, path[}\DecValTok{1}\NormalTok{:]))}

\NormalTok{best\_path, best\_len }\OperatorTok{=} \VariableTok{None}\NormalTok{, }\BuiltInTok{float}\NormalTok{(}\StringTok{"inf"}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ perm }\KeywordTok{in}\NormalTok{ itertools.permutations(cities):}
\NormalTok{    length }\OperatorTok{=}\NormalTok{ path\_length(perm)}
    \ControlFlowTok{if}\NormalTok{ length }\OperatorTok{\textless{}}\NormalTok{ best\_len:}
\NormalTok{        best\_len, best\_path }\OperatorTok{=}\NormalTok{ length, perm}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Best path:"}\NormalTok{, best\_path, }\StringTok{"Length:"}\NormalTok{, best\_len)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-34}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase the number of cities---how quickly does brute force become
  infeasible?
\item
  Add a greedy heuristic (always go to nearest city)---compare results
  with brute force.
\item
  Reflect: why does much of AI research focus on clever approximations
  for NP-hard problems?
\end{enumerate}

\subsection{36. Approximation and heuristics as
necessity}\label{approximation-and-heuristics-as-necessity}

When exact solutions are intractable, AI relies on approximation
algorithms and heuristics. Instead of guaranteeing the optimal answer,
these methods aim for ``good enough'' solutions within feasible time.
This pragmatic trade-off makes otherwise impossible problems solvable in
practice.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-35}

Think of packing a suitcase in a hurry. The optimal arrangement would
maximize space perfectly, but finding it would take hours. Instead, you
use a heuristic---roll clothes, fill corners, put shoes on the bottom.
The result isn't optimal, but it's practical.

\subsubsection{Deep Dive}\label{deep-dive-35}

\begin{itemize}
\item
  Approximation algorithms: guarantee solutions within a factor of the
  optimum (e.g., TSP with 1.5× bound).
\item
  Heuristics: rules of thumb, no guarantees, but often effective (e.g.,
  greedy search, hill climbing).
\item
  Metaheuristics: general strategies like simulated annealing, genetic
  algorithms, tabu search.
\item
  AI applications:

  \begin{itemize}
  \tightlist
  \item
    Game playing: heuristic evaluation functions.
  \item
    Scheduling: approximate resource allocation.
  \item
    Robotics: heuristic motion planning.
  \end{itemize}
\item
  Trade-off: speed vs.~accuracy. Heuristics enable scalability but may
  yield poor results in worst cases.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2170}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2830}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2170}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2830}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Guarantee
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Exact algorithm & Optimal solution & Brute-force SAT solver & Infeasible
at scale \\
Approximation algorithm & Within known performance gap & Approx. TSP
solver & May still be expensive \\
Heuristic & No guarantee, fast in practice & Greedy search in graphs &
Can miss good solutions \\
Metaheuristic & Broad search strategies & Genetic algorithms, SA & May
require tuning, stochastic \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-35}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Greedy heuristic for Traveling Salesman Problem}
\ImportTok{import}\NormalTok{ random}

\NormalTok{cities }\OperatorTok{=}\NormalTok{ [}\StringTok{"A"}\NormalTok{,}\StringTok{"B"}\NormalTok{,}\StringTok{"C"}\NormalTok{,}\StringTok{"D"}\NormalTok{]}
\NormalTok{distances }\OperatorTok{=}\NormalTok{ \{}
\NormalTok{    (}\StringTok{"A"}\NormalTok{,}\StringTok{"B"}\NormalTok{): }\DecValTok{2}\NormalTok{, (}\StringTok{"A"}\NormalTok{,}\StringTok{"C"}\NormalTok{): }\DecValTok{5}\NormalTok{, (}\StringTok{"A"}\NormalTok{,}\StringTok{"D"}\NormalTok{): }\DecValTok{7}\NormalTok{,}
\NormalTok{    (}\StringTok{"B"}\NormalTok{,}\StringTok{"C"}\NormalTok{): }\DecValTok{3}\NormalTok{, (}\StringTok{"B"}\NormalTok{,}\StringTok{"D"}\NormalTok{): }\DecValTok{4}\NormalTok{,}
\NormalTok{    (}\StringTok{"C"}\NormalTok{,}\StringTok{"D"}\NormalTok{): }\DecValTok{2}
\NormalTok{\}}

\KeywordTok{def}\NormalTok{ dist(a,b):}
    \ControlFlowTok{return}\NormalTok{ distances.get((}\BuiltInTok{min}\NormalTok{(a,b), }\BuiltInTok{max}\NormalTok{(a,b)), }\DecValTok{0}\NormalTok{)}

\KeywordTok{def}\NormalTok{ greedy\_tsp(start):}
\NormalTok{    unvisited }\OperatorTok{=} \BuiltInTok{set}\NormalTok{(cities)}
\NormalTok{    path }\OperatorTok{=}\NormalTok{ [start]}
\NormalTok{    unvisited.remove(start)}
    \ControlFlowTok{while}\NormalTok{ unvisited:}
\NormalTok{        next\_city }\OperatorTok{=} \BuiltInTok{min}\NormalTok{(unvisited, key}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ c: dist(path[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{], c))}
\NormalTok{        path.append(next\_city)}
\NormalTok{        unvisited.remove(next\_city)}
    \ControlFlowTok{return}\NormalTok{ path}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Greedy path:"}\NormalTok{, greedy\_tsp(}\StringTok{"A"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-35}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare greedy paths with brute-force optimal ones---how close are
  they?
\item
  Randomize starting city---does it change the quality of the solution?
\item
  Reflect: why are heuristics indispensable in AI despite their lack of
  guarantees?
\end{enumerate}

\subsection{37. Resource-bounded
rationality}\label{resource-bounded-rationality}

Classical rationality assumes unlimited time and computational resources
to find the optimal decision. Resource-bounded rationality recognizes
real-world limits: agents must make good decisions quickly with limited
data, time, and processing power. In AI, this often means
``satisficing'' rather than optimizing.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-36}

Imagine playing chess with only 10 seconds per move. You cannot explore
every possible sequence. Instead, you look a few moves ahead, use
heuristics, and pick a reasonable option. This is rationality under
resource bounds.

\subsubsection{Deep Dive}\label{deep-dive-36}

\begin{itemize}
\item
  Bounded rationality (Herbert Simon): decision-makers use heuristics
  and approximations within limits.
\item
  Anytime algorithms: produce a valid solution quickly and improve it
  with more time.
\item
  Meta-reasoning: deciding how much effort to spend thinking before
  acting.
\item
  Real-world AI:

  \begin{itemize}
  \tightlist
  \item
    Self-driving cars must act in milliseconds.
  \item
    Embedded devices have strict memory and CPU constraints.
  \item
    Cloud AI balances accuracy with cost and energy.
  \end{itemize}
\item
  Key trade-off: doing the best possible with limited resources
  vs.~chasing perfect optimality.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1652}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3130}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2261}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2957}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Advantage
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Perfect rationality & Exhaustive search in chess & Optimal solution &
Infeasible with large state spaces \\
Resource-bounded & Alpha-Beta pruning, heuristic search & Fast, usable
decisions & May miss optimal moves \\
Anytime algorithm & Iterative deepening search & Improves with time &
Requires time allocation strategy \\
Meta-reasoning & Adaptive compute allocation & Balances speed
vs.~quality & Complex to implement \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-36}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Anytime algorithm: improving solution over time}
\ImportTok{import}\NormalTok{ random}

\KeywordTok{def}\NormalTok{ anytime\_max(iterations):}
\NormalTok{    best }\OperatorTok{=} \BuiltInTok{float}\NormalTok{(}\StringTok{"{-}inf"}\NormalTok{)}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(iterations):}
\NormalTok{        candidate }\OperatorTok{=}\NormalTok{ random.randint(}\DecValTok{0}\NormalTok{, }\DecValTok{100}\NormalTok{)}
        \ControlFlowTok{if}\NormalTok{ candidate }\OperatorTok{\textgreater{}}\NormalTok{ best:}
\NormalTok{            best }\OperatorTok{=}\NormalTok{ candidate}
        \ControlFlowTok{yield}\NormalTok{ best  }\CommentTok{\# current best solution}

\ControlFlowTok{for}\NormalTok{ result }\KeywordTok{in}\NormalTok{ anytime\_max(}\DecValTok{5}\NormalTok{):}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Current best:"}\NormalTok{, result)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-36}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase iterations---watch how the solution improves over time.
\item
  Add a time cutoff to simulate resource limits.
\item
  Reflect: when should an AI stop computing and act with the best
  solution so far?
\end{enumerate}

\subsection{38. Physical limits of computation (energy,
speed)}\label{physical-limits-of-computation-energy-speed}

Computation is not abstract alone---it is grounded in physics. The
energy required, the speed of signal propagation, and thermodynamic laws
set ultimate limits on what machines can compute. For AI, this means
efficiency is not just an engineering concern but a fundamental
constraint.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-37}

Imagine trying to boil water instantly. No matter how good the pot or
stove, physics won't allow it---you're bounded by energy transfer
limits. Similarly, computers cannot compute arbitrarily fast without
hitting physical barriers.

\subsubsection{Deep Dive}\label{deep-dive-37}

\begin{itemize}
\item
  Landauer's principle: erasing one bit of information requires at least
  \(kT \ln 2\) energy (thermodynamic cost).
\item
  Speed of light: limits how fast signals can propagate across chips and
  networks.
\item
  Heat dissipation: as transistor density increases, power and cooling
  become bottlenecks.
\item
  Quantum limits: classical computation constrained by physical laws,
  leading to quantum computing explorations.
\item
  AI implications:

  \begin{itemize}
  \tightlist
  \item
    Training massive models consumes megawatt-hours of energy.
  \item
    Hardware design (GPUs, TPUs, neuromorphic chips) focuses on pushing
    efficiency.
  \item
    Sustainable AI requires respecting physical resource constraints.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2326}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3488}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4186}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Physical Limit
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Explanation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Impact on AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Landauer's principle & Minimum energy per bit erased & Lower bound on
computation cost \\
Speed of light & Limits interconnect speed & Affects distributed AI,
data centers \\
Heat dissipation & Power density ceiling & Restricts chip scaling \\
Quantum effects & Noise at nanoscale transistors & Push toward quantum /
new paradigms \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-37}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Estimate Landauer\textquotesingle{}s limit energy for bit erasure}
\ImportTok{import}\NormalTok{ math}

\NormalTok{k }\OperatorTok{=} \FloatTok{1.38e{-}23}  \CommentTok{\# Boltzmann constant}
\NormalTok{T }\OperatorTok{=} \DecValTok{300}       \CommentTok{\# room temperature in Kelvin}
\NormalTok{energy }\OperatorTok{=}\NormalTok{ k }\OperatorTok{*}\NormalTok{ T }\OperatorTok{*}\NormalTok{ math.log(}\DecValTok{2}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Minimum energy per bit erase:"}\NormalTok{, energy, }\StringTok{"Joules"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-37}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the temperature---how does energy per bit change?
\item
  Compare energy per bit with energy use in a modern GPU---see the gap.
\item
  Reflect: how do physical laws shape the trajectory of AI hardware and
  algorithm design?
\end{enumerate}

\subsection{39. Complexity and intelligence:
trade-offs}\label{complexity-and-intelligence-trade-offs}

Greater intelligence often requires handling greater computational
complexity. Yet, too much complexity makes systems slow, inefficient, or
fragile. Designing AI means balancing sophistication with
tractability---finding the sweet spot where intelligence is powerful but
still practical.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-38}

Think of learning to play chess. A beginner looks only one or two moves
ahead---fast but shallow. A grandmaster considers dozens of
possibilities---deep but time-consuming. Computers face the same
dilemma: more complexity gives deeper insight but costs more resources.

\subsubsection{Deep Dive}\label{deep-dive-38}

\begin{itemize}
\item
  Complex models: deep networks, probabilistic programs, symbolic
  reasoners---capable but expensive.
\item
  Simple models: linear classifiers, decision stumps---fast but limited.
\item
  Trade-offs:

  \begin{itemize}
  \tightlist
  \item
    Depth vs.~speed (deep reasoning vs.~real-time action).
  \item
    Accuracy vs.~interpretability (complex vs.~simple models).
  \item
    Optimality vs.~feasibility (exact vs.~approximate algorithms).
  \end{itemize}
\item
  AI strategies:

  \begin{itemize}
  \tightlist
  \item
    Hierarchical models: combine simple reflexes with complex planning.
  \item
    Hybrid systems: symbolic reasoning + sub-symbolic learning.
  \item
    Resource-aware learning: adjust model complexity dynamically.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2192}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3288}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4521}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Low Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
High Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Speed & Fast, responsive & Slow, resource-heavy \\
Accuracy & Coarse, less general & Precise, adaptable \\
Interpretability & Transparent, explainable & Opaque, hard to analyze \\
Robustness & Fewer failure modes & Prone to overfitting, brittleness \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-38}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Trade{-}off: simple vs. complex models}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}
\ImportTok{from}\NormalTok{ sklearn.neural\_network }\ImportTok{import}\NormalTok{ MLPClassifier}
\ImportTok{from}\NormalTok{ sklearn.datasets }\ImportTok{import}\NormalTok{ make\_classification}
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split}

\NormalTok{X, y }\OperatorTok{=}\NormalTok{ make\_classification(n\_samples}\OperatorTok{=}\DecValTok{500}\NormalTok{, n\_features}\OperatorTok{=}\DecValTok{20}\NormalTok{, random\_state}\OperatorTok{=}\DecValTok{42}\NormalTok{)}
\NormalTok{X\_train, X\_test, y\_train, y\_test }\OperatorTok{=}\NormalTok{ train\_test\_split(X, y, test\_size}\OperatorTok{=}\FloatTok{0.2}\NormalTok{)}

\NormalTok{simple\_model }\OperatorTok{=}\NormalTok{ LogisticRegression().fit(X\_train, y\_train)}
\NormalTok{complex\_model }\OperatorTok{=}\NormalTok{ MLPClassifier(hidden\_layer\_sizes}\OperatorTok{=}\NormalTok{(}\DecValTok{50}\NormalTok{,}\DecValTok{50}\NormalTok{), max\_iter}\OperatorTok{=}\DecValTok{500}\NormalTok{).fit(X\_train, y\_train)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Simple model accuracy:"}\NormalTok{, simple\_model.score(X\_test, y\_test))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Complex model accuracy:"}\NormalTok{, complex\_model.score(X\_test, y\_test))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-38}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare training times of the two models---how does complexity affect
  speed?
\item
  Add noise to data---does the complex model overfit while the simple
  model stays stable?
\item
  Reflect: in which domains is simplicity preferable, and where is
  complexity worth the cost?
\end{enumerate}

\subsection{40. Theoretical boundaries of AI
systems}\label{theoretical-boundaries-of-ai-systems}

AI is constrained not just by engineering challenges but by fundamental
theoretical limits. Some problems are provably unsolvable, others are
intractable, and some cannot be solved reliably under uncertainty.
Recognizing these boundaries prevents overpromising and guides realistic
AI design.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-39}

Imagine asking a calculator to tell you whether any arbitrary computer
program will run forever or eventually stop. No matter how advanced the
calculator is, this question---the Halting Problem---is mathematically
undecidable. AI inherits these hard boundaries from computation theory.

\subsubsection{Deep Dive}\label{deep-dive-39}

\begin{itemize}
\item
  Unsolvable problems:

  \begin{itemize}
  \tightlist
  \item
    Halting problem: no algorithm can decide for all programs if they
    halt.
  \item
    Certain logical inference tasks are undecidable.
  \end{itemize}
\item
  Intractable problems: solvable in principle but not in reasonable time
  (NP-hard, PSPACE-complete).
\item
  Approximation limits: some problems cannot even be approximated
  efficiently.
\item
  Uncertainty limits: no model can perfectly predict inherently
  stochastic or chaotic processes.
\item
  Implications for AI:

  \begin{itemize}
  \tightlist
  \item
    Absolute guarantees are often impossible.
  \item
    AI must rely on heuristics, approximations, and probabilistic
    reasoning.
  \item
    Awareness of boundaries helps avoid misusing AI in domains where
    guarantees are essential.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2234}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3511}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4255}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Boundary Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Undecidable & No algorithm exists & Halting problem, general theorem
proving \\
Intractable & Solvable, but not efficiently & Planning, SAT solving,
TSP \\
Approximation barrier & Cannot approximate within factor & Certain graph
coloring problems \\
Uncertainty bound & Outcomes inherently unpredictable & Stock prices,
weather chaos limits \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-39}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Halting problem illustration (toy version)}
\KeywordTok{def}\NormalTok{ halts(program, input\_data):}
    \ControlFlowTok{raise} \PreprocessorTok{NotImplementedError}\NormalTok{(}\StringTok{"Impossible to implement universally"}\NormalTok{)}

\ControlFlowTok{try}\NormalTok{:}
\NormalTok{    halts(}\KeywordTok{lambda}\NormalTok{ x: x}\OperatorTok{+}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\ControlFlowTok{except} \PreprocessorTok{NotImplementedError} \ImportTok{as}\NormalTok{ e:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Halting problem:"}\NormalTok{, e)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-39}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Explore NP-complete problems like SAT or Sudoku---why do they scale
  poorly?
\item
  Reflect on cases where undecidability or intractability forces AI to
  rely on heuristics.
\item
  Ask: how should policymakers and engineers account for these
  boundaries when deploying AI?
\end{enumerate}

\section{Chapter 5. Representation and
Abstraction}\label{chapter-5.-representation-and-abstraction}

\subsection{41. Why representation matters in
intelligence}\label{why-representation-matters-in-intelligence}

Representation determines what an AI system can perceive, reason about,
and act upon. The same problem framed differently can be easy or
impossible to solve. Good representations make patterns visible, reduce
complexity, and enable generalization.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-40}

Imagine solving a maze. If you only see the walls one step at a time,
navigation is hard. If you have a map, the maze becomes much easier. The
representation---the raw sensory stream vs.~the structured map---changes
the difficulty of the task.

\subsubsection{Deep Dive}\label{deep-dive-40}

\begin{itemize}
\item
  Role of representation: it bridges raw data and actionable knowledge.
\item
  Expressiveness: rich enough to capture relevant details.
\item
  Compactness: simple enough to be efficient.
\item
  Generalization: supports applying knowledge to new situations.
\item
  AI applications:

  \begin{itemize}
  \tightlist
  \item
    Vision: pixels → edges → objects.
  \item
    Language: characters → words → embeddings.
  \item
    Robotics: sensor readings → state space → control policies.
  \end{itemize}
\item
  Challenge: too simple a representation loses information, too complex
  makes reasoning intractable.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1776}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2710}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2617}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2897}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Representation Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Raw data & Pixels, waveforms & Complete, no preprocessing & Redundant,
hard to interpret \\
Hand-crafted & SIFT features, parse trees & Human insight, interpretable
& Brittle, domain-specific \\
Learned & Word embeddings, latent codes & Adaptive, scalable & Often
opaque, hard to interpret \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-40}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Comparing representations: raw vs. transformed}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Raw pixel intensities (3x3 image patch)}
\NormalTok{raw }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{, }\DecValTok{255}\NormalTok{, }\DecValTok{0}\NormalTok{],}
\NormalTok{                [}\DecValTok{255}\NormalTok{, }\DecValTok{255}\NormalTok{, }\DecValTok{255}\NormalTok{],}
\NormalTok{                [}\DecValTok{0}\NormalTok{, }\DecValTok{255}\NormalTok{, }\DecValTok{0}\NormalTok{]])}

\CommentTok{\# Derived representation: edges (simple horizontal diff)}
\NormalTok{edges }\OperatorTok{=}\NormalTok{ np.}\BuiltInTok{abs}\NormalTok{(np.diff(raw, axis}\OperatorTok{=}\DecValTok{1}\NormalTok{))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Raw data:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, raw)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Edge{-}based representation:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, edges)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-40}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Replace the pixel matrix with a new pattern---how does the edge
  representation change?
\item
  Add noise to raw data---does the transformed representation make the
  pattern clearer?
\item
  Reflect: what representations make problems easier for humans vs.~for
  machines?
\end{enumerate}

\subsection{42. Symbolic vs.~sub-symbolic
representations}\label{symbolic-vs.-sub-symbolic-representations}

AI representations can be broadly divided into symbolic (explicit
symbols and rules) and sub-symbolic (distributed numerical patterns).
Symbolic approaches excel at reasoning and structure, while sub-symbolic
approaches excel at perception and pattern recognition. Modern AI often
blends the two.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-41}

Think of language. A grammar book describes language symbolically with
rules (noun, verb, adjective). But when you actually \emph{hear} speech,
your brain processes sounds sub-symbolically---patterns of frequencies
and rhythms. Both perspectives are useful but different.

\subsubsection{Deep Dive}\label{deep-dive-41}

\begin{itemize}
\tightlist
\item
  Symbolic representation: logic, rules, graphs, knowledge bases.
  Transparent, interpretable, suited for reasoning.
\item
  Sub-symbolic representation: vectors, embeddings, neural activations.
  Captures similarity, fuzzy concepts, robust to noise.
\item
  Hybrid systems: neuro-symbolic AI combines the interpretability of
  symbols with the flexibility of neural networks.
\item
  Challenge: symbols handle structure but lack adaptability;
  sub-symbolic systems learn patterns but lack explicit reasoning.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1273}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2727}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Symbolic & Expert systems, logic programs & Transparent, rule-based
reasoning & Brittle, hard to learn from data \\
Sub-symbolic & Word embeddings, deep nets & Robust, generalizable &
Opaque, hard to explain reasoning \\
Neuro-symbolic & Logic + neural embeddings & Combines structure +
learning & Integration still an open problem \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-41}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Symbolic vs. sub{-}symbolic toy example}

\CommentTok{\# Symbolic rule: if animal has wings {-}\textgreater{} classify as bird}
\KeywordTok{def}\NormalTok{ classify\_symbolic(animal):}
    \ControlFlowTok{if} \StringTok{"wings"} \KeywordTok{in}\NormalTok{ animal:}
        \ControlFlowTok{return} \StringTok{"bird"}
    \ControlFlowTok{return} \StringTok{"not bird"}

\CommentTok{\# Sub{-}symbolic: similarity via embeddings}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\NormalTok{emb }\OperatorTok{=}\NormalTok{ \{}\StringTok{"bird"}\NormalTok{: np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{]), }\StringTok{"cat"}\NormalTok{: np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{]), }\StringTok{"bat"}\NormalTok{: np.array([}\FloatTok{0.8}\NormalTok{,}\FloatTok{0.2}\NormalTok{])\}}

\KeywordTok{def}\NormalTok{ cosine(a, b):}
    \ControlFlowTok{return}\NormalTok{ np.dot(a,b)}\OperatorTok{/}\NormalTok{(np.linalg.norm(a)}\OperatorTok{*}\NormalTok{np.linalg.norm(b))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Symbolic:"}\NormalTok{, classify\_symbolic([}\StringTok{"wings"}\NormalTok{]))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Sub{-}symbolic similarity (bat vs bird):"}\NormalTok{, cosine(emb[}\StringTok{"bat"}\NormalTok{], emb[}\StringTok{"bird"}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-41}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more symbolic rules---how brittle do they become?
\item
  Expand embeddings with more animals---does similarity capture fuzzy
  categories?
\item
  Reflect: why might the future of AI require blending symbolic clarity
  with sub-symbolic power?
\end{enumerate}

\subsection{43. Data structures: vectors, graphs,
trees}\label{data-structures-vectors-graphs-trees}

Intelligent systems rely on structured ways to organize information.
Vectors capture numerical features, graphs represent relationships, and
trees encode hierarchies. Each data structure enables different forms of
reasoning, making them foundational to AI.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-42}

Think of a city: coordinates (latitude, longitude) describe locations as
vectors; roads connecting intersections form a graph; a family tree of
neighborhoods and sub-districts is a tree. Different structures reveal
different aspects of the same world.

\subsubsection{Deep Dive}\label{deep-dive-42}

\begin{itemize}
\item
  Vectors: fixed-length arrays of numbers; used in embeddings, features,
  sensor readings.
\item
  Graphs: nodes + edges; model social networks, molecules, knowledge
  graphs.
\item
  Trees: hierarchical branching structures; model parse trees in
  language, decision trees in learning.
\item
  AI applications:

  \begin{itemize}
  \tightlist
  \item
    Vectors: word2vec, image embeddings.
  \item
    Graphs: graph neural networks, pathfinding.
  \item
    Trees: search algorithms, syntactic parsing.
  \end{itemize}
\item
  Key trade-off: choosing the right data structure shapes efficiency and
  insight.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0804}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1339}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2411}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2679}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2768}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Structure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Representation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Vector & Array of values & Word embeddings, features & Compact,
efficient computation & Limited structural expressivity \\
Graph & Nodes + edges & Knowledge graphs, GNNs & Rich relational
modeling & Costly for large graphs \\
Tree & Hierarchical & Decision trees, parse trees & Intuitive, recursive
reasoning & Less flexible than graphs \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-42}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Vectors, graphs, trees in practice}
\ImportTok{import}\NormalTok{ networkx }\ImportTok{as}\NormalTok{ nx}

\CommentTok{\# Vector: embedding for a word}
\NormalTok{vector }\OperatorTok{=}\NormalTok{ [}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.8}\NormalTok{, }\FloatTok{0.5}\NormalTok{]}

\CommentTok{\# Graph: simple knowledge network}
\NormalTok{G }\OperatorTok{=}\NormalTok{ nx.Graph()}
\NormalTok{G.add\_edges\_from([(}\StringTok{"AI"}\NormalTok{,}\StringTok{"ML"}\NormalTok{), (}\StringTok{"AI"}\NormalTok{,}\StringTok{"Robotics"}\NormalTok{), (}\StringTok{"ML"}\NormalTok{,}\StringTok{"Deep Learning"}\NormalTok{)])}

\CommentTok{\# Tree: nested dictionary as a simple hierarchy}
\NormalTok{tree }\OperatorTok{=}\NormalTok{ \{}\StringTok{"Animal"}\NormalTok{: \{}\StringTok{"Mammal"}\NormalTok{: [}\StringTok{"Dog"}\NormalTok{,}\StringTok{"Cat"}\NormalTok{], }\StringTok{"Bird"}\NormalTok{: [}\StringTok{"Sparrow"}\NormalTok{,}\StringTok{"Eagle"}\NormalTok{]\}\}}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Vector:"}\NormalTok{, vector)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Graph neighbors of AI:"}\NormalTok{, }\BuiltInTok{list}\NormalTok{(G.neighbors(}\StringTok{"AI"}\NormalTok{)))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Tree root categories:"}\NormalTok{, }\BuiltInTok{list}\NormalTok{(tree[}\StringTok{"Animal"}\NormalTok{].keys()))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-42}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add another dimension to the vector---how does it change
  interpretation?
\item
  Add nodes and edges to the graph---what new paths emerge?
\item
  Expand the tree---how does hierarchy help organize complexity?
\end{enumerate}

\subsection{44. Levels of abstraction: micro vs.~macro
views}\label{levels-of-abstraction-micro-vs.-macro-views}

Abstraction allows AI systems to operate at different levels of detail.
The micro view focuses on fine-grained, low-level states, while the
macro view captures higher-level summaries and patterns. Switching
between these views makes complex problems tractable.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-43}

Imagine traffic on a highway. At the micro level, you could track every
car's position and speed. At the macro level, you think in terms of
``traffic jam ahead'' or ``smooth flow.'' Both perspectives are valid
but serve different purposes.

\subsubsection{Deep Dive}\label{deep-dive-43}

\begin{itemize}
\item
  Micro-level representations: precise, detailed, computationally heavy.
  Examples: pixel-level vision, molecular simulations.
\item
  Macro-level representations: aggregated, simplified, more
  interpretable. Examples: object recognition, weather patterns.
\item
  Bridging levels: hierarchical models and abstractions (e.g., CNNs
  build from pixels → edges → objects).
\item
  AI applications:

  \begin{itemize}
  \tightlist
  \item
    Natural language: characters → words → sentences → topics.
  \item
    Robotics: joint torques → motor actions → tasks → goals.
  \item
    Systems: log events → user sessions → overall trends.
  \end{itemize}
\item
  Challenge: too much detail overwhelms; too much abstraction loses
  important nuance.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0900}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2900}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3200}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Level
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Micro & Pixel intensities in an image & Precise, full information & Hard
to interpret, inefficient \\
Macro & Object labels (``cat'', ``dog'') & Concise, human-aligned &
Misses fine-grained details \\
Hierarchy & Pixels → edges → objects & Balance of detail and efficiency
& Requires careful design \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-43}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Micro vs. macro abstraction}
\NormalTok{pixels }\OperatorTok{=}\NormalTok{ [[}\DecValTok{0}\NormalTok{, }\DecValTok{255}\NormalTok{, }\DecValTok{0}\NormalTok{],}
\NormalTok{          [}\DecValTok{255}\NormalTok{, }\DecValTok{255}\NormalTok{, }\DecValTok{255}\NormalTok{],}
\NormalTok{          [}\DecValTok{0}\NormalTok{, }\DecValTok{255}\NormalTok{, }\DecValTok{0}\NormalTok{]]}

\CommentTok{\# Macro abstraction: majority value (simple summary)}
\NormalTok{flattened }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(pixels, [])}
\NormalTok{macro }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(}\BuiltInTok{set}\NormalTok{(flattened), key}\OperatorTok{=}\NormalTok{flattened.count)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Micro (pixels):"}\NormalTok{, pixels)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Macro (dominant intensity):"}\NormalTok{, macro)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-43}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Replace the pixel grid with a different pattern---does the macro
  summary still capture the essence?
\item
  Add intermediate abstraction (edges, shapes)---how does it help bridge
  micro and macro?
\item
  Reflect: which tasks benefit from fine detail, and which from coarse
  summaries?
\end{enumerate}

\subsection{45. Compositionality and
modularity}\label{compositionality-and-modularity}

Compositionality is the principle that complex ideas can be built from
simpler parts. Modularity is the design strategy of keeping components
separable and reusable. Together, they allow AI systems to scale,
generalize, and adapt by combining building blocks.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-44}

Think of LEGO bricks. Each brick is simple, but by snapping them
together, you can build houses, cars, or spaceships. AI works the same
way---small representations (words, features, functions) compose into
larger structures (sentences, models, systems).

\subsubsection{Deep Dive}\label{deep-dive-44}

\begin{itemize}
\item
  Compositionality in language: meanings of sentences derive from
  meanings of words plus grammar.
\item
  Compositionality in vision: objects are built from parts (edges →
  shapes → objects → scenes).
\item
  Modularity in systems: separating perception, reasoning, and action
  into subsystems.
\item
  Benefits:

  \begin{itemize}
  \tightlist
  \item
    Scalability: large systems built from small components.
  \item
    Generalization: reuse parts in new contexts.
  \item
    Debuggability: easier to isolate errors.
  \end{itemize}
\item
  Challenges:

  \begin{itemize}
  \tightlist
  \item
    Deep learning models often entangle representations.
  \item
    Explicit modularity may reduce raw predictive power but improve
    interpretability.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1301}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3415}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2683}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2602}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Principle
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Compositionality & Language: words → phrases → sentences & Enables
systematic generalization & Hard to capture in neural models \\
Modularity & ML pipelines: preprocessing → model → eval & Maintainable,
reusable & Integration overhead \\
Hybrid & Neuro-symbolic systems & Combines flexibility + structure &
Still an open research problem \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-44}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple compositionality example}
\NormalTok{words }\OperatorTok{=}\NormalTok{ \{}\StringTok{"red"}\NormalTok{: }\StringTok{"color"}\NormalTok{, }\StringTok{"ball"}\NormalTok{: }\StringTok{"object"}\NormalTok{\}}

\KeywordTok{def}\NormalTok{ compose(phrase):}
    \ControlFlowTok{return}\NormalTok{ [words[w] }\ControlFlowTok{for}\NormalTok{ w }\KeywordTok{in}\NormalTok{ phrase.split() }\ControlFlowTok{if}\NormalTok{ w }\KeywordTok{in}\NormalTok{ words]}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Phrase: \textquotesingle{}red ball\textquotesingle{}"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Composed representation:"}\NormalTok{, compose(}\StringTok{"red ball"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-44}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Extend the dictionary with more words---what complex meanings can you
  build?
\item
  Add modular functions (e.g., color(), shape()) to handle categories
  separately.
\item
  Reflect: why do humans excel at compositionality, and how can AI
  systems learn it better?
\end{enumerate}

\subsection{46. Continuous vs.~discrete
abstractions}\label{continuous-vs.-discrete-abstractions}

Abstractions in AI can be continuous (smooth, real-valued) or discrete
(symbolic, categorical). Each offers strengths: continuous abstractions
capture nuance and gradients, while discrete abstractions capture
structure and rules. Many modern systems combine both.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-45}

Think of music. The sheet notation uses discrete symbols (notes, rests),
while the actual performance involves continuous variations in pitch,
volume, and timing. Both are essential to represent the same melody.

\subsubsection{Deep Dive}\label{deep-dive-45}

\begin{itemize}
\item
  Continuous representations: vectors, embeddings, probability
  distributions. Enable optimization with calculus and gradient descent.
\item
  Discrete representations: logic rules, parse trees, categorical
  labels. Enable precise reasoning and combinatorial search.
\item
  Hybrid representations: discretized latent variables, quantized
  embeddings, symbolic-neural hybrids.
\item
  AI applications:

  \begin{itemize}
  \tightlist
  \item
    Vision: pixels (continuous) vs.~object categories (discrete).
  \item
    Language: embeddings (continuous) vs.~grammar rules (discrete).
  \item
    Robotics: control signals (continuous) vs.~task planning (discrete).
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1468}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2844}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2752}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2936}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Abstraction Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Continuous & Word embeddings, sensor signals & Smooth optimization,
nuance & Harder to interpret \\
Discrete & Grammar rules, class labels & Clear structure, interpretable
& Brittle, less flexible \\
Hybrid & Vector-symbol integration & Combines flexibility + clarity &
Still an open research challenge \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-45}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Continuous vs. discrete abstraction}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Continuous: word embeddings}
\NormalTok{embeddings }\OperatorTok{=}\NormalTok{ \{}\StringTok{"cat"}\NormalTok{: np.array([}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.8}\NormalTok{]),}
              \StringTok{"dog"}\NormalTok{: np.array([}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.75}\NormalTok{])\}}

\CommentTok{\# Discrete: labels}
\NormalTok{labels }\OperatorTok{=}\NormalTok{ \{}\StringTok{"cat"}\NormalTok{: }\StringTok{"animal"}\NormalTok{, }\StringTok{"dog"}\NormalTok{: }\StringTok{"animal"}\NormalTok{\}}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Continuous similarity (cat vs dog):"}\NormalTok{,}
\NormalTok{      np.dot(embeddings[}\StringTok{"cat"}\NormalTok{], embeddings[}\StringTok{"dog"}\NormalTok{]))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Discrete label (cat):"}\NormalTok{, labels[}\StringTok{"cat"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-45}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more embeddings---does similarity reflect semantic closeness?
\item
  Add discrete categories that clash with continuous similarities---what
  happens?
\item
  Reflect: when should AI favor continuous nuance, and when discrete
  clarity?
\end{enumerate}

\subsection{47. Representation learning in modern
AI}\label{representation-learning-in-modern-ai}

Representation learning is the process by which AI systems automatically
discover useful ways to encode data, instead of relying solely on
hand-crafted features. Modern deep learning thrives on this principle:
neural networks learn hierarchical representations directly from raw
inputs.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-46}

Imagine teaching a child to recognize animals. You don't explicitly tell
them ``look for four legs, a tail, fur.'' Instead, they learn these
features themselves by seeing many examples. Representation learning
automates this same discovery process in machines.

\subsubsection{Deep Dive}\label{deep-dive-46}

\begin{itemize}
\item
  Manual features vs.~learned features: early AI relied on
  expert-crafted descriptors (e.g., SIFT in vision). Deep learning
  replaced these with data-driven embeddings.
\item
  Hierarchical learning:

  \begin{itemize}
  \tightlist
  \item
    Low layers capture simple patterns (edges, phonemes).
  \item
    Mid layers capture parts or phrases.
  \item
    High layers capture objects, semantics, or abstract meaning.
  \end{itemize}
\item
  Self-supervised learning: representations can be learned without
  explicit labels (contrastive learning, masked prediction).
\item
  Applications: word embeddings, image embeddings, audio features,
  multimodal representations.
\item
  Challenge: learned representations are powerful but often opaque,
  raising interpretability and bias concerns.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2300}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2200}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3100}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2400}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Hand-crafted features & SIFT, TF-IDF & Interpretable, domain knowledge &
Brittle, not scalable \\
Learned representations & CNNs, Transformers & Adaptive, scalable & Hard
to interpret \\
Self-supervised reps & Word2Vec, SimCLR, BERT & Leverages unlabeled data
& Data- and compute-hungry \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-46}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Toy example: representation learning with PCA}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.decomposition }\ImportTok{import}\NormalTok{ PCA}

\CommentTok{\# 2D points clustered by class}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{],[}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{],[}\DecValTok{3}\NormalTok{,}\DecValTok{3}\NormalTok{],[}\DecValTok{8}\NormalTok{,}\DecValTok{8}\NormalTok{],[}\DecValTok{9}\NormalTok{,}\DecValTok{7}\NormalTok{],[}\DecValTok{10}\NormalTok{,}\DecValTok{9}\NormalTok{]])}
\NormalTok{pca }\OperatorTok{=}\NormalTok{ PCA(n\_components}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
\NormalTok{X\_reduced }\OperatorTok{=}\NormalTok{ pca.fit\_transform(X)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Original shape:"}\NormalTok{, X.shape)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Reduced representation:"}\NormalTok{, X\_reduced.ravel())}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-46}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Apply PCA on different datasets---how does dimensionality reduction
  reveal structure?
\item
  Replace PCA with autoencoders---how do nonlinear representations
  differ?
\item
  Reflect: why is learning representations directly from data a
  breakthrough for AI?
\end{enumerate}

\subsection{48. Cognitive science views on
abstraction}\label{cognitive-science-views-on-abstraction}

Cognitive science studies how humans form and use abstractions, offering
insights for AI design. Humans simplify the world by grouping details
into categories, building mental models, and reasoning hierarchically.
AI systems that mimic these strategies can achieve more flexible and
general intelligence.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-47}

Think of how a child learns the concept of ``chair.'' They see many
different shapes---wooden chairs, office chairs, beanbags---and extract
an abstract category: ``something you can sit on.'' The ability to
ignore irrelevant details while preserving core function is abstraction
in action.

\subsubsection{Deep Dive}\label{deep-dive-47}

\begin{itemize}
\item
  Categorization: humans cluster experiences into categories (prototype
  theory, exemplar theory).
\item
  Conceptual hierarchies: categories are structured (animal → mammal →
  dog → poodle).
\item
  Schemas and frames: mental templates for understanding situations
  (e.g., ``restaurant script'').
\item
  Analogical reasoning: mapping structures from one domain to another.
\item
  AI implications:

  \begin{itemize}
  \tightlist
  \item
    Concept learning in symbolic systems.
  \item
    Representation learning inspired by human categorization.
  \item
    Analogy-making in problem solving and creativity.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2439}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3171}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4390}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Cognitive Mechanism
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Human Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Parallel
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Categorization & ``Chair'' across many shapes & Clustering,
embeddings \\
Hierarchies & Animal → Mammal → Dog & Ontologies, taxonomies \\
Schemas/frames & Restaurant dining sequence & Knowledge graphs,
scripts \\
Analogical reasoning & Atom as ``solar system'' & Structure mapping,
transfer learning \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-47}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple categorization via clustering}
\ImportTok{from}\NormalTok{ sklearn.cluster }\ImportTok{import}\NormalTok{ KMeans}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Toy data: height, weight of animals}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{30}\NormalTok{,}\DecValTok{5}\NormalTok{],[}\DecValTok{32}\NormalTok{,}\DecValTok{6}\NormalTok{],[}\DecValTok{100}\NormalTok{,}\DecValTok{30}\NormalTok{],[}\DecValTok{110}\NormalTok{,}\DecValTok{35}\NormalTok{]])}
\NormalTok{kmeans }\OperatorTok{=}\NormalTok{ KMeans(n\_clusters}\OperatorTok{=}\DecValTok{2}\NormalTok{, random\_state}\OperatorTok{=}\DecValTok{0}\NormalTok{).fit(X)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Cluster labels:"}\NormalTok{, kmeans.labels\_)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-47}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more animals---do the clusters still make intuitive sense?
\item
  Compare clustering (prototype-based) with nearest-neighbor
  (exemplar-based).
\item
  Reflect: how can human-inspired abstraction mechanisms improve AI
  flexibility and interpretability?
\end{enumerate}

\subsection{49. Trade-offs between fidelity and
simplicity}\label{trade-offs-between-fidelity-and-simplicity}

Representations can be high-fidelity, capturing rich details, or simple,
emphasizing ease of reasoning and efficiency. AI systems must balance
the two: detailed models may be accurate but costly and hard to
generalize, while simpler models may miss nuance but scale better.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-48}

Imagine a city map. A satellite photo has perfect fidelity but is
overwhelming for navigation. A subway map is much simpler, omitting
roads and buildings, but makes travel decisions easy. The ``best''
representation depends on the task.

\subsubsection{Deep Dive}\label{deep-dive-48}

\begin{itemize}
\item
  High-fidelity representations: retain more raw information, closer to
  reality. Examples: full-resolution images, detailed simulations.
\item
  Simple representations: abstract away details, highlight essentials.
  Examples: feature vectors, symbolic summaries.
\item
  Trade-offs:

  \begin{itemize}
  \tightlist
  \item
    Accuracy vs.~interpretability.
  \item
    Precision vs.~efficiency.
  \item
    Generality vs.~task-specific utility.
  \end{itemize}
\item
  AI strategies:

  \begin{itemize}
  \tightlist
  \item
    Dimensionality reduction (PCA, autoencoders).
  \item
    Task-driven simplification (decision trees vs.~deep nets).
  \item
    Multi-resolution models (use detail only when needed).
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1863}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2843}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2843}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2451}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Representation Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Advantage
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
High-fidelity & Pixel-level vision models & Precise, detailed &
Expensive, overfits noise \\
Simple & Bag-of-words for documents & Fast, interpretable & Misses
nuance and context \\
Multi-resolution & CNN pyramids, hierarchical RL & Balance detail and
efficiency & More complex to design \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-48}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Trade{-}off: detailed vs. simplified representation}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.decomposition }\ImportTok{import}\NormalTok{ PCA}

\CommentTok{\# High{-}fidelity: 4D data}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{7}\NormalTok{],[}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{11}\NormalTok{],[}\DecValTok{5}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{13}\NormalTok{,}\DecValTok{21}\NormalTok{]])}

\CommentTok{\# Simplified: project down to 2D with PCA}
\NormalTok{pca }\OperatorTok{=}\NormalTok{ PCA(n\_components}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{X\_reduced }\OperatorTok{=}\NormalTok{ pca.fit\_transform(X)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Original (4D):"}\NormalTok{, X)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Reduced (2D):"}\NormalTok{, X\_reduced)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-48}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase the number of dimensions---how much information is lost in
  reduction?
\item
  Try clustering on high-dimensional vs.~reduced data---does simplicity
  help?
\item
  Reflect: when should AI systems prioritize detail, and when should
  they embrace abstraction?
\end{enumerate}

\subsection{50. Towards universal
representations}\label{towards-universal-representations}

A long-term goal in AI is to develop universal
representations---encodings that capture the essence of knowledge across
tasks, modalities, and domains. Instead of learning separate features
for images, text, or speech, universal representations promise
transferability and general intelligence.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-49}

Imagine a translator who can switch seamlessly between languages, music,
and math, using the same internal ``mental code.'' No matter the
medium---words, notes, or numbers---the translator taps into one shared
understanding. Universal representations aim for that kind of
versatility in AI.

\subsubsection{Deep Dive}\label{deep-dive-49}

\begin{itemize}
\item
  Current practice: task- or domain-specific embeddings (e.g., word2vec
  for text, CNN features for vision).
\item
  Universal approaches: large-scale foundation models trained on
  multimodal data (text, images, audio).
\item
  Benefits:

  \begin{itemize}
  \tightlist
  \item
    Transfer learning: apply knowledge across tasks.
  \item
    Efficiency: fewer task-specific models.
  \item
    Alignment: bridge modalities (vision-language, speech-text).
  \end{itemize}
\item
  Challenges:

  \begin{itemize}
  \tightlist
  \item
    Biases from pretraining data propagate universally.
  \item
    Interpretability remains difficult.
  \item
    May underperform on highly specialized domains.
  \end{itemize}
\item
  Research frontier: multimodal transformers, contrastive representation
  learning, world models.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2062}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2887}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2577}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2474}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Representation Scope
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Task-specific & Word2Vec, ResNet embeddings & Optimized for domain &
Limited transferability \\
Domain-general & BERT, CLIP & Works across many tasks & Still biased by
modality \\
Universal & Multimodal foundation models & Cross-domain adaptability &
Hard to align perfectly \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-49}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Toy multimodal representation: text + numeric features}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{text\_emb }\OperatorTok{=}\NormalTok{ np.array([}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.7}\NormalTok{])   }\CommentTok{\# e.g., "cat"}
\NormalTok{image\_emb }\OperatorTok{=}\NormalTok{ np.array([}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.75}\NormalTok{]) }\CommentTok{\# embedding from an image of a cat}

\CommentTok{\# Universal space: combine}
\NormalTok{universal\_emb }\OperatorTok{=}\NormalTok{ (text\_emb }\OperatorTok{+}\NormalTok{ image\_emb) }\OperatorTok{/} \DecValTok{2}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Universal representation:"}\NormalTok{, universal\_emb)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-49}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add audio embeddings to the universal vector---how does it integrate?
\item
  Compare universal embeddings for semantically similar vs.~dissimilar
  items.
\item
  Reflect: is true universality possible, or will AI always need
  task-specific adaptations?
\end{enumerate}

\section{Chapter 6. Learning vs Reasoning: Two Paths to
Intelligence}\label{chapter-6.-learning-vs-reasoning-two-paths-to-intelligence}

\subsection{51. Learning from data and
experience}\label{learning-from-data-and-experience}

Learning allows AI systems to improve performance over time by
extracting patterns from data or direct experience. Unlike hard-coded
rules, learning adapts to new inputs and environments, making it a
cornerstone of artificial intelligence.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-50}

Think of a child riding a bicycle. At first they wobble and fall, but
with practice they learn to balance, steer, and pedal smoothly. The
``data'' comes from their own experiences---successes and failures
shaping future behavior.

\subsubsection{Deep Dive}\label{deep-dive-50}

\begin{itemize}
\tightlist
\item
  Supervised learning: learn from labeled examples (input → correct
  output).
\item
  Unsupervised learning: discover structure without labels (clustering,
  dimensionality reduction).
\item
  Reinforcement learning: learn from rewards and penalties over time.
\item
  Online vs.~offline learning: continuous adaptation vs.~training on a
  fixed dataset.
\item
  Experience replay: storing and reusing past data to stabilize
  learning.
\item
  Challenges: data scarcity, noise, bias, catastrophic forgetting.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1313}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2727}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2828}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3131}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Learning Mode
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Supervised & Image classification & Accurate with labels & Requires
large labeled datasets \\
Unsupervised & Word embeddings, clustering & Reveals hidden structure &
Hard to evaluate, ambiguous \\
Reinforcement & Game-playing agents & Learns sequential strategies &
Sample inefficient \\
Online & Stock trading bots & Adapts in real time & Risk of
instability \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-50}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Supervised learning toy example}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LinearRegression}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Data: study hours vs. test scores}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{],[}\DecValTok{4}\NormalTok{],[}\DecValTok{5}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{50}\NormalTok{, }\DecValTok{60}\NormalTok{, }\DecValTok{65}\NormalTok{, }\DecValTok{70}\NormalTok{, }\DecValTok{80}\NormalTok{])}

\NormalTok{model }\OperatorTok{=}\NormalTok{ LinearRegression().fit(X, y)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Prediction for 6 hours:"}\NormalTok{, model.predict([[}\DecValTok{6}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-50}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more training data---does the prediction accuracy improve?
\item
  Try removing data points---how sensitive is the model?
\item
  Reflect: why is the ability to learn from data the defining feature of
  AI over traditional programs?
\end{enumerate}

\subsection{52. Inductive vs.~deductive
inference}\label{inductive-vs.-deductive-inference}

AI systems can reason in two complementary ways: induction, drawing
general rules from specific examples, and deduction, applying general
rules to specific cases. Induction powers machine learning, while
deduction powers logic-based reasoning.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-51}

Suppose you see 10 swans, all white. You infer inductively that ``all
swans are white.'' Later, given the rule ``all swans are white,'' you
deduce that the next swan you see will also be white. One builds the
rule, the other applies it.

\subsubsection{Deep Dive}\label{deep-dive-51}

\begin{itemize}
\item
  Inductive inference:

  \begin{itemize}
  \tightlist
  \item
    Data → rule.
  \item
    Basis of supervised learning, clustering, pattern discovery.
  \item
    Example: from labeled cats and dogs, infer a classifier.
  \end{itemize}
\item
  Deductive inference:

  \begin{itemize}
  \tightlist
  \item
    Rule + fact → conclusion.
  \item
    Basis of logic, theorem proving, symbolic AI.
  \item
    Example: ``All cats are mammals'' + ``Garfield is a cat'' →
    ``Garfield is a mammal.''
  \end{itemize}
\item
  Abduction (related): best explanation from evidence.
\item
  AI practice:

  \begin{itemize}
  \tightlist
  \item
    Induction: neural networks generalizing patterns.
  \item
    Deduction: Prolog-style reasoning engines.
  \item
    Combining both is a key challenge in hybrid AI.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1207}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1810}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2586}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1983}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2414}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Inference Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Direction
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Induction & Specific → General & Learning classifiers from data &
Adapts, generalizes & Risk of overfitting \\
Deduction & General → Specific & Rule-based expert systems & Precise,
interpretable & Limited flexibility, brittle \\
Abduction & Evidence → Hypothesis & Medical diagnosis systems & Handles
incomplete info & Not guaranteed correct \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-51}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Deductive reasoning example}
\NormalTok{facts }\OperatorTok{=}\NormalTok{ \{}\StringTok{"Garfield"}\NormalTok{: }\StringTok{"cat"}\NormalTok{\}}
\NormalTok{rules }\OperatorTok{=}\NormalTok{ \{}\StringTok{"cat"}\NormalTok{: }\StringTok{"mammal"}\NormalTok{\}}

\KeywordTok{def}\NormalTok{ deduce(entity):}
\NormalTok{    kind }\OperatorTok{=}\NormalTok{ facts[entity]}
    \ControlFlowTok{return}\NormalTok{ rules.get(kind, }\VariableTok{None}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Garfield is a"}\NormalTok{, deduce(}\StringTok{"Garfield"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-51}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more facts and rules---can your deductive system scale?
\item
  Try inductive reasoning by fitting a simple classifier on data.
\item
  Reflect: why does modern AI lean heavily on induction, and what's lost
  without deduction?
\end{enumerate}

\subsection{53. Statistical learning vs.~logical
reasoning}\label{statistical-learning-vs.-logical-reasoning}

AI systems can operate through statistical learning, which finds
patterns in data, or through logical reasoning, which derives
conclusions from explicit rules. These approaches represent two
traditions: data-driven vs.~knowledge-driven AI.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-52}

Imagine diagnosing an illness. A statistician looks at thousands of
patient records and says, ``People with these symptoms usually have
flu.'' A logician says, ``If fever AND cough AND sore throat, THEN
flu.'' Both approaches reach the same conclusion, but through different
means.

\subsubsection{Deep Dive}\label{deep-dive-52}

\begin{itemize}
\item
  Statistical learning:

  \begin{itemize}
  \tightlist
  \item
    Probabilistic, approximate, data-driven.
  \item
    Example: logistic regression, neural networks.
  \item
    Pros: adapts well to noise, scalable.
  \item
    Cons: opaque, may lack guarantees.
  \end{itemize}
\item
  Logical reasoning:

  \begin{itemize}
  \tightlist
  \item
    Rule-based, symbolic, precise.
  \item
    Example: first-order logic, theorem provers.
  \item
    Pros: interpretable, guarantees correctness.
  \item
    Cons: brittle, struggles with uncertainty.
  \end{itemize}
\item
  Integration efforts: probabilistic logic, differentiable reasoning,
  neuro-symbolic AI.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1562}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2969}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2578}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2891}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Statistical learning & Neural networks, regression & Robust to noise,
learns from data & Hard to interpret, needs lots of data \\
Logical reasoning & Prolog, rule-based systems & Transparent, exact
conclusions & Brittle, struggles with ambiguity \\
Hybrid approaches & Probabilistic logic, neuro-symbolic AI & Balance
data + rules & Computationally challenging \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-52}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Statistical learning vs logical reasoning toy example}

\CommentTok{\# Statistical: learn from data}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])  }\CommentTok{\# threshold at \textasciitilde{}1.5}
\NormalTok{model }\OperatorTok{=}\NormalTok{ LogisticRegression().fit(X,y)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Statistical prediction for 2.5:"}\NormalTok{, model.predict([[}\FloatTok{2.5}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}

\CommentTok{\# Logical: explicit rule}
\KeywordTok{def}\NormalTok{ rule(x):}
    \ControlFlowTok{return} \DecValTok{1} \ControlFlowTok{if}\NormalTok{ x }\OperatorTok{\textgreater{}=} \DecValTok{2} \ControlFlowTok{else} \DecValTok{0}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Logical rule for 2.5:"}\NormalTok{, rule(}\FloatTok{2.5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-52}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add noise to the training data---does the statistical model still
  work?
\item
  Break the logical rule---how brittle is it?
\item
  Reflect: how might AI combine statistical flexibility with logical
  rigor?
\end{enumerate}

\subsection{54. Pattern recognition and
generalization}\label{pattern-recognition-and-generalization}

AI systems must not only recognize patterns in data but also generalize
beyond what they have explicitly seen. Pattern recognition extracts
structure, while generalization allows applying that structure to new,
unseen situations---a core ingredient of intelligence.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-53}

Think of learning to recognize cats. After seeing a few examples, you
can identify new cats, even if they differ in color, size, or posture.
You don't memorize exact images---you generalize the pattern of
``catness.''

\subsubsection{Deep Dive}\label{deep-dive-53}

\begin{itemize}
\item
  Pattern recognition:

  \begin{itemize}
  \tightlist
  \item
    Detecting regularities in inputs (shapes, sounds, sequences).
  \item
    Tools: classifiers, clustering, convolutional filters.
  \end{itemize}
\item
  Generalization:

  \begin{itemize}
  \tightlist
  \item
    Extending knowledge from training to novel cases.
  \item
    Relies on inductive bias---assumptions baked into the model.
  \end{itemize}
\item
  Overfitting vs.~underfitting:

  \begin{itemize}
  \tightlist
  \item
    Overfit = memorizing patterns without generalizing.
  \item
    Underfit = failing to capture patterns at all.
  \end{itemize}
\item
  AI applications:

  \begin{itemize}
  \tightlist
  \item
    Vision: detecting objects.
  \item
    NLP: understanding paraphrases.
  \item
    Healthcare: predicting disease risk from limited data.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1810}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2952}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3238}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Pitfall
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Pattern recognition & Identifying structure in data & CNNs detecting
edges and shapes & Can be superficial \\
Generalization & Applying knowledge to new cases & Transformer
understanding synonyms & Requires bias + data \\
Overfitting & Memorizing noise as patterns & Perfect train accuracy,
poor test & No transferability \\
Underfitting & Missing true structure & Always guessing majority class &
Poor accuracy overall \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-53}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Toy generalization example}
\ImportTok{from}\NormalTok{ sklearn.tree }\ImportTok{import}\NormalTok{ DecisionTreeClassifier}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{],[}\DecValTok{4}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])  }\CommentTok{\# threshold around 2}

\NormalTok{model }\OperatorTok{=}\NormalTok{ DecisionTreeClassifier().fit(X,y)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Seen example (2):"}\NormalTok{, model.predict([[}\DecValTok{2}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Unseen example (5):"}\NormalTok{, model.predict([[}\DecValTok{5}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-53}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase tree depth---does it overfit to training data?
\item
  Reduce training data---can the model still generalize?
\item
  Reflect: why is generalization the hallmark of intelligence, beyond
  rote pattern matching?
\end{enumerate}

\subsection{55. Rule-based vs.~data-driven
methods}\label{rule-based-vs.-data-driven-methods}

AI methods can be designed around explicit rules written by humans or
patterns learned from data. Rule-based approaches dominated early AI,
while data-driven approaches power most modern systems. The two differ
in flexibility, interpretability, and scalability.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-54}

Imagine teaching a child arithmetic. A rule-based method is giving them
a multiplication table to memorize and apply exactly. A data-driven
method is letting them solve many problems until they infer the patterns
themselves. Both lead to answers, but the path differs.

\subsubsection{Deep Dive}\label{deep-dive-54}

\begin{itemize}
\item
  Rule-based AI:

  \begin{itemize}
  \tightlist
  \item
    Expert systems with ``if--then'' rules.
  \item
    Pros: interpretable, precise, easy to debug.
  \item
    Cons: brittle, hard to scale, requires manual encoding of knowledge.
  \end{itemize}
\item
  Data-driven AI:

  \begin{itemize}
  \tightlist
  \item
    Machine learning models trained on large datasets.
  \item
    Pros: adaptable, scalable, robust to variation.
  \item
    Cons: opaque, data-hungry, harder to explain.
  \end{itemize}
\item
  Hybrid approaches: knowledge-guided learning, neuro-symbolic AI.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1068}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3010}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3107}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2816}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Rule-based & Expert systems, Prolog & Transparent, logical consistency &
Brittle, hard to scale \\
Data-driven & Neural networks, decision trees & Adaptive, scalable &
Opaque, requires lots of data \\
Hybrid & Neuro-symbolic learning & Combines structure + flexibility &
Integration complexity \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-54}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Rule{-}based vs. data{-}driven toy example}

\CommentTok{\# Rule{-}based}
\KeywordTok{def}\NormalTok{ classify\_number(x):}
    \ControlFlowTok{if}\NormalTok{ x }\OperatorTok{\%} \DecValTok{2} \OperatorTok{==} \DecValTok{0}\NormalTok{:}
        \ControlFlowTok{return} \StringTok{"even"}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{return} \StringTok{"odd"}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Rule{-}based:"}\NormalTok{, classify\_number(}\DecValTok{7}\NormalTok{))}

\CommentTok{\# Data{-}driven}
\ImportTok{from}\NormalTok{ sklearn.tree }\ImportTok{import}\NormalTok{ DecisionTreeClassifier}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{],[}\DecValTok{4}\NormalTok{],[}\DecValTok{5}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ [}\StringTok{"even"}\NormalTok{,}\StringTok{"odd"}\NormalTok{,}\StringTok{"even"}\NormalTok{,}\StringTok{"odd"}\NormalTok{,}\StringTok{"even"}\NormalTok{,}\StringTok{"odd"}\NormalTok{]}

\NormalTok{model }\OperatorTok{=}\NormalTok{ DecisionTreeClassifier().fit(X,y)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Data{-}driven:"}\NormalTok{, model.predict([[}\DecValTok{7}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-54}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more rules---how quickly does the rule-based approach become
  unwieldy?
\item
  Train the model on noisy data---does the data-driven approach still
  generalize?
\item
  Reflect: when is rule-based precision preferable, and when is
  data-driven flexibility essential?
\end{enumerate}

\subsection{56. When learning outperforms
reasoning}\label{when-learning-outperforms-reasoning}

In many domains, learning from data outperforms hand-crafted reasoning
because the real world is messy, uncertain, and too complex to capture
with fixed rules. Machine learning adapts to variation and scale where
pure logic struggles.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-55}

Think of recognizing faces. Writing down rules like ``two eyes above a
nose above a mouth'' quickly breaks---faces vary in shape, lighting, and
angle. But with enough examples, a learning system can capture these
variations automatically.

\subsubsection{Deep Dive}\label{deep-dive-55}

\begin{itemize}
\item
  Reasoning systems: excel when rules are clear and complete. Fail when
  variation is high.
\item
  Learning systems: excel in perception-heavy tasks with vast diversity.
\item
  Examples where learning wins:

  \begin{itemize}
  \tightlist
  \item
    Vision: object and face recognition.
  \item
    Speech: recognizing accents, noise, and emotion.
  \item
    Language: understanding synonyms, idioms, context.
  \end{itemize}
\item
  Why:

  \begin{itemize}
  \tightlist
  \item
    Data-driven flexibility handles ambiguity.
  \item
    Statistical models capture probabilistic variation.
  \item
    Scale of modern datasets makes pattern discovery possible.
  \end{itemize}
\item
  Limitation: learning can succeed without ``understanding,'' leading to
  brittle generalization.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1081}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4730}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4189}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Domain
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Reasoning (rule-based)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Learning (data-driven)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Vision & ``Eye + nose + mouth'' rules brittle & CNNs adapt to
lighting/angles \\
Speech & Phoneme rules fail on noise/accents & Deep nets generalize from
data \\
Language & Hand-coded grammar misses idioms & Transformers learn from
corpora \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-55}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Learning beats reasoning in noisy classification}
\ImportTok{from}\NormalTok{ sklearn.neighbors }\ImportTok{import}\NormalTok{ KNeighborsClassifier}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Data: noisy "rule" for odd/even classification}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{],[}\DecValTok{4}\NormalTok{],[}\DecValTok{5}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ [}\StringTok{"even"}\NormalTok{,}\StringTok{"odd"}\NormalTok{,}\StringTok{"even"}\NormalTok{,}\StringTok{"odd"}\NormalTok{,}\StringTok{"odd"}\NormalTok{,}\StringTok{"odd"}\NormalTok{]  }\CommentTok{\# noise at index 4}

\NormalTok{model }\OperatorTok{=}\NormalTok{ KNeighborsClassifier(n\_neighbors}\OperatorTok{=}\DecValTok{1}\NormalTok{).fit(X,y)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Prediction for 4 (noisy):"}\NormalTok{, model.predict([[}\DecValTok{4}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Prediction for 6 (generalizes):"}\NormalTok{, model.predict([[}\DecValTok{6}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-55}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more noisy labels---does the learner still generalize better than
  brittle rules?
\item
  Increase dataset size---watch the learning system smooth out noise.
\item
  Reflect: why are perception tasks dominated by learning methods
  instead of reasoning systems?
\end{enumerate}

\subsection{57. When reasoning outperforms
learning}\label{when-reasoning-outperforms-learning}

While learning excels at perception and pattern recognition, reasoning
dominates in domains that require structure, rules, and guarantees.
Logical inference can succeed where data is scarce, errors are costly,
or decisions must follow strict constraints.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-56}

Think of solving a Sudoku puzzle. A learning system trained on examples
might guess, but a reasoning system follows logical rules to guarantee
correctness. Here, rules beat patterns.

\subsubsection{Deep Dive}\label{deep-dive-56}

\begin{itemize}
\item
  Strengths of reasoning:

  \begin{itemize}
  \tightlist
  \item
    Works with little or no data.
  \item
    Provides transparent justifications.
  \item
    Guarantees correctness when rules are complete.
  \end{itemize}
\item
  Examples where reasoning wins:

  \begin{itemize}
  \tightlist
  \item
    Mathematics \& theorem proving: correctness requires logic, not
    approximation.
  \item
    Formal verification: ensuring software or hardware meets safety
    requirements.
  \item
    Constraint satisfaction: scheduling, planning, optimization with
    strict limits.
  \end{itemize}
\item
  Limitations of learning in these domains:

  \begin{itemize}
  \tightlist
  \item
    Requires massive data that may not exist.
  \item
    Produces approximate answers, not guarantees.
  \end{itemize}
\item
  Hybrid opportunity: reasoning provides structure, learning fills gaps.
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2593}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3086}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4321}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Domain
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Learning Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Reasoning Approach
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sudoku solving & Guess from patterns & Deductive logic guarantees
solution \\
Software verification & Predict defects from data & Prove correctness
formally \\
Flight scheduling & Predict likely routes & Optimize with constraints \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-56}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Reasoning beats learning: simple constraint solver}
\ImportTok{from}\NormalTok{ itertools }\ImportTok{import}\NormalTok{ permutations}

\CommentTok{\# Sudoku{-}like mini puzzle: fill 1{-}3 with no repeats}
\ControlFlowTok{for}\NormalTok{ perm }\KeywordTok{in}\NormalTok{ permutations([}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{]):}
    \ControlFlowTok{if}\NormalTok{ perm[}\DecValTok{0}\NormalTok{] }\OperatorTok{!=} \DecValTok{2}\NormalTok{:  }\CommentTok{\# constraint: first slot not 2}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"Valid solution:"}\NormalTok{, perm)}
        \ControlFlowTok{break}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-56}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more constraints---watch reasoning prune the solution space.
\item
  Try training a learner on the same problem---can it guarantee
  correctness?
\item
  Reflect: why do safety-critical AI applications often rely on
  reasoning over learning?
\end{enumerate}

\subsection{58. Combining learning and
reasoning}\label{combining-learning-and-reasoning}

Neither learning nor reasoning alone is sufficient for general
intelligence. Learning excels at perception and adapting to data, while
reasoning ensures structure, rules, and guarantees. Combining the
two---often called neuro-symbolic AI---aims to build systems that are
both flexible and reliable.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-57}

Imagine a lawyer-robot. Its learning side helps it understand spoken
language from clients, even with accents or noise. Its reasoning side
applies the exact rules of law to reach valid conclusions. Only together
can it work effectively.

\subsubsection{Deep Dive}\label{deep-dive-57}

\begin{itemize}
\item
  Why combine?

  \begin{itemize}
  \tightlist
  \item
    Learning handles messy, high-dimensional inputs.
  \item
    Reasoning enforces structure, constraints, and guarantees.
  \end{itemize}
\item
  Strategies:

  \begin{itemize}
  \tightlist
  \item
    Symbolic rules over learned embeddings.
  \item
    Neural networks guided by logical constraints.
  \item
    Differentiable logic and probabilistic programming.
  \end{itemize}
\item
  Applications:

  \begin{itemize}
  \tightlist
  \item
    Vision + reasoning: object recognition with relational logic.
  \item
    Language + reasoning: understanding and verifying arguments.
  \item
    Planning + perception: robotics combining neural perception with
    symbolic planners.
  \end{itemize}
\item
  Challenges:

  \begin{itemize}
  \tightlist
  \item
    Integration is technically hard.
  \item
    Differentiability vs.~discreteness mismatch.
  \item
    Interpretability vs.~scalability tension.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1268}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4507}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4225}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Component
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Learning & Robust, adaptive, scalable & Black-box, lacks guarantees \\
Reasoning & Transparent, rule-based, precise & Brittle, inflexible \\
Combined & Balances adaptability + rigor & Complex integration
challenges \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-57}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Hybrid: learning + reasoning toy demo}
\ImportTok{from}\NormalTok{ sklearn.tree }\ImportTok{import}\NormalTok{ DecisionTreeClassifier}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Learning: classify numbers}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{],[}\DecValTok{4}\NormalTok{],[}\DecValTok{5}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ [}\StringTok{"low"}\NormalTok{,}\StringTok{"low"}\NormalTok{,}\StringTok{"high"}\NormalTok{,}\StringTok{"high"}\NormalTok{,}\StringTok{"high"}\NormalTok{]}
\NormalTok{model }\OperatorTok{=}\NormalTok{ DecisionTreeClassifier().fit(X,y)}

\CommentTok{\# Reasoning: enforce a constraint (no "high" if \textless{}3)}
\KeywordTok{def}\NormalTok{ hybrid\_predict(x):}
\NormalTok{    pred }\OperatorTok{=}\NormalTok{ model.predict([[x]])[}\DecValTok{0}\NormalTok{]}
    \ControlFlowTok{if}\NormalTok{ x }\OperatorTok{\textless{}} \DecValTok{3} \KeywordTok{and}\NormalTok{ pred }\OperatorTok{==} \StringTok{"high"}\NormalTok{:}
        \ControlFlowTok{return} \StringTok{"low (corrected by rule)"}
    \ControlFlowTok{return}\NormalTok{ pred}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Hybrid prediction for 2:"}\NormalTok{, hybrid\_predict(}\DecValTok{2}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Hybrid prediction for 5:"}\NormalTok{, hybrid\_predict(}\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-57}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Train the learner on noisy labels---does reasoning help correct
  mistakes?
\item
  Add more rules to refine the hybrid output.
\item
  Reflect: what domains today most need neuro-symbolic AI (e.g., law,
  medicine, robotics)?
\end{enumerate}

\subsection{59. Current neuro-symbolic
approaches}\label{current-neuro-symbolic-approaches}

Neuro-symbolic AI seeks to unify neural networks (pattern recognition,
learning from data) with symbolic systems (logic, reasoning, knowledge
representation). The goal is to build systems that can perceive like a
neural net and reason like a logic engine.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-58}

Think of a self-driving car. Its neural network detects pedestrians,
cars, and traffic lights from camera feeds. Its symbolic system reasons
about rules like ``red light means stop'' or ``yield to pedestrians.''
Together, the car makes lawful, safe decisions.

\subsubsection{Deep Dive}\label{deep-dive-58}

\begin{itemize}
\item
  Integration strategies:

  \begin{itemize}
  \tightlist
  \item
    Symbolic on top of neural: neural nets produce symbols (objects,
    relations) → reasoning engine processes them.
  \item
    Neural guided by symbolic rules: logic constraints regularize
    learning (e.g., logical loss terms).
  \item
    Fully hybrid models: differentiable reasoning layers integrated into
    networks.
  \end{itemize}
\item
  Applications:

  \begin{itemize}
  \tightlist
  \item
    Vision + logic: scene understanding with relational reasoning.
  \item
    NLP + logic: combining embeddings with knowledge graphs.
  \item
    Robotics: neural control + symbolic task planning.
  \end{itemize}
\item
  Research challenges:

  \begin{itemize}
  \tightlist
  \item
    Scalability to large knowledge bases.
  \item
    Differentiability vs.~symbolic discreteness.
  \item
    Interpretability of hybrid models.
  \end{itemize}
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2137}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2906}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2650}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2308}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Symbolic on top of neural & Neural scene parser + Prolog rules &
Interpretable reasoning & Depends on neural accuracy \\
Neural guided by symbolic & Logic-regularized neural networks & Enforces
consistency & Hard to balance constraints \\
Fully hybrid & Differentiable theorem proving & End-to-end learning +
reasoning & Computationally intensive \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-58}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Neuro{-}symbolic toy example: neural output corrected by rule}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Neural{-}like output (probabilities)}
\NormalTok{pred\_probs }\OperatorTok{=}\NormalTok{ \{}\StringTok{"stop"}\NormalTok{: }\FloatTok{0.6}\NormalTok{, }\StringTok{"go"}\NormalTok{: }\FloatTok{0.4}\NormalTok{\}}

\CommentTok{\# Symbolic rule: if red light, must stop}
\NormalTok{observed\_light }\OperatorTok{=} \StringTok{"red"}

\ControlFlowTok{if}\NormalTok{ observed\_light }\OperatorTok{==} \StringTok{"red"}\NormalTok{:}
\NormalTok{    final\_decision }\OperatorTok{=} \StringTok{"stop"}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    final\_decision }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(pred\_probs, key}\OperatorTok{=}\NormalTok{pred\_probs.get)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Final decision:"}\NormalTok{, final\_decision)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-58}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the observed light---does the symbolic rule override the neural
  prediction?
\item
  Add more rules (e.g., ``yellow = slow down'') and combine with neural
  uncertainty.
\item
  Reflect: will future AI lean more on neuro-symbolic systems to achieve
  robustness and trustworthiness?
\end{enumerate}

\subsection{60. Open questions in
integration}\label{open-questions-in-integration}

Blending learning and reasoning is one of the grand challenges of AI.
While neuro-symbolic approaches show promise, many open questions remain
about scalability, interpretability, and how best to combine discrete
rules with continuous learning.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-59}

Think of oil and water. Neural nets (fluid, continuous) and symbolic
logic (rigid, discrete) often resist mixing. Researchers keep trying to
find the right ``emulsifier'' that allows them to blend smoothly into
one powerful system.

\subsubsection{Deep Dive}\label{deep-dive-59}

\begin{itemize}
\tightlist
\item
  Scalability: Can hybrid systems handle the scale of modern AI
  (billions of parameters, massive data)?
\item
  Differentiability: How to make discrete logical rules trainable with
  gradient descent?
\item
  Interpretability: How to ensure the symbolic layer explains what the
  neural part has learned?
\item
  Transferability: Can integrated systems generalize across domains
  better than either alone?
\item
  Benchmarks: What tasks truly test the benefit of integration
  (commonsense reasoning, law, robotics)?
\item
  Philosophical question: Is human intelligence itself a neuro-symbolic
  hybrid, and if so, what is the right architecture to model it?
\end{itemize}

Comparison Table

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2073}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3902}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4024}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Open Question
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Why It Matters
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Current Status
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Scalability & Needed for real-world deployment & Small demos, not yet at
LLM scale \\
Differentiability & Enables end-to-end training & Research in
differentiable logic \\
Interpretability & Builds trust, explains decisions & Still opaque in
hybrids \\
Transferability & Key to general intelligence & Limited evidence so
far \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-59}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Toy blend: neural score + symbolic constraint}
\NormalTok{neural\_score }\OperatorTok{=}\NormalTok{ \{}\StringTok{"cat"}\NormalTok{: }\FloatTok{0.6}\NormalTok{, }\StringTok{"dog"}\NormalTok{: }\FloatTok{0.4}\NormalTok{\}}
\NormalTok{constraints }\OperatorTok{=}\NormalTok{ \{}\StringTok{"must\_be\_animal"}\NormalTok{: [}\StringTok{"cat"}\NormalTok{,}\StringTok{"dog"}\NormalTok{,}\StringTok{"horse"}\NormalTok{]\}}

\CommentTok{\# Integration: filter neural outputs by symbolic constraint}
\NormalTok{filtered }\OperatorTok{=}\NormalTok{ \{k:v }\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ neural\_score.items() }\ControlFlowTok{if}\NormalTok{ k }\KeywordTok{in}\NormalTok{ constraints[}\StringTok{"must\_be\_animal"}\NormalTok{]\}}
\NormalTok{decision }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(filtered, key}\OperatorTok{=}\NormalTok{filtered.get)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Final decision after integration:"}\NormalTok{, decision)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-59}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add a constraint that conflicts with neural output---what happens?
\item
  Adjust neural scores---does symbolic filtering still dominate?
\item
  Reflect: what breakthroughs are needed to make hybrid AI the default
  paradigm?
\end{enumerate}

\section{Chapter 7. Search, Optimization, and
Decision-Making}\label{chapter-7.-search-optimization-and-decision-making}

\subsection{61. Search as a core paradigm of
AI}\label{search-as-a-core-paradigm-of-ai}

At its heart, much of AI reduces to search: systematically exploring
possibilities to find a path from a starting point to a desired goal.
Whether planning moves in a game, routing a delivery truck, or designing
a protein, the essence of intelligence often lies in navigating large
spaces of alternatives efficiently.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-60}

Imagine standing at the entrance of a vast library. Somewhere inside is
the book you need. You could wander randomly, but that might take
forever. Instead, you use an index, follow signs, or ask a librarian.
Each strategy is a way of searching the space of books more effectively
than brute force.

\subsubsection{Deep Dive}\label{deep-dive-60}

Search provides a unifying perspective for AI because it frames problems
as states, actions, and goals. The system begins in a state, applies
actions that generate new states, and continues until it reaches a goal
state. This formulation underlies classical pathfinding, symbolic
reasoning, optimization, and even modern reinforcement learning.

The power of search lies in its generality. A chess program does not
need a bespoke strategy for every board---it needs a way to search
through possible moves. A navigation app does not memorize every
possible trip---it searches for the best route. Yet this generality
creates challenges, since search spaces often grow exponentially with
problem size. Intelligent systems must therefore balance completeness,
efficiency, and optimality.

To appreciate the spectrum of search strategies, it helps to compare
their properties. At one extreme, uninformed search methods like
breadth-first and depth-first blindly traverse states until a goal is
found. At the other, informed search methods like A* exploit heuristics
to guide exploration, reducing wasted effort. Between them lie iterative
deepening, bidirectional search, and stochastic sampling methods.

Comparison Table: Uninformed vs.~Informed Search

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2062}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3918}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4021}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Uninformed Search
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Informed Search
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Guidance & No knowledge beyond problem definition & Uses heuristics or
estimates \\
Efficiency & Explores many irrelevant states & Focuses exploration on
promising states \\
Guarantee & Can ensure completeness and optimality & Depends on
heuristic quality \\
Example Algorithms & BFS, DFS, Iterative Deepening & A*, Greedy
Best-First, Beam Search \\
Typical Applications & Puzzle solving, graph traversal & Route planning,
game-playing, NLP \\
\end{longtable}

Search also interacts closely with optimization. The difference is often
one of framing: search emphasizes paths in discrete spaces, while
optimization emphasizes finding best solutions in continuous spaces. In
practice, many AI problems blend both---for example, reinforcement
learning agents search over action sequences while optimizing reward
functions.

Finally, search highlights the limits of brute-force intelligence.
Without heuristics, even simple problems can become intractable. The
challenge is designing representations and heuristics that compress vast
spaces into manageable ones. This is where domain knowledge, learned
embeddings, and hybrid systems enter, bridging raw computation with
informed guidance.

\subsubsection{Tiny Code}\label{tiny-code-60}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple uninformed search (BFS) for a path in a graph}
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ deque}

\NormalTok{graph }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"A"}\NormalTok{: [}\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{],}
    \StringTok{"B"}\NormalTok{: [}\StringTok{"D"}\NormalTok{, }\StringTok{"E"}\NormalTok{],}
    \StringTok{"C"}\NormalTok{: [}\StringTok{"F"}\NormalTok{],}
    \StringTok{"D"}\NormalTok{: [], }\StringTok{"E"}\NormalTok{: [}\StringTok{"F"}\NormalTok{], }\StringTok{"F"}\NormalTok{: []}
\NormalTok{\}}

\KeywordTok{def}\NormalTok{ bfs(start, goal):}
\NormalTok{    queue }\OperatorTok{=}\NormalTok{ deque([[start]])}
    \ControlFlowTok{while}\NormalTok{ queue:}
\NormalTok{        path }\OperatorTok{=}\NormalTok{ queue.popleft()}
\NormalTok{        node }\OperatorTok{=}\NormalTok{ path[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}
        \ControlFlowTok{if}\NormalTok{ node }\OperatorTok{==}\NormalTok{ goal:}
            \ControlFlowTok{return}\NormalTok{ path}
        \ControlFlowTok{for}\NormalTok{ neighbor }\KeywordTok{in}\NormalTok{ graph.get(node, []):}
\NormalTok{            queue.append(path }\OperatorTok{+}\NormalTok{ [neighbor])}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Path from A to F:"}\NormalTok{, bfs(}\StringTok{"A"}\NormalTok{, }\StringTok{"F"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-60}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Replace BFS with DFS and compare the paths explored---how does
  efficiency change?
\item
  Add a heuristic function and implement A*---does it reduce
  exploration?
\item
  Reflect: why does AI often look like ``search made smart''?
\end{enumerate}

\subsection{62. State spaces and exploration
strategies}\label{state-spaces-and-exploration-strategies}

Every search problem can be described in terms of a state space: the set
of all possible configurations the system might encounter. The
effectiveness of search depends on how this space is structured and how
exploration is guided through it.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-61}

Think of solving a sliding-tile puzzle. Each arrangement of tiles is a
state. Moving one tile changes the state. The state space is the entire
set of possible board configurations, and exploring it is like
navigating a giant tree whose branches represent moves.

\subsubsection{Deep Dive}\label{deep-dive-61}

A state space has three ingredients:

\begin{itemize}
\tightlist
\item
  States: representations of situations, such as board positions, robot
  locations, or logical facts.
\item
  Actions: operations that transform one state into another, such as
  moving a piece or taking a step.
\item
  Goals: specific target states or conditions to be achieved.
\end{itemize}

The way states and actions are represented determines both the size of
the search space and the strategies available for exploring it. Compact
representations make exploration efficient, while poor representations
explode the space unnecessarily.

Exploration strategies dictate how states are visited: systematically,
heuristically, or stochastically. Systematic strategies such as
breadth-first search guarantee coverage but can be inefficient.
Heuristic strategies like best-first search exploit additional knowledge
to guide exploration. Stochastic strategies like Monte Carlo sampling
probe the space randomly, trading completeness for speed.

Comparison Table: Exploration Strategies

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2308}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2115}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2885}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2692}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Strategy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Exploration Pattern
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strengths
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Weaknesses
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Systematic (BFS/DFS) & Exhaustive, structured & Completeness,
reproducibility & Inefficient in large spaces \\
Heuristic (A*) & Guided by estimates & Efficient, finds optimal paths &
Depends on heuristic quality \\
Stochastic (Monte Carlo) & Random sampling & Scalable, good for huge
spaces & No guarantee of optimality \\
\end{longtable}

In AI practice, state spaces can be massive. Chess has about \(10^{47}\)
legal positions, Go even more. Enumerating these spaces is impossible,
so effective strategies rely on pruning, abstraction, and heuristic
evaluation. Reinforcement learning takes this further by exploring state
spaces not explicitly enumerated but sampled through interaction with
environments.

\subsubsection{Tiny Code}\label{tiny-code-61}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# State space exploration: DFS vs BFS}
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ deque}

\NormalTok{graph }\OperatorTok{=}\NormalTok{ \{}\StringTok{"A"}\NormalTok{: [}\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{], }\StringTok{"B"}\NormalTok{: [}\StringTok{"D"}\NormalTok{, }\StringTok{"E"}\NormalTok{], }\StringTok{"C"}\NormalTok{: [}\StringTok{"F"}\NormalTok{], }\StringTok{"D"}\NormalTok{: [], }\StringTok{"E"}\NormalTok{: [], }\StringTok{"F"}\NormalTok{: []\}}

\KeywordTok{def}\NormalTok{ dfs(start, goal):}
\NormalTok{    stack }\OperatorTok{=}\NormalTok{ [[start]]}
    \ControlFlowTok{while}\NormalTok{ stack:}
\NormalTok{        path }\OperatorTok{=}\NormalTok{ stack.pop()}
\NormalTok{        node }\OperatorTok{=}\NormalTok{ path[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}
        \ControlFlowTok{if}\NormalTok{ node }\OperatorTok{==}\NormalTok{ goal:}
            \ControlFlowTok{return}\NormalTok{ path}
        \ControlFlowTok{for}\NormalTok{ neighbor }\KeywordTok{in}\NormalTok{ graph.get(node, []):}
\NormalTok{            stack.append(path }\OperatorTok{+}\NormalTok{ [neighbor])}

\KeywordTok{def}\NormalTok{ bfs(start, goal):}
\NormalTok{    queue }\OperatorTok{=}\NormalTok{ deque([[start]])}
    \ControlFlowTok{while}\NormalTok{ queue:}
\NormalTok{        path }\OperatorTok{=}\NormalTok{ queue.popleft()}
\NormalTok{        node }\OperatorTok{=}\NormalTok{ path[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}
        \ControlFlowTok{if}\NormalTok{ node }\OperatorTok{==}\NormalTok{ goal:}
            \ControlFlowTok{return}\NormalTok{ path}
        \ControlFlowTok{for}\NormalTok{ neighbor }\KeywordTok{in}\NormalTok{ graph.get(node, []):}
\NormalTok{            queue.append(path }\OperatorTok{+}\NormalTok{ [neighbor])}

\BuiltInTok{print}\NormalTok{(}\StringTok{"DFS path A→F:"}\NormalTok{, dfs(}\StringTok{"A"}\NormalTok{,}\StringTok{"F"}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"BFS path A→F:"}\NormalTok{, bfs(}\StringTok{"A"}\NormalTok{,}\StringTok{"F"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-61}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add loops to the graph---how do exploration strategies handle cycles?
\item
  Replace BFS/DFS with a heuristic that prefers certain nodes first.
\item
  Reflect: how does the choice of state representation reshape the
  difficulty of exploration?
\end{enumerate}

\subsection{63. Optimization problems and solution
quality}\label{optimization-problems-and-solution-quality}

Many AI tasks are not just about finding \emph{a} solution, but about
finding the best one. Optimization frames problems in terms of an
objective function to maximize or minimize. Solution quality is measured
by how well the chosen option scores relative to the optimum.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-62}

Imagine planning a road trip. You could choose \emph{any} route that
gets you from city A to city B, but some are shorter, cheaper, or more
scenic. Optimization is the process of evaluating alternatives and
selecting the route that best satisfies your chosen criteria.

\subsubsection{Deep Dive}\label{deep-dive-62}

Optimization problems are typically expressed as:

\begin{itemize}
\tightlist
\item
  Variables: the choices to be made (e.g., path, schedule, parameters).
\item
  Objective function: a numerical measure of quality (e.g., total
  distance, cost, accuracy).
\item
  Constraints: conditions that must hold (e.g., maximum budget, safety
  requirements).
\end{itemize}

In AI, optimization appears at multiple levels. At the algorithmic
level, pathfinding seeks the shortest or safest route. At the
statistical level, training a machine learning model minimizes loss. At
the systems level, scheduling problems allocate limited resources
effectively.

Solution quality is not always binary. Often, multiple solutions exist
with varying trade-offs, requiring approximation or heuristic methods.
For example, linear programming problems may yield exact solutions,
while combinatorial problems like the traveling salesman often require
heuristics that balance quality and efficiency.

Comparison Table: Exact vs.~Approximate Optimization

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3716}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2095}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2230}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1959}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Guarantee
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Efficiency
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Exact (e.g., linear programming) & Optimal solution guaranteed & Slow
for large problems & Resource scheduling, planning \\
Approximate (e.g., greedy, local search) & Close to optimal, no
guarantees & Fast, scalable & Routing, clustering \\
Heuristic/metaheuristic (e.g., simulated annealing, GA) & Often
near-optimal & Balances exploration/exploitation & Game AI, design
problems \\
\end{longtable}

Optimization also interacts with multi-objective trade-offs. An AI
system may need to maximize accuracy while minimizing cost, or balance
fairness against efficiency. This leads to Pareto frontiers, where no
solution is best across all criteria, only better in some dimensions.

\subsubsection{Tiny Code}\label{tiny-code-62}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple optimization: shortest path with Dijkstra}
\ImportTok{import}\NormalTok{ heapq}

\NormalTok{graph }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"A"}\NormalTok{: \{}\StringTok{"B"}\NormalTok{:}\DecValTok{2}\NormalTok{,}\StringTok{"C"}\NormalTok{:}\DecValTok{5}\NormalTok{\},}
    \StringTok{"B"}\NormalTok{: \{}\StringTok{"C"}\NormalTok{:}\DecValTok{1}\NormalTok{,}\StringTok{"D"}\NormalTok{:}\DecValTok{4}\NormalTok{\},}
    \StringTok{"C"}\NormalTok{: \{}\StringTok{"D"}\NormalTok{:}\DecValTok{1}\NormalTok{\},}
    \StringTok{"D"}\NormalTok{: \{\}}
\NormalTok{\}}

\KeywordTok{def}\NormalTok{ dijkstra(start, goal):}
\NormalTok{    queue }\OperatorTok{=}\NormalTok{ [(}\DecValTok{0}\NormalTok{, start, [])]}
\NormalTok{    seen }\OperatorTok{=} \BuiltInTok{set}\NormalTok{()}
    \ControlFlowTok{while}\NormalTok{ queue:}
\NormalTok{        (cost, node, path) }\OperatorTok{=}\NormalTok{ heapq.heappop(queue)}
        \ControlFlowTok{if}\NormalTok{ node }\KeywordTok{in}\NormalTok{ seen:}
            \ControlFlowTok{continue}
\NormalTok{        path }\OperatorTok{=}\NormalTok{ path }\OperatorTok{+}\NormalTok{ [node]}
        \ControlFlowTok{if}\NormalTok{ node }\OperatorTok{==}\NormalTok{ goal:}
            \ControlFlowTok{return}\NormalTok{ (cost, path)}
\NormalTok{        seen.add(node)}
        \ControlFlowTok{for}\NormalTok{ n, c }\KeywordTok{in}\NormalTok{ graph[node].items():}
\NormalTok{            heapq.heappush(queue, (cost}\OperatorTok{+}\NormalTok{c, n, path))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Shortest path A→D:"}\NormalTok{, dijkstra(}\StringTok{"A"}\NormalTok{,}\StringTok{"D"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-62}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add an extra edge to the graph---does it change the optimal solution?
\item
  Modify edge weights---how sensitive is the solution quality to
  changes?
\item
  Reflect: why does optimization unify so many AI problems, from
  learning weights to planning strategies?
\end{enumerate}

\subsection{64. Trade-offs: completeness, optimality,
efficiency}\label{trade-offs-completeness-optimality-efficiency}

Search and optimization in AI are always constrained by trade-offs. An
algorithm can aim to be complete (always finds a solution if one
exists), optimal (finds the best possible solution), or efficient (uses
minimal time and memory). In practice, no single method can maximize all
three.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-63}

Imagine looking for your car keys. A complete strategy is to search
every inch of the house---you'll eventually succeed but waste time. An
optimal strategy is to find them in the absolute minimum time, which may
require foresight you don't have. An efficient strategy is to quickly
check likely spots (desk, kitchen counter) but risk missing them if
they're elsewhere.

\subsubsection{Deep Dive}\label{deep-dive-63}

Completeness ensures reliability. Algorithms like breadth-first search
are complete but can be slow. Optimality ensures the best solution---A*
with an admissible heuristic guarantees optimal paths. Efficiency,
however, often requires cutting corners, such as greedy search, which
may miss the best path.

The choice among these depends on the domain. In robotics, efficiency
and near-optimality may be more important than strict completeness. In
theorem proving, completeness may outweigh efficiency. In logistics,
approximate optimality is often good enough if efficiency scales to
millions of deliveries.

Comparison Table: Properties of Search Algorithms

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1393}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1557}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1803}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2869}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2377}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complete?
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Optimal?
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Efficiency
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Typical Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Breadth-First & Yes & Yes (if costs uniform) & Low (explores widely) &
Simple shortest-path problems \\
Depth-First & Yes (finite spaces) & No & High memory efficiency, can be
slow & Exploring large state spaces \\
Greedy Best-First & No & No & Very fast & Quick approximate solutions \\
A* (admissible) & Yes & Yes & Moderate, depends on heuristic & Optimal
pathfinding \\
\end{longtable}

This trilemma highlights why heuristic design is critical. Good
heuristics push algorithms closer to optimality and efficiency without
sacrificing completeness. Poor heuristics waste resources or miss good
solutions.

\subsubsection{Tiny Code}\label{tiny-code-63}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Greedy vs A* search demonstration}
\ImportTok{import}\NormalTok{ heapq}

\NormalTok{graph }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"A"}\NormalTok{: \{}\StringTok{"B"}\NormalTok{:}\DecValTok{1}\NormalTok{,}\StringTok{"C"}\NormalTok{:}\DecValTok{4}\NormalTok{\},}
    \StringTok{"B"}\NormalTok{: \{}\StringTok{"C"}\NormalTok{:}\DecValTok{2}\NormalTok{,}\StringTok{"D"}\NormalTok{:}\DecValTok{5}\NormalTok{\},}
    \StringTok{"C"}\NormalTok{: \{}\StringTok{"D"}\NormalTok{:}\DecValTok{1}\NormalTok{\},}
    \StringTok{"D"}\NormalTok{: \{\}}
\NormalTok{\}}

\NormalTok{heuristic }\OperatorTok{=}\NormalTok{ \{}\StringTok{"A"}\NormalTok{:}\DecValTok{3}\NormalTok{,}\StringTok{"B"}\NormalTok{:}\DecValTok{2}\NormalTok{,}\StringTok{"C"}\NormalTok{:}\DecValTok{1}\NormalTok{,}\StringTok{"D"}\NormalTok{:}\DecValTok{0}\NormalTok{\}  }\CommentTok{\# heuristic estimates}

\KeywordTok{def}\NormalTok{ astar(start, goal):}
\NormalTok{    queue }\OperatorTok{=}\NormalTok{ [(}\DecValTok{0}\OperatorTok{+}\NormalTok{heuristic[start],}\DecValTok{0}\NormalTok{,start,[])]}
    \ControlFlowTok{while}\NormalTok{ queue:}
\NormalTok{        f,g,node,path }\OperatorTok{=}\NormalTok{ heapq.heappop(queue)}
\NormalTok{        path }\OperatorTok{=}\NormalTok{ path}\OperatorTok{+}\NormalTok{[node]}
        \ControlFlowTok{if}\NormalTok{ node }\OperatorTok{==}\NormalTok{ goal:}
            \ControlFlowTok{return}\NormalTok{ (g,path)}
        \ControlFlowTok{for}\NormalTok{ n,c }\KeywordTok{in}\NormalTok{ graph[node].items():}
\NormalTok{            heapq.heappush(queue,(g}\OperatorTok{+}\NormalTok{c}\OperatorTok{+}\NormalTok{heuristic[n],g}\OperatorTok{+}\NormalTok{c,n,path))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"A* path:"}\NormalTok{, astar(}\StringTok{"A"}\NormalTok{,}\StringTok{"D"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-63}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Replace the heuristic with random values---how does it affect
  optimality?
\item
  Compare A* to greedy search (use only heuristic, ignore g)---which is
  faster?
\item
  Reflect: why can't AI systems maximize completeness, optimality, and
  efficiency all at once?
\end{enumerate}

\subsection{65. Greedy, heuristic, and informed
search}\label{greedy-heuristic-and-informed-search}

Not all search strategies blindly explore possibilities. Greedy search
follows the most promising-looking option at each step. Heuristic search
uses estimates to guide exploration. Informed search combines
problem-specific knowledge with systematic search, often achieving
efficiency without sacrificing too much accuracy.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-64}

Imagine hiking up a mountain in fog. A greedy approach is to always step
toward the steepest upward slope---you'll climb quickly, but you may end
up on a local hill instead of the highest peak. A heuristic approach
uses a rough map that points you toward promising trails. An informed
search balances both---map guidance plus careful checking to ensure
you're really reaching the summit.

\subsubsection{Deep Dive}\label{deep-dive-64}

Greedy search is fast but shortsighted. It relies on evaluating the
immediate ``best'' option without considering long-term consequences.
Heuristic search introduces estimates of how far a state is from the
goal, such as distance in pathfinding. Informed search algorithms like
A* integrate actual cost so far with heuristic estimates, ensuring both
efficiency and optimality when heuristics are admissible.

The effectiveness of these methods depends heavily on heuristic quality.
A poor heuristic may waste time or mislead the search. A well-crafted
heuristic, even if simple, can drastically reduce exploration. In
practice, heuristics are often domain-specific: straight-line distance
in maps, Manhattan distance in puzzles, or learned estimates in modern
AI systems.

Comparison Table: Greedy vs.~Heuristic vs.~Informed

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1468}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1376}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1651}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2936}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2569}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Strategy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Cost Considered
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Goal Estimate Used
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Weakness
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Greedy Search & No & Yes & Very fast, low memory & May get stuck in
local traps \\
Heuristic Search & Sometimes & Yes & Guides exploration & Quality
depends on heuristic \\
Informed Search & Yes (path cost) & Yes & Balances efficiency +
optimality & More computation per step \\
\end{longtable}

In modern AI, informed search generalizes beyond symbolic search spaces.
Neural networks learn heuristics automatically, approximating
distance-to-goal functions. This connection bridges classical AI
planning with contemporary machine learning.

\subsubsection{Tiny Code}\label{tiny-code-64}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Greedy vs A* search with heuristic}
\ImportTok{import}\NormalTok{ heapq}

\NormalTok{graph }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"A"}\NormalTok{: \{}\StringTok{"B"}\NormalTok{:}\DecValTok{2}\NormalTok{,}\StringTok{"C"}\NormalTok{:}\DecValTok{5}\NormalTok{\},}
    \StringTok{"B"}\NormalTok{: \{}\StringTok{"C"}\NormalTok{:}\DecValTok{1}\NormalTok{,}\StringTok{"D"}\NormalTok{:}\DecValTok{4}\NormalTok{\},}
    \StringTok{"C"}\NormalTok{: \{}\StringTok{"D"}\NormalTok{:}\DecValTok{1}\NormalTok{\},}
    \StringTok{"D"}\NormalTok{: \{\}}
\NormalTok{\}}

\NormalTok{heuristic }\OperatorTok{=}\NormalTok{ \{}\StringTok{"A"}\NormalTok{:}\DecValTok{6}\NormalTok{,}\StringTok{"B"}\NormalTok{:}\DecValTok{4}\NormalTok{,}\StringTok{"C"}\NormalTok{:}\DecValTok{2}\NormalTok{,}\StringTok{"D"}\NormalTok{:}\DecValTok{0}\NormalTok{\}}

\KeywordTok{def}\NormalTok{ greedy(start, goal):}
\NormalTok{    queue }\OperatorTok{=}\NormalTok{ [(heuristic[start], start, [])]}
\NormalTok{    seen }\OperatorTok{=} \BuiltInTok{set}\NormalTok{()}
    \ControlFlowTok{while}\NormalTok{ queue:}
\NormalTok{        \_, node, path }\OperatorTok{=}\NormalTok{ heapq.heappop(queue)}
        \ControlFlowTok{if}\NormalTok{ node }\KeywordTok{in}\NormalTok{ seen: }
            \ControlFlowTok{continue}
\NormalTok{        path }\OperatorTok{=}\NormalTok{ path }\OperatorTok{+}\NormalTok{ [node]}
        \ControlFlowTok{if}\NormalTok{ node }\OperatorTok{==}\NormalTok{ goal:}
            \ControlFlowTok{return}\NormalTok{ path}
\NormalTok{        seen.add(node)}
        \ControlFlowTok{for}\NormalTok{ n }\KeywordTok{in}\NormalTok{ graph[node]:}
\NormalTok{            heapq.heappush(queue, (heuristic[n], n, path))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Greedy path:"}\NormalTok{, greedy(}\StringTok{"A"}\NormalTok{,}\StringTok{"D"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-64}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare greedy and A* on the same graph---does A* find shorter paths?
\item
  Change the heuristic values---how sensitive are the results?
\item
  Reflect: how do learned heuristics in modern AI extend this classical
  idea?
\end{enumerate}

\subsection{66. Global vs.~local optima
challenges}\label{global-vs.-local-optima-challenges}

Optimization problems in AI often involve navigating landscapes with
many peaks and valleys. A local optimum is a solution better than its
neighbors but not the best overall. A global optimum is the true best
solution. Distinguishing between the two is a central challenge,
especially in high-dimensional spaces.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-65}

Imagine climbing hills in heavy fog. You reach the top of a nearby hill
and think you're done---yet a taller mountain looms beyond the mist.
That smaller hill is a local optimum; the tallest mountain is the global
optimum. AI systems face the same trap when optimizing.

\subsubsection{Deep Dive}\label{deep-dive-65}

Local vs.~global optima appear in many AI contexts. Neural network
training often settles in local minima, though in very high dimensions,
``bad'' minima are surprisingly rare and saddle points dominate.
Heuristic search algorithms like hill climbing can get stuck at local
maxima unless randomization or diversification strategies are
introduced.

To escape local traps, techniques include:

\begin{itemize}
\tightlist
\item
  Random restarts: re-run search from multiple starting points.
\item
  Simulated annealing: accept worse moves probabilistically to escape
  local basins.
\item
  Genetic algorithms: explore populations of solutions to maintain
  diversity.
\item
  Momentum methods in deep learning: help optimizers roll through small
  valleys.
\end{itemize}

The choice of method depends on the problem structure. Convex
optimization problems, common in linear models, guarantee global optima.
Non-convex problems, such as deep neural networks, require approximation
strategies and careful initialization.

Comparison Table: Local vs.~Global Optima

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1954}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4138}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3908}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Feature
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Local Optimum
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Global Optimum
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Definition & Best in a neighborhood & Best overall \\
Detection & Easy (compare neighbors) & Hard (requires whole search) \\
Example in AI & Hill-climbing gets stuck & Linear regression finds exact
best \\
Escape Strategies & Randomization, annealing, heuristics & Convexity
ensures unique optimum \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-65}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Local vs global optima: hill climbing on a bumpy function}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\KeywordTok{def}\NormalTok{ f(x):}
    \ControlFlowTok{return}\NormalTok{ np.sin(}\DecValTok{5}\OperatorTok{*}\NormalTok{x) }\OperatorTok{*}\NormalTok{ (}\DecValTok{1}\OperatorTok{{-}}\NormalTok{x) }\OperatorTok{+}\NormalTok{ x2}

\KeywordTok{def}\NormalTok{ hill\_climb(start, step}\OperatorTok{=}\FloatTok{0.01}\NormalTok{, iters}\OperatorTok{=}\DecValTok{1000}\NormalTok{):}
\NormalTok{    x }\OperatorTok{=}\NormalTok{ start}
    \ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(iters):}
\NormalTok{        neighbors }\OperatorTok{=}\NormalTok{ [x}\OperatorTok{{-}}\NormalTok{step, x}\OperatorTok{+}\NormalTok{step]}
\NormalTok{        best }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(neighbors, key}\OperatorTok{=}\NormalTok{f)}
        \ControlFlowTok{if}\NormalTok{ f(best) }\OperatorTok{\textless{}=}\NormalTok{ f(x):}
            \ControlFlowTok{break}  \CommentTok{\# stuck at local optimum}
\NormalTok{        x }\OperatorTok{=}\NormalTok{ best}
    \ControlFlowTok{return}\NormalTok{ x, f(x)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Hill climbing from 0.5:"}\NormalTok{, hill\_climb(}\FloatTok{0.5}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Hill climbing from 2.0:"}\NormalTok{, hill\_climb(}\FloatTok{2.0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-65}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the starting point---do you end up at different optima?
\item
  Increase step size or add randomness---can you escape local traps?
\item
  Reflect: why do real-world AI systems often settle for ``good enough''
  rather than chasing the global best?
\end{enumerate}

\subsection{67. Multi-objective
optimization}\label{multi-objective-optimization}

Many AI systems must optimize not just one objective but several, often
conflicting, goals. This is known as multi-objective optimization.
Instead of finding a single ``best'' solution, the goal is to balance
trade-offs among objectives, producing a set of solutions that represent
different compromises.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-66}

Imagine buying a laptop. You want it to be powerful, lightweight, and
cheap. But powerful laptops are often heavy or expensive. The ``best''
choice depends on how you weigh these competing factors. Multi-objective
optimization formalizes this dilemma.

\subsubsection{Deep Dive}\label{deep-dive-66}

Unlike single-objective problems where a clear optimum exists,
multi-objective problems often lead to a Pareto frontier---the set of
solutions where improving one objective necessarily worsens another. For
example, in machine learning, models may trade off accuracy against
interpretability, or performance against energy efficiency.

The central challenge is not only finding the frontier but also deciding
which trade-off to choose. This often requires human or policy input.
Algorithms like weighted sums, evolutionary multi-objective optimization
(EMO), and Pareto ranking help navigate these trade-offs.

Comparison Table: Single vs.~Multi-Objective Optimization

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1778}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3556}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4667}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Single-Objective Optimization
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Multi-Objective Optimization
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Goal & Minimize/maximize one function & Balance several conflicting
goals \\
Solution & One optimum & Pareto frontier of non-dominated solutions \\
Example in AI & Train model to maximize accuracy & Train model for
accuracy + fairness \\
Decision process & Automatic & Requires weighing trade-offs \\
\end{longtable}

Applications of multi-objective optimization in AI are widespread:

\begin{itemize}
\tightlist
\item
  Fairness vs.~accuracy in predictive models.
\item
  Energy use vs.~latency in edge devices.
\item
  Exploration vs.~exploitation in reinforcement learning.
\item
  Cost vs.~coverage in planning and logistics.
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-66}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Multi{-}objective optimization: Pareto frontier (toy example)}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{solutions }\OperatorTok{=}\NormalTok{ [(x, }\DecValTok{1}\OperatorTok{/}\NormalTok{x) }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ np.linspace(}\FloatTok{0.1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{)]  }\CommentTok{\# trade{-}off curve}

\CommentTok{\# Identify Pareto frontier}
\NormalTok{pareto }\OperatorTok{=}\NormalTok{ []}
\ControlFlowTok{for}\NormalTok{ s }\KeywordTok{in}\NormalTok{ solutions:}
    \ControlFlowTok{if} \KeywordTok{not} \BuiltInTok{any}\NormalTok{(o[}\DecValTok{0}\NormalTok{] }\OperatorTok{\textless{}=}\NormalTok{ s[}\DecValTok{0}\NormalTok{] }\KeywordTok{and}\NormalTok{ o[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textless{}=}\NormalTok{ s[}\DecValTok{1}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ o }\KeywordTok{in}\NormalTok{ solutions }\ControlFlowTok{if}\NormalTok{ o }\OperatorTok{!=}\NormalTok{ s):}
\NormalTok{        pareto.append(s)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Solutions:"}\NormalTok{, solutions)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Pareto frontier:"}\NormalTok{, pareto)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-66}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more objectives (e.g., x, 1/x, and x²)---how does the frontier
  change?
\item
  Adjust the trade-offs---what happens to the shape of Pareto optimal
  solutions?
\item
  Reflect: in real-world AI, who decides how to weigh competing
  objectives, the engineer, the user, or society at large?
\end{enumerate}

\subsection{68. Decision-making under
uncertainty}\label{decision-making-under-uncertainty}

In real-world environments, AI rarely has perfect information.
Decision-making under uncertainty is the art of choosing actions when
outcomes are probabilistic, incomplete, or ambiguous. Instead of
guaranteeing success, the goal is to maximize expected utility across
possible futures.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-67}

Imagine driving in heavy fog. You can't see far ahead, but you must
still decide whether to slow down, turn, or continue straight. Each
choice has risks and rewards, and you must act without full knowledge of
the environment.

\subsubsection{Deep Dive}\label{deep-dive-67}

Uncertainty arises in AI from noisy sensors, incomplete data,
unpredictable environments, or stochastic dynamics. Handling it requires
formal models that weigh possible outcomes against their probabilities.

\begin{itemize}
\tightlist
\item
  Probabilistic decision-making uses expected value calculations: choose
  the action with the highest expected utility.
\item
  Bayesian approaches update beliefs as new evidence arrives, refining
  decision quality.
\item
  Decision trees structure uncertainty into branches of possible
  outcomes with associated probabilities.
\item
  Markov decision processes (MDPs) formalize sequential decision-making
  under uncertainty, where each action leads probabilistically to new
  states and rewards.
\end{itemize}

A critical challenge is balancing risk and reward. Some systems aim for
maximum expected payoff, while others prioritize robustness against
worst-case scenarios.

Comparison Table: Strategies for Uncertain Decisions

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1557}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2705}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2459}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3279}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Strategy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Core Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strengths
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Weaknesses
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Expected Utility & Maximize average outcome & Rational, mathematically
sound & Sensitive to mis-specified probabilities \\
Bayesian Updating & Revise beliefs with evidence & Adaptive, principled
& Computationally demanding \\
Robust Optimization & Focus on worst-case scenarios & Safe, conservative
& May miss high-payoff opportunities \\
MDPs & Sequential probabilistic planning & Rich, expressive framework &
Requires accurate transition model \\
\end{longtable}

AI applications are everywhere: medical diagnosis under incomplete
tests, robotics navigation with noisy sensors, financial trading with
uncertain markets, and dialogue systems managing ambiguous user inputs.

\subsubsection{Tiny Code}\label{tiny-code-67}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Expected utility under uncertainty}
\ImportTok{import}\NormalTok{ random}

\NormalTok{actions }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"safe"}\NormalTok{: [(}\DecValTok{10}\NormalTok{, }\FloatTok{1.0}\NormalTok{)],           }\CommentTok{\# always 10}
    \StringTok{"risky"}\NormalTok{: [(}\DecValTok{50}\NormalTok{, }\FloatTok{0.2}\NormalTok{), (}\DecValTok{0}\NormalTok{, }\FloatTok{0.8}\NormalTok{)] }\CommentTok{\# 20\% chance 50, else 0}
\NormalTok{\}}

\KeywordTok{def}\NormalTok{ expected\_utility(action):}
    \ControlFlowTok{return} \BuiltInTok{sum}\NormalTok{(v}\OperatorTok{*}\NormalTok{p }\ControlFlowTok{for}\NormalTok{ v,p }\KeywordTok{in}\NormalTok{ action)}

\ControlFlowTok{for}\NormalTok{ a }\KeywordTok{in}\NormalTok{ actions:}
    \BuiltInTok{print}\NormalTok{(a, }\StringTok{"expected utility:"}\NormalTok{, expected\_utility(actions[a]))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-67}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Adjust the probabilities---does the optimal action change?
\item
  Add a risk-averse criterion (e.g., maximize minimum payoff)---how does
  it affect choice?
\item
  Reflect: should AI systems always chase expected reward, or sometimes
  act conservatively to protect against rare but catastrophic outcomes?
\end{enumerate}

\subsection{69. Sequential decision
processes}\label{sequential-decision-processes}

Many AI problems involve not just a single choice, but a sequence of
actions unfolding over time. Sequential decision processes model this
setting, where each action changes the state of the world and influences
future choices. Success depends on planning ahead, not just optimizing
the next step.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-68}

Think of playing chess. Each move alters the board and constrains the
opponent's replies. Winning depends less on any single move than on
orchestrating a sequence that leads to checkmate.

\subsubsection{Deep Dive}\label{deep-dive-68}

Sequential decisions differ from one-shot choices because they involve
state transitions and temporal consequences. The challenge is
compounding uncertainty, where early actions can have long-term effects.

The classical framework is the Markov Decision Process (MDP), defined
by:

\begin{itemize}
\tightlist
\item
  A set of states.
\item
  A set of actions.
\item
  Transition probabilities specifying how actions change states.
\item
  Reward functions quantifying the benefit of each state-action pair.
\end{itemize}

Policies are strategies that map states to actions. The optimal policy
maximizes expected cumulative reward over time. Variants include
Partially Observable MDPs (POMDPs), where the agent has incomplete
knowledge of the state, and multi-agent decision processes, where
outcomes depend on the choices of others.

Sequential decision processes are the foundation of reinforcement
learning, where agents learn optimal policies through trial and error.
They also appear in robotics, operations research, and control theory.

Comparison Table: One-Shot vs.~Sequential Decisions

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1831}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3099}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5070}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
One-Shot Decision
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Sequential Decision
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Action impact & Immediate outcome only & Shapes future opportunities \\
Information & Often complete & May evolve over time \\
Objective & Maximize single reward & Maximize long-term cumulative
reward \\
Example in AI & Medical test selection & Treatment planning over
months \\
\end{longtable}

Sequential settings emphasize foresight. Greedy strategies may fail if
they ignore long-term effects, while optimal policies balance immediate
gains against future consequences. This introduces the classic
exploration vs.~exploitation dilemma: should the agent try new actions
to gather information or exploit known strategies for reward?

\subsubsection{Tiny Code}\label{tiny-code-68}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Sequential decision: simple 2{-}step planning}
\NormalTok{states }\OperatorTok{=}\NormalTok{ [}\StringTok{"start"}\NormalTok{, }\StringTok{"mid"}\NormalTok{, }\StringTok{"goal"}\NormalTok{]}
\NormalTok{actions }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"start"}\NormalTok{: \{}\StringTok{"a"}\NormalTok{: (}\StringTok{"mid"}\NormalTok{, }\DecValTok{5}\NormalTok{), }\StringTok{"b"}\NormalTok{: (}\StringTok{"goal"}\NormalTok{, }\DecValTok{2}\NormalTok{)\},}
    \StringTok{"mid"}\NormalTok{: \{}\StringTok{"c"}\NormalTok{: (}\StringTok{"goal"}\NormalTok{, }\DecValTok{10}\NormalTok{)\}}
\NormalTok{\}}

\KeywordTok{def}\NormalTok{ simulate(policy):}
\NormalTok{    state, total }\OperatorTok{=} \StringTok{"start"}\NormalTok{, }\DecValTok{0}
    \ControlFlowTok{while}\NormalTok{ state }\OperatorTok{!=} \StringTok{"goal"}\NormalTok{:}
\NormalTok{        action }\OperatorTok{=}\NormalTok{ policy[state]}
\NormalTok{        state, reward }\OperatorTok{=}\NormalTok{ actions[state][action]}
\NormalTok{        total }\OperatorTok{+=}\NormalTok{ reward}
    \ControlFlowTok{return}\NormalTok{ total}

\NormalTok{policy1 }\OperatorTok{=}\NormalTok{ \{}\StringTok{"start"}\NormalTok{:}\StringTok{"a"}\NormalTok{,}\StringTok{"mid"}\NormalTok{:}\StringTok{"c"}\NormalTok{\}  }\CommentTok{\# plan ahead}
\NormalTok{policy2 }\OperatorTok{=}\NormalTok{ \{}\StringTok{"start"}\NormalTok{:}\StringTok{"b"}\NormalTok{\}            }\CommentTok{\# greedy}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Planned policy reward:"}\NormalTok{, simulate(policy1))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Greedy policy reward:"}\NormalTok{, simulate(policy2))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-68}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the rewards---does the greedy policy ever win?
\item
  Extend the horizon---how does the complexity grow with each extra
  step?
\item
  Reflect: why does intelligence require looking beyond the immediate
  payoff?
\end{enumerate}

\subsection{70. Real-world constraints in
optimization}\label{real-world-constraints-in-optimization}

In theory, optimization seeks the best solution according to a
mathematical objective. In practice, real-world AI must handle
constraints: limited resources, noisy data, fairness requirements,
safety guarantees, and human preferences. These constraints shape not
only what is \emph{optimal} but also what is \emph{acceptable}.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-69}

Imagine scheduling flights for an airline. The mathematically cheapest
plan might overwork pilots, delay maintenance, or violate safety rules.
A ``real-world optimal'' schedule respects all these constraints, even
if it sacrifices theoretical efficiency.

\subsubsection{Deep Dive}\label{deep-dive-69}

Real-world optimization rarely occurs in a vacuum. Constraints define
the feasible region within which solutions can exist. They can be:

\begin{itemize}
\tightlist
\item
  Hard constraints: cannot be violated (budget caps, safety rules, legal
  requirements).
\item
  Soft constraints: preferences or guidelines that can be traded off
  against objectives (comfort, fairness, aesthetics).
\item
  Dynamic constraints: change over time due to resource availability,
  environment, or feedback loops.
\end{itemize}

In AI systems, constraints appear everywhere:

\begin{itemize}
\tightlist
\item
  Robotics: torque limits, collision avoidance.
\item
  Healthcare AI: ethical guidelines, treatment side effects.
\item
  Logistics: delivery deadlines, fuel costs, driver working hours.
\item
  Machine learning: fairness metrics, privacy guarantees.
\end{itemize}

Handling constraints requires specialized optimization techniques:
constrained linear programming, penalty methods, Lagrangian relaxation,
or multi-objective frameworks. Often, constraints elevate a simple
optimization into a deeply complex, sometimes NP-hard, real-world
problem.

Comparison Table: Ideal vs.~Constrained Optimization

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3571}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4762}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Ideal Optimization
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Real-World Optimization
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Assumptions & Unlimited resources, no limits & Resource, safety,
fairness, ethics apply \\
Solution space & All mathematically possible & Only feasible under
constraints \\
Output & Mathematically optimal & Practically viable and acceptable \\
Example & Shortest delivery path & Fastest safe path under traffic
rules \\
\end{longtable}

Constraints also highlight the gap between AI theory and deployment. A
pathfinding algorithm may suggest an ideal route, but the real driver
must avoid construction zones, follow regulations, and consider comfort.
This tension between theory and practice is one reason why real-world AI
often values robustness over perfection.

\subsubsection{Tiny Code}\label{tiny-code-69}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Constrained optimization: shortest path with blocked road}
\ImportTok{import}\NormalTok{ heapq}

\NormalTok{graph }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"A"}\NormalTok{: \{}\StringTok{"B"}\NormalTok{:}\DecValTok{1}\NormalTok{,}\StringTok{"C"}\NormalTok{:}\DecValTok{5}\NormalTok{\},}
    \StringTok{"B"}\NormalTok{: \{}\StringTok{"C"}\NormalTok{:}\DecValTok{1}\NormalTok{,}\StringTok{"D"}\NormalTok{:}\DecValTok{4}\NormalTok{\},}
    \StringTok{"C"}\NormalTok{: \{}\StringTok{"D"}\NormalTok{:}\DecValTok{1}\NormalTok{\},}
    \StringTok{"D"}\NormalTok{: \{\}}
\NormalTok{\}}

\NormalTok{blocked }\OperatorTok{=}\NormalTok{ (}\StringTok{"B"}\NormalTok{,}\StringTok{"C"}\NormalTok{)  }\CommentTok{\# constraint: road closed}

\KeywordTok{def}\NormalTok{ constrained\_dijkstra(start, goal):}
\NormalTok{    queue }\OperatorTok{=}\NormalTok{ [(}\DecValTok{0}\NormalTok{,start,[])]}
\NormalTok{    seen }\OperatorTok{=} \BuiltInTok{set}\NormalTok{()}
    \ControlFlowTok{while}\NormalTok{ queue:}
\NormalTok{        cost,node,path }\OperatorTok{=}\NormalTok{ heapq.heappop(queue)}
        \ControlFlowTok{if}\NormalTok{ node }\KeywordTok{in}\NormalTok{ seen:}
            \ControlFlowTok{continue}
\NormalTok{        path }\OperatorTok{=}\NormalTok{ path}\OperatorTok{+}\NormalTok{[node]}
        \ControlFlowTok{if}\NormalTok{ node }\OperatorTok{==}\NormalTok{ goal:}
            \ControlFlowTok{return}\NormalTok{ cost,path}
\NormalTok{        seen.add(node)}
        \ControlFlowTok{for}\NormalTok{ n,c }\KeywordTok{in}\NormalTok{ graph[node].items():}
            \ControlFlowTok{if}\NormalTok{ (node,n) }\OperatorTok{!=}\NormalTok{ blocked:  }\CommentTok{\# enforce constraint}
\NormalTok{                heapq.heappush(queue,(cost}\OperatorTok{+}\NormalTok{c,n,path))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Constrained path A→D:"}\NormalTok{, constrained\_dijkstra(}\StringTok{"A"}\NormalTok{,}\StringTok{"D"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-69}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more blocked edges---how does the feasible path set shrink?
\item
  Add a ``soft'' constraint by penalizing certain edges instead of
  forbidding them.
\item
  Reflect: why do most real-world AI systems optimize under constraints
  rather than chasing pure mathematical optima?
\end{enumerate}

\section{Chapter 8. Data, Signals and
Measurement}\label{chapter-8.-data-signals-and-measurement}

\subsection{71. Data as the foundation of
intelligence}\label{data-as-the-foundation-of-intelligence}

No matter how sophisticated the algorithm, AI systems are only as strong
as the data they learn from. Data grounds abstract models in the
realities of the world. It serves as both the raw material and the
feedback loop that allows intelligence to emerge.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-70}

Think of a sculptor and a block of marble. The sculptor's skill matters,
but without marble there is nothing to shape. In AI, algorithms are the
sculptor, but data is the marble---they cannot create meaning from
nothing.

\subsubsection{Deep Dive}\label{deep-dive-70}

Data functions as the foundation in three key ways. First, it provides
representations of the world: pixels stand in for objects, sound waves
for speech, and text for human knowledge. Second, it offers examples of
behavior, allowing learning systems to infer patterns, rules, or
preferences. Third, it acts as feedback, enabling systems to improve
through error correction and reinforcement.

But not all data is equal. High-quality, diverse, and well-structured
datasets produce robust models. Biased, incomplete, or noisy datasets
distort learning and decision-making. This is why data governance,
curation, and documentation are now central to AI practice.

In modern AI, the scale of data has become a differentiator. Classical
expert systems relied on rules hand-coded by humans, but deep learning
thrives because billions of examples fuel the discovery of complex
representations. At the same time, more data is not always better:
redundancy, poor quality, and ethical issues can make massive datasets
counterproductive.

Comparison Table: Data in Different AI Paradigms

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2391}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4022}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3587}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Paradigm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Role of Data
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Symbolic AI & Encoded as facts, rules, knowledge & Expert systems,
ontologies \\
Classical ML & Training + test sets for models & SVMs, decision trees \\
Deep Learning & Large-scale inputs for representation & ImageNet, GPT
pretraining corpora \\
Reinforcement Learning & Feedback signals from environment &
Game-playing agents, robotics \\
\end{longtable}

The future of AI will likely hinge less on raw data scale and more on
data efficiency: learning robust models from smaller, carefully curated,
or synthetic datasets. This shift mirrors human learning, where a child
can infer concepts from just a few examples.

\subsubsection{Tiny Code}\label{tiny-code-70}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple learning from data: linear regression}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LinearRegression}

\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{],[}\DecValTok{4}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{8}\NormalTok{])  }\CommentTok{\# perfect line: y=2x}

\NormalTok{model }\OperatorTok{=}\NormalTok{ LinearRegression().fit(X,y)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Prediction for x=5:"}\NormalTok{, model.predict([[}\DecValTok{5}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-70}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Corrupt the dataset with noise---how does prediction accuracy change?
\item
  Reduce the dataset size---does the model still generalize?
\item
  Reflect: why is data often called the ``new oil,'' and where does this
  metaphor break down?
\end{enumerate}

\subsection{72. Types of data: structured, unstructured,
multimodal}\label{types-of-data-structured-unstructured-multimodal}

AI systems work with many different kinds of data. Structured data is
neatly organized into tables and schemas. Unstructured data includes raw
forms like text, images, and audio. Multimodal data integrates multiple
types, enabling richer understanding. Each type demands different
methods of representation and processing.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-71}

Think of a library. A catalog with author, title, and year is structured
data. The books themselves---pages of text, illustrations, maps---are
unstructured data. A multimedia encyclopedia that combines text, images,
and video is multimodal. AI must navigate all three.

\subsubsection{Deep Dive}\label{deep-dive-71}

Structured data has been the foundation of traditional machine learning.
Rows and columns make statistical modeling straightforward. However,
most real-world data is unstructured: free-form text, conversations,
medical scans, video recordings. The rise of deep learning reflects the
need to automatically process this complexity.

Multimodal data adds another layer: combining modalities to capture
meaning that no single type can provide. A video of a lecture is richer
than its transcript alone, because tone, gesture, and visuals convey
context. Similarly, pairing radiology images with doctor's notes
strengthens diagnosis.

The challenge lies in integration. Structured and unstructured data
often coexist within a system, but aligning them---synchronizing
signals, handling scale differences, and learning cross-modal
representations---remains an open frontier.

Comparison Table: Data Types

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0968}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4113}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2823}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2097}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Data Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Examples
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strengths
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Challenges
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Structured & Databases, spreadsheets, sensors & Clean, easy to query,
interpretable & Limited expressiveness \\
Unstructured & Text, images, audio, video & Rich, natural, human-like &
High dimensionality, noisy \\
Multimodal & Video with subtitles, medical record (scan + notes) &
Comprehensive, context-rich & Alignment, fusion, scale \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-71}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Handling structured vs unstructured data}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{from}\NormalTok{ sklearn.feature\_extraction.text }\ImportTok{import}\NormalTok{ CountVectorizer}

\CommentTok{\# Structured: tabular}
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{"age"}\NormalTok{:[}\DecValTok{25}\NormalTok{,}\DecValTok{32}\NormalTok{,}\DecValTok{40}\NormalTok{],}\StringTok{"score"}\NormalTok{:[}\DecValTok{88}\NormalTok{,}\DecValTok{92}\NormalTok{,}\DecValTok{75}\NormalTok{]\})}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Structured data sample:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, df)}

\CommentTok{\# Unstructured: text}
\NormalTok{texts }\OperatorTok{=}\NormalTok{ [}\StringTok{"AI is powerful"}\NormalTok{, }\StringTok{"Data drives AI"}\NormalTok{]}
\NormalTok{vectorizer }\OperatorTok{=}\NormalTok{ CountVectorizer()}
\NormalTok{X }\OperatorTok{=}\NormalTok{ vectorizer.fit\_transform(texts)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Unstructured text as bag{-}of{-}words:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, X.toarray())}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-71}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add images as another modality---how would you represent them
  numerically?
\item
  Combine structured scores with unstructured student essays---what
  insights emerge?
\item
  Reflect: why does multimodality bring AI closer to human-like
  perception and reasoning?
\end{enumerate}

\subsection{73. Measurement, sensors, and signal
processing}\label{measurement-sensors-and-signal-processing}

AI systems connect to the world through measurement. Sensors capture raw
signals---light, sound, motion, temperature---and convert them into
data. Signal processing then refines these measurements, reducing noise
and extracting meaningful features for downstream models.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-72}

Imagine listening to a concert through a microphone. The microphone
captures sound waves, but the raw signal is messy: background chatter,
echoes, electrical interference. Signal processing is like adjusting an
equalizer, filtering out the noise, and keeping the melody clear.

\subsubsection{Deep Dive}\label{deep-dive-72}

Measurements are the bridge between physical reality and digital
computation. In robotics, lidar and cameras transform environments into
streams of data points. In healthcare, sensors turn heartbeats into ECG
traces. In finance, transactions become event logs.

Raw sensor data, however, is rarely usable as-is. Signal processing
applies transformations such as filtering, normalization, and feature
extraction. For instance, Fourier transforms reveal frequency patterns
in audio; edge detectors highlight shapes in images; statistical
smoothing reduces random fluctuations in time series.

Quality of measurement is critical: poor sensors or noisy environments
can degrade even the best AI models. Conversely, well-processed signals
can compensate for limited model complexity. This interplay is why
sensing and preprocessing remain as important as learning algorithms
themselves.

Comparison Table: Role of Measurement and Processing

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2022}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4045}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3933}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Stage
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI Applications
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Measurement & Capture raw signals & Camera images, microphone audio \\
Preprocessing & Clean and normalize data & Noise reduction in ECG
signals \\
Feature extraction & Highlight useful patterns & Spectrograms for speech
recognition \\
Modeling & Learn predictive or generative tasks & CNNs on processed
image features \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-72}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Signal processing: smoothing noisy measurements}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Simulated noisy sensor signal}
\NormalTok{np.random.seed(}\DecValTok{0}\NormalTok{)}
\NormalTok{signal }\OperatorTok{=}\NormalTok{ np.sin(np.linspace(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{50}\NormalTok{)) }\OperatorTok{+}\NormalTok{ np.random.normal(}\DecValTok{0}\NormalTok{,}\FloatTok{0.3}\NormalTok{,}\DecValTok{50}\NormalTok{)}

\CommentTok{\# Simple moving average filter}
\KeywordTok{def}\NormalTok{ smooth(x, window}\OperatorTok{=}\DecValTok{3}\NormalTok{):}
    \ControlFlowTok{return}\NormalTok{ np.convolve(x, np.ones(window)}\OperatorTok{/}\NormalTok{window, mode}\OperatorTok{=}\StringTok{\textquotesingle{}valid\textquotesingle{}}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Raw signal sample:"}\NormalTok{, signal[:}\DecValTok{5}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Smoothed signal sample:"}\NormalTok{, smooth(signal)[:}\DecValTok{5}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-72}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more noise to the signal---how does smoothing help or hurt?
\item
  Replace moving average with Fourier filtering---what patterns emerge?
\item
  Reflect: why is ``garbage in, garbage out'' especially true for
  sensor-driven AI? \#\#\# 74. Resolution, granularity, and sampling
\end{enumerate}

Every measurement depends on how finely the world is observed.
Resolution is the level of detail captured, granularity is the size of
the smallest distinguishable unit, and sampling determines how often
data is collected. Together, they shape the fidelity and usefulness of
AI inputs.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-73}

Imagine zooming into a digital map. At a coarse resolution, you only see
countries. Zoom further and cities appear. Zoom again and you see
individual streets. The underlying data is the same world, but
resolution and granularity determine what patterns are visible.

\subsubsection{Deep Dive}\label{deep-dive-73}

Resolution, granularity, and sampling are not just technical
choices---they define what AI can or cannot learn. Too coarse a
resolution hides patterns, like trying to detect heart arrhythmia with
one reading per hour. Too fine a resolution overwhelms systems with
redundant detail, like storing every frame of a video when one per
second suffices.

Sampling theory formalizes this trade-off. The Nyquist-Shannon theorem
states that to capture a signal without losing information, it must be
sampled at least twice its highest frequency. Violating this leads to
aliasing, where signals overlap and distort.

In practice, resolution and granularity are often matched to task
requirements. Satellite imaging for weather forecasting may only need
kilometer granularity, while medical imaging requires sub-millimeter
detail. The art lies in balancing precision, efficiency, and relevance.

Comparison Table: Effects of Resolution and Sampling

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1485}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1980}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3366}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3168}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Setting
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Benefit
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Risk if too low
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Risk if too high
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
High resolution & Captures fine detail & Miss critical patterns & Data
overload, storage costs \\
Low resolution & Compact, efficient & Aliasing, hidden structure & Loss
of accuracy \\
Dense sampling & Preserves dynamics & Misses fast changes & Redundancy,
computational burden \\
Sparse sampling & Saves resources & Fails to track important variation &
Insufficient for predictions \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-73}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Sampling resolution demo: sine wave}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}

\NormalTok{x\_high }\OperatorTok{=}\NormalTok{ np.linspace(}\DecValTok{0}\NormalTok{, }\DecValTok{2}\OperatorTok{*}\NormalTok{np.pi, }\DecValTok{1000}\NormalTok{)   }\CommentTok{\# high resolution}
\NormalTok{y\_high }\OperatorTok{=}\NormalTok{ np.sin(x\_high)}

\NormalTok{x\_low }\OperatorTok{=}\NormalTok{ np.linspace(}\DecValTok{0}\NormalTok{, }\DecValTok{2}\OperatorTok{*}\NormalTok{np.pi, }\DecValTok{10}\NormalTok{)      }\CommentTok{\# low resolution}
\NormalTok{y\_low }\OperatorTok{=}\NormalTok{ np.sin(x\_low)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"High{-}res sample (first 5):"}\NormalTok{, y\_high[:}\DecValTok{5}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Low{-}res sample (all):"}\NormalTok{, y\_low)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-73}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase low-resolution sampling points---at what point does the wave
  become recognizable?
\item
  Undersample a higher-frequency sine---do you see aliasing effects?
\item
  Reflect: how does the right balance of resolution and sampling depend
  on the domain (healthcare, robotics, astronomy)?
\end{enumerate}

\subsection{75. Noise reduction and signal
enhancement}\label{noise-reduction-and-signal-enhancement}

Real-world data is rarely clean. Noise---random errors, distortions, or
irrelevant fluctuations---can obscure the patterns AI systems need.
Noise reduction and signal enhancement are preprocessing steps that
improve data quality, making models more accurate and robust.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-74}

Think of tuning an old radio. Amid the static, you strain to hear a
favorite song. Adjusting the dial filters out the noise and sharpens the
melody. Signal processing in AI plays the same role: suppressing
interference so the underlying pattern is clearer.

\subsubsection{Deep Dive}\label{deep-dive-74}

Noise arises from many sources: faulty sensors, environmental
conditions, transmission errors, or inherent randomness. Its impact
depends on the task---small distortions in an image may not matter for
object detection but can be critical in medical imaging.

Noise reduction techniques include:

\begin{itemize}
\tightlist
\item
  Filtering: smoothing signals (moving averages, Gaussian filters) to
  remove high-frequency noise.
\item
  Fourier and wavelet transforms: separating signal from noise in the
  frequency domain.
\item
  Denoising autoencoders: deep learning models trained to reconstruct
  clean inputs.
\item
  Ensemble averaging: combining multiple noisy measurements to cancel
  out random variation.
\end{itemize}

Signal enhancement complements noise reduction by amplifying features of
interest---edges in images, peaks in spectra, or keywords in audio
streams. The two processes together ensure that downstream learning
algorithms focus on meaningful patterns.

Comparison Table: Noise Reduction Techniques

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Domain Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Moving average filter & Time series (finance) & Simple, effective &
Blurs sharp changes \\
Fourier filtering & Audio signals & Separates noise by frequency &
Requires frequency-domain insight \\
Denoising autoencoder & Image processing & Learns complex patterns &
Needs large training data \\
Ensemble averaging & Sensor networks & Reduces random fluctuations &
Ineffective against systematic bias \\
\end{longtable}

Noise reduction is not only about data cleaning---it shapes the very
boundary of what AI can perceive. A poor-quality signal limits
performance no matter the model complexity, while enhanced, noise-free
signals can enable simpler models to perform surprisingly well.

\subsubsection{Tiny Code}\label{tiny-code-74}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Noise reduction with a moving average}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Simulate noisy signal}
\NormalTok{np.random.seed(}\DecValTok{1}\NormalTok{)}
\NormalTok{signal }\OperatorTok{=}\NormalTok{ np.sin(np.linspace(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{50}\NormalTok{)) }\OperatorTok{+}\NormalTok{ np.random.normal(}\DecValTok{0}\NormalTok{,}\FloatTok{0.4}\NormalTok{,}\DecValTok{50}\NormalTok{)}

\KeywordTok{def}\NormalTok{ moving\_average(x, window}\OperatorTok{=}\DecValTok{3}\NormalTok{):}
    \ControlFlowTok{return}\NormalTok{ np.convolve(x, np.ones(window)}\OperatorTok{/}\NormalTok{window, mode}\OperatorTok{=}\StringTok{\textquotesingle{}valid\textquotesingle{}}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Noisy signal (first 5):"}\NormalTok{, signal[:}\DecValTok{5}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Smoothed signal (first 5):"}\NormalTok{, moving\_average(signal)[:}\DecValTok{5}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-74}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more noise---does the moving average still recover the signal
  shape?
\item
  Compare moving average with a median filter---how do results differ?
\item
  Reflect: in which domains (finance, healthcare, audio) does noise
  reduction make the difference between failure and success?
\end{enumerate}

\subsection{76. Data bias, drift, and blind
spots}\label{data-bias-drift-and-blind-spots}

AI systems inherit the properties of their training data. Bias occurs
when data systematically favors or disadvantages certain groups or
patterns. Drift happens when the underlying distribution of data changes
over time. Blind spots are regions of the real world poorly represented
in the data. Together, these issues limit reliability and fairness.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-75}

Imagine teaching a student geography using a map that only shows Europe.
The student becomes an expert on European countries but has no knowledge
of Africa or Asia. Their understanding is biased, drifts out of date as
borders change, and contains blind spots where the map is incomplete. AI
faces the same risks with data.

\subsubsection{Deep Dive}\label{deep-dive-75}

Bias arises from collection processes, sampling choices, or historical
inequities embedded in the data. For example, facial recognition systems
trained mostly on light-skinned faces perform poorly on darker-skinned
individuals.

Drift occurs in dynamic environments where patterns evolve. A fraud
detection system trained on last year's transactions may miss new attack
strategies. Drift can be covariate drift (input distributions change),
concept drift (label relationships shift), or prior drift (class
proportions change).

Blind spots reflect the limits of coverage. Rare diseases in medical
datasets, underrepresented languages in NLP, or unusual traffic
conditions in self-driving cars all highlight how missing data reduces
robustness.

Mitigation strategies include diverse sampling, continual learning,
fairness-aware metrics, drift detection algorithms, and active
exploration of underrepresented regions.

Comparison Table: Data Challenges

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0902}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3115}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3115}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2869}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Challenge
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example in AI
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Mitigation Strategy
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bias & Systematic distortion in training data & Hiring models favoring
majority groups & Balanced sampling, fairness metrics \\
Drift & Distribution changes over time & Spam filters missing new
campaigns & Drift detection, model retraining \\
Blind spots & Missing or underrepresented cases & Self-driving cars in
rare weather & Active data collection, simulation \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-75}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simulating drift in a simple dataset}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}

\CommentTok{\# Train data (old distribution)}
\NormalTok{X\_train }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{]])}
\NormalTok{y\_train }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])}
\NormalTok{model }\OperatorTok{=}\NormalTok{ LogisticRegression().fit(X\_train, y\_train)}

\CommentTok{\# New data (drifted distribution)}
\NormalTok{X\_new }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{],[}\DecValTok{4}\NormalTok{],[}\DecValTok{5}\NormalTok{]])}
\NormalTok{y\_new }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])  }\CommentTok{\# relationship changed}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Old model predictions:"}\NormalTok{, model.predict(X\_new))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"True labels (new distribution):"}\NormalTok{, y\_new)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-75}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more skewed training data---does the model amplify bias?
\item
  Simulate concept drift by flipping labels---how fast does performance
  degrade?
\item
  Reflect: why must AI systems monitor data continuously rather than
  assuming static distributions?
\end{enumerate}

\subsection{77. From raw signals to usable
features}\label{from-raw-signals-to-usable-features}

Raw data streams are rarely in a form directly usable by AI models.
Feature extraction transforms messy signals into structured
representations that highlight the most relevant patterns. Good features
reduce noise, compress information, and make learning more effective.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-76}

Think of preparing food ingredients. Raw crops from the farm are
unprocessed and unwieldy. Washing, chopping, and seasoning turn them
into usable components for cooking. In the same way, raw data needs
transformation into features before becoming useful for AI.

\subsubsection{Deep Dive}\label{deep-dive-76}

Feature extraction depends on the data type. In images, raw pixels are
converted into edges, textures, or higher-level embeddings. In audio,
waveforms become spectrograms or mel-frequency cepstral coefficients
(MFCCs). In text, words are encoded into bags of words, TF-IDF scores,
or distributed embeddings.

Historically, feature engineering was a manual craft, with domain
experts designing transformations. Deep learning has automated much of
this, with models learning hierarchical representations directly from
raw data. Still, preprocessing remains crucial: even deep networks rely
on normalized inputs, cleaned signals, and structured metadata.

The quality of features often determines the success of downstream
tasks. Poor features burden models with irrelevant noise; strong
features allow even simple algorithms to perform well. This is why
feature extraction is sometimes called the ``art'' of AI.

Comparison Table: Feature Extraction Approaches

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0795}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3182}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3523}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Domain
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Raw Signal Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Typical Features
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Modern Alternative
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Vision & Pixel intensity values & Edges, SIFT, HOG descriptors &
CNN-learned embeddings \\
Audio & Waveforms & Spectrograms, MFCCs & Self-supervised audio
models \\
Text & Words or characters & Bag-of-words, TF-IDF & Word2Vec, BERT
embeddings \\
Tabular & Raw measurements & Normalized, derived ratios & Learned
embeddings in deep nets \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-76}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Feature extraction: text example}
\ImportTok{from}\NormalTok{ sklearn.feature\_extraction.text }\ImportTok{import}\NormalTok{ TfidfVectorizer}

\NormalTok{texts }\OperatorTok{=}\NormalTok{ [}\StringTok{"AI transforms data"}\NormalTok{, }\StringTok{"Data drives intelligence"}\NormalTok{]}
\NormalTok{vectorizer }\OperatorTok{=}\NormalTok{ TfidfVectorizer()}
\NormalTok{X }\OperatorTok{=}\NormalTok{ vectorizer.fit\_transform(texts)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Feature names:"}\NormalTok{, vectorizer.get\_feature\_names\_out())}
\BuiltInTok{print}\NormalTok{(}\StringTok{"TF{-}IDF matrix:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, X.toarray())}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-76}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Apply TF-IDF to a larger set of documents---what features dominate?
\item
  Replace TF-IDF with raw counts---does classification accuracy change?
\item
  Reflect: when should features be hand-crafted, and when should they be
  learned automatically?
\end{enumerate}

\subsection{78. Standards for measurement and
metadata}\label{standards-for-measurement-and-metadata}

Data alone is not enough---how it is measured, described, and
standardized determines whether it can be trusted and reused. Standards
for measurement ensure consistency across systems, while metadata
documents context, quality, and meaning. Without them, AI models risk
learning from incomplete or misleading inputs.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-77}

Imagine receiving a dataset of temperatures without knowing whether
values are in Celsius or Fahrenheit. The numbers are useless---or worse,
dangerous---without metadata to clarify their meaning. Standards and
documentation are the ``units and labels'' that make data interoperable.

\subsubsection{Deep Dive}\label{deep-dive-77}

Measurement standards specify how data is collected: the units,
calibration methods, and protocols. For example, a blood pressure
dataset must specify whether readings were taken at rest, what device
was used, and how values were rounded.

Metadata adds descriptive layers:

\begin{itemize}
\tightlist
\item
  Descriptive metadata: what the dataset contains (variables, units,
  formats).
\item
  Provenance metadata: where the data came from, when it was collected,
  by whom.
\item
  Quality metadata: accuracy, uncertainty, missing values.
\item
  Ethical metadata: consent, usage restrictions, potential biases.
\end{itemize}

In large-scale AI projects, metadata standards like Dublin Core,
schema.org, or ML data cards help datasets remain interpretable and
auditable. Poorly documented data leads to reproducibility crises,
opaque models, and fairness risks.

Comparison Table: Data With vs.~Without Standards

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1910}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4270}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3820}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
With Standards \& Metadata
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Without Standards \& Metadata
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Consistency & Units, formats, and protocols aligned & Confusion,
misinterpretation \\
Reusability & Datasets can be merged and compared & Silos, duplication,
wasted effort \\
Accountability & Provenance and consent are transparent & Origins
unclear, ethical risks \\
Model reliability & Clear assumptions improve performance & Hidden
mismatches degrade accuracy \\
\end{longtable}

Standards are especially critical in regulated domains like healthcare,
finance, and geoscience. A model predicting disease progression must not
only be accurate but also auditable---knowing how, when, and why the
training data was collected.

\subsubsection{Tiny Code}\label{tiny-code-77}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example: attaching simple metadata to a dataset}
\NormalTok{dataset }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"data"}\NormalTok{: [}\FloatTok{36.6}\NormalTok{, }\FloatTok{37.1}\NormalTok{, }\FloatTok{38.0}\NormalTok{],  }\CommentTok{\# temperatures}
    \StringTok{"metadata"}\NormalTok{: \{}
        \StringTok{"unit"}\NormalTok{: }\StringTok{"Celsius"}\NormalTok{,}
        \StringTok{"source"}\NormalTok{: }\StringTok{"Thermometer Model X"}\NormalTok{,}
        \StringTok{"collection\_date"}\NormalTok{: }\StringTok{"2025{-}09{-}16"}\NormalTok{,}
        \StringTok{"notes"}\NormalTok{: }\StringTok{"Measured at rest, oral sensor"}
\NormalTok{    \}}
\NormalTok{\}}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Data:"}\NormalTok{, dataset[}\StringTok{"data"}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Metadata:"}\NormalTok{, dataset[}\StringTok{"metadata"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-77}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Remove the unit metadata---how ambiguous do the values become?
\item
  Add provenance (who, when, where)---does it increase trust in the
  dataset?
\item
  Reflect: why is metadata often the difference between raw numbers and
  actionable knowledge?
\end{enumerate}

\subsection{79. Data curation and
stewardship}\label{data-curation-and-stewardship}

Collecting data is only the beginning. Data curation is the ongoing
process of organizing, cleaning, and maintaining datasets to ensure they
remain useful. Data stewardship extends this responsibility to
governance, ethics, and long-term sustainability. Together, they make
data a durable resource rather than a disposable byproduct.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-78}

Think of a museum. Artifacts are not just stored---they are cataloged,
preserved, and contextualized for future generations. Data requires the
same care: without curation and stewardship, it degrades, becomes
obsolete, or loses trustworthiness.

\subsubsection{Deep Dive}\label{deep-dive-78}

Curation ensures datasets are structured, consistent, and ready for
analysis. It includes cleaning errors, filling missing values,
normalizing formats, and documenting processes. Poorly curated data
leads to fragile models and irreproducible results.

Stewardship broadens the scope. It emphasizes responsible ownership,
ensuring data is collected ethically, used according to consent, and
maintained with transparency. It also covers lifecycle management: from
acquisition to archival or deletion. In AI, this is crucial because
models may amplify harms hidden in unmanaged data.

The FAIR principles---Findable, Accessible, Interoperable,
Reusable---guide modern stewardship. Compliance requires metadata
standards, open documentation, and community practices. Without these,
even large datasets lose value quickly.

Comparison Table: Curation vs.~Stewardship

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1176}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3882}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4941}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Data Curation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Data Stewardship
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Focus & Technical preparation of datasets & Ethical, legal, and
lifecycle management \\
Activities & Cleaning, labeling, formatting & Governance, consent,
compliance, access \\
Timescale & Immediate usability & Long-term sustainability \\
Example & Removing duplicates in logs & Ensuring patient data privacy
over decades \\
\end{longtable}

Curation and stewardship are not just operational tasks---they shape
trust in AI. Without them, datasets may encode hidden biases, degrade in
quality, or become non-compliant with evolving regulations. With them,
data becomes a shared resource for science and society.

\subsubsection{Tiny Code}\label{tiny-code-78}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example of simple data curation: removing duplicates}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}

\NormalTok{data }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
    \StringTok{"id"}\NormalTok{: [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{],}
    \StringTok{"value"}\NormalTok{: [}\DecValTok{10}\NormalTok{,}\DecValTok{20}\NormalTok{,}\DecValTok{20}\NormalTok{,}\DecValTok{30}\NormalTok{]}
\NormalTok{\})}

\NormalTok{curated }\OperatorTok{=}\NormalTok{ data.drop\_duplicates()}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Before curation:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, data)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"After curation:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, curated)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-78}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add missing values---how would you curate them (drop, fill, impute)?
\item
  Think about stewardship: who should own and manage this dataset
  long-term?
\item
  Reflect: why is curated, stewarded data as much a public good as clean
  water or safe infrastructure?
\end{enumerate}

\subsection{80. The evolving role of data in AI
progress}\label{the-evolving-role-of-data-in-ai-progress}

The history of AI can be told as a history of data. Early symbolic
systems relied on handcrafted rules and small knowledge bases. Classical
machine learning advanced with curated datasets. Modern deep learning
thrives on massive, diverse corpora. As AI evolves, the role of data
shifts from sheer quantity toward quality, efficiency, and responsible
use.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-79}

Imagine three eras of farming. First, farmers plant seeds manually in
small plots (symbolic AI). Next, they use irrigation and fertilizers to
cultivate larger fields (classical ML with curated datasets). Finally,
industrial-scale farms use machinery and global supply chains (deep
learning with web-scale data). The future may return to smaller, smarter
farms focused on sustainability---AI's shift to efficient, ethical data
use.

\subsubsection{Deep Dive}\label{deep-dive-79}

In early AI, data was secondary; knowledge was encoded directly by
experts. Success depended on the richness of rules, not scale. With
statistical learning, data became central, but curated datasets like
MNIST or UCI repositories sufficed. The deep learning revolution
reframed data as fuel: bigger corpora enabled models to learn richer
representations.

Yet this data-centric paradigm faces limits. Collecting ever-larger
datasets raises issues of redundancy, privacy, bias, and environmental
cost. Performance gains increasingly come from better data, not just
more data: filtering noise, balancing demographics, and aligning
distributions with target tasks. Synthetic data, data augmentation, and
self-supervised learning further reduce dependence on labeled corpora.

The next phase emphasizes data efficiency: achieving strong
generalization with fewer examples. Techniques like few-shot learning,
transfer learning, and foundation models show that high-capacity systems
can adapt with minimal new data if pretraining and priors are strong.

Comparison Table: Evolution of Data in AI

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1518}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3214}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2054}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3214}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Era
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Role of Data
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Systems
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Symbolic AI & Small, handcrafted knowledge bases & Expert systems
(MYCIN) & Brittle, limited coverage \\
Classical ML & Curated, labeled datasets & SVMs, decision trees &
Labor-intensive labeling \\
Deep Learning & Massive, web-scale corpora & GPT, ImageNet models &
Bias, cost, ethical concerns \\
Data-efficient AI & Few-shot, synthetic, curated signals & GPT-4,
diffusion models & Still dependent on pretraining scale \\
\end{longtable}

The trajectory suggests data will remain the cornerstone of AI, but the
focus is shifting. Rather than asking ``how much data,'' the key
questions become: ``what kind of data,'' ``how is it governed,'' and
``who controls it.''

\subsubsection{Tiny Code}\label{tiny-code-79}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simulating data efficiency: training on few vs many points}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}

\NormalTok{X\_many }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{],[}\DecValTok{4}\NormalTok{],[}\DecValTok{5}\NormalTok{]])}
\NormalTok{y\_many }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{]}

\NormalTok{X\_few }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{5}\NormalTok{]])}
\NormalTok{y\_few }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{]}

\NormalTok{model\_many }\OperatorTok{=}\NormalTok{ LogisticRegression().fit(X\_many,y\_many)}
\NormalTok{model\_few }\OperatorTok{=}\NormalTok{ LogisticRegression().fit(X\_few,y\_few)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Prediction with many samples (x=2):"}\NormalTok{, model\_many.predict([[}\DecValTok{2}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Prediction with few samples (x=2):"}\NormalTok{, model\_few.predict([[}\DecValTok{2}\NormalTok{]])[}\DecValTok{0}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-79}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Train on noisy data---does more always mean better?
\item
  Compare performance between curated small datasets and large but messy
  ones.
\item
  Reflect: is the future of AI about scaling data endlessly, or about
  making smarter use of less?
\end{enumerate}

\section{Chapter 9. Evaluation: Ground Truth, Metrics, and
Benchmark}\label{chapter-9.-evaluation-ground-truth-metrics-and-benchmark}

\subsection{81. Why evaluation is central to
AI}\label{why-evaluation-is-central-to-ai}

Evaluation is the compass of AI. Without it, we cannot tell whether a
system is learning, improving, or even functioning correctly. Evaluation
provides the benchmarks against which progress is measured, the feedback
loops that guide development, and the accountability that ensures trust.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-80}

Think of training for a marathon. Running every day without tracking
time or distance leaves you blind to improvement. Recording and
comparing results over weeks tells you whether you're faster, stronger,
or just running in circles. AI models, too, need evaluation to know if
they're moving closer to their goals.

\subsubsection{Deep Dive}\label{deep-dive-80}

Evaluation serves multiple roles in AI research and practice. At a
scientific level, it transforms intuition into measurable progress:
models can be compared, results replicated, and knowledge accumulated.
At an engineering level, it drives iteration: without clear metrics,
model improvements are indistinguishable from noise. At a societal
level, evaluation ensures systems meet standards of safety, fairness,
and usability.

The difficulty lies in defining ``success.'' For a translation system,
is success measured by BLEU score, human fluency ratings, or
communication effectiveness in real conversations? Each metric captures
part of the truth but not the whole. Overreliance on narrow metrics
risks overfitting to benchmarks while ignoring broader impacts.

Evaluation is also what separates research prototypes from deployed
systems. A model with 99\% accuracy in the lab may fail disastrously if
evaluated under real-world distribution shifts. Continuous evaluation is
therefore as important as one-off testing, ensuring robustness over
time.

Comparison Table: Roles of Evaluation

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1294}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4235}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4471}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Level
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Scientific & Measure progress, enable replication & Comparing algorithms
on ImageNet \\
Engineering & Guide iteration and debugging & Monitoring loss curves
during training \\
Societal & Ensure trust, safety, fairness & Auditing bias in hiring
algorithms \\
\end{longtable}

Evaluation is not just about accuracy but about defining values. What we
measure reflects what we consider important. If evaluation only tracks
efficiency, fairness may be ignored. If it only tracks benchmarks,
real-world usability may lag behind. Thus, designing evaluation
frameworks is as much a normative decision as a technical one.

\subsubsection{Tiny Code}\label{tiny-code-80}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple evaluation of a classifier}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ accuracy\_score}

\NormalTok{y\_true }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{]}
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{]}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Accuracy:"}\NormalTok{, accuracy\_score(y\_true, y\_pred))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-80}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add false positives or false negatives---does accuracy still reflect
  system quality?
\item
  Replace accuracy with precision/recall---what new insights appear?
\item
  Reflect: why does ``what we measure'' ultimately shape ``what we
  build'' in AI?
\end{enumerate}

\subsection{82. Ground truth: gold standards and
proxies}\label{ground-truth-gold-standards-and-proxies}

Evaluation in AI depends on comparing model outputs against a reference.
The most reliable reference is ground truth---the correct labels,
answers, or outcomes for each input. When true labels are unavailable,
researchers often rely on proxies, which approximate truth but may
introduce errors or biases.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-81}

Imagine grading math homework. If you have the official answer key, you
can check each solution precisely---that's ground truth. If the key is
missing, you might ask another student for their answer. It's quicker,
but you risk copying their mistakes---that's a proxy.

\subsubsection{Deep Dive}\label{deep-dive-81}

Ground truth provides the foundation for supervised learning and model
validation. In image recognition, it comes from labeled datasets where
humans annotate objects. In speech recognition, it comes from
transcripts aligned to audio. In medical AI, ground truth may be expert
diagnoses confirmed by follow-up tests.

However, obtaining ground truth is costly, slow, and sometimes
impossible. For example, in predicting long-term economic outcomes or
scientific discoveries, we cannot observe the ``true'' label in real
time. Proxies step in: click-through rates approximate relevance,
hospital readmission approximates health outcomes, human ratings
approximate translation quality.

The challenge is that proxies may diverge from actual goals. Optimizing
for clicks may produce clickbait, not relevance. Optimizing for
readmissions may ignore patient well-being. This disconnect is known as
the proxy problem, and it highlights the danger of equating
easy-to-measure signals with genuine ground truth.

Comparison Table: Ground Truth vs.~Proxies

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1481}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4198}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4321}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Ground Truth
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Proxies
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Accuracy & High fidelity, definitive & Approximate, error-prone \\
Cost & Expensive, labor-intensive & Cheap, scalable \\
Availability & Limited in scope, slow to collect & Widely available,
real-time \\
Risks & Narrow coverage & Misalignment, unintended incentives \\
Example & Radiologist-confirmed tumor labels & Hospital billing codes \\
\end{longtable}

Balancing truth and proxies is an ongoing struggle in AI. Gold standards
are needed for rigor but cannot scale indefinitely. Proxies allow rapid
iteration but risk misguiding optimization. Increasingly, hybrid
approaches are emerging---combining small high-quality ground truth
datasets with large proxy-driven datasets, often via semi-supervised or
self-supervised learning.

\subsubsection{Tiny Code}\label{tiny-code-81}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Comparing ground truth vs proxy evaluation}
\NormalTok{y\_true   }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{]  }\CommentTok{\# ground truth labels}
\NormalTok{y\_proxy  }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{]  }\CommentTok{\# proxy labels (noisy)}
\NormalTok{y\_pred   }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{]  }\CommentTok{\# model predictions}

\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ accuracy\_score}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Accuracy vs ground truth:"}\NormalTok{, accuracy\_score(y\_true, y\_pred))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Accuracy vs proxy:"}\NormalTok{, accuracy\_score(y\_proxy, y\_pred))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-81}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more noise to the proxy labels---how quickly does proxy accuracy
  diverge from true accuracy?
\item
  Combine ground truth with proxy labels---does this improve robustness?
\item
  Reflect: why does the choice of ground truth or proxy ultimately shape
  how AI systems behave in the real world?
\end{enumerate}

\subsection{83. Metrics for classification, regression,
ranking}\label{metrics-for-classification-regression-ranking}

Evaluation requires metrics---quantitative measures that capture how
well a model performs its task. Different tasks demand different
metrics: classification uses accuracy, precision, recall, and F1;
regression uses mean squared error or R²; ranking uses measures like
NDCG or MAP. Choosing the right metric ensures models are optimized for
what truly matters.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-82}

Think of judging a competition. A sprint race is scored by fastest time
(regression). A spelling bee is judged right or wrong (classification).
A search engine is ranked by how high relevant results appear (ranking).
The scoring rule changes with the task, just like metrics in AI.

\subsubsection{Deep Dive}\label{deep-dive-82}

In classification, the simplest metric is accuracy: the proportion of
correct predictions. But accuracy can be misleading when classes are
imbalanced. Precision measures the fraction of positive predictions that
are correct, recall measures the fraction of true positives identified,
and F1 balances the two.

In regression, metrics focus on error magnitude. Mean squared error
(MSE) penalizes large deviations heavily, while mean absolute error
(MAE) treats all errors equally. R² captures how much of the variance in
the target variable the model explains.

In ranking, the goal is ordering relevance. Metrics like Mean Average
Precision (MAP) evaluate precision across ranks, while Normalized
Discounted Cumulative Gain (NDCG) emphasizes highly ranked relevant
results. These are essential in information retrieval, recommendation,
and search engines.

The key insight is that metrics are not interchangeable. A fraud
detection system optimized for accuracy may ignore rare but costly fraud
cases, while optimizing for recall may catch more fraud but generate
false alarms. Choosing metrics means choosing trade-offs.

Comparison Table: Metrics Across Tasks

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2952}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5714}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Task
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Common Metrics
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
What They Emphasize
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Classification & Accuracy, Precision, Recall, F1 & Balance between
overall correctness and handling rare events \\
Regression & MSE, MAE, R² & Magnitude of prediction errors \\
Ranking & MAP, NDCG, Precision@k & Placement of relevant items at the
top \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-82}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ accuracy\_score, mean\_squared\_error}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ ndcg\_score}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Classification example}
\NormalTok{y\_true\_cls }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{]}
\NormalTok{y\_pred\_cls }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{]}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Classification accuracy:"}\NormalTok{, accuracy\_score(y\_true\_cls, y\_pred\_cls))}

\CommentTok{\# Regression example}
\NormalTok{y\_true\_reg }\OperatorTok{=}\NormalTok{ [}\FloatTok{2.5}\NormalTok{, }\FloatTok{0.0}\NormalTok{, }\FloatTok{2.1}\NormalTok{, }\FloatTok{7.8}\NormalTok{]}
\NormalTok{y\_pred\_reg }\OperatorTok{=}\NormalTok{ [}\FloatTok{3.0}\NormalTok{, }\OperatorTok{{-}}\FloatTok{0.5}\NormalTok{, }\FloatTok{2.0}\NormalTok{, }\FloatTok{7.5}\NormalTok{]}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Regression MSE:"}\NormalTok{, mean\_squared\_error(y\_true\_reg, y\_pred\_reg))}

\CommentTok{\# Ranking example}
\NormalTok{true\_relevance }\OperatorTok{=}\NormalTok{ np.asarray([[}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{]])}
\NormalTok{scores }\OperatorTok{=}\NormalTok{ np.asarray([[}\FloatTok{0.1}\NormalTok{,}\FloatTok{0.4}\NormalTok{,}\FloatTok{0.35}\NormalTok{]])}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Ranking NDCG:"}\NormalTok{, ndcg\_score(true\_relevance, scores))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-82}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more imbalanced classes to the classification task---does accuracy
  still tell the full story?
\item
  Compare MAE and MSE on regression---why does one penalize outliers
  more?
\item
  Change the ranking scores---does NDCG reward putting relevant items at
  the top?
\end{enumerate}

\subsection{84. Multi-objective and task-specific
metrics}\label{multi-objective-and-task-specific-metrics}

Real-world AI rarely optimizes for a single criterion. Multi-objective
metrics combine several goals---like accuracy and fairness, or speed and
energy efficiency---into evaluation. Task-specific metrics adapt general
principles to the nuances of a domain, ensuring that evaluation reflects
what truly matters in context.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-83}

Imagine judging a car. Speed alone doesn't decide the winner---safety,
fuel efficiency, and comfort also count. Similarly, an AI system must be
judged across multiple axes, not just one score.

\subsubsection{Deep Dive}\label{deep-dive-83}

Multi-objective metrics arise when competing priorities exist. For
example, in healthcare AI, sensitivity (catching every possible case)
must be balanced with specificity (avoiding false alarms). In
recommender systems, relevance must be balanced against diversity or
novelty. In robotics, task completion speed competes with energy
consumption and safety.

There are several ways to handle multiple objectives:

\begin{itemize}
\tightlist
\item
  Composite scores: weighted sums of different metrics.
\item
  Pareto analysis: evaluating trade-offs without collapsing into a
  single number.
\item
  Constraint-based metrics: optimizing one objective while enforcing
  thresholds on others.
\end{itemize}

Task-specific metrics tailor evaluation to the problem. In machine
translation, BLEU and METEOR attempt to measure linguistic quality. In
speech synthesis, MOS (Mean Opinion Score) reflects human perceptions of
naturalness. In medical imaging, Dice coefficient captures spatial
overlap between predicted and actual regions of interest.

The risk is that poorly chosen metrics incentivize undesirable
behavior---overfitting to leaderboards, optimizing proxies rather than
real goals, or ignoring hidden dimensions like fairness and usability.

Comparison Table: Multi-Objective and Task-Specific Metrics

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2111}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4222}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Context
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Multi-Objective Metric Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Task-Specific Metric Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Healthcare & Sensitivity + Specificity balance & Dice coefficient for
tumor detection \\
Recommender Systems & Relevance + Diversity & Novelty index \\
NLP & Fluency + Adequacy in translation & BLEU, METEOR \\
Robotics & Efficiency + Safety & Task completion time under
constraints \\
\end{longtable}

Evaluation frameworks increasingly adopt dashboard-style reporting
instead of single scores, showing trade-offs explicitly. This helps
researchers and practitioners make informed decisions aligned with
broader values.

\subsubsection{Tiny Code}\label{tiny-code-83}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Multi{-}objective evaluation: weighted score}
\NormalTok{precision }\OperatorTok{=} \FloatTok{0.8}
\NormalTok{recall }\OperatorTok{=} \FloatTok{0.6}

\CommentTok{\# Weighted composite: 70\% precision, 30\% recall}
\NormalTok{score }\OperatorTok{=} \FloatTok{0.7}\OperatorTok{*}\NormalTok{precision }\OperatorTok{+} \FloatTok{0.3}\OperatorTok{*}\NormalTok{recall}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Composite score:"}\NormalTok{, score)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-83}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Adjust weights between precision and recall---how does it change the
  ``best'' model?
\item
  Replace composite scoring with Pareto analysis---are some models
  incomparable?
\item
  Reflect: why is it dangerous to collapse complex goals into a single
  number?
\end{enumerate}

\subsection{85. Statistical significance and
confidence}\label{statistical-significance-and-confidence}

When comparing AI models, differences in performance may arise from
chance rather than genuine improvement. Statistical significance testing
and confidence intervals quantify how much trust we can place in
observed results. They separate real progress from random variation.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-84}

Think of flipping a coin 10 times and getting 7 heads. Is the coin
biased, or was it just luck? Without statistical tests, you can't be
sure. Evaluating AI models works the same way---apparent improvements
might be noise unless we test their reliability.

\subsubsection{Deep Dive}\label{deep-dive-84}

Statistical significance measures whether performance differences are
unlikely under a null hypothesis (e.g., two models are equally good).
Common tests include the t-test, chi-square test, and bootstrap
resampling.

Confidence intervals provide a range within which the true performance
likely lies, usually expressed at 95\% or 99\% levels. For example,
reporting accuracy as 92\% ± 2\% is more informative than a bare 92\%,
because it acknowledges uncertainty.

Significance and confidence are especially important when:

\begin{itemize}
\tightlist
\item
  Comparing models on small datasets.
\item
  Evaluating incremental improvements.
\item
  Benchmarking in competitions or leaderboards.
\end{itemize}

Without these safeguards, AI progress can be overstated. Many published
results that seemed promising later failed to replicate, fueling
concerns about reproducibility in machine learning.

Comparison Table: Accuracy vs.~Confidence

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2237}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2237}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5526}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Report Style
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Value
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Interpretation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Raw accuracy & 92\% & Single point estimate, no uncertainty \\
With confidence & 92\% ± 2\% (95\% CI) & True accuracy likely lies
between 90--94\% \\
Significance test & p \textless{} 0.05 & Less than 5\% chance result is
random noise \\
\end{longtable}

By treating evaluation statistically, AI systems are held to scientific
standards rather than marketing hype. This strengthens trust and helps
avoid chasing illusions of progress.

\subsubsection{Tiny Code}\label{tiny-code-84}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Bootstrap confidence interval for accuracy}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{y\_true }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{])}
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])}

\NormalTok{accuracy }\OperatorTok{=}\NormalTok{ np.mean(y\_true }\OperatorTok{==}\NormalTok{ y\_pred)}

\CommentTok{\# Bootstrap resampling}
\NormalTok{bootstraps }\OperatorTok{=} \DecValTok{1000}
\NormalTok{scores }\OperatorTok{=}\NormalTok{ []}
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.default\_rng(}\DecValTok{0}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(bootstraps):}
\NormalTok{    idx }\OperatorTok{=}\NormalTok{ rng.choice(}\BuiltInTok{len}\NormalTok{(y\_true), }\BuiltInTok{len}\NormalTok{(y\_true), replace}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    scores.append(np.mean(y\_true[idx] }\OperatorTok{==}\NormalTok{ y\_pred[idx]))}

\NormalTok{ci\_lower, ci\_upper }\OperatorTok{=}\NormalTok{ np.percentile(scores, [}\FloatTok{2.5}\NormalTok{,}\FloatTok{97.5}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Accuracy: }\SpecialCharTok{\{}\NormalTok{accuracy}\SpecialCharTok{:.2f\}}\SpecialStringTok{, 95\% CI: [}\SpecialCharTok{\{}\NormalTok{ci\_lower}\SpecialCharTok{:.2f\}}\SpecialStringTok{, }\SpecialCharTok{\{}\NormalTok{ci\_upper}\SpecialCharTok{:.2f\}}\SpecialStringTok{]"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-84}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Reduce the dataset size---how does the confidence interval widen?
\item
  Increase the number of bootstrap samples---does the CI stabilize?
\item
  Reflect: why should every AI claim of superiority come with
  uncertainty estimates?
\end{enumerate}

\subsection{86. Benchmarks and leaderboards in AI
research}\label{benchmarks-and-leaderboards-in-ai-research}

Benchmarks and leaderboards provide shared standards for evaluating AI.
A benchmark is a dataset or task that defines a common ground for
comparison. A leaderboard tracks performance on that benchmark, ranking
systems by their reported scores. Together, they drive competition,
progress, and sometimes over-optimization.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-85}

Think of a high-jump bar in athletics. Each athlete tries to clear the
same bar, and the scoreboard shows who jumped the highest. Benchmarks
are the bar, leaderboards are the scoreboard, and researchers are the
athletes.

\subsubsection{Deep Dive}\label{deep-dive-85}

Benchmarks like ImageNet for vision, GLUE for NLP, and Atari for
reinforcement learning have shaped entire subfields. They make progress
measurable, enabling fair comparisons across methods. Leaderboards add
visibility and competition, encouraging rapid iteration and innovation.

Yet this success comes with risks. Overfitting to benchmarks is common:
models achieve state-of-the-art scores but fail under real-world
conditions. Benchmarks may also encode biases, meaning leaderboard
``winners'' are not necessarily best for fairness, robustness, or
efficiency. Moreover, a focus on single numbers obscures trade-offs such
as interpretability, cost, or safety.

Comparison Table: Pros and Cons of Benchmarks

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Benefit & Risk \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Standardized evaluation & Narrow focus on specific tasks \\
Encourages reproducibility & Overfitting to test sets \\
Accelerates innovation & Ignores robustness and generality \\
Provides community reference & Creates leaderboard chasing culture \\
\end{longtable}

Benchmarks are evolving. Dynamic benchmarks (e.g., Dynabench)
continuously refresh data to resist overfitting. Multi-dimensional
leaderboards report robustness, efficiency, and fairness, not just raw
accuracy. The field is moving from static bars to richer ecosystems of
evaluation.

\subsubsection{Tiny Code}\label{tiny-code-85}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple leaderboard tracker}
\NormalTok{leaderboard }\OperatorTok{=}\NormalTok{ [}
\NormalTok{    \{}\StringTok{"model"}\NormalTok{: }\StringTok{"A"}\NormalTok{, }\StringTok{"score"}\NormalTok{: }\FloatTok{0.85}\NormalTok{\},}
\NormalTok{    \{}\StringTok{"model"}\NormalTok{: }\StringTok{"B"}\NormalTok{, }\StringTok{"score"}\NormalTok{: }\FloatTok{0.88}\NormalTok{\},}
\NormalTok{    \{}\StringTok{"model"}\NormalTok{: }\StringTok{"C"}\NormalTok{, }\StringTok{"score"}\NormalTok{: }\FloatTok{0.83}\NormalTok{\},}
\NormalTok{]}

\CommentTok{\# Rank models}
\NormalTok{ranked }\OperatorTok{=} \BuiltInTok{sorted}\NormalTok{(leaderboard, key}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ x: x[}\StringTok{"score"}\NormalTok{], reverse}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ i, entry }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(ranked, }\DecValTok{1}\NormalTok{):}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{i}\SpecialCharTok{\}}\SpecialStringTok{. }\SpecialCharTok{\{}\NormalTok{entry[}\StringTok{\textquotesingle{}model\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{ {-} }\SpecialCharTok{\{}\NormalTok{entry[}\StringTok{\textquotesingle{}score\textquotesingle{}}\NormalTok{]}\SpecialCharTok{:.2f\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-85}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add efficiency or fairness scores---does the leaderboard ranking
  change?
\item
  Simulate overfitting by artificially inflating one model's score.
\item
  Reflect: should leaderboards report a single ``winner,'' or a richer
  profile of performance dimensions?
\end{enumerate}

\subsection{87. Overfitting to benchmarks and Goodhart's
Law}\label{overfitting-to-benchmarks-and-goodharts-law}

Benchmarks are designed to measure progress, but when optimization
focuses narrowly on beating the benchmark, true progress may stall. This
phenomenon is captured by Goodhart's Law: \emph{``When a measure becomes
a target, it ceases to be a good measure.''} In AI, this means models
may excel on test sets while failing in the real world.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-86}

Imagine students trained only to pass practice exams. They memorize
patterns in past tests but struggle with new problems. Their scores
rise, but their true understanding does not. AI models can fall into the
same trap when benchmarks dominate training.

\subsubsection{Deep Dive}\label{deep-dive-86}

Overfitting to benchmarks happens in several ways. Models may exploit
spurious correlations in datasets, such as predicting ``snow'' whenever
``polar bear'' appears. Leaderboard competition can encourage marginal
improvements that exploit dataset quirks instead of advancing general
methods.

Goodhart's Law warns that once benchmarks become the primary target,
they lose their reliability as indicators of general capability. The
history of AI is filled with shifting benchmarks: chess, ImageNet,
GLUE---all once difficult, now routinely surpassed. Each success reveals
both the value and the limitation of benchmarks.

Mitigation strategies include:

\begin{itemize}
\tightlist
\item
  Rotating or refreshing benchmarks to prevent memorization.
\item
  Creating adversarial or dynamic test sets.
\item
  Reporting performance across multiple benchmarks and dimensions
  (robustness, efficiency, fairness).
\end{itemize}

Comparison Table: Healthy vs.~Unhealthy Benchmarking

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1771}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3646}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4583}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Benchmark Use
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Healthy Practice
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Unhealthy Practice
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Goal & Measure general progress & Chase leaderboard rankings \\
Model behavior & Robust improvements across settings & Overfitting to
dataset quirks \\
Community outcome & Innovation, transferable insights & Saturated
leaderboard with incremental gains \\
\end{longtable}

The key lesson is that benchmarks are tools, not goals. When treated as
ultimate targets, they distort incentives. When treated as indicators,
they guide meaningful progress.

\subsubsection{Tiny Code}\label{tiny-code-86}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simulating overfitting to a benchmark}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ accuracy\_score}

\CommentTok{\# Benchmark dataset (biased)}
\NormalTok{X\_train }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{]])}
\NormalTok{y\_train }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])  }\CommentTok{\# simple split}
\NormalTok{X\_test  }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{4}\NormalTok{],[}\DecValTok{5}\NormalTok{]])}
\NormalTok{y\_test  }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])}

\CommentTok{\# Model overfits quirks in train set}
\NormalTok{model }\OperatorTok{=}\NormalTok{ LogisticRegression().fit(X\_train, y\_train)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Train accuracy:"}\NormalTok{, accuracy\_score(y\_train, model.predict(X\_train)))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Test accuracy:"}\NormalTok{, accuracy\_score(y\_test, model.predict(X\_test)))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-86}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add noise to the test set---does performance collapse?
\item
  Train on a slightly different distribution---does the model still hold
  up?
\item
  Reflect: why does optimizing for benchmarks risk producing brittle AI
  systems?
\end{enumerate}

\subsection{88. Robust evaluation under distribution
shift}\label{robust-evaluation-under-distribution-shift}

AI systems are often trained and tested on neatly defined datasets. But
in deployment, the real world rarely matches the training distribution.
Distribution shift occurs when the data a model encounters differs from
the data it was trained on. Robust evaluation ensures performance is
measured not only in controlled settings but also under these shifts.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-87}

Think of a student who aces practice problems but struggles on the
actual exam because the questions are phrased differently. The knowledge
was too tuned to the practice set. AI models face the same problem when
real-world inputs deviate from the benchmark.

\subsubsection{Deep Dive}\label{deep-dive-87}

Distribution shifts appear in many forms:

\begin{itemize}
\tightlist
\item
  Covariate shift: input features change (e.g., new slang in language
  models).
\item
  Concept shift: the relationship between inputs and outputs changes
  (e.g., fraud patterns evolve).
\item
  Prior shift: class proportions change (e.g., rare diseases become more
  prevalent).
\end{itemize}

Evaluating robustness requires deliberately exposing models to such
changes. Approaches include stress-testing with out-of-distribution
data, synthetic perturbations, or domain transfer benchmarks. For
example, an image classifier trained on clean photos might be evaluated
on blurred or adversarially perturbed images.

Robust evaluation also considers worst-case performance. A model with
95\% accuracy on average may still fail catastrophically in certain
subgroups or environments. Reporting only aggregate scores hides these
vulnerabilities.

Comparison Table: Standard vs.~Robust Evaluation

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1485}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4257}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4257}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Standard Evaluation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Robust Evaluation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Data assumption & Train and test drawn from same distribution & Test
includes shifted or adversarial data \\
Metrics & Average accuracy or loss & Subgroup, stress-test, or
worst-case scores \\
Purpose & Validate in controlled conditions & Predict reliability in
deployment \\
Example & ImageNet test split & ImageNet-C (corruptions, noise, blur) \\
\end{longtable}

Robust evaluation is not only about detecting failure---it is about
anticipating environments where models will operate. For
mission-critical domains like healthcare or autonomous driving, this is
non-negotiable.

\subsubsection{Tiny Code}\label{tiny-code-87}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple robustness test: add noise to test data}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ accuracy\_score}

\CommentTok{\# Train on clean data}
\NormalTok{X\_train }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{]])}
\NormalTok{y\_train }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])}
\NormalTok{model }\OperatorTok{=}\NormalTok{ LogisticRegression().fit(X\_train, y\_train)}

\CommentTok{\# Test on clean vs shifted (noisy) data}
\NormalTok{X\_test\_clean }\OperatorTok{=}\NormalTok{ np.array([[}\FloatTok{1.1}\NormalTok{],[}\FloatTok{2.9}\NormalTok{]])}
\NormalTok{y\_test }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{])}

\NormalTok{X\_test\_shifted }\OperatorTok{=}\NormalTok{ X\_test\_clean }\OperatorTok{+}\NormalTok{ np.random.normal(}\DecValTok{0}\NormalTok{,}\FloatTok{0.5}\NormalTok{,(}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Accuracy (clean):"}\NormalTok{, accuracy\_score(y\_test, model.predict(X\_test\_clean)))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Accuracy (shifted):"}\NormalTok{, accuracy\_score(y\_test, model.predict(X\_test\_shifted)))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-87}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase the noise level---at what point does performance collapse?
\item
  Train on a larger dataset---does robustness improve naturally?
\item
  Reflect: why is robustness more important than peak accuracy for
  real-world AI?
\end{enumerate}

\subsection{89. Beyond accuracy: fairness, interpretability,
efficiency}\label{beyond-accuracy-fairness-interpretability-efficiency}

Accuracy alone is not enough to judge an AI system. Real-world
deployment demands broader evaluation criteria: fairness to ensure
equitable treatment, interpretability to provide human understanding,
and efficiency to guarantee scalability and sustainability. Together,
these dimensions extend evaluation beyond raw predictive power.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-88}

Imagine buying a car. Speed alone doesn't make it good---you also care
about safety, fuel efficiency, and ease of maintenance. Similarly, an AI
model can't be judged only by accuracy; it must also be fair,
understandable, and efficient to be trusted.

\subsubsection{Deep Dive}\label{deep-dive-88}

Fairness addresses disparities in outcomes across groups. A hiring
algorithm may achieve high accuracy overall but discriminate against
women or minorities. Fairness metrics include demographic parity,
equalized odds, and subgroup accuracy.

Interpretability ensures models are not black boxes. Humans need
explanations to build trust, debug errors, and comply with regulation.
Techniques include feature importance, local explanations (LIME, SHAP),
and inherently interpretable models like decision trees.

Efficiency considers the cost of deploying AI at scale. Large models may
be accurate but consume prohibitive energy, memory, or latency.
Evaluation includes FLOPs, inference time, and energy per prediction.
Efficiency matters especially for edge devices and climate-conscious
computing.

Comparison Table: Dimensions of Evaluation

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1818}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3750}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4432}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Question
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Metric
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Accuracy & Does it make correct predictions? & Error rate, F1 score \\
Fairness & Are outcomes equitable? & Demographic parity, subgroup
error \\
Interpretability & Can humans understand decisions? & Feature
attribution, transparency score \\
Efficiency & Can it run at scale sustainably? & FLOPs, latency, energy
per query \\
\end{longtable}

Balancing these metrics is challenging because improvements in one
dimension can hurt another. Pruning a model may improve efficiency but
reduce interpretability. Optimizing fairness may slightly reduce
accuracy. The art of evaluation lies in balancing competing values
according to context.

\subsubsection{Tiny Code}\label{tiny-code-88}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simple fairness check: subgroup accuracy}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ accuracy\_score}

\CommentTok{\# Predictions across two groups}
\NormalTok{y\_true }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{])}
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])}
\NormalTok{groups }\OperatorTok{=}\NormalTok{ np.array([}\StringTok{"A"}\NormalTok{,}\StringTok{"A"}\NormalTok{,}\StringTok{"B"}\NormalTok{,}\StringTok{"B"}\NormalTok{,}\StringTok{"B"}\NormalTok{,}\StringTok{"A"}\NormalTok{])}

\ControlFlowTok{for}\NormalTok{ g }\KeywordTok{in}\NormalTok{ np.unique(groups):}
\NormalTok{    idx }\OperatorTok{=}\NormalTok{ groups }\OperatorTok{==}\NormalTok{ g}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Group }\SpecialCharTok{\{}\NormalTok{g}\SpecialCharTok{\}}\SpecialStringTok{ accuracy:"}\NormalTok{, accuracy\_score(y\_true[idx], y\_pred[idx]))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-88}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Adjust predictions to make one group perform worse---how does fairness
  change?
\item
  Add runtime measurement to compare efficiency across models.
\item
  Reflect: should accuracy ever outweigh fairness or efficiency, or must
  evaluation always be multi-dimensional?
\end{enumerate}

\subsection{90. Building better evaluation
ecosystems}\label{building-better-evaluation-ecosystems}

An evaluation ecosystem goes beyond single datasets or metrics. It is a
structured environment where benchmarks, tools, protocols, and community
practices interact to ensure that AI systems are tested thoroughly,
fairly, and continuously. A healthy ecosystem enables sustained progress
rather than short-term leaderboard chasing.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-89}

Think of public health. One thermometer reading doesn't describe a
population's health. Instead, ecosystems of hospitals, labs, surveys,
and monitoring systems track multiple indicators over time. In AI,
evaluation ecosystems serve the same role---providing many complementary
views of model quality.

\subsubsection{Deep Dive}\label{deep-dive-89}

Traditional evaluation relies on static test sets and narrow metrics.
But modern AI operates in dynamic, high-stakes environments where
robustness, fairness, efficiency, and safety all matter. Building a true
ecosystem involves several layers:

\begin{itemize}
\tightlist
\item
  Diverse benchmarks: covering multiple domains, tasks, and
  distributions.
\item
  Standardized protocols: ensuring experiments are reproducible across
  labs.
\item
  Multi-dimensional reporting: capturing accuracy, robustness,
  interpretability, fairness, and energy use.
\item
  Continuous evaluation: monitoring models post-deployment as data
  drifts.
\item
  Community governance: open platforms, shared resources, and watchdogs
  against misuse.
\end{itemize}

Emerging efforts like Dynabench (dynamic data collection), HELM
(holistic evaluation of language models), and BIG-bench (broad
generalization testing) show how ecosystems can move beyond
single-number leaderboards.

Comparison Table: Traditional vs.~Ecosystem Evaluation

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1266}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3291}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5443}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Traditional Evaluation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Evaluation Ecosystem
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Benchmarks & Single static dataset & Multiple, dynamic, domain-spanning
datasets \\
Metrics & Accuracy or task-specific & Multi-dimensional dashboards \\
Scope & Pre-deployment only & Lifecycle-wide, including
post-deployment \\
Governance & Isolated labs or companies & Community-driven, transparent
practices \\
\end{longtable}

Ecosystems also encourage responsibility. By highlighting fairness gaps,
robustness failures, or energy costs, they force AI development to align
with broader societal goals. Without them, progress risks being measured
narrowly and misleadingly.

\subsubsection{Tiny Code}\label{tiny-code-89}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example: evaluation dashboard across metrics}
\NormalTok{results }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"accuracy"}\NormalTok{: }\FloatTok{0.92}\NormalTok{,}
    \StringTok{"robustness"}\NormalTok{: }\FloatTok{0.75}\NormalTok{,}
    \StringTok{"fairness"}\NormalTok{: }\FloatTok{0.80}\NormalTok{,}
    \StringTok{"efficiency"}\NormalTok{: }\StringTok{"120 ms/query"}
\NormalTok{\}}

\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ results.items():}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{.}\NormalTok{capitalize()}\SpecialCharTok{:\textless{}12\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{v}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-89}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add more dimensions (interpretability, cost)---how does the picture
  change?
\item
  Compare two models across all metrics---does the ``winner'' differ
  depending on which metric you value most?
\item
  Reflect: why does the future of AI evaluation depend on ecosystems,
  not isolated benchmarks?
\end{enumerate}

\section{Chapter 10. Reproductivity, tooling, and the scientific
method}\label{chapter-10.-reproductivity-tooling-and-the-scientific-method}

\subsection{91. The role of reproducibility in
science}\label{the-role-of-reproducibility-in-science}

Reproducibility is the backbone of science. In AI, it means that
experiments, once published, can be independently repeated with the same
methods and yield consistent results. Without reproducibility, research
findings are fragile, progress is unreliable, and trust in the field
erodes.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-90}

Imagine a recipe book where half the dishes cannot be recreated because
the instructions are vague or missing. The meals may have looked
delicious once, but no one else can cook them again. AI papers without
reproducibility are like such recipes---impressive claims, but
irreproducible outcomes.

\subsubsection{Deep Dive}\label{deep-dive-90}

Reproducibility requires clarity in three areas:

\begin{itemize}
\tightlist
\item
  Code and algorithms: precise implementation details, hyperparameters,
  and random seeds.
\item
  Data and preprocessing: availability of datasets, splits, and cleaning
  procedures.
\item
  Experimental setup: hardware, software libraries, versions, and
  training schedules.
\end{itemize}

Failures of reproducibility have plagued AI. Small variations in
preprocessing can change benchmark rankings. Proprietary datasets make
replication impossible. Differences in GPU types or software libraries
can alter results subtly but significantly.

The reproducibility crisis is not unique to AI---it mirrors issues in
psychology, medicine, and other sciences. But AI faces unique challenges
due to computational scale and reliance on proprietary resources.
Addressing these challenges involves open-source code release, dataset
sharing, standardized evaluation protocols, and stronger incentives for
replication studies.

Comparison Table: Reproducible vs.~Non-Reproducible Research

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1889}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3889}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4222}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Reproducible Research
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Non-Reproducible Research
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Code availability & Public, with instructions & Proprietary, incomplete,
or absent \\
Dataset access & Open, with documented preprocessing & Private,
undocumented, or changing \\
Results & Consistent across labs & Dependent on hidden variables \\
Community impact & Trustworthy, cumulative progress & Fragile, hard to
verify, wasted effort \\
\end{longtable}

Ultimately, reproducibility is not just about science---it is about
ethics. Deployed AI systems that cannot be reproduced cannot be audited
for safety, fairness, or reliability.

\subsubsection{Tiny Code}\label{tiny-code-90}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Ensuring reproducibility with fixed random seeds}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{np.random.seed(}\DecValTok{42}\NormalTok{)}
\NormalTok{data }\OperatorTok{=}\NormalTok{ np.random.rand(}\DecValTok{5}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Deterministic random data:"}\NormalTok{, data)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-90}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the random seed---how do results differ?
\item
  Run the same experiment on different hardware---does reproducibility
  hold?
\item
  Reflect: should conferences and journals enforce reproducibility as
  strictly as novelty?
\end{enumerate}

\subsection{92. Versioning of code, data, and
experiments}\label{versioning-of-code-data-and-experiments}

AI research and deployment involve constant iteration.
Versioning---tracking changes to code, data, and experiments---ensures
results can be reproduced, compared, and rolled back when needed.
Without versioning, AI projects devolve into chaos, where no one can
tell which model, dataset, or configuration produced a given result.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-91}

Imagine writing a book without saving drafts. If an editor asks about an
earlier version, you can't reconstruct it. In AI, every experiment is a
draft; versioning is the act of saving each one with context, so future
readers---or your future self---can trace the path.

\subsubsection{Deep Dive}\label{deep-dive-91}

Traditional software engineering relies on version control systems like
Git. In AI, the complexity multiplies:

\begin{itemize}
\tightlist
\item
  Code versioning tracks algorithm changes, hyperparameters, and
  pipelines.
\item
  Data versioning ensures the training and test sets used are
  identifiable and reproducible, even as datasets evolve.
\item
  Experiment versioning records outputs, logs, metrics, and random
  seeds, making it possible to compare experiments meaningfully.
\end{itemize}

Modern tools like DVC (Data Version Control), MLflow, and Weights \&
Biases extend Git-like practices to data and model artifacts. They
enable teams to ask: \emph{Which dataset version trained this model?
Which code commit and parameters led to the reported accuracy?}

Without versioning, reproducibility fails and deployment risk rises.
Bugs reappear, models drift without traceability, and research claims
cannot be verified. With versioning, AI development becomes a
cumulative, auditable process.

Comparison Table: Versioning Needs in AI

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1294}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4118}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4588}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Element
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Why It Matters
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Practice
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Code & Reproduce algorithms and parameters & Git commits, containerized
environments \\
Data & Ensure same inputs across reruns & DVC, dataset hashes, storage
snapshots \\
Experiments & Compare and track progress & MLflow logs, W\&B experiment
tracking \\
\end{longtable}

Versioning also supports collaboration. Teams spread across
organizations can reproduce results without guesswork, enabling science
and engineering to scale.

\subsubsection{Tiny Code}\label{tiny-code-91}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example: simple experiment versioning with hashes}
\ImportTok{import}\NormalTok{ hashlib}
\ImportTok{import}\NormalTok{ json}

\NormalTok{experiment }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"model"}\NormalTok{: }\StringTok{"logistic\_regression"}\NormalTok{,}
    \StringTok{"params"}\NormalTok{: \{}\StringTok{"lr"}\NormalTok{:}\FloatTok{0.01}\NormalTok{, }\StringTok{"epochs"}\NormalTok{:}\DecValTok{100}\NormalTok{\},}
    \StringTok{"data\_version"}\NormalTok{: }\StringTok{"hash1234"}
\NormalTok{\}}

\NormalTok{experiment\_id }\OperatorTok{=}\NormalTok{ hashlib.md5(json.dumps(experiment).encode()).hexdigest()}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Experiment ID:"}\NormalTok{, experiment\_id)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-91}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Change the learning rate---does the experiment ID change?
\item
  Add a new data version---how does it affect reproducibility?
\item
  Reflect: why is versioning essential not only for research
  reproducibility but also for regulatory compliance in deployed AI?
\end{enumerate}

\subsection{93. Tooling: notebooks, frameworks,
pipelines}\label{tooling-notebooks-frameworks-pipelines}

AI development depends heavily on the tools researchers and engineers
use. Notebooks provide interactive experimentation, frameworks offer
reusable building blocks, and pipelines organize workflows into
reproducible stages. Together, they shape how ideas move from concept to
deployment.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-92}

Think of building a house. Sketches on paper resemble notebooks: quick,
flexible, exploratory. Prefabricated materials are like frameworks:
ready-to-use components that save effort. Construction pipelines
coordinate the sequence---laying the foundation, raising walls,
installing wiring---into a complete structure. AI engineering works the
same way.

\subsubsection{Deep Dive}\label{deep-dive-92}

\begin{itemize}
\tightlist
\item
  Notebooks (e.g., Jupyter, Colab) are invaluable for prototyping,
  visualization, and teaching. They allow rapid iteration but can
  encourage messy, non-reproducible practices if not disciplined.
\item
  Frameworks (e.g., PyTorch, TensorFlow, scikit-learn) provide
  abstractions for model design, training loops, and optimization. They
  accelerate development but may introduce lock-in or complexity.
\item
  Pipelines (e.g., Kubeflow, Airflow, Metaflow) formalize data
  preparation, training, evaluation, and deployment into modular steps.
  They make experiments repeatable at scale, enabling collaboration
  across teams.
\end{itemize}

Each tool has strengths and trade-offs. Notebooks excel at exploration
but falter at production. Frameworks lower barriers to sophisticated
models but can obscure inner workings. Pipelines enforce rigor but may
slow early experimentation. The art lies in combining them to fit the
maturity of a project.

Comparison Table: Notebooks, Frameworks, Pipelines

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0781}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2969}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3203}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3047}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Tool Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strengths
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Weaknesses
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Notebooks & Interactive, visual, fast prototyping & Hard to reproduce,
version control issues & Teaching, exploratory analysis \\
Frameworks & Robust abstractions, community support & Complexity,
potential lock-in & Training deep learning models \\
Pipelines & Scalable, reproducible, collaborative & Setup overhead, less
flexibility & Enterprise ML deployment, model serving \\
\end{longtable}

Modern AI workflows typically blend these: a researcher prototypes in
notebooks, formalizes the model in a framework, and engineers deploy it
via pipelines. Without this chain, insights often die in notebooks or
fail in production.

\subsubsection{Tiny Code}\label{tiny-code-92}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example: simple pipeline step simulation}
\KeywordTok{def}\NormalTok{ load\_data():}
    \ControlFlowTok{return}\NormalTok{ [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{]}

\KeywordTok{def}\NormalTok{ train\_model(data):}
    \ControlFlowTok{return} \BuiltInTok{sum}\NormalTok{(data) }\OperatorTok{/} \BuiltInTok{len}\NormalTok{(data)  }\CommentTok{\# dummy "model"}

\KeywordTok{def}\NormalTok{ evaluate\_model(model):}
    \ControlFlowTok{return} \SpecialStringTok{f"Model value: }\SpecialCharTok{\{}\NormalTok{model}\SpecialCharTok{:.2f\}}\SpecialStringTok{"}

\CommentTok{\# Pipeline}
\NormalTok{data }\OperatorTok{=}\NormalTok{ load\_data()}
\NormalTok{model }\OperatorTok{=}\NormalTok{ train\_model(data)}
\BuiltInTok{print}\NormalTok{(evaluate\_model(model))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-92}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add another pipeline step---like data cleaning---does it make the
  process clearer?
\item
  Replace the dummy model with a scikit-learn classifier---can you track
  inputs/outputs?
\item
  Reflect: why do tools matter as much as algorithms in shaping the
  progress of AI?
\end{enumerate}

\subsection{94. Collaboration, documentation, and
transparency}\label{collaboration-documentation-and-transparency}

AI is rarely built alone. Collaboration enables teams of researchers and
engineers to combine expertise. Documentation ensures that ideas, data,
and methods are clear and reusable. Transparency makes models
understandable to both colleagues and the broader community. Together,
these practices turn isolated experiments into collective progress.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-93}

Imagine a relay race where each runner drops the baton without labeling
it. The team cannot finish the race because no one knows what's been
done. In AI, undocumented or opaque work is like a dropped
baton---progress stalls.

\subsubsection{Deep Dive}\label{deep-dive-93}

Collaboration in AI spans interdisciplinary teams: computer scientists,
domain experts, ethicists, and product managers. Without shared
understanding, efforts fragment. Version control platforms (GitHub,
GitLab) and experiment trackers (MLflow, W\&B) provide the
infrastructure, but human practices matter as much as tools.

Documentation ensures reproducibility and knowledge transfer. It
includes clear READMEs, code comments, data dictionaries, and experiment
logs. Models without documentation risk being ``black boxes'' even to
their creators months later.

Transparency extends documentation to accountability. Open-sourcing code
and data, publishing detailed methodology, and explaining limitations
prevent hype and misuse. Transparency also enables external audits for
fairness and safety.

Comparison Table: Collaboration, Documentation, Transparency

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1327}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4286}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4388}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Practice
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Implementation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Collaboration & Pool expertise, divide tasks & Shared repos, code
reviews, project boards \\
Documentation & Preserve knowledge, ensure reproducibility & README
files, experiment logs, data schemas \\
Transparency & Build trust, enable accountability & Open-source
releases, model cards, audits \\
\end{longtable}

Without these practices, AI progress becomes fragile---dependent on
individuals, lost in silos, and vulnerable to errors. With them,
progress compounds and can be trusted by both peers and the public.

\subsubsection{Tiny Code}\label{tiny-code-93}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example: simple documentation as metadata}
\NormalTok{model\_card }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"name"}\NormalTok{: }\StringTok{"Spam Classifier v1.0"}\NormalTok{,}
    \StringTok{"authors"}\NormalTok{: [}\StringTok{"Team A"}\NormalTok{],}
    \StringTok{"dataset"}\NormalTok{: }\StringTok{"Email dataset v2 (cleaned, deduplicated)"}\NormalTok{,}
    \StringTok{"metrics"}\NormalTok{: \{}\StringTok{"accuracy"}\NormalTok{: }\FloatTok{0.95}\NormalTok{, }\StringTok{"f1"}\NormalTok{: }\FloatTok{0.92}\NormalTok{\},}
    \StringTok{"limitations"}\NormalTok{: }\StringTok{"Fails on short informal messages"}
\NormalTok{\}}

\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ model\_card.items():}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{v}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-93}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add fairness metrics or energy usage to the model card---how does it
  change transparency?
\item
  Imagine a teammate taking over your project---would your documentation
  be enough?
\item
  Reflect: why does transparency matter not only for science but also
  for public trust in AI?
\end{enumerate}

\subsection{95. Statistical rigor and replication
studies}\label{statistical-rigor-and-replication-studies}

Scientific claims in AI require statistical rigor---careful design of
experiments, proper use of significance tests, and honest reporting of
uncertainty. Replication studies, where independent teams attempt to
reproduce results, provide the ultimate check. Together, they protect
the field from hype and fragile conclusions.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-94}

Think of building a bridge. It's not enough that one engineer's design
holds during their test. Independent inspectors must verify the
calculations and confirm the bridge can withstand real conditions. In
AI, replication serves the same role---ensuring results are not
accidents of chance or selective reporting.

\subsubsection{Deep Dive}\label{deep-dive-94}

Statistical rigor starts with designing fair comparisons: training
models under the same conditions, reporting variance across multiple
runs, and avoiding cherry-picking of best results. It also requires
appropriate statistical tests to judge whether performance differences
are meaningful rather than noise.

Replication studies extend this by testing results independently,
sometimes under new conditions. Successful replication strengthens
trust; failures highlight hidden assumptions or weak methodology.
Unfortunately, replication is undervalued in AI---top venues reward
novelty over verification, leading to a reproducibility gap.

The lack of rigor has consequences: flashy papers that collapse under
scrutiny, wasted effort chasing irreproducible results, and erosion of
public trust. A shift toward valuing replication, preregistration, and
transparent reporting would align AI more closely with scientific norms.

Comparison Table: Statistical Rigor vs.~Replication

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1414}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4343}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4242}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Statistical Rigor
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Replication Studies
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Focus & Correct design and reporting of experiments & Independent
verification of findings \\
Responsibility & Original researchers & External researchers \\
Benefit & Prevents overstated claims & Confirms robustness, builds
trust \\
Challenge & Requires discipline and education & Often unrewarded, costly
in time/resources \\
\end{longtable}

Replication is not merely checking math---it is part of the culture of
accountability. Without it, AI risks becoming an arms race of unverified
claims. With it, the field can build cumulative, durable knowledge.

\subsubsection{Tiny Code}\label{tiny-code-94}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Demonstrating variance across runs}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ accuracy\_score}

\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{],[}\DecValTok{4}\NormalTok{],[}\DecValTok{5}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])}

\NormalTok{scores }\OperatorTok{=}\NormalTok{ []}
\ControlFlowTok{for}\NormalTok{ seed }\KeywordTok{in}\NormalTok{ [}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{]:}
\NormalTok{    model }\OperatorTok{=}\NormalTok{ LogisticRegression(random\_state}\OperatorTok{=}\NormalTok{seed, max\_iter}\OperatorTok{=}\DecValTok{500}\NormalTok{).fit(X,y)}
\NormalTok{    scores.append(accuracy\_score(y, model.predict(X)))}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Accuracy across runs:"}\NormalTok{, scores)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Mean ± Std:"}\NormalTok{, np.mean(scores), }\StringTok{"±"}\NormalTok{, np.std(scores))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-94}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase the dataset noise---does variance between runs grow?
\item
  Try different random seeds---do conclusions still hold?
\item
  Reflect: should AI conferences reward replication studies as highly as
  novel results?
\end{enumerate}

\subsection{96. Open science, preprints, and publishing
norms}\label{open-science-preprints-and-publishing-norms}

AI research moves at a rapid pace, and the way results are shared shapes
the field. Open science emphasizes transparency and accessibility.
Preprints accelerate dissemination outside traditional journals.
Publishing norms guide how credit, peer review, and standards of
evidence are maintained. Together, they determine how knowledge spreads
and how trustworthy it is.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-95}

Imagine a library where only a few people can check out books, and the
rest must wait years. Contrast that with an open archive where anyone
can read the latest manuscripts immediately. The second library looks
like modern AI: preprints on arXiv and open code releases fueling fast
progress.

\subsubsection{Deep Dive}\label{deep-dive-95}

Open science in AI includes open datasets, open-source software, and
public sharing of results. This democratizes access, enabling small labs
and independent researchers to contribute alongside large institutions.
Preprints, typically on platforms like arXiv, bypass slow journal cycles
and allow rapid community feedback.

However, preprints also challenge traditional norms: they lack formal
peer review, raising concerns about reliability and hype. Publishing
norms attempt to balance speed with rigor. Conferences and journals
increasingly require code and data release, reproducibility checklists,
and clearer reporting standards.

The culture of AI publishing is shifting: from closed corporate secrecy
to open competitions; from novelty-only acceptance criteria to valuing
robustness and ethics; from slow cycles to real-time global
collaboration. But tensions remain between openness and
commercialization, between rapid sharing and careful vetting.

Comparison Table: Traditional vs.~Open Publishing

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1519}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3797}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4684}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Traditional Publishing
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Open Science \& Preprints
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Access & Paywalled journals & Free, open archives and datasets \\
Speed & Slow peer review cycle & Immediate dissemination via
preprints \\
Verification & Peer review before publication & Community feedback,
post-publication \\
Risks & Limited reach, exclusivity & Hype, lack of quality control \\
\end{longtable}

Ultimately, publishing norms reflect values. Do we value rapid
innovation, broad access, and transparency? Or do we prioritize rigorous
filtering, stability, and prestige? The healthiest ecosystem blends
both, creating space for speed without abandoning trust.

\subsubsection{Tiny Code}\label{tiny-code-95}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example: metadata for an "open science" AI paper}
\NormalTok{paper }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"title"}\NormalTok{: }\StringTok{"Efficient Transformers with Sparse Attention"}\NormalTok{,}
    \StringTok{"authors"}\NormalTok{: [}\StringTok{"A. Researcher"}\NormalTok{, }\StringTok{"B. Scientist"}\NormalTok{],}
    \StringTok{"venue"}\NormalTok{: }\StringTok{"arXiv preprint 2509.12345"}\NormalTok{,}
    \StringTok{"code"}\NormalTok{: }\StringTok{"https://github.com/example/sparse{-}transformers"}\NormalTok{,}
    \StringTok{"data"}\NormalTok{: }\StringTok{"Open dataset: WikiText{-}103"}\NormalTok{,}
    \StringTok{"license"}\NormalTok{: }\StringTok{"CC{-}BY 4.0"}
\NormalTok{\}}

\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ paper.items():}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{v}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-95}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add peer review metadata (accepted at NeurIPS, ICML)---how does
  credibility change?
\item
  Imagine this paper was closed-source---what opportunities would be
  lost?
\item
  Reflect: should open science be mandatory for publicly funded AI
  research?
\end{enumerate}

\subsection{97. Negative results and failure
reporting}\label{negative-results-and-failure-reporting}

Science advances not only through successes but also through
understanding failures. In AI, negative results---experiments that do
not confirm hypotheses or fail to improve performance---are rarely
reported. Yet documenting them prevents wasted effort, reveals hidden
challenges, and strengthens the scientific method.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-96}

Imagine a map where only successful paths are drawn. Explorers who
follow it may walk into dead ends again and again. A more useful map
includes both the routes that lead to treasure and those that led
nowhere. AI research needs such maps.

\subsubsection{Deep Dive}\label{deep-dive-96}

Negative results in AI often remain hidden in lab notebooks or private
repositories. Reasons include publication bias toward positive outcomes,
competitive pressure, and the cultural view that failure signals
weakness. This creates a distorted picture of progress, where flashy
results dominate while important lessons from failures are lost.

Examples of valuable negative results include:

\begin{itemize}
\tightlist
\item
  Novel architectures that fail to outperform baselines.
\item
  Promising ideas that do not scale or generalize.
\item
  Benchmark shortcuts that looked strong but collapsed under adversarial
  testing.
\end{itemize}

Reporting such outcomes saves others from repeating mistakes, highlights
boundary conditions, and encourages more realistic expectations.
Journals and conferences have begun to acknowledge this, with workshops
on reproducibility and negative results.

Comparison Table: Positive vs.~Negative Results in AI

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1648}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3846}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4505}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Positive Results
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Negative Results
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Visibility & Widely published, cited & Rarely published, often hidden \\
Contribution & Shows what works & Shows what does not work and why \\
Risk if missing & Field advances quickly but narrowly & Field repeats
mistakes, distorts progress \\
Example & New model beats SOTA on ImageNet & Variant fails despite
theoretical promise \\
\end{longtable}

By embracing negative results, AI can mature as a science. Failures
highlight assumptions, expose limits of generalization, and set
realistic baselines. Normalizing failure reporting reduces hype cycles
and fosters collective learning.

\subsubsection{Tiny Code}\label{tiny-code-96}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simulating a "negative result"}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}
\ImportTok{from}\NormalTok{ sklearn.svm }\ImportTok{import}\NormalTok{ SVC}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ accuracy\_score}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# Tiny dataset}
\NormalTok{X }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{0}\NormalTok{],[}\DecValTok{1}\NormalTok{],[}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{]])}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])}

\NormalTok{log\_reg }\OperatorTok{=}\NormalTok{ LogisticRegression().fit(X,y)}
\NormalTok{svm }\OperatorTok{=}\NormalTok{ SVC(kernel}\OperatorTok{=}\StringTok{"poly"}\NormalTok{, degree}\OperatorTok{=}\DecValTok{5}\NormalTok{).fit(X,y)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"LogReg accuracy:"}\NormalTok{, accuracy\_score(y, log\_reg.predict(X)))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"SVM (degree 5) accuracy:"}\NormalTok{, accuracy\_score(y, svm.predict(X)))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-96}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increase dataset size---does the ``negative'' SVM result persist?
\item
  Document why the complex model failed compared to the simple baseline.
\item
  Reflect: how would AI research change if publishing failures were as
  valued as publishing successes?
\end{enumerate}

\subsection{98. Benchmark reproducibility crises in
AI}\label{benchmark-reproducibility-crises-in-ai}

Many AI breakthroughs are judged by performance on benchmarks. But if
those results cannot be reliably reproduced, the benchmark itself
becomes unstable. The benchmark reproducibility crisis occurs when
published results are hard---or impossible---to replicate due to hidden
randomness, undocumented preprocessing, or unreleased data.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-97}

Think of a scoreboard where athletes' times are recorded, but no one
knows the track length, timing method, or even if the stopwatch worked.
The scores look impressive but cannot be trusted. Benchmarks in AI face
the same problem when reproducibility is weak.

\subsubsection{Deep Dive}\label{deep-dive-97}

Benchmark reproducibility failures arise from multiple factors:

\begin{itemize}
\tightlist
\item
  Data leakage: overlaps between training and test sets inflate results.
\item
  Unreleased datasets: claims cannot be independently verified.
\item
  Opaque preprocessing: small changes in tokenization, normalization, or
  image resizing alter scores.
\item
  Non-deterministic training: results vary across runs but only the best
  is reported.
\item
  Hardware/software drift: different GPUs, libraries, or seeds produce
  inconsistent outcomes.
\end{itemize}

The crisis undermines both research credibility and industrial
deployment. A model that beats ImageNet by 1\% but cannot be reproduced
is scientifically meaningless. Worse, models trained with leaky or
biased benchmarks may propagate errors into downstream applications.

Efforts to address this include reproducibility checklists at
conferences (NeurIPS, ICML), model cards and data sheets, open-source
implementations, and rigorous cross-lab verification. Dynamic benchmarks
that refresh test sets (e.g., Dynabench) also help prevent overfitting
and silent leakage.

Comparison Table: Stable vs.~Fragile Benchmarks

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2048}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4096}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3855}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stable Benchmark
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Fragile Benchmark
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Data availability & Public, with documented splits & Private or
inconsistently shared \\
Evaluation & Deterministic, standardized code & Ad hoc, variable
implementations \\
Reporting & Averages, with variance reported & Single best run
highlighted \\
Trust level & High, supports cumulative progress & Low, progress is
illusory \\
\end{longtable}

Benchmark reproducibility is not a technical nuisance---it is central to
AI as a science. Without stable, transparent benchmarks, leaderboards
risk becoming marketing tools rather than genuine measures of
advancement.

\subsubsection{Tiny Code}\label{tiny-code-97}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Demonstrating non{-}determinism}
\ImportTok{import}\NormalTok{ torch}
\ImportTok{import}\NormalTok{ torch.nn }\ImportTok{as}\NormalTok{ nn}

\NormalTok{torch.manual\_seed(}\DecValTok{0}\NormalTok{)   }\CommentTok{\# fix seed for reproducibility}

\CommentTok{\# Simple model}
\NormalTok{model }\OperatorTok{=}\NormalTok{ nn.Linear(}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\NormalTok{x }\OperatorTok{=}\NormalTok{ torch.randn(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Output with fixed seed:"}\NormalTok{, model(x))}

\CommentTok{\# Remove the fixed seed and rerun to see variability}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-97}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Train the same model twice without fixing the seed---do results
  differ?
\item
  Change preprocessing slightly (e.g., normalize inputs
  differently)---does accuracy shift?
\item
  Reflect: why does benchmark reproducibility matter more as AI models
  scale to billions of parameters?
\end{enumerate}

\subsection{99. Community practices for
reliability}\label{community-practices-for-reliability}

AI is not only shaped by algorithms and datasets but also by the
community practices that govern how research is conducted and shared.
Reliability emerges when researchers adopt shared norms: transparent
reporting, open resources, peer verification, and responsible
competition. Without these practices, progress risks being fragmented,
fragile, and untrustworthy.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-98}

Imagine a neighborhood where everyone builds their own houses without
common codes---some collapse, others block sunlight, and many hide
dangerous flaws. Now imagine the same neighborhood with shared building
standards, inspections, and cooperation. AI research benefits from
similar community standards to ensure safety and reliability.

\subsubsection{Deep Dive}\label{deep-dive-98}

Community practices for reliability include:

\begin{itemize}
\tightlist
\item
  Reproducibility checklists: conferences like NeurIPS now require
  authors to document datasets, hyperparameters, and code.
\item
  Open-source culture: sharing code, pretrained models, and datasets
  allows peers to verify claims.
\item
  Independent replication: labs repeating and auditing results before
  deployment.
\item
  Responsible benchmarking: resisting leaderboard obsession, reporting
  multiple dimensions (robustness, fairness, energy use).
\item
  Collaborative governance: initiatives like MLCommons or Hugging Face
  Datasets maintain shared standards and evaluation tools.
\end{itemize}

These practices counterbalance pressures for speed and novelty. They
help transform AI into a cumulative science, where progress builds on a
solid base rather than hype cycles.

Comparison Table: Weak vs.~Strong Community Practices

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1979}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3854}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4167}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Weak Practice
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strong Practice
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Code/Data Sharing & Closed, proprietary & Open repositories with
documentation \\
Reporting Standards & Selective metrics, cherry-picked runs & Full
transparency, including variance \\
Benchmarking & Single leaderboard focus & Multi-metric, multi-benchmark
evaluation \\
Replication Culture & Rare, undervalued & Incentivized, publicly
recognized \\
\end{longtable}

Community norms are cultural infrastructure. Just as the internet grew
by adopting protocols and standards, AI can achieve reliability by
aligning on transparent and responsible practices.

\subsubsection{Tiny Code}\label{tiny-code-98}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example: adding reproducibility info to experiment logs}
\NormalTok{experiment\_log }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"model"}\NormalTok{: }\StringTok{"Transformer{-}small"}\NormalTok{,}
    \StringTok{"dataset"}\NormalTok{: }\StringTok{"WikiText{-}103 (v2.1)"}\NormalTok{,}
    \StringTok{"accuracy"}\NormalTok{: }\FloatTok{0.87}\NormalTok{,}
    \StringTok{"std\_dev"}\NormalTok{: }\FloatTok{0.01}\NormalTok{,}
    \StringTok{"seed"}\NormalTok{: }\DecValTok{42}\NormalTok{,}
    \StringTok{"code\_repo"}\NormalTok{: }\StringTok{"https://github.com/example/research{-}code"}
\NormalTok{\}}

\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ experiment\_log.items():}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{v}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-98}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add fairness or energy-use metrics to the log---does it give a fuller
  picture?
\item
  Imagine a peer trying to replicate your result---what extra details
  would they need?
\item
  Reflect: why do cultural norms matter as much as technical advances in
  building reliable AI?
\end{enumerate}

\subsection{100. Towards a mature scientific culture in
AI}\label{towards-a-mature-scientific-culture-in-ai}

AI is transitioning from a frontier discipline to a mature science. This
shift requires not only technical breakthroughs but also a scientific
culture rooted in rigor, openness, and accountability. A mature culture
balances innovation with verification, excitement with caution, and
competition with collaboration.

\subsubsection{Picture in Your Head}\label{picture-in-your-head-99}

Think of medicine centuries ago: discoveries were dramatic but often
anecdotal, inconsistent, and dangerous. Over time, medicine built
standardized trials, ethical review boards, and professional norms. AI
is undergoing a similar journey---moving from dazzling demonstrations to
systematic, reliable science.

\subsubsection{Deep Dive}\label{deep-dive-99}

A mature scientific culture in AI demands several elements:

\begin{itemize}
\tightlist
\item
  Rigor: experiments designed with controls, baselines, and statistical
  validity.
\item
  Openness: datasets, code, and results shared for verification.
\item
  Ethics: systems evaluated not only for performance but also for
  fairness, safety, and societal impact.
\item
  Long-term perspective: research valued for durability, not just
  leaderboard scores.
\item
  Community institutions: conferences, journals, and collaborations that
  enforce standards and support replication.
\end{itemize}

The challenge is cultural. Incentives in academia and industry still
reward novelty and speed over reliability. Shifting this balance means
rethinking publication criteria, funding priorities, and corporate
secrecy. It also requires education: training new researchers to see
reproducibility and transparency as virtues, not burdens.

Comparison Table: Frontier vs.~Mature Scientific Culture

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2024}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3690}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4286}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Frontier AI Culture
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Mature AI Culture
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Research Goals & Novelty, demos, rapid iteration & Robustness,
cumulative knowledge \\
Publication Norms & Leaderboards, flashy results & Replication,
long-term benchmarks \\
Collaboration & Competitive secrecy & Shared standards, open
collaboration \\
Ethical Lens & Secondary, reactive & Central, proactive \\
\end{longtable}

This cultural transformation will not be instant. But just as physics or
biology matured through shared norms, AI too can evolve into a
discipline where progress is durable, reproducible, and aligned with
human values.

\subsubsection{Tiny Code}\label{tiny-code-99}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example: logging scientific culture dimensions for a project}
\NormalTok{project\_culture }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"rigor"}\NormalTok{: }\StringTok{"Statistical tests + multiple baselines"}\NormalTok{,}
    \StringTok{"openness"}\NormalTok{: }\StringTok{"Code + dataset released"}\NormalTok{,}
    \StringTok{"ethics"}\NormalTok{: }\StringTok{"Bias audit + safety review"}\NormalTok{,}
    \StringTok{"long\_term"}\NormalTok{: }\StringTok{"Evaluation across 3 benchmarks"}\NormalTok{,}
    \StringTok{"community"}\NormalTok{: }\StringTok{"Replication study submitted"}
\NormalTok{\}}

\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ project\_culture.items():}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{.}\NormalTok{capitalize()}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{v}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Try It Yourself}\label{try-it-yourself-99}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add missing cultural elements---what would strengthen the project's
  reliability?
\item
  Imagine incentives flipped: replication papers get more citations than
  novelty---how would AI research change?
\item
  Reflect: what does it take for AI to be remembered not just for its
  breakthroughs, but for its scientific discipline?
\end{enumerate}




\end{document}
